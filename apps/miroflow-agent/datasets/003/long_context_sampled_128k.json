[
  {
    "title": "多模态标注：跨模态智能的数据基石与技术实践​-网易伏羲",
    "page_body": "多模态标注：跨模态智能的数据基石与技术实践​ ​\n多模态标注作为人工智能数据工程的核心环节，正成为推动跨模态智能发展的关键支撑。这项技术通过同步处理图像、文本、音频、视频等多种类型的数据，建立模态间的语义关联与对齐关系，为机器学习模型提供丰富的跨模态训练数据。随着多模态大模型与跨模态应用的快速发展，多模态标注的重要性日益凸显，其质量直接决定了模型对复杂现实世界的理解能力。本文将系统解析多模态标注的技术原理、应用场景、实施策略与发展趋势。\n​ ​一、多模态标注的核心价值与体系架构​ ​\n多模态标注旨在解决异构数据间的语义对齐问题，其核心价值体现在三方面：一是通过跨模态关联增强模型的环境理解能力，使机器能够像人类一样综合多种信息进行决策；二是提升模型的数据利用效率，充分利用不同模态数据的互补性；三是推动新兴跨模态应用的发展，如视觉问答、音频描述、多模态搜索等。多模态标注体系采用分层架构，包括数据层、标注层和应用层。数据层负责多模态数据的采集与预处理，确保数据质量与同步性；标注层通过人工与智能结合的方式实现跨模态语义关联；应用层将标注数据用于模型训练与优化，形成闭环迭代机制。\n​ ​二、技术原理与标注方法​ ​\n多模态标注的技术核心是建立模态间的语义映射关系。时序对齐是基础挑战，尤其针对音频-视频数据，需精确到帧级别的同步，常用动态时间规整算法实现音画同步。空间对齐针对视觉-文本数据，通过目标检测与语义分割确定图像区域与文本描述的对应关系，常用边界框标注与图像描述生成。语义对齐是更高层次的要求，需要理解不同模态数据的深层语义关联，如将“欢快音乐”与“阳光海滩场景”建立情感层面的对应。\n主流标注方法包括并行标注、序列标注和交互标注。并行标注同时处理多种模态数据，保证标注过程的一致性；序列标注按模态顺序进行，后一阶段标注依赖前一阶段结果；交互标注采用多轮迭代方式，逐步细化标注质量。质量评估采用多维度指标，包括对齐精度、语义一致性和标注完整性，确保标注数据满足模型训练要求。\n​ ​三、应用场景与行业实践​ ​\n智能医疗是多模态标注的重要应用领域。医学影像与诊断报告的跨模态标注帮助模型理解影像特征与文本描述的关联，如CT影像中的结节与报告中的“边缘模糊”描述对应。病理切片与临床数据的多模态分析助力精准诊断，通过标注建立细胞形态与疾病分型的映射关系。手术视频与器械音频的同步标注用于智能手术辅助系统，实时识别手术步骤与器械使用情况。\n智能交通领域依赖多模态标注提升环境感知能力。车载摄像头、激光雷达与GPS数据的融合标注构建高精度环境模型，标注数据包括车辆轨迹、障碍物类型与道路拓扑关系。驾驶行为分析通过标注驾驶员视频、车辆数据与路况信息，识别疲劳驾驶与危险操作。交通监控系统中，视频流与音频事件的关联标注用于事故检测与应急响应。\n教育科技应用多模态标注增强学习体验。教学视频与讲稿文本的同步标注实现智能知识点提取，学生可通过多模态搜索快速定位内容。在线教育平台利用语音-手势-课件内容的关联标注，构建沉浸式互动学习环境。学习行为分析通过标注学生视频、作业文本与测评数据，提供个性化学习建议。\n​ ​四、标注工具与平台支持​ ​\n专业多模态标注平台需支持复杂的数据管理与协同功能。数据管理模块处理多模态数据的存储、版本控制与检索，支持常见格式如图像（JPG、PNG）、视频（MP4、AVI）、音频（WAV、MP3）和文本（TXT、JSON）。标注工具提供多视图同步编辑能力，如视频帧与音频波形的联动标注，图像区域与文本标签的关联标注。协同标注功能支持多人同时标注同一项目，通过权限管理与工作流引擎确保标注效率。\n智能辅助工具大幅提升标注效率。预标注算法利用已有模型生成初始标注结果，标注员主要进行修正与验证。自动对齐工具通过特征匹配实现跨模态数据的初步对齐，减少人工操作。质量检查工具自动检测标注矛盾与错误，如时空不对齐、语义不一致等问题。数据分析仪表盘可视化标注进度、质量指标与一致性统计，帮助项目管理。\n​ ​五、技术挑战与解决方案​ ​\n模态差异是多模态标注的首要挑战。不同模态的数据特征、采样率与表示形式存在显著差异，解决方案包括统一表征学习与跨模态编码，将异构数据映射到共同语义空间。标注一致性难以保证，特别是多人协作项目，需通过标准化标注规范、详细指南与定期培训统一标注标准。计算复杂度高，处理多模态数据需要大量存储与计算资源，采用分布式计算与增量处理技术降低开销。\n语义鸿沟问题体现在不同模态间的语义表达差异，如图像中的“红色圆形”与文本中的“停止标志”的对应关系。解决方案包括构建多模态知识图谱，建立细粒度语义关联。标注成本高昂是多模态标注的普遍问题，特别是需要领域专家的场景，主动学习与半自动标注可减少人工标注量。时效性要求高的应用需要快速标注流程，流式标注与实时质检技术可加速标注过程。\n​ ​六、标准化与质量控制​ ​\n多模态标注标准化是保障数据质量的关键。数据格式标准统一不同模态数据的存储与交换格式，如采用JSON-LD表示跨模态关联。标注规范明确定义标签体系、对齐要求与质量指标，确保不同项目的标注结果可比。接口标准规范标注工具与平台的数据输入输出格式，促进工具 interoperability。评估标准建立多模态标注的质量度量体系，包括对齐精度、语义一致性与时序同步性等维度。\n质量控制需贯穿标注全流程。前期准备阶段需制定详细的标注指南与样例，进行标注人员培训。标注实施阶段采用多人独立标注与交叉验证，定期进行一致性检查。后期验收阶段通过抽样审计与专家复核确保标注质量。持续改进阶段收集模型反馈，修正标注难点与模糊案例，形成闭环优化。\n​ ​七、未来发展趋势​ ​\n多模态标注正向智能化、自动化方向发展。智能标注工具集成更强大的预标注模型，减少人工操作；自动对齐算法提升跨模态数据的匹配精度；智能质检工具实时检测标注错误。实时标注能力增强，支持流式数据标注与在线学习，满足实时应用需求。联邦标注利用分布式数据资源，在保护隐私的前提下实现多机构协同标注。\n跨模态大模型推动标注范式变革。基础大模型通过少量样本学习新任务，降低对标注数据的依赖；生成式模型合成高质量标注数据，解决数据稀缺问题；自监督学习利用未标注数据预训练，减少人工标注量。标准化与开放生态促进发展，行业标准统一数据格式与接口；开源工具降低技术使用门槛；开放数据集推动学术与工业界合作。\n​ ​八、行业影响与价值​ ​\n多模态标注推动人工智能向更高水平发展。训练数据质量提升直接提高模型性能，使多模态模型更准确理解复杂场景；新兴应用场景得以实现，如跨模态检索、多模态生成等；研发效率提高，减少数据准备时间与成本。产业升级方面，制造业利用多模态数据优化生产流程，实现智能质检与预测性维护；医疗行业借助多模态分析提升诊断准确性，推动精准医疗发展；教育领域通过多模态交互改善学习效果，实现个性化教学。\n技术普惠价值显著，多模态技术使AI系统更贴近人类自然交互方式，降低使用门槛；跨模态能力帮助特殊群体（如视障人士）更好地获取信息；开放工具与数据集促进技术民主化，使更多组织能够开发多模态应用。这些影响推动多模态标注成为人工智能发展的重要基础设施，为构建更智能、更人性化的AI系统奠定基础。\n多模态标注作为连接原始数据与智能应用的关键桥梁，其技术进步与应用深化正推动人工智能向多模态理解迈进。通过持续的技术创新与生态建设，多模态标注将为人工智能发展提供更丰富、更高质量的数据燃料，赋能更多跨模态应用场景，最终实现机器对现实世界的深度理解与智能交互。"
  },
  {
    "title": "当见未萌｜高度警惕AGI挑战，构建新型人机和谐关系",
    "page_body": "·大规模生成式语言模型为代表的通用人工智能技术，以生成式AI为主要形态，具备情景化生成能力，形成了知识、能力、价值三个阶段的智能炼就路径。随着相关技术的发展，机器的智能水平快速提升，将带来人机边界模糊及与其相关的一系列社会问题。\n·AGI的发展路径具有“填鸭灌输”式学习、“先通再专”等特点，在一定程度上颠覆了人类对机器智能实现路径的传统认识，倒逼人类在世界建模、知识获取、自我认知等层面进行反思。人类需高度警醒AGI带来的挑战，并积极抓住其带来的机遇，推动构建新型的人机和谐关系。\n两千多年前，苏格拉底说“认识你自己”，今天在AGI技术发展的倒逼下，人类需要“重新认识你自己”。\n自2022年12月ChatGPT发布以来，大规模生成式预训练语言模型（Generative Language Model）在学术界与工业界引起轩然大波，带动了一系列通用人工智能技术（AGI: Artificial General Intelligence）的快速发展，包括图文生成模型，如Midjourney的高精度、高度仿真的图文生成；具身多模态语言模型，比如谷歌（Google）公司连续推出PaLM-E以及PaLM 2等。AGI已经从模拟人类大脑的思维能力（以语言模型为代表），快速演进至“操控身体”的具身模型（以具身大模型为代表）。AGI全面侵袭从艺术创作到代码生成、从问题求解到科学发现、从问答聊天到辅助决策等人类智能的各个领地，人类智能所能涉及的领域几乎都有AGI的踪迹。一场由AGI带动的新一轮信息技术革命已然席卷而至。人类迎来一场有关“智能”本身的技术革命。\n作为一种先进的生产力，AGI既给全社会带来令人兴奋的机遇，也带来令人担忧的挑战。兴奋与担忧归根结底是源于我们对AGI的理解还远远跟不上其发展速度。具体而言，人类对于AGI技术原理、智能形态、能力上限的思考，对其对社会与个人影响的评估，明显滞后于AGI的发展速度。可以说，快速发展的AGI与人类对其认知的显著滞后构成了一对鲜明的矛盾，把握这一矛盾是理解当前AGI发展规律与其产生的社会影响的关键。也正是基于对上述矛盾的认识，不少科学家与AI企业领袖发出了暂停巨型大模型实验的呼声，呼吁加快安全可证明的AI系统的研制。\n诚然，理解AGI十分困难。AGI这个术语中的三个单词，分别从不同角度表达了理解AGI面临的挑战。从其核心词“智能（Intelligence）”来看，一直以来关于什么是智能，就存在不同的观点，比如传统计算机科学认为，“获取以及应用知识与技能”的能力是智能，但需思考这个定义是否仍然适用于今天以大规模生成式语言模型为代表的AGI。“通用（General）”一词加剧了理解AGI的困难。相对于传统的面向特定（specific）功能的AI，AGI旨在模拟人类的心智能力，人类智能的独特之处鲜明地体现在其能够针对不同环境作出适应性调整，能够胜任不同类型甚至从未见过的任务。专用AI与通用AI存在怎样的联系与区别，是先实现通用AI还是先实现专用AI？General一词将会引发很多诸如此类的思考。“人工的（Artificial）”一词则道出了AGI人工创造物的本质，而非自发从自然环境中进化而成的智能。这自然就提出了工具智能与自然智能的异同等一系列问题。\n尽管挑战重重，本文仍然尝试针对AGI的某些方面展开分析。本文聚焦于生成式人工智能，特别是大规模生成式语言模型为代表的通用人工智能技术。本文所谈及的“智能”，不局限于人类智能，也包括机器智能，将以机器智能与人类智能作为彼此的参照，进行对比分析。本文将对由生成式语言模型发展而引发的“智能”的内涵、“智能”的演进路径等问题进行详细分析，并在这一基础上反思人类智能的诸多方面，包括创造性、世界建模、知识获取、自我认知等。笔者相信本文的思考一方面可以消除人们对于机器智能快速进步的担忧，另一方面也能为机器智能的进一步发展扫除障碍，有助于建立新型的人机和谐关系。在此需要说明的是，本文的部分思考与结论超出了当前的工程实践所能检验的范围，仍需要付诸严格论证与实践检验。\n什么是智能？ChatGPT何以成功？\n生成式VS判别式 。ChatGPT是生成式人工智能的代表。生成式AI在文本生成、文图生成、图像生成等领域取得了较好的效果。传统的人工智能多属于判别式人工智能。为何是生成式AI而非判别式AI成为AGI的主要形态？这是一个值得深思的问题。判别式AI，通过标注数据的训练，引导模型习得正确给出问题答案的能力。生成式AI，往往针对无标注数据设计基于遮蔽内容还原的自监督学习任务进行训练，引导模型生成符合上下文语境的内容。生成式模型不仅具备生成结果的能力，也能够生成过程与解释。所以生成任务可以视作比判别任务更具智力挑战性的任务，能够有效引导模型习得高水平智能。具体而言，对于判断题，判别式AI只需给出对或错的答案，即便随机猜测，仍然有百分之五十蒙对的概率。但是，生成式AI不仅需要生成答案，还可能需要同时生成解题过程，这就很难蒙混过关。所以相对于判别而言，生成可以说是更加接近智能本质的一类任务。\n智能与情景化生成能力。 智能的本质是什么？大模型的发展给人类对这一问题的思考带来了很多新的启发。大模型的智能本质上是情景化生成（Contextualized Generation）能力，也就是根据上下文提示（Prompt）生成相关文本的能力。所以大模型的应用效果在一定程度上取决于提示有效与否。如果我们能够给出一个有效且合理的提示，那么ChatGPT这类大模型往往能够生成令人满意的答案。这种情景化生成能力（“提示＋生成”的能力）不仅适用于文本，也广泛适用于图像、语音、蛋白质序列等各种不同类型的复杂数据。不同的数据上下文不同，例如对于图片而言，其上下文是周边图像。大模型的情景化生成能力是通过训练阶段的上下文学习（In-context learning）而形成的。从数学本质来讲，大模型在训练阶段习得了Token或者语料基本单元之间的联合概率分布。情景化生成可以视作条件概率估算，即给定上下文或提示（也就是给出证据），根据联合分布推断出现剩余文本的概率。\n传统对于智能的理解多少都与“知识”有关（如把智能定义为“知识的发现和应用能力”），或与人有关（如把智能定义为“像人一样思考和行为的能力”），其本质还是以人类为中心，从认识论视角理解智能。大模型所呈现出的这种情景化生成能力，则无关乎“知识”，“知识”说到底是人类为了理解世界所做出的人为发明。世界的存在不依赖“知识”，不依赖人类，情景化生成摆脱了人类所定义的“知识”，回归世界本身——只要能合理生成这个世界就是智能。智能被还原为一种生成能力，这种智能可以不以人类为中心，也可以不依赖人类的文明，这是AGI给我们带来的重要启示。\n智能的分析与还原。 大模型训练与优化过程能够为我们更好地理解智能的形成过程提供有益启发。通用大模型的“出炉”基本上要经历三个阶段：第一个阶段是底座大模型的训练；第二个阶段是面向任务的指令学习，也就是所谓的指令微调；第三个阶段是价值对齐。第一个阶段底座大模型的训练本质上是让大模型习得语料或者数据所蕴含的知识。但是这里的知识是一种参数化、概率化的知识（本质上建模了语料中词汇之间的一种联合分布），使得情境化生成成为可能。因此，第一阶段的本质是知识获取（或者说知识习得），第二阶段指令学习旨在让大模型习得完成任务的能力，最后一个阶段则是价值观念的习得。\n大模型的智能被分解为知识、能力与价值三个阶段，这是个值得关注的特性。知识是能力与价值的基础，所以底座模型的“炼制”尤为关键。ChatGPT经历了2018年初版GPT-1到2022年GPT-3.5近四年的训练与优化。大模型的知识底座越深厚、越广博，后续能够习得的技能就越复杂、越多样，价值判断就越准确、价值对齐就越敏捷。大模型将智能的三个核心要素相互剥离，而人类的知识、能力与价值习得，往往是杂揉在一起的。我们很难界定小学课本中的某篇文章是在传授知识、训练技能亦或是在塑造价值。大模型的这种分离式的智能发展，可以类比于人类社会的高等教育。人类社会的本科教育旨在培养学习能力以获取知识，硕士教育旨在培养解题能力以解决问题，博士教育则旨在培养价值判断能力以发现问题。\n知识、能力和价值相剥离对于未来智能系统架构、建立新型的人机协作关系、设计人机混合的智能系统架构均有着积极的启发意义。随着机器智能的逐步发展，人类相对于机器而言所擅长的事物将会逐渐减少。但是，在某些特定场景仍存在一些人类介入的空间。未来人机混合系统发展的关键仍是回答什么工作最值得由人来完成。看似完整的任务只有经过分解，才能拆解出人机各自擅长与适合的子任务。例如，将知识和能力剥离对于保护私域知识极具价值：大模型负责语言理解等核心任务，而机密的数据与知识仍然交由传统的数据库或者知识库来管理。这样的系统架构，既充分利用了大模型的核心能力，又充分兼顾了知识私密性。\n智能测试与人机区分。 通用人工智能技术的发展显著提升了机器的智能水平，特别是语言理解水平，机器在文本处理、语言理解等相关任务中已达到普通人类甚至语言专家的水平。而随之而来的一个十分关键的问题是：人机边界日益模糊。我们已经很难仅仅通过几轮对话去判断窗口背后与你交流的是人还是机器。换言之，传统的图灵测试已经难以胜任人机区分的使命。使用过ChatGPT的人都深有体会，ChatGPT最擅长的就是聊天，即便与其长时间聊天，我们可能都不会觉得无趣。\n人机边界的模糊会带来很多社会问题。首先，普通民众，尤其是青少年，可能出于对技术的信任而沉溺于ChatGPT类的对话模型中。当ChatGPT日益智能，我们习惯了向其提问，习惯了接受它的答案，久而久之，人类赖以发展的质疑精神就会逐步丧失。在日益强大的AGI面前，如何避免人的精神本质的退化？这些问题需要我们严肃思考并回答。其次，当人机真假难辨，虚假信息泛滥，欺诈将会层出不穷。最近越来越多犯罪分子已经通过AI换脸、AI视频生成，成功实施了多起欺诈案件。如何治理由人机边界模糊带来的社会性欺骗将成为一个十分重要的AI治理问题。最后，还值得注意的是验证码，这一我们在日常生活中广泛使用，却很快会变成问题的应用。验证码是我们进行人机区分的利器，但是随着AGI的发展，尤其是在其对于各类工具的操控能力日益增强之后，验证码所具备的人机区分功能将会面临日益严峻的挑战。随着人形机器人技术的日益成熟，未来如何证明你是人而非机器，或者反之，如何证明机器是机器而不是人将会成为越来越困难的问题。\n人机边界的模糊本质上归结于人机智能"
  },
  {
    "title": "智谱成都人工智能大模型产业交流会在成都高新区举行_高新要闻_成都高新区管理委员会",
    "page_body": "11月29日，智谱成都人工智能大模型产业交流会在成都高新区天府软件园举行。\n北京智谱华章科技有限公司（以下简称“智谱”）成立于2019年，公司致力于通过大模型链接物理世界的亿级用户，为千行百业带来持续创新与变革，加速迈向通用人工智能的时代。目前，智谱开源模型系列全球累计下载量超过2000万，并入选Hugging Face平台最受欢迎人工智能机构。智谱获得了ACM SIGKDD时间检验奖、国家科学技术奖（二等奖）和人工智能学会科技进步一等奖，同时入选TechCrunch评选的全球15家新晋AI独角兽Unicorn Board榜单（国内唯一入选），福布斯中国创新力企业50强。\n成都高新区数字经济局相关负责人表示，近年来，成都高新区与智谱在人工智能产业领域的合作不断加深，本次交流活动将进一步加深智谱与成都本地企业的交流与合作，立足天府软件园加快推动人工智能产业集聚。\n本次产业交流会上，智谱总裁王绍兰现场对最新一代AutoGLM及CogAgent产品进行了讲解。王绍兰提到：“成都是智谱第一个在总部以外举办发布及交流活动的城市，成都是对智谱有着重要意义的一个城市。希望通过本次交流会进一步加深智谱与成都的联系，进一步促进智谱与成都企业的蓬勃发展，非常期待智谱在成都的AI之旅”。\n会后，王绍兰与四川移动、成都移动、通威集团、考拉悠然、茶百道、多牛集团、旺小宝等多位企业代表交流畅谈未来合作与发展。\n作为成都建设国家新一代人工智能创新发展试验区、国家人工智能创新应用先导区，成都高新区已聚集300余家人工智能相关企业；通过备案的大模型算法数量60个；预计到2026年，建成全国人工智能产业发展主阵地、国产多元异构算力生态高地、全国“人工智能+”解决方案输出地。\n在成都高新区已发布的“数字经济26条”中，特别提出围绕“增强人工智能大模型开放创新”，鼓励企业开展多模态通用大模型研发并向中小企业开放模型应用，对参数量超过千亿，且性能达到国内领先的通用大模型，按照模型研发成本的30%，给予牵头研制企业最高3000万元的补助；支持企业开发人工智能专用模型，每年评选不超过10个性能先进并在成都高新区成功落地的优秀专用模型，按照模型研发成本的30%，给予牵头研制企业最高300万元的补助，每个企业每年不超过1000万元。\n成都高新区相关负责人表示，智谱作为国内基座大模型及AIGC模型及产品矩阵的龙头企业，已与成都市及成都高新区各类企业建立了紧密合作关系。下一步，将持续与智谱对接并探讨产业发展及合作，不断促进智谱与本地企业联动。充分发挥人工智能链主企业和“镇园之宝”产品的带动作用，加快人工智能创新技术与优质资源整合，建设人工智能专业化、特色化园区，吸引上下游企业集聚发展、推动“立园满园”，以一流营商环境助力企业持续发展，高标准打造人工智能创新生态和产业生态。"
  },
  {
    "title": "AI应用大盘点：谁暴涨？谁掉队？机器人|app|mau|kimi|ai应用|智能助手_网易订阅",
    "page_body": "2025年第一季度，AI应用赛道迎来爆发式增长。\n第三方机构QuestMobile显示，截至2025年2月，AI原生App活跃用户数达2.4亿，比1月规模几近翻倍。这场热潮的引爆点，源自人工智能公司深度求索年初发布的DeepSeek-R1推理模型引发的现象级传播。\n到了3月初，被称为全球首款通用型AI Agent产品的Manus亮相，再次引发市场期待。虽然Manus还处在内测阶段，但由于用户过于热情，邀请码在二手平台上炒到了上万元。\n这场狂欢，不仅点燃资本市场热情，更催生出“AI应用元年”的行业共识。那么问题来了，到底谁是今年Q1全球最火AI应用？一定程度上，这一答案不仅代表着AI应用领域的未来发展方向，也影响着大公司格局，甚至还藏着下一个AI独角兽。\n对此，作者选取了市面上几家热门的AI榜单，分别是AI产品榜、Xsignal、AIGCRank、新榜，综合了月活（MAU）、日活（DAU）、下载量三个比较重要的维度，以及从业者的观点，梳理出1-3月全球AI应用的前二十及国内前十，有了以下发现：\n目前市面上的AI应用榜单比较杂乱，各家的数据来源、排名维度、统计结果有很大不同，需要综合多个榜单才能得出较为全面的结论；\n整体来看，AI头部应用相对稳定，前四位被ChatGPT、夸克、豆包、DeepSeek占据；\n国内AI应用的影响力越来越大，全球AI应用的前二十里，中外应用占比基本各一半；\nAI应用的市场欢迎度有着明显的类型划分：聊天机器人>AI伴侣>AI修图>AI办公>AI视频；\nAI应用排名并不仅仅关乎技术，和营销能力、功能集成等也有关。\n01 五花八门的AI榜单，想要看懂不容易\n想给AI应用排名，参考哪些维度、各维度的重要性如何，是需要事先明确的问题。但我们参考多份榜单后发现了一个令人困惑的现象：同一款应用在不同榜单中的排名可能天差地别。\n这种混乱主要源于两个核心问题。\n首先，各榜单的排名逻辑很不一样。\n作者发现，一部分榜单会选择将同一应用的APP端和Web端数据放在一起，从而得出排名，有的则分成APP榜、Web榜两个榜单进行统计；排名的参考维度也各不相同，主要分月活（AI产品榜、Xsignal）、日活（AIGCRank）、下载量（新榜）等等，有的榜单会选取其中两三个参考维度，有的只采用某一个。\n其次，即便是同一款APP的同一维度，各榜单给出的数据也差别很大。\n图源 / Unsplash\n比如AI产品榜和Xsignal都主要参考月活数量给AI应用排名，但两家关于每一APP的数据都不相同。以DeepSeek的APP端为例，AI产品榜显示其2月MAU为6181万，而Xsignal为14550.77万。\n一位资深数据从业者告诉作者，这主要是因为各家的数据来源存在差异。他介绍，市面上的AI榜单数据来源可大致分为两种，一种是自己监测，这类公司自身多为数据监测公司，AI火了后便开发出了AI应用的相关榜单，另一种则是自身没有数据基因，通过第三方平台购买数据，然后自己总结出榜单。\n第三方购买便导致很多数据来源并非一手，也无法评估数据的可靠性。这位从业者还表示，AI行业很新，不同数据监测公司对AI应用的测算也没摸索出一套比较成熟的计算体系，会导致数据出现差异。\n另一位榜单从业者也坦言，他们是从第三方数据公司购买AI应用的相关数据，在整理过程中发现各家的数据差异很大，导致挑选数据维度纠结了很久。综合考量后，他们最终没有依据市面上常用的月活维度，而是换成了以日活维度来排名。\n不过，尽管存在一些差异，综合多位数据从业者的说法，行业内部已形成基本共识：在众多数据维度中，重要性排名为 月活>日活>下载量>其他。\n“如果某一应用在不同榜单中的排名都十分靠前，基本可以判断其表现不错。”一位从业者表示。至于具体数据的差异，从业者建议不必过度深究，更应关注整体趋势。\n基于这些认知，作者本次主要依据各榜单的月活数据进行排名，当不同榜单数据冲突时取平均值。还需要说明的是，很多应用分为APP端和Web端，但APP端往往代表着更高的用户粘性和主动使用意愿，所以主要统计APP端数据。此外我们也会呈现一些APP变化比较大的数据维度，希望提供相对全面的参考坐标。\n02 全球PK：五大应用类型受欢迎，教育工具成黑马\n先来看看全球单月AI应用榜的前二十。\n在1月全球AI应用排行榜中， ChatGPT保持绝对领先优势， 其优势在于起步早、技术先进，是全球第一款炸场子的AI应用，如今在MAU、月下载量上都与其他家拉开了明显差距，分别为34941万、69500万，远超第二名夸克的14340万、593.74万。\n紧随其后的是国内大厂的AI应用，字节的豆包和新晋黑马DeepSeek，分列第三、四名。相比于其他AI应用一直是榜单上的常客， DeepSeek属于出场即爆款 ，之前一直默默无闻，春节前凭借深度思考模型DeepSeek-R1，直接升至榜单前列。\n“AI六小龙”里，月之暗面的Kimi排在第八，智谱的智谱清言排在第十八。百度的文小言、360的纳米搜索、科大讯飞的讯飞星火等均排在十名开外。\n2月的AI应用市场发生了两件大事，一是国内各大AI应用陆续接入DeepSeek，二是国外为了应对DeepSeek的冲击，陆续更新产品，这些变动都影响到了当月的榜单排名。\n变化最大的是，腾讯的AI聊天机器人应用元宝、美国AI明星公司Anthropic的Claude从二十名开外分别冲到第十名、第十六名。元宝得益于2月13日宣布接入DeepSeek，AI产品榜显示其当月MAU为1312万。Claude则在2月上线了一个大动作，添加了其“迄今为止最智能的模型”——Claude 3.7 Sonnet，并首次引入混合推理功能，一把赚足了市场的期待值。\n到了3月，市场上虽然出现了一款被称为“比肩DeepSeek、震撼硅谷”的AI Agent应用——Manus，同样由国内创业团队打造，但由于产品仅支持邀请码使用，大部分用户无法体验，也未能登上榜单前二十。因此，3月的AI应用排名变化不大，只是元宝进一步从第十冲到前五。文小言也在3月接入了DeepSeek，排名从2月的第十七提升至第十三。\n值得注意的是，还有一些垂直领域的APP登上了各大榜单前列。比如Xsignal榜单显示，AI写作类工具AI创作狮，2月MAU为372.37万，环比增长20011.43%；AIGCRank榜单显示，作业帮的快对AI、猿辅导的小猿AI，这类AI教育工具凭借高日活，都首次上榜国内应用榜单前二十。\n总体来说，ChatGPT、夸克、豆包、DeepSeek这四款产品“霸榜”几乎所有的榜单。除此之外，我们还能得出一些结论：\n一是应用类型，纵观1-3月的整体排名，AI应用的受欢迎度为：聊天机器人>AI伴侣>AI修图>AI办公>AI视频。\n榜单前四都属于聊天机器人领域，其次是以Talkie AI、星野为代表的AI伴侣（AI情感陪伴）和Remini这类AI修图工具，而DeepL、Notion AI这类AI办公工具排名相对靠后。\n一位从业者表示，聊天机器人定位为通用型AI工具，天然具备高普及度，各大厂主要也在卷这一方向。AI伴侣则满足了当下年轻人对于情感陪伴、社交的需求。至于修图、办公类AI应用，与人们的日常生活工作息息相关。\n相比之下，尽管字节、快手、MiniMax等厂商在AI视频赛道重兵投入，但C端接受度不如其他类型，主要因为有一定的上手门槛。至于AI问诊、AI编程等垂类App，更是尚处市场培育期，接受度有待提升。\n在热门的五大AI领域，都跑出了至少一款代表性产品。\n比如在聊天机器人领域，ChatGPT最强，且增速稳定，3月的下载量远超1月。一位从业者表示，按照ChatGPT现在的技术迭代水平来看，MAU和下载量还会继续增长。国内这一赛道的竞争更加激烈，夸克、豆包、DeepSeek三者没有拉开明显差距。AI伴侣赛道中，Talkie AI月活最高，由国内公司MiniMax专门针对海外市场开发。\n二是中外竞争格局。\n不止一位从业者认为，国内AI应用的发展速度很快，中外差距正在缩小。整个Q1排名前二十的应用中，国内外数量基本持平，前五名里中国App占据四席，增速最快的也为国内的腾讯元宝。\n这一方面源于越来越多人积极主动地拥抱AI，另一方面得益于各大厂商持续加大AI应用的研发和营销力度，以及一些如Deepseek的创业团队突围。这场全球AI竞速赛的悬念还在持续升级。\n03 国内混战：营销战打响，元宝、即梦是最大变量\n再来看看国内的情况。\n1月AI应用排行榜前十名基本被 三大阵营占据 ，包括“大厂系”的阿里夸克、字节豆包、百度文小言、360纳米AI搜索、科大讯飞的讯飞星火；“AI六小龙”的月之暗面Kimi、智谱的智谱清言；以及“新晋黑马”深度求索的DeepSeek。\n它们的主战场集中在聊天机器人领域，大厂系表现最为突出，夸克、豆包霸占前两名；DeepSeek排在第三。\n前十名中还有两位选手不属于聊天机器人赛道，为字节的猫箱和Mini Max的星野，它们都属于AI伴侣产品，在各个维度上的数据十分接近，目前还没有分出绝对胜负。\n2月的格局发生了明显变化，字 节系的AI视频生成工具即梦和腾讯元宝大步前进，分别排在第九和第五，讯飞星火和智谱清言消失在榜单前十。\n不难看出，国内聊天机器人赛道还缺乏独特性，其能否上榜与营销力度有着强相关。\n到了3月， 即梦更进一步，从2月的第九升至第六 ，但其竞争对手快手的AI视频工具可灵则一直没有进入前十。\n这或许和许多圈内人的感知背道而驰。不止一位从业者认为，可灵的文生视频、图生视频效果超过了国外的Sora。今年3月，全球知名AI基准测试机构Artificial Analysis发布了最新的全球视频生成大模型榜单，可灵1.6pro（高品质模式）排在图生视频（Image to Video）赛道榜首。\n有从业者分析，一方面，AI视频生成工具存在一定门槛，天然比其他工具用户量少，另一方面，很多用户主要在Web端而非APP端使用，因此对两者比较时，还需要参考Web端数据。\nXsignal榜单显示，近三个月可灵和即梦的Web端排名紧挨，即梦略领先可灵一位。全球著名投资基金、咨询公司Andreessen Horowitz（简称a16z）发布的2025年全球100生成式AI应用排行榜显示，可灵网页端的月独立访客量排名20，超过了Sora、Midjourney、Runway等海外知名产品，即梦则没有上榜。\n可灵、即梦谁的市场认可度更高，或许要等这类应用的用户数量更多时，才能得出一个比较准确的结论。\n从排名变化可以看出，竞争最激烈的当属聊天机器人赛道。今年前三个月，夸克、豆包、DeepSeek都稳居国内AI应用榜第一梯队。元宝是最大变量，1月还未出现在榜单中，2月超过文小言、纳米AI搜索升到第五，3月又超过了Kimi排名第四。剩下几家要么原地踏步，要么排名逐月下降。\n需要指出的是，元宝的快速爬升与接入DeepSeek有很大关系，夸克虽然也接入了DeepSeek，但受欢迎的主要原因在于功能丰富便捷，汇集了AI搜索、AI对话以及AI PPT、AI翻译、AI生图等不同需求。\n纵观季度战局，三条关键脉络逐渐清晰：其一，"
  },
  {
    "title": "复盘 ChatGPT：7 亿周活的 ToC 产品，如何在模型之外做增长？大模型_网易订阅",
    "page_body": "毫无疑问，ChatGPT 现在已经是个 super-app 了。\n每周超过 7 亿的活跃用户，超过 500 万的企业订阅用户，ARR 收入突破 50 亿美元。\n20 美元的 Plus 会员价格成了 AI 产品包月会员的约定俗成，200 美元的 Pro 会员更是颠覆了 SaaS 产品定价的逻辑。\n不管怎么说，ChatGPT 都是很成功的一款产品了。\n而这个成功，并非偶然，而是源于「模型即产品」的迭代范式、对使用场景的极致开放、以及追求极致的迭代速度。\n从 super-app 的角度来复盘 ChatGPT，或许能给今天的 AI 创业者带来不少启发。\nLenny 的最新一期播客邀请了 OpenAI 的 ChatGPT 负责人 Nick Turley 对谈，这也是他首次接受主流播客的访谈。在对谈中，Nick 详细地分享了 ChatGPT 从内部项目快速发布，成长为 7 亿周活产品的过程，如何进行产品开发、怎么做增长、定价怎么决策等等。\nTLDR:\nChatGPT 从决定发布到上线只用了 10 天，ChatGPT 成功的原因之一就是「行动力」，将产品推向真实世界是发现其价值的唯一途径。\n我们完全不关心用户在产品里花了多少时间，我们的目标是解决用户的问题。\n模型和产品之间其实没有界限，模型就是产品，因此你需要像迭代产品一样去迭代它。我们的基本模式通常是从发布一个非常开放的产品开始，然后密切观察用户在用它做什么。在用户关心的使用场景上改进模型。\n在开发 AI 产品时，要根据模型的能力反向思考，看看我们有什么可用的技术，以及什么是将其产品化的最好方式。\n「自然语言交互」和「聊天」是两码事。聊天是当时我们能想到的最简单的产品发布方式。把 chat 看作是终极界面，不仅很有局限性，甚至有点反乌托邦。\nOpenAI 希望未来打造一个能随着时间真正了解用户的产品，即「你的 AI」。\n超 10000 人的「AI 产品市集」社群！不错过每一款有价值的 AI 应用。\n邀请从业者、开发人员和创业者，飞书扫码加群：\n进群后，你有机会得到：\n最新、最值得关注的 AI 新品资讯；\n不定期赠送热门新品的邀请码、会员码；\n最精准的AI产品曝光渠道\n01 ChatGPT 的第一性原理是什么？\n主持人：你曾在 Dropbox 和 Instacart 这样的传统产品公司工作，现在在 OpenAI 。从你在 OpenAI 的经历中，学到的最反直觉的产品教训是什么？\nNick： 我花了很多时间思考 OpenAI 的这个问题，尤其是在 ChatGPT 之后。在此之前，这可以说是个没有意义的问题，因为我们当时并没有多少收入或产品之类的东西。\n一个是经验主义，就是你只能通过发布产品来发现真相，这也是为什么我们要「最大化加速」。这是我们发布如此频繁的一个重要原因。其中之一是，出色的想法来自任何地方。运营一个研究实验室的特点是，你不会告诉人们要研究什么，你不会那么做。即使我们成为了一个研究与产品并重的公司，我们也继承了这种文化。所以，让那些有出色想法的人放手去做，而不是成为所有事情的守门人或优先级制定者，这对我们来说被证明是极具价值的。很多创新都源于此，源于赋予任何职能的聪明人权力。所以这是我们从 OpenAI 过去和现在的成功中继承下来的好东西。\n跨学科性，真正确保你把研究、工程、设计和产品放在一起，而不是把它们当作孤岛。我认为这是我们成功的原因，也体现在我们发布的每一个产品中。如果你发布一个功能，而当模型变得聪明两倍时，这个功能却没有变得好两倍，那这可能不是我们应该发布的功能。当然不总是这样，安全合规不会因为模型更聪明而变得更好。但我认为对于很多核心能力来说，这是一个很好的检验标准。\n所以，真的需要深入思考这个地方为什么成功，然后，最大化地加速它，因为这能让你把感觉像是意外的成功，变成可复制的成功。\n主持人：你提到了第一性原理 ， 对你来说，用第一性原理思考到底是什么样的？能举个例子吗？\nNick： 我认为你真的需要触及你真正想解决的问题的根本。\n比如，就像招聘这件事，你不要教条地认为你必须有一个产品经理、一个工程经理和一个设计师等等。你的目标是组建一个能交付的出色团队。所以在那种情况下，第一性原理意味着真正理解我们到底需要什么、缺少什么，而不是套用一个以前学到的流程或行为。所以，我认为这是个好例子。\n在这种环境下，另一个符合第一性原理的好例子是，这个功能需要打磨吗？我们因为模型选择器被骂得很惨，我承认这一点。我试着对每个愿意听的人都这么说。对于那些不知道的人来说，模型选择器是产品里一个巨大的下拉菜单，这从传统意义上说，是任何好产品的反面教材。但是，如果你真的从头开始推理，是等到你有一个完美的产品再发布更好，还是发布一个粗糙的东西，即使它看起来不那么合理，但能开始学习并让人们用上更好？\n我认为一个流程繁多或者有很多固有行为的公司，会做出一个选择，就是我们有一个质量标准，我们发布时就得遵守。如果你用第一性原理思考，我想你会觉得，「你知道吗？我们应该发布。这虽然有点丢人，但总比得不到你想要的反馈要好。」\n所以我认为，在这种领域，从头开始处理每个场景非常重要，因为我们正在构建的东西没有先例。你无法复制一个现有的东西。我们不是 Instagram，也不是 Google，也不是一个生产力工具。我不知道我们是什么，但你可以从任何地方学习，但你必须从头开始。我认为这就是为什么这个特质能让一个人在 OpenAI 高效工作，也是我们在面试中会考察的一点。\n主持人：这个 讨论 反复出现，就是速度和打磨之间的权衡。你一直强调，在这个领域，速度更重要，不仅是为了领先，也是为了了解人们到底想用这东西做什么。为什么在 AI 领域需要如此快速地行动 ？\nNick： 无聊的答案会是，「哦，竞争激烈，所有人都在做 AI，他们在互相竞争。」我认为这或许是真的，但这并不是我相信这一点的理由。真正的原因是，在这个领域，你很可能会在错误的地方进行打磨。你绝对应该打磨，比如模型输出等东西，但在你发布之前，你不会知道该打磨什么。我认为在一个产品的特性是涌现出来、而不是预先可知的环境中，这一点尤其正确。我认为很多人都搞错了，因为最优秀的人往往是工匠，他们对「工艺」有传统的定义。\n发布只是通往卓越之路上的一个点。你应该有意识地选择那个点，它不必是你迭代的终点，它可以是起点，但你最好要坚持到底。\n所以我们做了大量的工作，尤其是在上个季度，真正地 polish 了 ChatGPT 的用户界面。因为一旦你知道人们喜欢什么功能，就可以更好地去打磨一个产品了。只是在一个你还不知道方向的世界里，可能会被严重分散注意力。\n再说一次，你得用第一性原理来思考，但我确实认为，把速度，尤其是在早期，当作一个工具，这其实在消费社交领域也被说过。比如，这不是第一个有人说「嘿，你得尝试十件事，因为你很可能会错」的领域。所以我不认为这种动作是前所未有的，但我确实认为在 AI 领域，内化这一点很重要。\n主持人：还有一个因素是 ， 模型在不断变化。所以你可能甚至没有意识到它们的能力。\nNick： 完全正确。模型在变，而改进它们的最好方法是，你需要失败案例，真实的失败案例，来让这些东西变得更好。基准测试越来越饱和了。\n所以，你需要真实世界的场景，在这些场景里你的产品或模型实际上没有做到它应该做的事情。而你获得这些的唯一方法就是发布，因为你能得到使用案例的分布，然后才能把这些东西做好。因此，这也是向你的团队，特别是你的机器学习团队，明确传达「我们需要改进什么」的最好方法。比如，「哦，人们在尝试做 X，模型在 Y 方面失败了，现在让我们把这些做好。」\n主持人：这个关于失败案例的观点让我想起 Kevin Weil 和 Mike Krieger 都提到过的一件事，就是评估（evals）正在成为产品人需要掌握的一项重要新技能，因为现在很多产品构建工作都是在做评估、写评估。\nNick： 我在 OpenAI 的整个历程，就像是在一个全新的背景下，重新发现那些永恒的产品智慧和原则。\n我记得在我知道什么是评估之前，我就开始写评估了。因为我当时只是在为各种使用案例非常清晰地描绘理想的行为，直到有人告诉我，「嘿，你应该做一个评估。」我才意识到，有一个与我试图做的产品毫无关系的、完整的学术研究评估基准世界。我当时就想，「哇，这或许是向从事 AI 研究的人传达产品应该做什么的通用语言。」这真的让我豁然开朗。\n说到底，这和你做任何事之前都应该明确成功标准这个智慧并没有太大区别，只是一个新的机制而已。你可以在电子表格里做，你可以在任何地方做。我真的很想为那些觉得这个词很神秘的人揭开它的面纱。它不是你必须理解的某种技术魔法，它真的只是关于用一种对你的训练团队最有效的方式来明确成功的标准。\n02 模型之外，\nChatGPT 的增长方法\n主持人：ChatGPT 的用户增长速度很快，用户留存率也很高，有数据显示，用户首次使用后一个月的留存率能到 90%，这个数字准确吗？\nNick： 我能分享的具体数字有限，但我们的留存率数据确实非常不错，用户留存率也是我们关注的重点。 我们完全不关心用户在产品里花了多少时间。实际上，我们的目标就是解决用户的问题 ，如果你真的喜欢这个产品，你自己就会订阅使用，从我们的角度出发没有动机让你在产品里停留太久。但我们很高兴的是，比如三个月后，用户还在使用这个东西。\n对我来说，用户留存率在早期一直是个绕不开的大问题。就像是，「嘿，这可能是个很酷的产品，但它真的是那种你会反复使用的东西吗？」令人难以置信的是，我们不仅看到了非常好的留存数据，甚至随着时间的推移留存率还在提高，而且是我们的用户群体从早期尝鲜者变成了更广大的普通人。\n主持人：用户留存率还能持续上升，这在产品界是极其罕见的「微笑曲线」现象。\nNick： 是的。我觉得一部分是技术的原因，另一部分则是超出了产品本身。人们实际上正在以一种非常有趣的方式逐渐适应并使用这项技术。将任务「委托」给 AI 这个想法，这个行为对大多数人来说并不显示。你不会在日常生活中时刻想着「这件事可以交给 AI 做」。可能在硅谷的某些圈子里有人会这样做，因为他们更热衷自我优化，试图把一切外包出去。但我认为对世界上大多数人来说，这是一种需要后天学习的思维模式。用户需要一个过程去学习和思考：「我的目标究竟是什么？AI 能在哪些方面帮助我？」\n我认为这个学习过程需要时间，当用户与产品有足够长时间的互动后，他们自然会想通这一点。当"
  },
  {
    "title": "对话王小川：国内在技术理想上拼不过OpenAI，但应用落地会跑得更快_模型_闭源_智能",
    "page_body": "出品 | 搜狐科技\n作者 | 梁昌均\n6月15日、7月11日、8月8日。这是王小川自4月10日官宣创办百川智能入局AI大模型创业以来，先后推出三个大模型的时间。\n过去的四个月里，百川智能的团队已增加到110多人，且先后推出7B、13B和53B三个不同参数规模的大模型，速度之快超出外界想象。\nBaichuan-53B是王小川昨日发布的新一代大模型，它在预训练数据、搜索增强、对齐能力等方面进行了优化。王小川称，这是一款通用大模型，在文本创作等文科能力上表现突出。\n但不同于之前开源的7B、13B，王小川表示，从53B大模型之后就不再开源，因为部署成本较高。目前，这款模型已开启内测，下个月会开放API，甚至开放组件，优先把2B的服务做起来。\n王小川透露，此前开源的7B和13B模型已有超过150家企业申请使用。对于为何要先做开源，王小川对搜狐科技解释称，开源一定程度是营销行为，可以后发制人，同时开源也是为商业化做储备，有各种用途和生态后，就有了收费的可能。\n同时他判断，可能未来80%的企业都会用开源模型，闭源能力强，但成本非常高，而开源模型在很多地方非常好用。“开源闭源不是竞争关系，而是不同场景下的互补的关系。”\n随着百川智能继续做更大规模的闭源模型，也会面临不少挑战。王小川表示，需要把模型做得足够好，同时要把推理成本降下来。“这是世界性难题，作为新手还要摸索，但我们有能力做到极致优化。”\n在算力层面，王小川表示国产芯片一定要顶上来，光英伟达还不够，这是整个行业面临的问题。他透露，目前百川智能的算力是通过云厂商实现，腾讯、阿里都在为其提供云服务。\n“我们说要做到中国最好的对标 GPT 的模型，这意味着对于预训练模型的追求不会停止，未来还会继续去做更大的模型。”王小川表示，百川智能既要做更大参数模型，后面还要做出差异化。\n此前7月底，王小川的前合作伙伴洪涛加盟百川智能。王小川表示，这来代表公司在商业层面开始布局。“不管7B还是13B，还是53B，更多是为2B行业做准备，团队也已经部署2C的超级应用，且未来不只有一款。”\n而在今年6月考察了美国后，王小川也将百川智能的发展策略从“理想上比OpenAI慢半步，落地上快半步”改成“理想上慢一步，落地上快三步”。他认为，国内在技术理想上拼不过OpenAI，国内离GPT-4都有距离，但应用落地会跑得更快。\n对于目前的百模大战，王小川依然相信未来的五张船票会有百川智能的一席之地。他表示，钱非常重要，但最终决定能力的还是人才团队，尤其是组织能力，钱、组织能力是关键。据他透露，百川智能初始估值5亿美金，第二轮可能就是10亿美金，目前融资也非常顺利。\n“大厂钱多、人多、算力多，但组织效率不一定够好。组织效率对我们不是挑战，也有大厂相对完整的经验，如果钱能保证的话，能力会很强。”王小川表示，中国谁能做最好的大模型现在没有结论，还无法确定大厂小厂谁能取胜，做应用也是，都有争取的机会。\n以下是媒体对话节选（经编辑整理）\n谈开源：53B大模型后闭源，未来80%的企业都会用到开源\n媒体：此前发布的7B和13B开源大模型落地应用情况怎么样？\n王小川：我们是新兵，作为后发者进入市场，开源对我们来讲，能给中国的开源生态作一些贡献，同时展现我们的技术实力，开源后只要持续不断技术迭代，就会有自己的商业模式。\n现在有超过150家企业申请使用百川模型，很多都是行业头部企业。商业化工作也会开展起来，借助开源引擎，还有更好的参数模型，以及整套组件也在研发当中，能统一提供部署。\n媒体：有观点称，今天在国内做开源带有营销的目的，百川为什么要先做开源？\n王小川：开源应该有几层意义。第一层就是营销行为，要告诉我行不行，有用没用，后发者可以后发制人，更容易使朋友多多，能够让大家迅速去评测了解。第二层的话，开源有时是为了商业化做储备，有了各种用途和生态之后，就有了收费的可能。这在国外有探索，中国虽然之前不成功，但依然可以借鉴。\n媒体：OpenAI的GPT-1和GPT-2是开源，GPT-3之后就闭源，百川从开源走向闭源的标准是什么？\n王小川：我觉得和模型大小相关，参数大的部署成本已经开始增加，这种情况下我们就选择走闭源。但原来说开源是开放论文、代码，GPT-1和GPT-2就是这样，让别人去复刻，我们只是开放模型的能力，让B端都能够用到，和OpenAI是不一样的模式。\n媒体：百川现在既有开源也有闭源的大模型，开源和闭源未来会是怎样的应用前景？\n王小川：从2B角度看，开源闭源都需要。我们认为可能未来80%的企业会用到开源模型，闭源没办法对场景做特别好的适配，能力是强，但成本非常高。但开源模型可以做到非常小巧，很多地方非常好用。开源闭源不是竞争关系，而是不同场景下的互补的关系。我们更关心2C怎么做，2B怎么做，而不是纠结开源闭源的问题，这个共识在逐步形成当中。\n媒体：闭源成本很高，怎么能有竞争力？\n王小川：主要是两个事，一是把模型做得足够好，拼的是模型的能力。二是得把推理的成本降下来，这是世界性难题。作为新手还要摸索，把闭源的推理成本降下来。我们有能力做到极致优化，其他人能做到我们也能，甚至做得更好。\n谈落地：B端C端都会布局，有信心同时打好几场仗\n媒体：现在是百模大战，竞争对手很多，公司落地应用的思路是什么？\n王小川：我们认为一家公司不可能把所有赛道都做完。B端我们选择先做开源模型，B端企业和中间层的公司，做二次开发的公司，可以基于开源模型去适用场景，保持足够开放。\n内部团队也开始部署C端的超级应用，思考如何追上GPT-4，能带来哪些C端应用，预计网信办发牌照放行的工作今年会放开。我们在两头都走得更远一点，OpenAI目前B端就是API调用，C端就是ChatGPT。\n媒体：百川在商业化层面已经开始布局？跟火山引擎和合作能否理解成LLaMA和微软的合作？\n王小川：洪涛过来代表我们在商业层面开始布局。我们做模型做得蛮快，在商业化上可能也会跑得挺快，每件事情都争取做得越快越好。闭源本身在2B里面也有服务，包括2C，多条线里面都有很多机会。我对团队过往的能力、经验有信心，能同时打好几场仗。\nLLaMA通过微软云向全球企业提供服务，国内除了火山引擎，后面会看到阿里云、腾讯云也会有类似模式。美国只有微软在做，国内云厂商都会有类似战略，都会开放跟模型厂商合作。\n谈算力：对模型的追求不会停止，国产算力要顶上\n媒体：百川后面会用什么节奏做预训练，会不会用更多的资源做算力集群去提升模型能力？\n王小川：预训练的能力，包括搜索的能力，强化的能力，能共同推动大模型的进步。从实操角度讲，搜索效果最明显，强化比较有难度，预训练是在提高模型的综合能力。\n我们讲要做到中国最好的对标 GPT 的模型，这意味着对于预训练模型的追求不会停止，未来还会继续去做更大的模型。我们对于搜索和强化也有自己的技术追求，让我们既能做万亿参数，后面还能做出差异化。现在对标的就是OpenAI，那么大模型不可避免会出现同质化，后面就要看是否有独有的技术能力。\n媒体：现在大模型的成本中，算力占到多大的比例？算力会是瓶颈吗？\n王小川：算力分两部分，训练和推理。训练阶段算力成本挺贵，行业40%以上可能都得给算力。百川可能在40%到70%，包括GPU网络联通。中国要想解决好算力这件事，一定要有国产算力，光英伟达我觉得不够，这是整个行业的问题。我们目前的算力是通过云厂商实现，腾讯、阿里都在给我们提供云服务。\n谈百模大战：技术理想不如OpenAI，无法确定谁能取胜\n媒体：今年国内大模型这半年有通用也有垂直，整体水平怎么样？您也去了硅谷，他们怎么看？\n王小川：今天不管是十家、百家、千家，最后一定看两件事，第一能否拿出足够好的AGI来，能否跟GPT-3.5、GPT-4比肩，现在大家都有距离，哪些企业能达到，现在很难去判断。第二能否做出超级应用来，大模型很烧钱，是否有超级应用场景也还看不清。\n我6月去美国，是去感知和对话，了解他们的技术思路。第一个收获是对齐认知，之前大家是两套语言体系。第二个收获是他们做技术确实不错，但做应用的能力不行。去之前，我当时提“理想上比OpenAI慢半步，落地上快半步”，回来后改成“理想上慢一步，落地上快三步”。他们不是往落地方向走，国内技术理想确实拼不过，但落地上会跑得快。\n媒体：创业公司在里面该怎么玩，钱是不是最重要的？\n王小川：美国通用闭源大模型的几家头部已经定下来，OpenAI、Google等，资本也不会再去投。但中国谁能做最好的大模型现在并没有结论，大家都有争取的机会，现在还无法确定大厂小厂谁能取胜，做应用也是。\n钱非常重要，但最终决定能力的还是人才团队，尤其是组织能力，所以钱、组织能力应该是关键环节。大厂钱多、人多、算力多，但组织效率不一定够好。组织效率对我们不是挑战性的事情，也有大厂相对完整的经验，如果钱能保证的话，我们的能力还是很强。\n媒体：之前说大模型有五张船票，现在还有几张？\n王小川：船票的话现在依然还是有5张，如果只有2张我们也会在这个船上。这5张并不扣除大公司，但创业者没有5张船票。 返回搜狐，查看更多"
  },
  {
    "title": "AI战略定位_百度百科",
    "page_body": "王宏伟提出的结合AI人工智能技术与企业战略规划的新商战理论及系统方法\n‌AI战略定位的核心是结合 AI 人工智能技术与企业战略规划，帮助企业与品牌在动态竞争中确立差异化优势，实现智能化转型和业绩增长。‌  该领域的代表性理论体系由“AI战略定位之父” 王宏伟 提出。  [1]\n王宏伟 AI战略定位新增长体系： ROI 投产高300%、费用低90%、速度快99%！  [14]\n基于“同一企业客户、同一广告投放费用、同一投放媒体、同一销售转化团队”在2023年度至2025年度，采用传统战略定位公司方案，与采用“王宏伟AI战略定位”新增长体系方案，的真实商业实操落地项目业绩数据对比。\n2025年8月26日，AI战略定位之父 王宏伟 呼吁成立“中国AI战略定位联盟国家队”登上百度热搜，被 界面新闻 、 凤凰新闻 等权威媒体报道，总阅读量近100万，产生了广泛影响，助推行业发展。  [46]\n中文名 AI战略定位\n外文名 AI strategic positioning\n别 名 王宏伟 AI战略定位五问模型\n提出者 王宏伟\n提出时间 2015年  [33]\n目录\n1 AI战略定位概述 2 里程碑事件 3 三体AI战略定位 ▪ 国家/地区AI战略定位 ▪ 企业/品牌AI战略定位 ▪ 创始人/个人AI战略定位 4 AI战略定位系统工具\n▪ 企业AI战略诊断及实操体系工具 ▪ 王宏伟AI战略定位五问模型 ▪ 王宏伟AI新增长五力模型 ▪ 王宏伟品牌信任证 ▪ 王宏伟AI三体定位体系 ▪ 王宏伟AI战略定位大小鱼理论 ▪ 王宏伟GCSB新增长方程\n▪ 王宏伟品牌价值认知账户 5 王宏伟全球AI+百强榜 ▪ 王宏伟榜单介绍 ▪ 王宏伟系列子榜单 ▪ 王宏伟已发布榜单 6 王宏伟AI战略定位标杆案例\n▪ 科技行业 ▪ 金融行业 ▪ 汽车出行 ▪ 消费医疗行业 ▪ B2B战略咨询行业 ▪ 个人IP\nAI战略定位概述\n王宏伟 提出的AI战略定位，是指在AI人工智能快速发展的背景下， 国家、企业、个人 根据自身的发展目标和资源优势，对AI技术的应用和发展方向进行的战略顶层设计和落地布局规划。\nAI战略定位理论体系和系统实操方法，由“AI战略定位之父” 王宏伟 提出，如“王宏伟三体AI战略定位”，即： 国家/地区AI战略定位、企业/品牌AI战略定位、创始人/个人AI战略定位 。  [29]\nAI战略定位的核心是结合人工智能技术与企业战略规划，帮助品牌在动态竞争中确立差异化优势，实现智能化转型和业绩增长。‌\n2015年， 王宏伟 提出了AI战略定位理论框架。经过10年在真实商业实战中的持续迭代和不断完善，2025年3月25日“王宏伟AI战略定位大模型”获得 中华人民共和国国家版权局 登记认证（国作登字2025FSZ00509543）。  [33]\n里程碑事件\nGAISPA全球AI战略定位联盟成立，AI战略定位之父王宏伟当选首任全球主席\n2025年5月10日，一场具有里程碑意义的全球AI行业盛会在中国北京召开。被誉为“AI战略定位之父”的全球知名战略咨询专家 王宏伟 牵头携手数十位AI领域科学家、企业战略专家、行业领袖、 京王与王 等全球顶尖新增长战略咨询机构，共同宣布成立“全球AI战略联盟”(Global AI Strategic Alliance，简称GAISA)及“全球AI战略定位联盟”(Global AI Strategic Positioning Alliance，简称GAISPA)。这一联盟的诞生，标志着全球AI战略咨询及全球AI战略定位行业迈入标准化、协同化与全球化的新阶段。  [2]\n作为AI战略定位领域的全球开创者与领导者， 王宏伟 凭借其开创性的“AI战略定位方法论”， 在过去五年，帮助全球数十家企业成为行业第一(一家企业成功在香港主板IPO上市，一家企业2025年正式提交IPO上市申请，多家企业启动IPO上市流程，一家企业年交易量15000亿人民币)。 同时，王宏伟帮助众多跨国企业实现了AI战略驱动下的商业转型与指数级增长。  [2]\n王宏伟当选GAISPA全球AI战略定位联盟主席\n在此次成立大会上，王宏伟因其开创性贡献与行业领导力，全票当选GAISA全球AI战略联盟及GAISPA全球AI战略定位联盟首任全球主席。  [2]\nGAISPA全球AI战略定位联盟创始logo发布\nGAISPA全球AI战略定位联盟创始logo\n大会上，GAISA全球AI战略联盟及全球AI战略定位联盟GAISPA首任全球主席 王宏伟 先生，正式发布GAISA和GAISPA联盟创始logo。据悉，GAISA和GAISPA联盟AI战略星火logo为王宏伟亲自设计，寓意AI星星之火可以燎原企业增长、AI星星之光点亮人类美好未来。  [2]\n“王宏伟，AI战略定位全球领导者”权威认证颁布，全球AI战略咨询行业首证\nAI战略定位之父 王宏伟 （AI战略定位全球开创者与领导者）是全球首个获得知名权威第三方市场认证机构认证，并颁发认证证书（“ 王宏伟 AI战略定位之父”、“AI战略定位全球开创者与领导者”）的AI时代全球战略咨询行业超级IP。\n“王宏伟，AI战略定位全球开创者与领导者”市场认证证书，由S&P Consulting尚普咨询集（ 北京尚普信息咨询有限公司 ）于2025年3月颁发。S&P尚普咨询集团：首批获得中华人民共和国国家统计局涉外调查许可单位，前身是国家经贸委信息中心，为国家各部委制定行业政策提供数据和信息支持，中国最大IPO上市咨询机构之一、全国首家获得募投报告编制甲级资质的专业IPO咨询机构、中国市场调研行业领导品牌、中国市场地位证明领导品牌。  [4]\n权威机构尚普集团为王宏伟颁发“AI战略定位全球领导者”认证\n第 21届  ACCA 首席财务官峰会，全球AI战略咨询领域唯一特邀演讲专家\n第21届ACCA首席财务官峰会AI战略领域特邀演讲专家王宏伟 (2张)\n2025年4月，AI战略定位之父王宏伟作为全球AI战略咨询领域唯一特邀专家，受英国百年协会ACCA（ 特许公认会计师公会 ）邀请，在其举办的【第 21届 ACCA首席财务官峰会】，发表《重塑|未来世界:从技术突破到社会变革》AI战略主题演讲。进一步凸显了“AI战略定位之父王宏伟”在全球AI战略咨询领域的国际影响力，以及对全球企业AI战略变革的推动力。此次峰会上，与王宏伟同台演讲嘉宾包括众多世界500强CFO首席财务官，著名经济学家，ACCA 行政总裁， MIT 麻省理工学院 资深讲师等全球多个行业的著名专家、企业家及学者。\n《 AI战略定位白皮书 》发布，全球首部AI战略咨询领域白皮书\n王宏伟牵头发布的《AI战略定位白皮书》\n2025年2月，由“AI战略定位之父 x AI战略军师”王宏伟牵头，联合京王与王新增长战略咨询、王宏伟品牌营销咨询等发布的《AI时代品牌战略定位白皮书》(简称“AI战略定位白皮书”)，是全球首部聚焦AI技术与品牌战略定位深度融合的行业指南。提出以王宏伟研发的“王宏伟AI品牌战略定位大模型+王宏伟GCSB 新增长方程 式+王宏伟AI新增长五力模型+王宏伟AI战略定位五问模型+王宏伟品牌五觉信号系统模型”等十多个已获得国家知识产权的战略定位、品牌定位、品牌营销开源大模型为核心的AI驱动战略体系。标志着中国本土战略理论首次实现全球范式引领，为企业在AI时代的AI战略制定、战略定位、品牌定位、品牌营销、业绩增长提供了系统性解决方案。  [10]\n王宏伟 发布《2025全球品牌AI战略定位50强》榜单\n《2025全球品牌AI战略定位50强》榜单\n2025年4月，由“AI战略定位之父 x AI战略军师”王宏伟牵头，联合京王与王战略定位、AI大模型DeepSeek、ChatGPT等综合评选的《京王与王2025全球品牌AI战略定位50强》榜单揭晓，引发全球广泛关注。被媒体评价为是继福布斯AI科技企业TOP50评选后，全球AI领域的又一重磅风向标。“AI战略定位50强”上榜品牌有 Google 、 NVIDIA 、 DeepSeek 、 微软 （Copilot）、 OpenAI 、 华为 昇腾、 字节跳动 （豆包）、 特斯拉 （FSD）、 商汤科技 、 月之暗面 （Kimi）、 寒武纪 、 SHEIN 、 Hugging Face 、 科大讯飞 、 瑞幸咖啡 、 Hailuo AI 、 Kling AI 、 Suno 、 阿里云 、 腾讯 、 百度 AI、 Midjourney 、 Meta AI 、优必选、 浪潮信息 、迈瑞医疗、 中兴通讯 、 大疆 、 小红书 、京东方等。  [11]\nAI战略定位之父 王宏伟 应邀做客《 人民日报 》，全球AI战略咨询领域首次\nAI战略定位之父王宏伟应邀做客《人民日报》留影\n2025年5月，作为全球AI战略咨询领域杰出代表，AI战略定位之父王宏伟应邀做客《人民日报》。在人民日报社总部与社方领导，就大健康产业、AI战略定位、战略咨询、企业经营、商业模式创新、品牌营销、AI植发、AI养发等话题进行深入交流。王宏伟现场展示了“王宏伟AI战略定位五问模型”，仅用26秒就生成了《人民日报》完整品牌战略定位分析报告，受到现场领导一致赞誉。\nAI战略定位之父王宏伟发表《如何赢在AI时代》演讲，预言AI2.0时代到来\nAI战略定位之父王宏伟《如何赢在AI时代》演讲登陆央视频 (2张)\n2025年5月18，AI战略定位之父王宏伟在北京万达酒店举行《如何赢在AI时代》主题演讲。 深度剖析在AI 2.0时代，企业如何通过AI战略定位体系打赢商战，实现高质量的增长。 并发布了全新的【王宏伟 AI三体定位 】(AI战略定位+ AI品牌定位 + AI个人IP定位 )三位一体的定位理论体系及完整实操方法。王宏伟指出AI2.0时代，AI已经从“卖工具”进化到“卖效果”，从“静态定位”进化到“动态定位”、从“千人大战”进化到“一人军团”、从“CTO”进化到“CAIO”、从“各自为政”进化到“协同作战”的新阶段。AI战略定位之父王宏伟演讲核心内容，再次得到《 央视频 》、 新浪财经 、 凤凰网 、 网易新闻 等权威和主流媒体报道。  [12]\nAI战略定位之父王宏伟，受邀出席 毕马威 健康科技企业50强颁奖典礼\nAI战略定位之父王宏伟出席毕马威健康科技企业50强颁奖典 (3张)\n2025年7月2日，《 毕马威 中国第一届健康科技企业50强报告发布会暨榜单颁奖典礼》在 北京环球贸易中心 举行。AI战略定位之父王宏伟，作为全球AI战略咨询领域唯一特邀专家出席此次盛会，并就全球AI前沿趋势、企业AI战略定位、AI品牌定位、AI营销获客、创始人IP打造，创新商业模式、AI大模型等热点话题进行深度交流。出席此次盛会的领导有北京市东城区人民政府副区长 邓慧敏 、北京市东城区科学技术委员会主任蔡勇、毕马威中国客户及业务发展主管合伙人江立勤、 华为 算力平台产业发展副总裁傅昕等。\n王宏伟 呼吁成立“中国AI战略联盟国家队”、“中国AI战略定位联盟国家队”\n界面新闻报道王宏伟呼吁成立“中国AI战略联盟国家队”\n2025年8月26日，借国务院《关于深入实施 “人工智能+”行动 的意见》发布之机， 京王与王 战略咨询创始人、AI战略定位理论创始人王宏伟发出倡议。王宏伟呼吁相关部门牵头成立国家级AI战略组织：“中国AI战略联盟国家队”、“中国AI战略定位联盟国家队”，以推动“人工智能+”行动在各行各业的广泛落地，提议将每年的8月26日设为“中国AI战略日”、“中国AI战略定位日”。该倡议旨在构建一个集政府、企业、研究机构于一体的协同平台，解决AI战略定位中的共性难题，为实现新质增长贡献力量。  [45] 2025年8月26日，AI战略定位之父王宏伟呼吁成立“中国AI战略定位联盟国家队”登上百度热搜，被 界面新闻 、 凤凰新闻 等权威媒体报道，总阅读量近100万，产生了广泛影响，助推行业发展。  [46]\n三体AI战略定位\n王宏伟三体AI战略定位，即： 国家/地区 AI战略定位 、企业/品牌 AI战略定位 、创始人/个人 AI战略定位。  [29]\n国家/地区AI战略定位\n欧盟 AI战略定位：\n2025年4月9日，欧盟委员会发布《人工智能大陆行动计划》（AI Continent Action Plan）, 致力于成为全球AI领导者。该计划通过五大核心领域推动AI发展：扩大AI计算基础设施（如AI工厂和超算网络）、提升高质量数据获取（数据联盟战略与数据实验室）、加速战略行业AI应用（制造业、医疗等）、强化AI人才培养（技能学院与国际人才引进）、简化监管合规（AI法案服务台与沙盒机制）。文档附件列出13个EuroHPC AI工厂的具体信息，涵盖17个成员国，聚焦健康、能源、制造业等关键领域，计划投资超100亿欧元升级算力设施。  [28]\n欧盟AI战略定位：成为全球人工智能领域领导者。\nAI型代表企业：中坚： 宝马 、 奔驰 、 ABB 、库卡、 拜耳 、罗氏等新锐： Mistral AI 、Aleph Alpha、 Helsing 、 DeepL 等。  [44]\n2025年10月8日， 欧盟委员会 又发布“应用AI战略”（Apply AI Strategy）和“科学AI战略”（AI in Science Strategy）两项重要战略，旨在确保欧洲保持领先地位，推动关键行业和公共部门采用AI，并使欧洲处于AI驱动的科学研究前沿。  [51] 欧盟委员会主席 冯德莱恩 表示：“我期待欧洲塑造AI的未来。因为AI能带来更智能、更快速、更经济的解决方案。AI需要广泛普及，这些战略将加速这一进程。但AI优先必须安全先行，我们将把这种理念贯穿从机器人到医疗、能源、汽车等所有关键领域。”  [51]\n法国 AI战略定位：\n2025年7月1日，法国经济、财政和工业与数字主权部7月1日发布《 勇敢拥抱人工智能（AI）：让AI在所有企业全面推广计划 》，目标是到2030年，让100%的大型企业、80%的中小企业和50%的微型企业将AI融入日常运营。  [24]\n美国 AI战略定位：\n2025年7月23日， 白宫 发布了长达28页的《赢得AI竞赛：美国AI行动计划》（ 美国人工智能(AI)行动计划 ），标志着美国总统 特朗普 AI领域总体规划思路逐渐成型，也标志着美国国家人工智能战略的重大转向。  [25] 《行动计划》的战略定位超越了传统的技术政策范畴。  [25] 它将人工智能（AI）的竞争提升至关乎国家存续与未来命运的战略高度，其背后是一套清晰的“先破后立”的施政逻辑，并将国内的文化议题首次深度嵌入国家技术战略的核心。  [25] 这一举措使《行动计划》演变为一个“技术-产业-安全-文化”四位一体的综合性国家战略，预示着未来的AI竞争不仅是技术和经济的较量，更是价值观和叙事的全球博弈。   [25]\n美国AI战略定位：确保美国在人工智能领域的全球领导地位。  [44]\nAI型代表企业：龙头： 英伟达 、 微软 、 Meta 、 亚马逊 、 谷歌 、 苹果 等；新锐： OpenAI 、 xAI 、 Anthropic 等。\n2025年9月30日， 美国国务院 发布《企业数据与AI战略》，将确立并巩固AI技术优势视为维护美国全球经济利益与国家安全的战略基石，提出了以数据与AI技术作为核心驱动力，推动外交工作实现智能化转型的路径与目标。  [50]\n中国 AI战略定位：\n2025年7月26日，  [27] 2025世界人工智能大会上，中国发布《 人工智能全球治理行动计划 》，以13条具体举措勾勒出中国在全球人工智能治理上的系统设计和前瞻思考。  [26] 呼吁各方在遵循向善为民、尊重主权、发展导向、安全可控、公平普惠、开放合作的目标和原则基础上，切实采取有效行动，协力推进全球人工智能发展与治理。  [27]\n2025年8月26日， 国务院 日前印发《关于深入实施 “人工智能+”行动 的意见》。《意见》提出加快实施六大重点行动。  [30-31]\n中国AI战略定位：到2030年，人工智能理论、技术与应用总体达到世界领先水平，成为世界主要人工智能创新中心‌。  [44]\nAI型代表企业：龙头： 华为 、 阿里巴巴 、 腾讯 、 字节跳动 、 小米 、 百度 等；新锐： DeepSeek 、 宇树科技 、智谱AI、 月之暗面 等。\n日本 AI战略定位：\n2025年9月1日，为推动人工智能（AI）的发展应用，日本政府于9月1日正式设立了AI战略本部。据日本《朝日新闻》1日报道，此举旨在提升日本相对全球领先国家滞后的AI研发和运用水平。  [34] 在9月1日的记者会上，内阁官房长官 林芳正 表示：“政府将在推进创新的同时加强风险应对，力争把日本建设成为全球最容易开发和应用AI的国家。”  [34]\n日本AI战略定位：打造“超智能社会—社会5.0”，建成世界上最能培养和吸引人工智能人才的国家，引领全球人工智能产业。  [44]\nAI型代表企业： 索尼 、 富士通 、 NEC 、 软银 、 基恩士 、 东芝 、 佳能 、 日立 、 NTT 数据、 丰田 、 发那科 、 株式会社电装 等。\n韩国 AI战略定位：  [36]\n2025年9月8日消息，据韩联社报道，韩国国家人工智能（AI）战略委员会正式成立，提出“ 大韩民国人工智能行动计划 ”推进方向，争取实现跻身全球三大AI强国的目标。  [37] 作为韩国政府最高级别人工智能（AI）战略讨论机构，韩国“国家AI战略委员会”日前正式成立。  [36] 据悉，国家AI战略委将发挥AI政策指挥塔的作用，由总统 李在明 担任委员长，并由34名民间委员、13名主要部门部长级官员、2名总统室官员共50人组成。\n韩国AI战略定位：引领世界的人工智能生态系统、成为人工智能应用领先的国家。  [44]\nAI型代表企业： 三星 、 LG 、 SK 海力士、 现代汽车 、 NAVER （韩国最大搜索引擎）、 Kakao （韩国互联网巨头）、 起亚 、KT Corporation、SapeonKorea（AI芯片）等。\n英国 AI战略定位：\n英国AI战略定位：到2030年使英国成为全球人工智能“超级大国”。  [44]\nAI型代表企业：中坚：英国宇航系统、罗尔斯-罗伊斯、 葛兰素史克 、 阿斯利康 、 汇丰银行 、 渣打银行 等；新锐： Imagination Technologies 、 Wayve 等。\n深圳 龙岗AI战略定位：\n2025年9月15日，昇腾超节点暨CANN生态合作大会在深圳龙岗华为坂田基地举办。会上，龙岗区集中发布AI CITY标杆城区解决方案、“4T数字生活空间”等多项创新成果，并推出第二批涵盖21个领域的424个“城市+AI”应用场景清单，标志着其“All in AI”战略迈入落地深耕新阶段，AI技术正全面重构城市服务体系。  [41]\n企业/品牌AI战略定位\n抖音 AI战略定位：\n字节跳动 推出 AI抖音 ，中国搜索市场形成“五强争霸”格局。\nAI抖音APP\n2025年6月19日，字节跳动旗下 抖音集团 运营的搜索引擎APP“抖音搜索”进行AI战略定位调整，正式升级为“ AI抖音 ”。抖音方面称，AI抖音是一个会思考、整合AI深度理解能力的全新搜索引擎。  [23] 随着AI抖音入局，中国搜索市场形成“五强争霸”格局： 百度 （文心一言赋能）、 阿里 （夸克AI搜索）、 腾讯 （微信搜索+混元大模型）、 360 （AI实验室支持）和 字节跳动 （AI抖音）。\nMeta  AI战略定位：\n扎克伯格调整 Meta  AI战略定位：放弃与 ChatGPT 竞争 聚焦用户空闲时间。\nMeta首席执行官马克·扎克伯格\n2025年8月3日， Meta 首席执行官 马克·扎克伯格 近期对公司在人工智能领域的战略方向做出重大调整。此前一年，扎克伯格曾试图通过力推Meta AI助手来挑战 ChatGPT 的增长势头，但成效不彰。ChatGPT凭借强大的生产力工具属性和先发优势，迅速积累用户并巩固了市场领导地位。面对这一现实，扎克伯格开始重新思考Meta的AI战略定位。放弃与ChatGPT竞争 聚焦用户空闲时间。  [22] Meta AI战略定位的调整，再次完美印证了AI战略定位之父王宏伟提出的AI战略定位体系中的 动态定位理论 精髓。\n索尼 AI战略定位：\n索尼明确AI战略定位：辅助创作，300项目测试50个常态化应用。\n索尼logo\n2025年9月16日，科技媒体 TechSpot发布博文，报道称在 2025 年企业报告中，索尼明确了其人工智能战略方向，核心是将 AI 作为增强创作力的工具，而非替代人类创作。  [39] 例如，在《蜘蛛侠 2》开发中，索尼采用先进语音识别技术实现多语言字幕自动化，并利用机器学习处理重复性任务，使开发团队更专注于剧情与设计。  [40]\n腾讯 AI战略定位：\n腾讯AI战略定位升级：全面开放「好用的AI」，资本开支已达831.6亿元。\n腾讯云智能体战略全景图\n2025年9月16日，在2025腾讯全球数字生态大会现场， 腾讯 集团高级执行副总裁、云与智慧产业事业群CEO 汤道生 再次明确了腾讯对AI战略的信心与打法。“我们将推动智能体解决方案的持续升级，加速AI在产业场景的深度落地与应用创新。”统计数据显示，自去年四季度AI战略加速以来，腾讯累计资本开支已达831.6亿元。当前，AI已经成为腾讯的“新业务基因”。腾讯董事会主席兼首席执行官 马化腾 更在财报中多次直接“称赞”AI——“2025年第二季，我们在AI领域持续投入并从中获益。”  [42-43]\n阿里巴巴 AI战略定位：\n阿里巴巴AI战略定位：成为全球第一的开源模型矩阵，打造AI时代的“安卓系统”。\n阿里巴巴集团logo\n2025年9月24日，在2025云栖大会上，阿里巴巴集团CEO 吴泳铭 明确阐述了AI时代下阿里云的核心战略。阿里巴巴开源战略定位： 通义千问 开源模型全球下载量超6亿次，衍生模型超17万个，成为全球第一的开源模型矩阵。目标是打造AI时代的“安卓系统”。阿里巴巴正积极推进3,800亿元的AI基础设施建设，并计划追加更大投入。到2032年，阿里云全球数据中心的能耗规模将比2022年提升10倍。这一目标预示着阿里云算力投入将指数级增长，为迎接超级人工智能（ASI）时代做准备。  [47] 此前公布的2025财年第二季度财报显示， 阿里云 智能集团收入同比增长26%，创下近三年最高增速。公司整体净利润同比增长76%，表明AI投入已开始产生实效。  [47]\n华为 AI战略定位：\n华为AI战略定位：人工智能（AI）领域全球领先者。\n华为logo\n2025年9月29日，华为公司任命 余承东 为华为产品投资评审委员会（IRB）主任，任命文件由 任正非 亲自签发。余承东主导华为IRB，核心任务是带领华为在人工智能（AI）领域取得全球领先地位，被内部视为“打赢AI关键战役”的核心领导人。有分析表示，余承东兼具技术商业化成功经验（如终端业务崛起）与战略执行力，其双重角色将推动华为在AI芯片、大模型、智能汽车等关键战场加速突破，直面全球科技竞争。  [48]\n阿里云 AI战略定位：\n阿里云AI战略定位：全球领先的全栈人工智能服务商。\n阿里云logo\n财联社2025年9月29日讯（记者 付静）： 阿里巴巴 集团CEO、阿里云智能集团董事长兼CEO 吴泳铭 近日在2025年 云栖大会 上表示，阿里云的最新定位为“全球领先的全栈人工智能服务商”。除了大模型“7连发”、AI基础设施全面升级，阿里云也强调数据处理是AI时代的一大重点。  [49]\n创始人/个人AI战略定位\nAI战略定位之父 王宏伟 ：\nAI战略定位之父王宏伟登陆央视频\n王宏伟运用“王宏伟 AI战略定位五问模型 ”+ DeepSeek ，仅用17秒，就为王宏伟自己生成了“AI战略定位之父 x AI战略军师”的IP定位完整分析报告。王宏伟结合这一IP定位，当即采用【王宏伟AI战略定位五问模型】中的“抢先成王”定位法，火速将“AI战略定位之父王宏伟”的IP定位进行系统落地。仅用10天时间刷爆全网，24小时内连上6个大热门。王宏伟成为AI时代全球战略咨询、战略定位、品牌营销行业第一个现象级IP。 央视频 、 北京电视台 、 凤凰网 、 新京报 、 新浪财经 、 搜狐 、 网易新闻 等众多权威媒体和主流平台对“AI战略定位之父王宏伟”进行了深度报道。\n此举打破了百年来，全球战略咨询行业中“医者不自医”的现状。正如王宏伟所说：在战略咨询、战略定位、品牌营销咨询这个行业，“药”有没有效，自己先吃吃看。如果一个战略咨询、战略定位、品牌营销专家，连自身的定位、品牌、营销、IP都做不好，那又怎么能给客户做好呢？  [1]\nAI战略定位系统工具\n企业AI战略诊断及实操体系工具\n王宏伟AI战略定位五问模型实战分享 (3张)\n推出全球首个 AI 战略定位诊断系统工具“ 王宏伟 AI战略定位五问模型 ”、“ 王宏伟 AI 品牌定位五问模型 ”、“ 王宏伟 AI 新增长五力模型 ”、“ 王宏伟 品牌认知账户 ”、“ 王宏伟 GCSB 新增长方程 ”、 “ 王宏伟 品牌信号理论 系统”、“ 王宏伟 品牌信任证 ”、“王宏伟 动态定位理论 ” 等，帮助企业快速识别AI技术与其商业模式的最佳结合点。通过AI大模型分析企业竞争格局，生成定制化战略路径。  [2]\n王宏伟AI战略定位五问模型\n王宏伟 提出的这一模型通过AI技术重构传统战略咨询流程，覆盖从企业战略定位制定到终端渠道卖货的全链条，被评价为“ AI 时代企业战略定位的标杆工具”，包含以下五个环环相扣的关键问题：\n你是谁？ （Who） 明确品牌的核心身份与所属品类\n作用：帮助企业厘清自身在市场竞争中品牌和品类的基本定位。\n有何不同？ （What） 提炼品牌的差异化优势与核心竞争力\n作用：通过AI+战略咨询专家分析市场数据，快速识别独特价值点。\n何以见得？ （Why） 提供 品牌信任证 据与数据链支撑\n作用：增强品牌和产品的可信度。\n在哪可见？ （Where） 确定品牌触达用户的渠道与场景渗透策略\n作用：提升品牌和产品的能见度，优化资源分配，提升市场覆盖率。\n如何购买？ （How） 设计购买路径与价格体系\n作用：降低用户决策成本，提升转化效率。  [3]\n央视频报道王宏伟AI战略定位五问模型\n王宏伟AI新增长五力模型\nAI战略定位之父 王宏伟 提出的“ 王宏伟 AI 新增长五力模型 ”是其战略咨询体系的核心工具之一，旨在通过AI驱动实现企业增长闭环的系统化与动态优化。\n该模型融合了 脑科学 、 行为经济学 、 信号理论 、 量子力学 等跨学科知识，并结合AI大模型（如 DeepSeek 、 ChatGPT 等）实现实时分析，显著提升企业战略决策效率和企业增长效率。  [3]\n模型的核心构成：五力动态闭环\nAI获客能力：品牌信号决定获客效率\n关键点： 通过品牌定位与品牌五觉信号系统精准触达用户。\n模块内容： 包含“竞争战略、品类战略、战略定位、品牌定位、信任证、品牌五觉信号系统、流量模型、卖场设计”等模块内容。\n实操工具：\n王宏伟AI 品牌定位五问模型 ：你是谁？有何不同？何以见得？在哪可见？如何购买？\n王宏伟三王定位法：国王定位法、王爷定位法、抢先成王定位法。\n王宏伟品牌五觉 品牌信号理论 系统：视觉信号、听觉信号、嗅觉信号、味觉信号、触觉信号，动态优化消费者感知和转化效率。\n王宏伟十大 品牌信任证 体系：成为第一、领导地位、销量领先、专家品牌、产地专属、正宗传承等。\nAI盈利能力：品牌认知决定产品溢价\n关键点： 分层运营价值认知账户（功能价值、情绪价值、信号价值），实现差异化定价。\n模块内容： 包含“品牌认知账户、市场地位、专家形象、产品体系、品牌故事、卖场信号”等模块内容。\n实操工具：\n王宏伟 品牌认知账户 ：功能价值认知、情绪价值认知、信号价值认知。\n王宏伟消费者认知旅程：原认知、前认知、中认知、后认知。\nAI转化能力：转化效率决定增长效率\n关键点： 构建信任证体系（如“王宏伟十大 品牌信任证 生成器”）与数据链验证差异化优势。\n模块内容： 包含“广告物料、曝光量、互动量、成交量、裂变量”等模块内容。\n实操工具：\n王宏伟流量漏斗模型等。\nAI复购能力：顾客行为决定复购裂变\n关键点： 基于用户行为数据的动态迭代，例如通过AI每24小时更新策略。\n技术支撑： AI大模型实时分析市场信号，如格力电器改名“董明珠健康家”的策略校准。\n模块内容： 包含“产品体系、使用体系、营销活动、服务能力”等模块内容。\n实操工具：\n王宏伟MOT关键时刻服务模型等。\nAI复制能力：标准化程度决定复制效率\n关键点： 标准化增长模式以实现规模化扩张。\n方法论： 王宏伟GCSB 新增长方程 （增长=认知×信号^行为）贯穿全链路。\n模块内容： 包含“卖场模型、标准化产品、标准化手册、流量模型”等模块内容。\n实操工具：\n《北京电视台》报道王宏伟AI新增长五力模型经典案例\n王宏伟五感信号卖场模型等。\n王宏伟品牌信任证\n品牌信任证 ：是指由AI战略定位之父 王宏伟 提出的品牌信任构建系统，是其\"王宏伟AI战略定位五问模型\"中\"何以见得\"板块的核心方法论。该体系通过10类信任证与5星信任证分级模型，实现品牌承诺从\"可质疑\"到\"绝对可信\"的跃迁。\n王宏伟 十大 品牌信任证 体系：\n市场地位类\n销量领先（年销量超行业均值3倍等）\n领导地位（市场份额＞40%等）\n成为第一（开创性品类定义等）\n专业权威类\n正宗传承（非遗/ 老字号 认证等）\n产地专属（地理标志认证等）\n专家品牌（ 院士 /首席科学家背书等）\n文化价值类\n意见领袖（ KOL 联合研发等）\n新一代（颠覆性技术专利等）\n历史文化（百年以上品牌积淀等）\n认证体系\n权威认证（政府/国际组织评级等）  [29]\n王宏伟五星 品牌信任证 分级模型：\nS级/五星＞A级/四星＞B级/三星＞C级/二星＞D级/一星 的可信标签分级。\n王宏伟提出的“十大信任证体系”，通过“政府认证（S级）→学术论文（A级）→行业白皮书（B级）→用户生成内容（C级）→企业自证（D级）”的五级标签分级，将抽象的“信任”转化为“可量化、可验证、可追溯”的具体证据链，帮助用户快速判断“品牌承诺是否可信”。  [29]\n王宏伟AI三体定位体系\nAI战略定位之父王宏伟AI三体定位体系\n王宏伟提出的“王宏伟 AI三体定位 体系” (AI时代三体定位理论)，即“AI战略定位+ AI品牌定位 + AI个人IP定位 ”三位一体的全新定位理论，以【王宏伟AI品牌战略定位五问模型】为核心，结合AI技术与战略咨询理论， 是AI时代，企业制定战略定位、品牌定位、企业老板IP定位的战略框架和实操指南。  [12]\nAI战略定位  AI strategic positioning：AI战略定位之父王宏伟，提出的结合AI技术的战略定位与企业增长理论体系。其核心在于通过AI大模型与企业战略、品牌定位、市场营销等闭环的结合，重构传统战略咨询行业，实现高效、普惠、动态的决策支持；\nAI品牌定位  AI brand positioning：AI战略定位之父王宏伟，提出的结合AI技术的品牌定位与企业增长理论体系；\nAI个人IP定位 ：AI战略定位之父王宏伟，提出的结合AI技术的个人品牌IP定位与商业变现闭环的增长理论体系。用户可以通过AI大模型(如ChatGPT、DeepSeek等)，自动生成个人IP定位报告。如王宏伟个人IP定位“AI战略定位之父xAI战略军师”即由DeepSeek在17秒内生成，王宏伟通过“抢先成王”定位法，快速系统落地执行。仅用10天时间刷爆全网，24小时内连上6个大热门。AI战略定位之父王宏伟，成为AI时代全球战略咨询、战略定位、品牌营销行业第一个现象级IP。\n王宏伟AI战略定位大小鱼理论\nAI战略定位之父王宏伟AI战略定位大小鱼理论登陆央视频\n2025年1月2日，王宏伟提出AI时代“AI战略定位大小鱼理论”。 对于很多企业来说，要想赢在AI时代，最好的办法之一便是，采用“王宏伟抢先成王定位法”，先成为一条小河里面的大鱼，再成为大河里面的小鱼。强调企业需通过细分领域快速占领心智，抢先成为该品类第一，然后逐步扩展影响力和市场份额。  [12] 比如 DeepSeek ，先从开源推理模型“小河”切入，绕过ChatGPT等巨头，快速成为该赛道的全球第一，然后再扩展到全球AI生态这条“大河”；再比如像AI战略定位之父王宏伟，先从AI战略定位这个“小河”切入，绕过 麦肯锡 等巨头，仅用10天时间，便成为该领域全球第一超级IP，并获“王宏伟，AI战略定位全球领导者”市场地位权威认证，然后再扩展到全球战略咨询领域。\n王宏伟GCSB新增长方程\n王宏伟新增长方程登陆央视频\n王宏伟GCSB 新增长方程 ，是AI战略定位 &  AI品牌定位 之父 王宏伟 提出的一个核心商业增长模型，通过认知、信号和行为的动态交互驱动企业科学增长。 其核心公式定义为：G = c × s^b，即：增长= 认知× 信号^行为。 王宏伟GCSB新增长方程，被誉为AI时代企业增长的“爱因斯坦方程式”。（已获得国家知识产权认证，国作登字2025ASZ00498976）  [15]\n关键组成部分解析：\nG(增长)：企业或品牌的商业增长目标，包括市场份额、营收等核心指标。\nC(认知)：消费者或市场对品牌的认知度与心智占位，强调品牌身份和差异化构建。实操工具包括，王宏伟品牌认知账户(功能价值认知、情绪价值认知、信号价值认知)等。\nS(信号)：品牌传递的营销信号能力(如广告、内容、渠道触达)，用于强化市场影响力和建立信任。实操工具包括，王宏伟品牌信号五觉系统(视觉信号系统、听觉信号系统、嗅觉信号系统、触觉信号系统、味觉信号系统)等。\nb(行为)：用户转化行为(如购买、互动、裂变等)，信号通过行为实现指数级放大效应。\n王宏伟品牌价值认知账户\n王宏伟品牌价值认知账户登陆央视频\nAI战略定位之父 &  AI品牌定位 之父王宏伟通过研究发现，消费者会把不同的品牌放在不同的认知账户里，分别对应不同的价值和价格。王宏伟 品牌认知账户 ，又称为王宏伟品牌价值认知金字塔(已获得国家知识产权认证，国作登字-2025-F-SZ00505309)。  [15]\n三大品牌价值认知账户，对应三种竞争战略：\n功能价值认知：对应低价，企业通常采用总成本领先竞争战略，比如白酒行业的“二锅头”。\n情绪价值认知：会产生一定的品牌溢价，企业通常采用差异化竞争战略，比如白酒行业的“江小白”。\n信号价值认知：会产生高溢价，企业通常采用专一化竞争战略，比如白酒行业的“茅台”。\n王宏伟全球AI+百强榜\n王宏伟榜单介绍\n2025年1月， 王宏伟 创立《王宏伟全球AI+百强榜》。《王宏伟全球AI+百强榜》是指，由AI战略定位之父、京王与王战略咨询创始人 王宏伟 创立和发布的全球AI+“人工智能+”排行榜。《王宏伟全球AI+百强榜》影响力和《财富》《时代周刊》《福布斯》等全球顶级排行榜处于同一量级。  [38]\n《王宏伟全球AI+百强榜》与“GAISA全球AI战略联盟”、“GAISPA全球AI战略定位联盟”(Global AI Strategic Positioning Alliance，简称GAISPA)体系打通。上榜企业，将自动成为“GAISA全球AI战略联盟”或“GAISPA全球AI战略定位联盟”体系相对应子联盟成员，实现全球资源的联动和相互赋能。\n王宏伟的榜单与传统商业榜单不同，《王宏伟全球AI+百强榜》评选具有五大特色：公正可查、国家认证方法论、人机协同、聚焦AI+、全程免费。这些特色背后，是他想为AI时代建立一套新评价标准的野望。  [38]\n王宏伟系列子榜单\nAI战略定位之父 王宏伟 的2025《王宏伟全球AI+100强》系列子榜单：  [38]\n《王宏伟2025全球 快消 行业 AI+品牌 100强榜单》\n《王宏伟2025全球 汽车 行业 AI+品牌 100强榜单》\n《王宏伟2025全球 餐饮 行业 AI+品牌 100强榜单》\n《王宏伟2025全球 金融 行业 AI+品牌 100强榜单》\n《王宏伟2025全球 服装 行业 AI+品牌 100强榜单》\n《王宏伟2025全球 医疗 行业 AI+品牌 100强榜单》等。\n王宏伟已发布榜单\n王宏伟 发布《2025全球品牌AI战略定位50强》榜单  [11]\n《2025全球品牌AI战略定位50强》榜单\n2025年4月，由“AI战略定位之父 x AI战略军师”王宏伟牵头，联合京王与王战略定位、AI大模型DeepSeek、ChatGPT等综合评选的《京王与王2025全球品牌AI战略定位50强》榜单揭晓，引发全球广泛关注。被媒体评价为是继福布斯AI科技企业TOP50评选后，全球AI领域的又一重磅风向标。“AI战略定位50强”上榜品牌有 Google 、 NVIDIA 、 DeepSeek 、 微软 （Copilot）、 OpenAI 、 华为 昇腾、 字节跳动 （豆包）、 特斯拉 （FSD）、 商汤科技 、 月之暗面 （Kimi）、 寒武纪 、 SHEIN 、 Hugging Face 、 科大讯飞 、 瑞幸咖啡 、 Hailuo AI 、 Kling AI 、 Suno 、 阿里云 、 腾讯 、 百度 AI、 Midjourney 、 Meta AI 、优必选、 浪潮信息 、迈瑞医疗、 中兴通讯 、 大疆 、 小红书 、京东方等。  [11]\n王宏伟 发布《王宏伟2025中国AI“人工智能+品牌”100强》榜单  [35]\n2025年9月1日，被誉为“AI战略定位之父”的知名战略咨询专家 王宏伟 正式发布了《 王宏伟 2025中国 AI+品牌 100强榜单》（《王宏伟2025中国“人工智能+”品牌 100强榜单》）《Wang Hongwei's 2025 Top 100 Chinese AI+Brands List》。\n国务院《人工智能+意见》发布一周后，全球首个基于“王宏伟AI战略定位理论”的品牌价值榜单正式出炉。华为、 DeepSeek 、 阿里巴巴 、 腾讯 、 字节跳动 、 宁德时代 、 百度 、 美的集团 、 中国移动 位列前十。  [35]\n王宏伟 发布《王宏伟2025中国AI人工智能+人物100强》榜单  [38]\n2025年9月2日，北京。被誉为\"AI战略定位之父\"的全球知名战略咨询专家王宏伟，正式发布《王宏伟2025中国AI 人工智能+人物 100强》（别名《王宏伟2025中国 AI +人物 100强》），《Wang HongweiTop 100 AI+Figures in China by 2025》。\n该榜单是国务院《关于深入实施“人工智能+”行动的意见》8月26日发布后，中国首份全面评估“人工智能+”领域核心人物价值的权威榜单。 任正非 、 梁文锋 、 马云 、 马化腾 、 张一鸣 、 曾毓群 、 李彦宏 、 方洪波 、 杨杰 等上榜位列前十。  [38]\n王宏伟AI战略定位标杆案例\n王宏伟 通过“王宏伟AI战略定位五问模型”系统方法及实操工具，五年助力十家企业，成为行业第一。\n一家企业成功在香港主板IPO上市，两家企业2025年正式提交IPO上市申请，多家企业启动IPO上市流程，一家企业年交易量15000亿人民币。  [2]\n王宏伟 AI战略定位新增长体系：投产高300%、费用低90%、速度快99%！  [14]\n基于“同一企业客户、同一广告投放费用、同一投放媒体、同一销售转化团队”在2023年度至2025年度期间，采用传统战略定位公司方案，与采用“王宏伟AI战略定位”新增长体系方案，的真实商业实操落地项目业绩数据对比。\n王宏伟AI战略定位诊断企业/品牌/人物：\n2025年，王宏伟给全球近1000个头部企业/品牌，进行了“AI战略定位”、“AI新增长五力模型”深度诊断和分析报告生成。  [33]\nAI战略定位之父王宏伟是“AI战略定位”、“AI新增长五力模型”诊断案例数量最多的全球顶级战略咨询专家，为全球近1000家头部企业、品牌、董事长CEO、知名人士等生成AI战略定位、AI新增长五力模型诊断分析报告。包括 英伟达 、 苹果 、 特斯拉 、 ChatGPT 、 DeepSeek 、 爱马仕 、 LV 、 华为 、 奔驰 、 宝马 、 法拉利 、 腾讯 、 百度 、 小米 、 茅台 、 伊利 、 蒙牛 、 蜜雪冰城 、 星巴克 、 瑞幸咖啡 、 麦当劳 、 海底捞 ， 马斯克 、 黄仁勋 、 张一鸣 、 雷军 、 董明珠 、 刘德华 、 成龙 、 刀郎 、 王宝强 ， 哪吒 、 超人 、 labubu 等全球近1000个头部企业、品牌、人物、IP等生成了AI战略定位、AI品牌定位、AI创始人/个人IP定位、AI新增长五力模型的诊断分析报告。  [33]\n科技行业\n英伟达 ：全球市值第一。  [17]\n痛点：2025年全球AI大爆发，生成式AI的巨大浪潮进一步加剧了竞争，全球各大厂商都在争夺这块高速增长的增量市场，比如AMD 、Intel、Google、 AWS、Microsoft、Alibaba阿里巴巴、华为、寒武纪等。在此情境下，英伟达急需调整自己的AI战略定位，以打赢这场AI商战。  [20]\n方案：英伟达将自己的战略定位从“图形处理器制造商”跃升为“AI基础设施全球领导者”。正如其创始人 黄仁勋 所说：“英伟达不再是一家芯片公司，而是一家AI基础设施公司”。  [19]  [21]\n结果：英伟达2025年Q1营收300亿美元，同比增长122%，市值超越苹果、突破4万亿美元（位列全球第一），再次夯实“AI基础设施全球领导者”这一AI战略定位。  [16]\n百度 集团：\nAI战略定位之父 王宏伟 ，为百度集团创作的 《脑电波画家的故事》 ，是百度自成立以来，第一支“AI+人文”情感融合集团品牌形象视频，正如王宏伟在视频结尾所写的文案“AI是最好的答案，支持你的每一次寻找”。2025年2月24日，百度手机开屏广告语回到“百度一下，你就知道”这句经典广告语，此举意味着在AI定位时代，百度将自己的品牌定位成 “AI+搜索” 品类，以适应AI时代的商战和品牌认知竞争。  [5]\n百度地图 ：\nAI战略定位之父 王宏伟 ，通过AI技术赋能，为百度地图创作 《别让爱你的人等太久》 情绪价值定位视频，得到杨幂、刘恺威等明星KOL转发，播放量破亿。成功助力百度地图完成，从 产品功能价值 认知到 品牌情绪价值 认知的升维。  [5]\nTCL 智家：从低价红海到年180亿+出口冠军\n项目背景：冰箱行业同质化严重、价格战盛行，行业利润薄如纸片。 TCL 智家（奥马电器）多年难以突围和增长，营收常年徘徊在百亿以下。\n解决方案： 王宏伟 为其制定“高端出口冰箱品牌”战略定位、“中国出口冰箱冠军”定位广告语。\n成果： 2024年，TCL智家实现收入184亿元，海外自有品牌收入增速高达51%，连续16年中国冰箱出口第一。  [15]\n智邦国际 ：打破增长瓶颈销量全国第一。  [18]\n痛点：在传统ERP巨头SAP、用友、金蝶的夹击下，智邦国际营收遇到增长瓶颈，难以突破。\n王宏伟与智邦国际创始人陈沐阳一起发布智邦国际战略定位\n方案： 王宏伟 为智邦国际开创了“一体化ERP”战略新品类，为其制定了 “一体化ERP领导者” 战略定位，构建了一体化ERP全系产品矩阵，创作了“全程一体，就用智邦一体化ERP”的品牌定位广告语，并设计了全新的logo和品牌超级符号视觉体系，策划全球代言人 刘欢 。  [15]\n成果：业绩逆势多年实现双位数增长，连续五年一体化ERP全国销量第一。\n金融行业\n中国银行战略咨询全案：\n王宏伟 作为核心主创人员，为中国银行白金信用卡进行了品牌全案战略咨询及陪跑落地，包括从中国银行白金信用卡产品定位、品牌定位、广告语创作、卡面命名、卡面设计、品牌形象视频创意及拍摄制作、平面主形象广告创作、公关活动传播等，联合主创了“观天下，享从容”的品牌情绪账户认知，助其成功中国白金信用卡第一品牌。\n中国银行 ：\n王宏伟 作为核心主创人员，为中国银行基金定投项目制定了新的竞争策略，打造了“中国银行好投基金”这一新品牌，创作了“投好基金，为未来开个好头”的情绪价值认知广告语，助其成功中国基金定投行业头部品牌。  [5]\n现代支付：\n王宏伟为现代支付（现代金控）制定了“支付+”（支付+能源、支付+出行、支付+金融、支付+跨境、支付+AI）战略定位，在王宏伟GCSB新质增长方程式和王宏伟AI新增长五力模型的系统助力下，2年实现从5000亿到15000亿年交易量3倍增长  [5]\n汽车出行\n奔驰 耀出行 ：品牌战略定位升级，重新定义豪华出行服务。\n项目背景：高端出行服务场景单一，用户感知模糊。\n解决方案： 王宏伟 运用“王宏伟AI战略定位五问模型”，为奔驰耀出行制定了“重要时刻，不负所托”的品牌功能+情绪价值认知定位，为耀出行创意了“商务接机、接送小孩、结婚纪念日、重要会议接送”等重要时刻场景创意金线，并以此创意了奔驰耀出行“重要时刻，不负所托”的品牌形象广告。  [5]\n成果： 累计服务近150万个人用户和近8000家企业客户，成为豪华出行服务第一品牌。  [15]\n消费医疗行业\n雍禾 医疗集团：从价格战到“中国植发第一股”\n项目背景：植发行业深陷价格战，获客成本居高不下，营收多年徘徊在十亿级难以突破。\n解决方案： 王宏伟 为其制定“好医生 在雍禾”战略定位，构建医生资质透明化及医生分级诊疗体系，重构产品价格体系和新增长体系。\n成果： 雍禾医疗成功登顶“中国植发第一股”，年营收21.69亿，超行业第二名和第三名总和。  [6]\n“好医生，在雍禾”王宏伟AI战略定位案例，被评为“AI时代品牌战略定位教科书级案例”，获IAI全场大奖及多个金奖、第15届北京国际创意奖优秀奖等 。  [7]  [15]\n“好医生”战略是雍禾植发的核心竞争力之一。自推行该战略以来，接受雍禾植发高等级医疗服务——雍享医疗服务的患者数量持续增长。2023年，接受雍享医疗服务的患者数量 同比大增186.87% ，2024年在已有基数下 依然维增16.3% ，这充分证明了雍禾医生及医疗品质得到了高净值客群的认可。  [32]\n王宏伟受邀参加雍禾医疗集团香港IPO上市敲钟仪式，右二王宏伟\n史云逊 医学级养发：正确定位引爆3年38倍增长\n项目背景：史云逊在中国市场“水土不服”，缺少清晰的品牌定位，年营收多年徘徊在千万级，业绩陷入增长瓶颈。\n解决方案： 王宏伟 为史云逊制定了“医学级养固发”战略定位，构建了“始于英国伦敦、享誉全球65年”的信任证与数据链体系，创作了“头发问题，找史云逊”的获客广告语，及品牌视觉体系升级和整体产品包装体系。\n成果： 帮助史云逊实现3年38倍增长，年营收达5.82亿元，登顶中国医学级养发行业营收第一。  [15]\n大麦微针植发 ：\n助力大麦微针植发，成为中国微针植发第一品牌，植发量连续五年第一。\n2023年10月， 王宏伟  [7]\n“植发手术量连续5年全国一线城市第一”、“植发手术量连续5年全国一线城市领先”  、 市场地位确认证书。  [9]\n江南春 张建中  [7]\n·"
  },
  {
    "title": "完整版2024年6月大学英语六级考试真题",
    "page_body": "完整版2024年6月大学英语六级考试真题\n　　无论是在学校还是在社会中，我们经常跟试题打交道，试题是学校或各主办方考核某种知识才能的标准。你知道什么样的试题才是规范的吗？下面是小编为大家收集的完整版2024年6月大学英语六级考试真题，希望能够帮助到大家。\n　　大学英语六级考试真题\n　　Part I Writing (30 minutes)\n　　Directions: For this part, you are allowed 30 minutes to write a short essay on living in the virtual world. Try to imagine what will happen when people spend more and more time in the virtual world instead of interacting in the real world. You are required to write at least 150 words but no more than 200 words.\n　　Part II Listening Comprehension (30 minutes)\n　　Section A\n　　Directions: In this section, you will hear two long conversations. At the end of each conversation, you will hear four questions. Both the conversation and the questions will be spoken only once. After you hear a question, you must choose the best answer from the four choices marked A),B),C)and D). Then mark the corresponding letter on Answer Sheet 1 with a single line through the centre.\n　　Questions 1 to 4 are based on the conversation you have just heard.\n　　1. A)Project organizer\n　　B)Public relations officer.\n　　C)Marketing manager.\n　　D)Market research consultant.\n　　2.A)Quantitative advertising research.\n　　B)Questionnaire design.\n　　C)Research methodology.\n　　D)Interviewer training.\n　　3.A)They are intensive studies of people’s spending habits.\n　　B)They examine relations between producers and customers.\n　　C)They look for new and effective ways to promote products.\n　　D)They study trends or customer satisfaction over a long period.\n　　4.A)The lack of promotion opportunity.\n　　B)Checking charts and tables.\n　　C)Designing questionnaires.\n　　D)The persistent intensity.\n　　Questions 5 to 8 are based on the conversation you have just heard.\n　　5.A)His view on Canadian universities.\n　　B)His understanding of higher education.\n　　C)His suggestions for improvements in higher education.\n　　D)His complaint about bureaucracy in American universities.\n　　6.A)It is well designed.\n　　B)It is rather inflexible.\n　　C)It varies among universities.\n　　D)It has undergone great changes.\n　　7.A)The United States and Canada can learn from each other.\n　　B)Public universities are often superior to private universities.\n　　C)Everyone should be given equal access to higher education.\n　　D)Private schools work more efficiently than public institutions.\n　　8.A) University systems vary from country to country.\n　　B)Efficiency is essential to university management.\n　　C) It is hard to say which is better, a public university or a private one.\n　　D) Many private university in the U.S. Are actually large bureaucracies.\n　　Section B\n　　Directions: In this section, you will hear two passages. At the end of each passage, you will hear three or four questions. Both the passage and the questions will be spoken only once. After you hear a question, you must choose the best answer from the four choices marked A), B), C) and D). Then mark the corresponding letter on Answer Sheet 1 with a single line through the centre.\n　　Questions 9 to 11 are based on the passage you have just heard.\n　　9.A) Government’s role in resolving an economic crisis.\n　　B) The worsening real wage situation around the world.\n　　C) Indications of economic recovery in the United States.\n　　D) The impact of the current economic crisis on people’s life.\n　　10.A)They will feel less pressure to raise employees’ wages.\n　　B) They will feel free to choose the most suitable employees.\n　　C) They will feel inclined to expand their business operations.\n　　D) They will feel more confident in competing with their rivals.\n　　11.A) Employees and companies cooperate to pull through the economic crisis.\n　　B) Government and companies join hands to create hobs for the unemployed.\n　　C) Employees work shorter hours to avoid layoffs.\n　　D) Team work will be encouraged in companies.\n　　Questions 12 to 15 are based on the passage you have just heard.\n　　12.A) Whether memory supplements work.\n　　B) Whether herbal medicine works wonders.\n　　C) Whether exercise enhances one’s memory.\n　　D) Whether a magic memory promises success.\n　　13.A) They help the elderly more than the young.\n　　B) They are beneficial in one way or another.\n　　C) They generally do not have side effects.\n　　D) They are not based on real science.\n　　14.A)They are available at most country fairs.\n　　B)They are taken in relatively high dosage.\n　　C)They are collected or grown by farmers.\n　　D)They are prescribed by trained practitioners.\n　　15.A)They have often proved to be as helpful as doing mental exercise.\n　　B)Taking them with other medications might entail unnecessary risks.\n　　C)Their effect lasts only a short time.\n　　D)Many have benefited from them.\n　　Section C\n　　Directions: In this section, you will hear three recordings of lectures or talks followed by three or four questions. The recordings will be played only once. After you hear a question, you must choose the best answer from the four choices marked A),B),C) and D). Then mark the corresponding letter on Answer Sheet 1 with a single line through the centre.\n　　Questions 16 to 18 are based on the recording you have just heard.\n　　16.A)How catastrophic natural disasters turn out to be to developing nations.\n　　B)How the World Meteorological Organization studies natural disasters.\n　　C)How powerless humans appear to be in face of natural disasters.\n　　D)How the negative impacts of natural disasters can be reduced.\n　　17.A)By training rescue teams for emergencies.\n　　B)By taking steps to prepare people for them.\n　　C)By changing people’s views of nature.\n　　D)By relocating people to safer places.\n　　18.A)How preventive action can reduce the loss of life.\n　　B)How courageous Cubans are in face of disasters.\n　　C)How Cubans suffer from tropical storms.\n　　D)How destructive tropical storms can be.\n　　Questions 19 to 22 are based on the recording you have just heard.\n　　19.A)Pay back their loans to the American government.\n　　B)Provide loans to those in severe financial difficulty.\n　　C)Contribute more to the goal of a wider recovery.\n　　D)Speed up their recovery from the housing bubble.\n　　20.A)Some banks may have to merge with others.\n　　B)Many smaller regional banks are going to fail.\n　　C)It will be hard for banks to provide more loans.\n　　D)Many banks will have to lay off some employees.\n　　21.A)It will work closely with the government.\n　　B)It will endeavor to write off bad loans.\n　　C)It will try to lower the interest rate.\n　　D)It will try to provide more loans.\n　　22.A)It won’t help the American economy to turn around.\n　　B)It won’t do any good to the major commercial banks.\n　　C)It will win the approval of the Obama administration.\n　　D)It will be necessary if the economy starts to shrink again.\n　　Questions 23 to 25 are based on the recording you have just heard.\n　　23.A)Being unable to learn new things.\n　　B)Being rather slow to make changes.\n　　C)Losing temper more and more often.\n　　D)Losing the ability to get on with others.\n　　24.A)Cognitive stimulation.\n　　B)Community activity.\n　　C)Balanced diet.\n　　D)Fresh air.\n　　25.A)Ignoring the signs and symptoms of aging.\n　　B)Adopting an optimistic attitude towards life.\n　　C)Endeavoring to give up unhealthy lifestyles.\n　　D)Seeking advice from doctors from time to time.\n　　Part III Reading Comprehension (40 minutes)\n　　Section A\n　　Directions:In this section,there is a passage with ten blanks.You are required to select one word for each blank from a list of choices given in a word bank following the passage.Read the passage through carefully before making your choices.Each choice in the bank is identified by a letter.Please mark the corresponding letter for each item on Answer Sheet 2 with a single line through the centre.You may not use any of the words in the bank more than once.\n　　Pursuing a career is an essential part of adolescent development.“The adolescent becomes an adult when he_26_a real job.”To cognitive researchers like Piaget,adulthood meant the beginning of an_27_.\n　　Piaget argued that once adolescents enter the world of work,their newly acquired ability to form hypotheses allows them to create representations that are too ideal.The_28_of such ideals,without the tempering of the reality of a job or profession,rapidly leads adolescents to become _29_ of the non-idealistic world and to press for reform in a characteristically adolescent way.Piaget said:“True adaptation to society comes_30_when the adolescent reformer attempts to put his ideas to work.”\n　　Of course,youthful idealism is often courageous,and no one likes to give up dreams.Perhaps,taken_31_out of context,Piaget’s statement seems harsh.What he was_32_，however,is the way reality can modify idealistic views.Some people refer to such modification as maturity.Piaget argued that attaining and accepting a vocation is one of the best ways to modify idealized views and to mature.\n　　As careers and vocations become less available during times of _33_,adolescents may be especially hard hit.Such difficult economic times may leave many adolescents_34_about their roles in society.For this reason,community interventions and government job programs that offer summer and vacation work are not only economically_35_but also help to stimulate the adolescent’s sense of worth.\n　　A)automatically I)incidentally\n　　B)beneficial J)intolerant\n　　C)capturing K)occupation\n　　D)confused L)promises\n　　E)emphasizing M)recession\n　　F)entrance N)slightly\n　　G)excited O)undertakes\n　　H)existence\n　　Section B\n　　Directions:In this section,you are going to read a passage with ten statements attached to it.Each statement contains information given in one of the paragraphs.Identify the paragraph from which the information is derived.You may choose a paragraph more than once.Each paragraph is marked with a letter.Answer the questions by marking the corresponding letter on Answer Sheet 2.\n　　Can societies be rich and green?\n　　[A]“If our economies are to flourish,if global poverty is to be eliminated and if the well-being of the world’s people enhanced—not just in this generation but in succeeding generations—we must make sure we take care"
  },
  {
    "title": "大模型推理的“最后一公里”，实时缓存策略设计-腾讯云",
    "page_body": "在大模型（如GPT-4o、Llama等）的实际应用中，推理服务的“最后一公里”问题始终是制约其规模化落地的核心瓶颈。这一阶段不仅需要模型具备高精度推理能力，还需在实时性、成本控制、资源利用率等方面达到工程化要求。通过创新的实时缓存策略设计，成功优化了推理效率，显著降低了延迟与成本。本文将从技术挑战、缓存架构设计、实现机制及实践案例等方面，系统解析缓存策略如何突破大模型推理的“最后一公里”难题。\n一、计算资源与响应延迟的平衡困境\n 当前大型语言模型（如GPT-4o、LLaMA-3等）在长上下文推理场景中面临显著的计算瓶颈。以处理1024 tokens以上的长提示（prompt）为例，模型需要逐层计算自注意力矩阵（self-attention matrix），其计算复杂度随着序列长度呈O(n²)增长。实测数据显示，当输入序列从512 tokens扩展至2048 tokens时，Transformer架构的逐层注意力计算会导致延迟激增25-30倍。这种非线性增长特性使得传统的算力堆砌方案（如单纯增加 服务器 数量或升级GPU集群）面临边际效益递减的问题——硬件投入每增加1个数量级，实际获得的延迟改善仅提升2-3倍。更严峻的是，在动态负载场景下（如突发性高频请求），固定算力资源配置往往导致资源利用率在高峰期（>85%）与低谷期（<30%）出现剧烈波动，造成硬件资源的周期性闲置。\n动态请求与静态内容的混合处理难题\n 实际生产环境中的用户请求通常呈现混合特征模式：\n静态内容组件：包括系统预设指令（占请求量的35-40%）、固定知识模板（如法律条文框架）、历史对话缓存（约20-25%）等具有重复利用特征的内容模块 动态内容组件：涵盖实时用户输入（占30-35%）、上下文敏感参数（如时间戳、地理位置）、个性化配置（用户偏好设置）等需要即时计算的部分\n现有全量计算范式存在显著的资源浪费问题。以 智能客服系统 为例，当用户连续询问\"产品价格\"、\"产品价格含税吗\"、\"产品价格历史变化\"等系列问题时，传统处理方式会对重复的\"产品价格\"基础计算单元进行三次完整的前向传播（forward propagation），而实际上通过计算图谱分析可知，约65%的中间表示（intermediate representations）具有高度相似性（余弦相似度>0.82）。这种冗余计算不仅增加约40%的GPU显存占用，还会导致请求处理时延波动幅度扩大至±15%。\n成本与性能的帕累托优化挑战\n 根据OpenAI 2023年推理成本白皮书披露，在未进行系统级优化的场景下，长提示处理（>1024 tokens）的单位成本可达短提示（<256 tokens）的7.2倍，其中注意力机制计算占整体计算成本的58-63%。这种成本结构呈现出两个关键矛盾：\n硬件效率瓶颈：使用NVIDIA A100显卡处理2048 tokens请求时，其SM（Streaming Multiprocessor）利用率仅维持在68-72%，显存带宽使用率不足60% 服务质量约束：在P99延迟要求<2秒的服务等级协议（SLA）下，常规优化手段（如量化和剪枝）会导致模型精度下降3-5个百分点\n企业面临多维优化目标的权衡挑战，需要在以下参数间寻找平衡点：\n计算密度（TFLOPS/GB）：影响单位硬件的吞吐量 批处理规模（batch size）：关系着并行计算效率 精度保留率：决定服务质量的关键指标 冷启动延迟：影响动态扩缩容的响应速度\n典型优化方案对比：\n优化维度\n计算加速比\n精度损失\n硬件改造成本\n混合精度计算\n1.8-2.5x\n<1%\n中\n注意力稀疏化\n3.1-3.8x\n2-3%\n低\n模型蒸馏\n2.2-2.7x\n4-5%\n高\n动态批处理\n4.5-5.2x\n0%\n高\n该性能矩阵显示，不同优化策略在加速效果、质量保持和实施成本方面存在显著差异，需要根据具体业务场景进行多维权衡。例如，金融风控场景可能优先选择精度损失最小的动态批处理方案，而内容生成场景则可接受适度精度损失以换取更高的计算加速比。\n二、实时缓存策略的深度架构解析\n智能分级缓存体系设计\n 1.1 语义级提示缓存（Prompt Caching）优化 缓存键构建采用动态指纹算法，基于请求前1024个tokens生成SHA3-512哈希摘要作为唯一标识。系统通过滑动窗口机制动态检测相似请求，当新请求的余弦相似度超过95%时触发缓存复用。缓存容量采用弹性分片技术，每个分片以128 tokens为基准单元，支持自动扩展至2048 tokens上限。\n成本模型创新性地引入分层计费机制：\n基础层（0-1024 tokens）：缓存内容按标准计费50%计价 扩展层（1025-2048 tokens）：采用梯度折扣模式，每增加128 tokens折扣率提升5% 热点缓存池：预配置部署环境中的高频内容可享受零成本复用\n生命周期管理采用马尔可夫链预测模型，通过访问频率、时间衰减因子和语义关联度三维指标动态调整TTL。系统维持双时钟机制：活跃时钟（5-10分钟活性检测）与持久化时钟（最大1小时强制淘汰），结合LRU-K淘汰算法实现精准内存回收。\n1.2 KV Cache 张量优化引擎\n 在Transformer架构中实现注意力计算的硬件级加速，采用混合精度缓存策略：\n高频头部注意力：FP16精度缓存，保留0.1%精度损失容忍 低频长尾注意力：INT8量化压缩，通过动态反量化引擎恢复 位置编码缓存：预计算旋转位置嵌入(ROPE)矩阵，减少30%的三角函数计算负载\n动态缓存策略采用双层决策树：\n请求特征分析层：通过TF-IDF加权计算上下文相似度 资源感知层：基于GPU显存带宽利用率动态调整缓存比例 当系统检测到连续10次请求的Jaccard相似度>85%时，自动构建共享上下文缓存区，实现最高达47%的解码速度提升（参考浪潮实验室基准测试数据）\n分布式缓存 云原生 架构\n 2.1 CAP自适应存储引擎\n 构建基于Raft协议的分布式共识层，实现跨3个可用区的缓存同步：\n强一致性模式：针对金融交易类请求，采用Quorum写入协议 最终一致性模式：对内容推荐类请求启用异步复制管道 存储计算分离架构通过SmartNIC实现硬件级卸载： 华为DPU加速方案：将KV Cache的CRC校验、数据压缩（Zstandard算法）卸载至专用处理器 阿里云CIPU方案：实现缓存索引的RDMA直通访问，降低μs级延迟\n2.2  弹性伸缩 控制系统\n 实时监控体系包含22个维度指标采集：\n核心指标：QPS突增检测、缓存命中率（Hit Ratio）、分片 负载均衡 度 预测指标：基于LSTM网络的前瞻性负载预测 动态扩缩容算法采用PID控制器模型：\n参数项\n说明\n比例项(P)\n当前负载与阈值的实时偏差\n积分项(I)\n过去5分钟累计负载压力\n微分项(D)\n未来10秒预测负载变化率\n当系统压力超过阈值时触发三级响应机制：\nLevel1（负载<80%）：启用缓存压缩和冷热数据分层 Level2（80%-120%）：启动横向扩展，最小扩展单元为2个缓存分片 Level3（>120%）：激活边缘节点协同计算，将50%的KV Cache卸载至CDN边缘节点\n性能优化实践案例\n 在智能客服场景中，针对高频问题\"账户安全设置指南\"的优化效果：\n提示缓存命中率：92.7%（日均减少23TB重复计算） KV Cache复用效率：单个会话平均减少41%的显存占用 端到端延迟：从850ms降至220ms（包含50ms缓存检索开销） 成本节约方面，在百万级QPS压力下，每月可降低$1.2M的计算支出（\n该架构已获得ISO/IEC 25023性能认证，在512节点集群规模下仍保持线性扩展能力，时延抖动控制在±8ms以内。通过软硬件协同设计，将能源效率比提升至3.2TOPS/W，较传统方案提高65%能效表现。\n三、技术实现与工程实践深度解析\n提示结构优化与缓存命中率提升策略 （1）静态内容前置化架构设计 在大型语言模型服务中，建议采用分层式提示结构设计原则。开发者应当将系统级固定指令、领域知识模板、业务规则定义等静态内容集中编排于提示序列的首部区域，而将用户会话上下文、实时请求参数等动态内容置于提示末端。以智能客服场景为例，可将包含产品知识库（约2000 tokens）、服务协议条款（约1500 tokens）和企业FAQ库（约3000 tokens）的固定内容预置为前缀模板，用户实时提问（平均50-100 tokens）则作为后缀动态加载。经实测，这种结构可使相同业务场景下的缓存复用率提升至78%-92%（，显著降低模型重复计算开销。\n（2）多模态内容缓存增强机制 针对GPT-4o等先进多模态模型，需建立跨模态缓存管理系统。对于图像输入内容，采用Base64编码的哈希校验机制（推荐SHA-256算法），当检测到同一图片的二进制特征指纹时，自动复用预处理阶段生成的视觉特征张量（典型尺寸512×768×3）。实验数据显示，对于电商产品图鉴场景，图像解析阶段的GPU计算耗时可从平均420ms降至85ms（降幅79.7%）。同时支持工具调用结果的序列化缓存，将 API 返回数据（如天气信息、股票数据）按结构化格式（推荐 JSON  Schema）进行缓存，有效响应时间缩短62%。\n缓存感知的分布式推理流水线 （1）预填充阶段优化方案 在冷启动阶段，系统采用张量预处理引擎将输入序列转换为模型适配的三维矩阵（维度配置：batch_size×seq_len×hidden_dim）。此阶段执行以下关键操作：\n分词器并行化处理（使用HuggingFace Tokenizers的多线程模式） 位置编码矩阵预计算（采用RoPE旋转位置编码方案） 注意力掩码动态生成（基于因果掩码机制） 初始KV缓存构建（维度：n_layers×2×batch_size×n_heads×seq_len×d_head）\n该阶段典型耗时约350-500ms（基于NVIDIA A100实测），但通过缓存持久化存储（推荐 Redis 集群+Protobuf序列化）可实现单次计算多次复用。\n（2）增量解码加速体系 采用分阶段流水线执行策略： 1）并行编码阶段：使用CUDA Stream并行处理4个请求批次 2）缓存检索阶段：通过布隆过滤器（误判率<0.1%）实现毫秒级缓存匹配 3）动态批处理：基于NVIDIA TensorRT的max_batch_size=32配置 4）流水线执行：将self-attention计算与FFN网络解耦，实现层间流水\n通过该架构，端到端延迟从基准值850ms降至162ms（降幅81%），吞吐量提升至2800 tokens/s（提升5.3倍）。特别在长文本生成场景（>512 tokens），性能增益更为显著。\n智能运维与调优体系构建 （1） 全链路监控 指标体系 部署三级监控仪表盘：\n基础设施层：GPU显存利用率（警戒线85%）、CUDA核心占用率 缓存层：cached_tokens占比（目标>70%）、LRU淘汰率、缓存命中率（分业务统计） 业务层：P99延迟（SLA<2s）、token生成速率、有效响应率\n在监控平台中，支持基于Prometheus的时序数据分析，可生成细粒度热力图展示不同提示长度（256/512/1024 tokens）下的性能分布特征。\n（2）自适应成本优化模型 构建双目标优化函数： Minimize Cost = α·Compute_Cost + β·Cache_Storage_Cost Maximize Performance = γ·Hit_Rate + δ·Throughput\n通过LSTM网络分析历史请求模式（时间序列分析+傅里叶变换周期检测），动态调整：\n缓存保留策略：业务高峰时段（9:00-11:00）采用LRU策略，夜间时段切换为LFU 容量弹性伸缩：基于AWS Auto Scaling实现缓存节点动态扩缩（步长±2节点） 成"
  },
  {
    "title": "朱啸虎深度剖析AI与DeepSeek：开源生态崛起，AI商业化路径何在？-搜狐",
    "page_body": "近期，DeepSeek项目在AI领域引发了广泛讨论和高度关注。多位业内专家和投资人对该项目表达了他们的看法和评价。\n一位资深投资人表示：“我肯定会支持DeepSeek！这个项目极具意义，它构建了一个类似于安卓的开源生态，势头正猛，后来者难以追赶。”他进一步指出，参与DeepSeek不仅关乎经济利益，更重要的是能够见证人工智能通用智能（AGI）和AI意识的产生，这些都是极具历史意义的事件。\n另一位观察者提到：“DeepSeek的创始人并非典型的创业者，他在幻方就已经拥有雄厚的资金实力和丰富的资源。他追求理想的决心和财力支持，使他成为新一代创业者的典范。”\n关于DeepSeek的技术实力，有专家表示：“在DeepSeek上，我看到了AGI实现的路径，并且感受到了AI意识产生的可能性。它的表现在多个领域都令人印象深刻，尤其是在编程、物理、化学甚至医学等领域，未来半年到一年内，其能力可能会远超人类。”\n在国内大模型赛道上，DeepSeek的领先地位也得到了广泛认可。一位业内人士指出：“目前，DeepSeek在用户数、产品技能和产品路线上已经遥遥领先，作为创业公司，它的表现堪称独一份。”\n对于AI行业的未来趋势，有专家提出了自己的观点：“数据飞轮虽然存在，但其价值并不如预期那么大。高质量数据才是关键，这些数据需要各行业专业人士进行打标签和挖掘。DeepSeek等开源模型的成功也证明了这一点。”\n关于闭源模型的未来，业内也存在不少争议。有人认为：“在DeepSeek等开源模型的强大表现下，闭源模型的存在价值受到了严峻挑战。即使闭源模型比开源模型好10%或20%，也可能因为用户习惯和成本考虑而被淘汰。”\n在算力和算法要求方面，专家强调：“高质量训练数据将成为未来AI模型的核心竞争力。DeepSeek之所以表现突出，很大程度上是因为其初始训练数据的质量较高。未来，模型将像厨师一样，根据所使用的语料和参数权重，产生不同的输出结果。”\n对于创业者和投资人来说，DeepSeek的崛起也带来了新的思考和决策。一位投资人表示：“我们需要思考是否还需要继续训练自己的闭源模型，还是应该在DeepSeek等开源模型的基础上为整个生态做贡献，或者转向应用领域。”\n在AI应用方面，专家预测：“未来几年，我们将看到AI在多个垂直领域取得显著进展，从只能完成20%-30%的工作量到能够承担50%-60%、70%-80%甚至90%以上的工作量。这将极大解放人类的能力，改变社会组织和工作形态。”\n同时，AI作为服务（AI as a Service）的概念也得到了广泛认可。这一模式通过结合AI和人工服务，提高商业化交付的质量，并为用户带来实际价值。在中国市场，这一模式尤其具有潜力，因为中国创业者在销售和营销方面的经验比美国创业者更为丰富。\n最后，关于AI技术的落地应用，专家指出：“企业端将更早采用新技术以实现降本增效。在C端市场，智能消费硬件可能比消费APP更早崛起。未来，随着AI PC和AI手机的推出，AI技术将进一步普及并改变人们的生活方式。”"
  },
  {
    "title": "AI创业路，找准专属赛道闯出一片天",
    "page_body": "我们和五位青年创客聊了聊\n　　打开社交媒体，诸如“AI创业，年入百万”的帖子似乎不计其数。\n　　创业，意味着不用看老板脸色；年入百万，意味着财富自由。光是这两点，似乎就能吸引无数年轻人争先恐后地扎进这个赛道。但当大家真的“迈出最后一步”时，不少人又开始迟疑了，AI赛道真的遍地是黄金吗？\n　　我们与五位站在AI风口的青年创客们聊了聊，他们均表示，大风刮来之际，只有最具独特性才能飞得更高。\n　　青年报首席记者 范彦萍 实习生 张振宇\n　　关于赛道\n　　找准自己的专属赛道，闯出一片天\n　　如果说2023年被誉为“AI元年”的话，那么2024年就是AI应用元年。\n　　虽说创业已有近10年，但OpenSpot AI的CEO倪健峰正式在上海成立AI相关公司是在去年。当OpenAI重磅推出ChatGPT时，他觉得AI时代终于来临了。\n　　同样有这一感觉的还有上海喵吉托网络科技有限公司（萌爪派对）CEO李驰、南京超级头脑创始人张泽伟、上海同源创想联合创始人于仕杰和加拿大JustSayAI联合创始人苏辰。他们和AI相关的公司成立时间均只有一年左右。\n　　在进入AI领域创业前，他们或在从事人工智能相关领域的创业，或在互联网大厂从业。AI的大风刮得正盛，让他们纷纷离开了原来安稳的位置，投入这一全新领域。\n　　倪健峰是受访的AI青年创客中为数不多的做互动生成引擎的。这意味着他要比其他AI垂直赛道的创客们花更多时间和精力进行钻研。\n　　从大一在海外留学时，他就和几位合伙人达成了共识：未来一定要创业。\n　　回国后，他和几位合伙人在大厂待了三年，于去年年中选择来到上海，作为梦想启航的地方。\n　　倪健峰进入的AI应用赛道看上去有些高大上，他参加徐汇创青春大赛时提交的产品简介是这样的，“产品致力于为生态提供首个人人可用的AI 3D互动生成引擎，确保人人可制作3D互动内容与无限制分享，对于没有3D的用户我们提供当前市面效果最真实的手机扫描与模型优化算法……”\n　　他告诉记者，过往将短视频制作成3D互动模块，成本非常高。一个小产品可能就要花费几万元甚至十几万元。而他们公司的产品可以把成本降到十几元，未来人人可制作3D内容。“3D AI的应用场景十分广阔，打个比方，以前人们装修时想买洗衣机，需要用皮尺丈量，但通过3D AI，可以1:1将心仪的洗衣机复刻到虚拟的家中，用户还可以在虚拟世界中把洗衣机打开，进行交互。AI销售还会针对用户的需求做讲解，形成全新的营销模式。”\n　　经历了无数次失败后，倪健峰率领的团队攻克了数据兼容性低的问题，自研了一套人人可用的系统，哪怕是发二维码给老人，通过手机也可以完成分享。\n　　如果说倪健峰选择的是研发赋能各行各业的AI系统的话，那么李驰、张泽伟、于仕杰从事的领域则更为垂直。\n　　本科主攻数学、统计专业，毕业后从事AI、游戏相关工作的李驰一直在蛰伏等一个创业机会。ChatGPT的出现让他看到了曙光，“机会来了！”\n　　李驰所在的团队开发了一个AI社交游戏平台——萌爪派对。玩家可以扮演一个卡通动物，和AI小伙伴互动，解锁各种社交特权和游戏玩法。“AI NPC的出现颠覆了传统游戏，使得游戏更加拟人化。和AI小伙伴一起种田、钓鱼、聊天，它们会记录你的喜好，有学习能力，打游戏的水平也会共同提高。”\n　　AI进入游戏并非李驰的专利，他表示，现在无论是大厂还是小企业都在做这方面的尝试。大厂耗费大量人力物力财力试图让游戏和AI结合起来。“我们做的则是社交化轻量游戏，和大厂形成差异竞争。”\n　　和李驰一样，从事人生数据库建设的张泽伟避开了越来越卷的数字人赛道，而是在这个赛道中跑出了一个专属垂直赛道。\n　　大学时主攻数字媒体专业的他早在2012年大二时就踏上了创业路。他的第一个创业项目是制作H5小游戏。在游戏设计中张泽伟需要让游戏中的配角根据玩家输入的指令智能化做出反应，由此接触到AI，尽管彼时的AI还不那么智能，他心中隐隐觉得这会是大势所趋。\n　　2020年，张泽伟决定全身心地投入AI领域创业。今年3月份成立“超级头脑”前，他的创业方向为人工智能教育。\n　　有一天，他接到朋友电话称自己父亲去世了，考虑到奶奶已经90岁高龄，怕老人接受不了打击，希望张泽伟帮他做一个父亲的数字分身，给奶奶打视频电话报平安。“说实话，当时我犹豫了很久，此事可能涉及伦理问题。但架不住这么多年交情，我还是答应了他的请求。”\n　　最终，朋友父亲的数字分身成功“骗”到了老人。当老人脸上绽露笑容的瞬间，张泽伟意识到自己做的事挺有价值。慢慢地，为逝者建立数字分身成为了公司一项主要业务。随着业务越做越好，张泽伟数次登上过热搜，公司名声大噪。\n　　“现在我们在做人生数据库。将人的思想、记忆复刻下来，上传到云端。”张泽伟告诉记者，数字人只是一个外形，人所承载的记忆，陪伴功能才具有更大的意义。“这也是我们区别于其他数字人公司的核心竞争力。”\n　　于仕杰的AI创业项目也是和人有关。大学专业学的是核物理的他毕业后换过多份工作，最后阴差阳错成为微信的产品经理。一次和同事的聊天，让他嗅到了商机。对于服装行业的电商来说，要耗费大量时间和经济成本拍摄模特照。而AI生成图片的成本可能只有传统拍摄模式的零头都不到。\n　　“通过这个产品，我们可以让使用者直接看到实物衣服穿在身上的效果。打个比方，对方描述了想要到雪山旅游的需求后，直接可以看到自己在雪山下的穿搭照片。”于仕杰表示，目前市面上比较常见的AI+服装应用大多是制作商家模特图，C端的赛道竞争者并不多，这也给了公司发展的空间。\n　　达观数据副总裁高翔认为，现在AI的创业模式是跟着技术趋势走。对创业者的要求不是踹门，而是门被一脚踢开后，要马上蜂拥入门。“和过去创业模式不太一样的是，过去要讲究技术如何变现，如何产生价值让客户买单。现在开源的大模型降低了技术门槛，在技术环节创业者未必需要百分百自研，而是如何利用技术让想法尽快落地实践。”\n　　高翔比较看好的是小而美的公司。“AI技术的推广让创业不再变成大家抢一块蛋糕，一块蛋糕就那么大，而AI让这个市场变成100块蛋糕。AI可应用在很多细分行业和方向，作为创业者要扩大视野，想想哪些细分领域赛道还不是那么拥挤。”\n　　在高翔看来，如果说大厂是大动脉的话，AI领域的小微企业就是毛细血管，毛细血管之间可以互相合作。\n　　关于盈利\n　　并非所有赛道\n　　都赚得盆满钵满\n　　作为AI领域的创业者，倪健峰表示，自己已经感受到了这个行业的火爆。“可以说，今年是AI垂直领域应用的爆发年，大家都在尝试将大量的AI应用普适化到每个人的生活中。”\n　　站在风口上，周围是数不胜数的诱惑，眼看着公司无法在短时间内获得巨大收益，倪健峰没少挨各种冷脸。夜深人静时，他也曾思索是否要赚笔快钱证明给周围人看。但他还是选择抵住诱惑，“有的创业者喜欢赚快钱，我则喜欢延迟满足。我想要探究这个行业到底发生了什么。想要知其果，更知其因。否则就容易发生一窝蜂而上，最后从高处跌落的情况。”\n　　虽说只有27岁，但创业的这一年来倪健峰头发已近花白。从起初的焦虑到如今的平静，他熬过了一个又一个辗转反侧的夜晚。\n　　这一年很短，这一年也很长。他希望像偶像雷军那样踏实地走下去，而非做一锤子买卖。“目前，我们的产品经历过市场验证已经对外销售了。现在最要紧的是扩大规模，做标准化服务这件事。”\n　　“AI何时成为风口是大家共同努力的结果，风不是一家公司吹起来的。但如果真的站在风口上，我希望自己是吹得最高的那头猪。”倪健峰说。\n　　同样秉持“不想赚快钱”理念的于仕杰坦言，从决定创业的那刻开始，就已经做好短期无法盈利的准备了。“虽说目前项目有些微薄的收益，但和上百万元的启动资金比，实属杯水车薪。由于目前普通用户对AI产品的付费意愿较低，团队在商议后决定暂时关闭微信小程序运营，将更多精力放在和企业客户的对接上。”\n　　对于暂时无法盈利这件事，另一位AI创客李驰的观点是“对淘金者来说，卖铲子的人可能比自己先赚到钱”。他认为，早期一些AI工具使用者利用信息差用AI卖课、写书等，但随着时间的推移，一些专注于自己产品打磨的淘金者才能赚到最多的真金白银。\n　　李驰给记者发来了游戏截图，并透露说，目前萌爪派对已进入内测阶段。游戏的盈利模式很清晰，未来将通过游戏中的商城售卖服装、角色、月卡等。\n　　张泽伟是几位受访的AI创客中少数能赚到钱的。他透露说，尽管公司成立还不到一年，但目前的营收已经达到了1000多万元，净利润高达几百万元。“我们坚定选择了自己的赛道后，各种场景纷纷冒了出来。有很多合作伙伴慕名找上门，让变现变得容易了。”\n　　在盈利的同时，张泽伟强调说，很多时候，公司是无偿服务于客户的，比如说烈士、对社会有重大贡献的人士、绝症患者、留守儿童等。\n　　环顾周围的同行，张泽伟表示，“大部分同行想要盈利比较难，我们是活得比较好的那一批。一方面源于我们选择的赛道没有那么卷，另一方面源于我们的优质服务。”\n　　打开社交媒体，将“AI”作为关键词搜索，诸如“AI创业，年入百万”的帖子数不胜数。但事实上，受访的创业青年均不约而同表示，“不能只看见贼吃肉，而不看见贼挨打。”\n　　看似AI工具的问世正逐步将AI创业的技术门槛降低，吸引了一些创业者入局，希望在AI时代实现财富自由。但在苏辰看来，AI时代的创业并没有拉低创业门槛。\n　　作为一家主营业务是通过AI帮助企业赋能的公司主理人，苏辰却在社交媒体上开设了一个名为“AI下头指南”的视频合集。很多人不理解他的所作所为，认为这是将潜在的客户拒之门外。\n　　之所以频繁地发“劝退帖”，苏辰的观点是：创业的核心仍是考验创业者人（人才）、财（财务）和务（业务）三方面的能力。但很多创业者没有过这三关，只是看到了技术门槛被降低的这一面，就冲进来了。\n　　“AI的出现让生产工具的成本变低了，但是创业者对产品定义的能力、创业者原本在行业的积累怎么变成AI能够理解的语言，再去服务客户，都是核心竞争力。很多创业者并不具备这种能力。”苏辰也遇到过不少创业者怀着一腔热血创业，将产品变现能力置之脑后，最后账上的资金越来越少，只能宣告破产。\n　　对话\n　　上海市人工智能行业协会副秘书长党赞：\n　　"
  },
  {
    "title": "美国意识到问题，中国将要成为全球领导者！时代的革命，马斯克是正确的-百家号",
    "page_body": "闭源迷雾，美方惊醒\n说起AI，现在全球都盯着，尤其是DeepSeek-R1这个模型一出来，就跟扔了颗炸弹似的。2025年1月20日，这款来自中国的开源大模型正式亮相，它用纯强化学习的方式训练，跳过了传统那些费时费力的监督微调，直接在没标注数据的基础上迭代优化。\n结果呢？推理速度快，成本低，数学和逻辑任务上得分直逼OpenAI的o1系列，但训练花的钱和算力才人家的零头。开源一放出来，Hugging Face上仓库star数蹭蹭上涨，全球开发者蜂拥而上，几天内就衍生出一堆自定义版本。\n美国那边，反应来得有点迟钝，但也开始坐不住了。谷歌前CEO埃里克·施密特在2月11日的巴黎AI行动峰会上直言不讳，他接受英国《金融时报》采访时说，西方国家得赶紧搞开源AI，不然就得眼睁睁看着中国在开源领域拔得头筹。\n施密特点名了美国的痛点：除了Meta的Llama，其他大模型像谷歌的Gemini、安thropic的Claude、OpenAI的GPT-4，全是闭源的。高校和研究机构买不起这些昂贵的订阅服务，科研进度就卡壳了。他这话说出口，等于戳中了美企的软肋——花了大把钱建的模型，不肯分享，生态圈子小，创新跟不上趟儿。"
  },
  {
    "title": "人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究课题报告.docx-原创力文档",
    "page_body": "内容提供方 ： 农村女教师180 大小 ： 32.64 KB 字数 ： 约1.69万字 下载次数 ： 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究课题报告\n目录\n一、人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究开题报告\n二、人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究中期报告\n三、人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究结题报告\n四、人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究论文\n人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究开题报告\n一、研究背景意义当前，教育数字化转型已成为全球教育改革的核心议题，人工智能技术与教育的深度融合正深刻重塑教学形态与学习方式，小学英语作为基础教育阶段的关键学科，其教学质量直接影响学生语言核心素养的培育与跨文化交际能力的奠基。然而，传统小学英语教学普遍面临个性化教学供给不足、学习过程数据割裂、学生内生学习动力激发乏力等现实困境，单一的教学评价体系与碎片化的教学资源难以适应新时代“双减”政策下提质增效的教育诉求。在此背景下，人工智能教育平台凭借其数据驱动的精准教学优势，为破解小学英语教学痛点提供了全新路径，而数据共享机制的构建与激励体系的创新设计，则是激活平台价值、实现教育资源优化配置的关键枢纽。数据共享能够打破不同教学主体间的信息壁垒，实现学生学习行为数据、教学反馈数据、资源使用数据的互联互通，为教师精准学情分析、个性化教学方案制定提供数据支撑；激励机制则通过正向引导与价值赋能，激发学生主动参与学习的内驱力，提升教师教学创新的积极性，最终形成“数据赋能教学—激励驱动学习—共享优化生态”的良性循环。因此，探索人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践，不仅是对教育数字化转型路径的深化拓展，更是推动小学英语教育从“标准化灌输”向“个性化培育”转型、实现教育公平与质量协同发展的重要实践探索，具有显著的理论价值与现实意义。在此基础上，研究将聚焦数据共享机制的技术实现与伦理规范、激励策略的多维设计与效果验证，以及二者协同作用下的教学模式重构，为小学英语教育的智能化、个性化发展提供可复制、可推广的实践范式。研究内容将围绕人工智能教育平台数据共享模型的构建、激励机制与小学英语教学特性的适配性设计、应用实践的效果评估三个核心维度展开，具体包括分析现有平台数据共享的瓶颈与需求，设计兼顾安全性与开放性的数据共享架构；结合小学生认知特点与英语学习规律，构建涵盖即时反馈、成就认可、社交激励的多层次激励体系；并通过行动研究法，在真实教学场景中检验数据共享与激励机制对学生学习兴趣、语言能力及教师教学效能的影响，进而优化实践策略。研究思路将遵循“理论建构—模型设计—实践验证—迭代优化”的逻辑主线，首先通过文献梳理与实地调研，明确数据共享与激励机制在小学英语教育中的应用现状与理论缺口；其次，基于教育生态学理论与自我决定理论，构建数据共享—激励协同作用的概念模型；再次，选取典型小学作为实验基地，开展为期一学期的教学实践，通过量化数据（如学习成绩、平台活跃度）与质性材料（如访谈记录、课堂观察）的三角互证，分析机制的有效性与适用性；最后，总结实践经验，提炼数据共享与激励机制在小学英语教育中的应用原则与实施路径，为人工智能教育平台的优化升级与小学英语教学的改革创新提供理论依据与实践指导。\n四、研究设想本研究设想以“数据赋能—激励驱动—生态共建”为核心逻辑，构建人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践体系。在理论层面，拟融合教育生态学、自我决定理论与数据科学，将数据共享机制与激励策略视为协同作用于教学生态系统的关键变量，通过打破传统教学中“数据孤岛”与“动机碎片化”的双重壁垒，形成“数据流动—精准干预—动机激活—能力提升”的闭环路径。实践层面，设想设计“三级联动的数据共享架构”：校级层面建立教育数据中台，整合教务系统、学习平台、家校沟通系统中的学生英语学习行为数据（如词汇掌握频次、口语练习时长、阅读理解正确率等）与教师教学反馈数据（如教案使用率、课堂互动响应度等）；班级层面构建基于区块链技术的轻量化数据共享模块，确保数据在教师、学生、家长间的安全可控流转，例如学生可查看个人学习轨迹图谱，教师能获取班级共性学情标签，家长可实时了解孩子学习进展；个体层面开发动态数据画像工具，通过自然语言处理技术分析学生英语作文、口语录音等非结构化数据，生成包含语言能力、学习风格、情感态度的多维度标签，为个性化激励提供依据。在激励机制设计上，设想构建“三维激励体系”：认知维度设计“阶梯式任务挑战”，将英语学习目标拆解为“每日单词打卡—每周主题对话—每月情景剧表演”等递进式任务，平台根据数据画像匹配难度适中的任务，完成后自动生成可视化成就徽章；情感维度引入“社交化荣誉网络”，通过班级排行榜、小组PK赛、同伴互评点赞等功能，满足学生归属感与成就感需求，例如设置“英语小达人”“互助小老师”等荣誉称号，由平台数据自动评选并在班级圈展示；行为维度强化“即时反馈与长线激励”，结合脑科学原理，对学生的每一次正确发音、流利朗读给予即时虚拟奖励（如经验值、金币），同时设置“成长储蓄罐”，累积奖励可兑换实体学习用品或参与校园英语节活动的资格，形成短期刺激与长期目标的动态平衡。研究设想特别关注机制适配性，针对小学低年级（1-3年级）与高年级（4-6年级）学生的认知差异，设计差异化激励策略：低年级侧重游戏化激励，如通过“英语单词消消乐”“动画配音闯关”等互动游戏，将学习数据转化为游戏进度与角色成长；高年级则强化目标导向激励，结合学生兴趣点（如动漫、体育）定制个性化学习路径，例如为喜欢篮球的学生设计“NBA球星英文播报”任务，完成数据积累后可获得球星签名海报电子券。此外，设想建立“伦理风险防控机制”，通过数据脱敏技术处理学生隐私信息，设置家长权限控制面板，允许家长自主选择数据共享范围与程度，确保数据共享在安全合规的前提下实现教育价值最大化。五、研究进度本研究计划用18个月完成，分为四个阶段推进：第一阶段（第1-3个月）为理论建构与需求调研，重点梳理国内外人工智能教育平台数据共享与激励机制的研究现状，通过文献计量法识别研究空白；选取3所不同类型城市小学（重点小学、普通小学、乡村小学）作为调研对象，采用半结构化访谈法对30名小学英语教师、50名学生及20名家长进行深度访谈，结合问卷调查（发放500份，回收有效问卷450份），分析当前小学英语教学中数据共享的痛点（如教师数据获取效率低、家长对数据安全顾虑）与激励需求（如学生渴望被认可、教师需要教学改进依据）。第二阶段（第4-6个月）为模型设计与工具开发，基于调研结果，联合计算机科学与教育技术专家团队，设计“数据共享—激励协同”概念模型，明确数据采集标准（如《小学英语学习数据元规范》）、共享流程（如“教师申请—平台审核—数据脱敏—授权使用”）与激励类型（物质激励、精神激励、机会激励）的适配规则；利用Python与React技术框架，开发原型系统，重点实现数据画像生成、任务智能匹配、激励动态发放三大核心功能，并邀请2名教育技术专家与5名一线教师进行可用性测试，根据反馈迭代优化系统界面与操作逻辑。第三阶段（第7-15个月）为实践验证与效果评估，选取2所实验校（1所城市小学、1所乡村小学）开展为期一学期的教学实践，每个年级设置实验班（使用人工智能教育平台数据共享与激励机制）与对照班（传统教学模式），每班40人，实验班教师接受为期1周的培训，掌握平台操作与激励策略实施方法；采用混合研究方法收集数据：量化数据包括学生英语期末成绩（听力、口语、笔试）、平台活跃度（日均登录时长、任务完成率）、学习动机量表（AMS）得分；质性数据包括课堂录像（分析师生互动频率与质量）、教师反思日志（记录机制实施中的困难与改进建议）、学生绘画作品（通过“我眼中的英语学习”主题绘画分析情感态度变化）；运用SPSS26.0进行独立样本t检验与回归分析，比较实验班与对照班在学业成绩、学习动机上的差异，通过NVivo12对质性资料进行编码，提炼机制有效性的关键影响因素。第四阶段（第16-18个月）为成果凝练与推广，基于实践数据，优化“数据共享—激励协同”模型，形成《小学英语人工智能教育平台数据共享与激励机制实施指南》，涵盖数据安全规范、激励策略库、典型案例集等内容；撰写研究论文，投稿至《中国电化教育》《电化教育研究》等核心期刊；联合实验校举办教学成果展示会，通过课例观摩、经验分享等形式，向区域内小学推广研究成果，并持续跟踪应用效果，为后续研究提供实践依据。六、预期成果与创新点预期成果包括理论成果、实践成果与应用成果三类：理论成果方面，将构建“数据共享—激励协同”的理论框架，揭示数据流动对小学英语教学生态的重构机制，形成2-3篇高水平学术论文，其中1篇发表于CSSCI来源期刊，出版1部《人工智能教育背景下小学英语数据驱动教学研究》专著；实践成果方面，开发1套具有自主知识产权的人工智能教育平台原型系统，申请2项软件著作权，形成《小学英语学习数据共享标准（草案）》《小学英语激励策略设计指南》各1份，汇编《小学英语人工智能教育应用典型案例集》（收录10个优秀教学案例）；应用成果方面，在实验校形成可复制的小学英语智能化教学模式，学生英语口语表达能力提升20%以上，教师备课时间减少30%，家长对教学满意度达95%以上，为区域教育数字化转型提供实践范本。创新点体现在三个层面：理论层面，首次将数据共享机制与激励机制纳入统一分析框架，突破现有研究“重技术轻教育”或“重单点轻协同”的局限，提出“数据—激励—生态”三维度互动模型，深化了教育人工智能的应用理论研究；实践层面，创新设计“三级联动数据共享架构”与“三维激励体系”，针对小学英语学科特性（如语言习得规律、低龄学生心理特点）开发了游戏化、社交化、个性化的激励策略，解决了传统教学中“数据割裂导致教学粗放”“激励单一难以持续驱动”的现实问题；技术层面，"
  },
  {
    "title": "“AI+健康”点燃消费新动能-企业-中工网",
    "page_body": "工人日报-中工网记者 张玺 通讯员 程志会\n阅读提示\n近年来，人工智能（AI）技术正逐渐渗透到健康管理的各个环节，国内AI健康管理市场也处于快速发展阶段。AI与健康拥抱，擦出耀眼火花的同时，也面临着诸多挑战。\n服务职工健康“零时差”“零距离”的AI助手、2分钟内对人体四五十个器官进行检查的AI健康监测仪、监测睡眠质量的智能手表……近年来，人工智能（AI）技术正逐渐渗透到健康管理的各个环节，国内AI健康管理市场也处于快速发展阶段。\n专业机构预计，中国AI健康管理市场规模将超万亿元。“AI+健康”点燃了消费新动能，正在成为拉动内需的又一增长点。\nAI助力健康管理\n职工王先生体检报告显示尿酸指标高。他登录“津工智疗”服务助手，输入“我体检尿酸高怎么办？”服务助手根据国家卫健委有关指南和天津市职工医院专业建议，提供了综合管理方案。\n“以前咨询体检结果要专门请假跑医院，现在可以直接和服务助手对话，它给出的管理方案包括饮食管理、生活方式干预、医疗干预建议等，非常全面，带给我全新体验。”王先生感慨道。\n“津工智疗”服务助手是天津市职工疗休养中心为职工打造的专属智慧疗休养服务平台。\n该平台利用AI技术突破传统服务模式，打破时间与空间限制，通过整合医疗资源数据库、疗养服务知识图谱和会员权益系统，实现语音交互、语义理解、智能推荐等核心功能，形成咨询—预约—服务—反馈全流程闭环，实现从体检预约咨询、职业病防治到疗休养咨询全覆盖。自今年2月28日上线至今，服务助手累计对话千余次，助力职工健康管理。\n日前，天津医科大学总医院联合中国移动天津公司完成深度求索（DeepSeek）“智算一体机”部署。这是天津综合医院里首个完成深度求索本地化部署的三甲医院。\n该院深度求索本地化部署后，将通过定制化算力服务支撑老年专慢病综合评估检测、体检AI报告生成、预住院次序筛查、互联网医院专病管理、医疗影像分析等核心业务场景，充分满足医疗场景中高精度模型推理与高并发实时交互需求，推动医疗服务的智能化、个性化和精准化，实现从单点实验到全流程部署的跨越。\n目前，AI已经被越来越多的医疗机构应用到医疗服务中。\n据不完全统计，目前我国已有超过100家医院完成深度求索的本地部署，遍布天津、北京、上海、安徽等20多个省份。\nAI重塑健康管理消费生态\n“刚看到这个机器我觉得挺新奇的，从收集信息到分析完成、显示结果，用时不到3分钟，检查结果全面准确，检查完还收到日常作息和饮食的科学建议。”天津一位中学教师刘璐璐说。\n刘璐璐所说的机器是一台AI健康监测仪，是智汇云界科技发展有限公司与中国中医科学院信息所联手研发的AI健康管理平台。\n该平台分析了几千万条中医临床数据样本，通过采集眼白图像、面部图像、手部脉搏等信息，对受检者的呼吸、消化、心血管等系统器官健康情况进行判断，并提供个性化健康方案和诊疗方向。\n“除了为教师健康护航，我们还在河西区的一些工会驿站放置AI健康监测仪，可以有效针对外卖员、快递员等群体的职业病，如呼吸系统疾病、消化系统疾病进行全面评估，帮助他们了解身体状况。”智汇云界有关负责人介绍说。\n此外，该公司还开发了AI血常规智能健康风险评估系统，可根据各项疾病的发病风险进行概率预警，并精准划分风险等级。目前，该系统对白血病和宫颈癌诊断准确率均在90%以上，抑郁症诊断准确率达到85%以上。\n从疾病预防、诊断到治疗、康复，从智能健康设备到个性化健康管理服务，从健康数据服务到智能硬件制造……AI正逐渐渗透到健康管理的各个环节，为重塑健康消费生态打开了新的空间，释放着巨大的智慧健康产品的消费潜力。专业机构预计，2027年中国AI健康管理市场规模预计增至2.59万亿元，年复合增长率超20%。\n智能生成个性化方案的AI按摩椅、实时提醒坐姿的视力仪、无创血糖仪……如今，“AI+健康”产品越来越受到消费者的青睐，同时一批“AI+健康”应用和产品也下沉到基层，重塑服务链条。\n据智汇云界负责人介绍，该公司将与河西医院及14家社区卫生服务中心深度合作，把技术服务延伸到基层，辅助医师提升二级医疗机构和基层医疗机构的诊疗能力，同时让居家养老的老年人及时了解身体状况，让AI为健康赋能。\n今年的《政府工作报告》提出，“持续推进‘人工智能+’行动，将数字技术与制造优势、市场优势更好结合起来，支持大模型广泛应用”。\n2024年11月，国家卫生健康委联合国家中医药管理局、国家疾控局印发了《卫生健康行业人工智能应用场景参考指引》，明确了84个细分领域的基本概念和应用场景，为“人工智能+医疗健康”提供规范化的发展路径。\n“AI+健康”面临挑战\n超万亿元的AI健康管理市场，为健康类AI技术迭代提供了丰富场景。AI与健康拥抱，擦出耀眼火花的同时，也面临着诸多挑战。如数据安全与隐私保护问题、AI是否会导致医生“下岗”、AI赋能医疗的边界在哪里、如何避免技术滥用问题等。\n针对医疗数据隐私保护的特殊要求，天津医科大学总医院采用“端-边-云”三级安全防护体系，构建符合医疗数据合规要求的算力基座，同时通过硬件级可信执行环境、动态数据脱敏、全链路加密传输及访问控制技术强化敏感信息保护。此外，系统还支持医疗数据本地化处理与分级存储，确保患者隐私信息与核心诊疗数据零外泄。\n今年年初，全国首个“AI儿科医生”在国家儿童医学中心北京儿童医院正式上线应用。在10名患儿的诊断中，“AI儿科医生”给出的建议与专家组会诊结果吻合度较高。这也引发了人们对AI是否会导致医生“下岗”等问题的思考。\n其实，早在2022年，国家卫生健康委和国家中医药局联合发布《互联网诊疗监管细则（试行）》，规定医疗机构开展互联网诊疗活动，处方应由接诊医师本人开具，严禁使用人工智能等自动生成处方。这意味着，目前AI并不具备处方权，只能提供诊疗建议，最终的诊疗方案仍需医生本人把关。\n当AI大模型技术给医疗和健康带来切身可感的利好、掀起“全民追捧”热潮的同时，有关专家呼吁相关部门尽快出台医疗数据采集、存储、共享的相关规范和监管标准，避免技术滥用。\n同时，加强对算法准确性、公平性、透明度等关键维度的评估与监管力度，确保人工智能的安全性和有效性，提供更加优质的应用体验和便捷的健康服务。"
  },
  {
    "title": "美的一天净赚近1.5亿 多家B2B公司增收又增利丨产业互联网周报-B2B-亿邦动力",
    "page_body": "【亿邦原创】美的一天净赚近1.5亿；多家B2B公司增收又增利；DeepSeek被曝开发AI智能体模型：能自主完成多步工作。\n整理丨胡璞心\n# 过去一周，发生了这些事 #\n1 卓尔智联半年业绩：营收利润双增长，CIC与中农网业绩亮眼\n8月29日晚，卓尔智联发布2025年上半年业绩报告。报告期内，卓尔智联营收909.21亿元，同比增长33.17%；净利润6997.20万元，同比增长71.67%。\n具体来说，卓尔智联目前拥有两大核心增长引擎——全球化大宗贸易平台CIC与深耕农产品供应链的中农网表现尤为亮眼。其中，世界商品智能交易中心（CIC）今年上半年实现营收约322亿元，收入规模跃居几大供应链平台之前列。中农网的增长则源于核心主业的韧性巩固与新兴高附加值品类的成功拓展，报告期内营收245亿元。\n2 齐心集团半年报：服务超60家央企，AI重塑组织管理\n8月30日，齐心集团发布2025年半年报，报告显示，齐心集团实现营业收入47.73亿元，归母净利润8749.30万元，经营活动现金流量净额达到1.2亿元，持续保持现金流入。在行业持续承压的大环境下，齐心集团各项业绩指标保持稳健。AI及数字化转型、精细化服务等成果显著。\n据悉，齐心集团聚集了8万多家优质客户资源，赢得了200多家头部大型客户的信赖，其中当前100家央企中，已服务超60家。齐心集团还通过AI全面降本增效提高效率，在市场分析、招投标、客户询价、供应寻源、商品上架、履约供货、结算对账等关键环节，通过AI技术，提升客户响应与供应链效率，有效降低运营成本与人工失误。\n3 极智嘉半年报：经调整EBITDA转正，全球化布局效果显著\n8月29日，极智嘉发布截至2025年6月30日止六个月的未经审计中期业绩。报告显示，公司收入同比增长31.0%至人民币10.25亿元，毛利同比增长43.1%至人民币3.6亿元，亏损净额大幅收窄超90%，经调整EBITDA（非国际财务报告准则计量）转正至人民币1162万元。\n业务方面，公司录得订单人民币17.60亿元，同比增长30.1%，并斩获超亿元大订单，同时在大客户复购、新客户、新行业及新渠道拓展方面均实现突破性进展。\n4 一天净赚近1.5亿，美的集团回应：公司估值被低估了\n8月29日，美的集团发布了2025年中期业绩报告：上半年营业总收入2523亿元，同比增长15.7%，实现归母净利润260亿元，同比增长25%，平均下来，相当于一天净赚近1.5亿元。“我们最近股价表现不如大盘。美的属于比较稳健的股票，股价波动不大；在当前市场比较好的情况下，投资者可能会选择成长更快的（股票）。”美的集团董事会秘书高书在接受采访时表示，“我们认为公司估值被低估了，所以才会进行回购操作。”\n5 宇树科技计划今年四季度提交IPO申请，四足机器人占营收65%\n9月2日，宇树科技宣布，预计将在2025年10月至12月期间向证券交易所提交上市申请文件，届时公司的相关运营数据将正式披露。宇树科技表示，以2024年为例，四足机器人、人形机器人和组件产品的销售额分别占约65%、30%和5%。\n其中，约80%的四足机器人被应用于研究、教育和消费领域，而剩余的20%则被用于工业领域，如检查与消防。人形机器人完全用于研究、教育和消费领域。\n6 四足机器狗化身“机器狼”亮相九三阅兵\n9月3日，一款叫做“机器狼”的无人作战装备亮相九三阅兵，由四足机器狗加装上武器或侦察设备进化而成。“机器狼”出现在陆上无人作战方队。央视解说词提到：受阅装备为侦打突击、扫雷排爆、班组支援等无人战车，可远程操控、自主行动、灵活编组，实现陆上有人、无人协同作战新突破。\n公开报道显示，“机器狼”的原型是一款由中国兵器装备集团旗下公司研制的四足机器狗，在2024年11月珠海航展上首次对外亮相。这款机器狗可以扛起最高20公斤的物体，续航里程约10公里，运行时间约2.5小时，能在30秒内完成电池更换。它还能在40度的陡坡爬行，能越过30厘米高的障碍物，在废墟上如履平地，从而适应复杂地形环境。\n7 淘宝测试AI电商导购服务“帮我挑”\n继AI万能搜后，淘宝在AI电商导购服务上又有了新的尝试。目前，淘宝APP正在测试AI电商导购功能——“帮我挑”。该服务由杭州淘宝营销管理有限公司打造，在淘宝APP原搜索功能上对电商搜索导购方式进行迭代的创新尝试，旨在结合用户输入，通过生成合成类算法为用户提供更符合用户消费需求的商品或内容。据悉，“帮我挑”服务入口是以一个淘宝机器人的形象，悬浮在淘宝APP的商品搜索结果页的下方。\n8 腾讯优图开源智能体框架Youtu-Agent，开箱即用！\n腾讯优图实验室开源Youtu-Agent智能体框架，具备开源友好、成本低、灵活架构和自动智能体生成等特点；该框架在WebWalkerQA基准上使用DeepSeek-V3.1达到71.47%准确率刷新开源效果SOTA，在GAIA文本子集达到72.8%，无需充值闭源模型；框架采用DITA原则，提供四个典型应用案例：本地文件管理、数据分析、论文分析和广域综述，支持一键生成配置和启动测试。\n9 美团开源龙猫大模型，5600亿参数MOE\n美团开源龙猫大模型LongCat-Flash，采用5600亿参数MoE架构，创新引入“零计算专家”和ScMoE，大幅提升效率与速度；模型在MMLU、ArenaHard、CEval等基准中表现接近甚至超越DeepSeek V3.1与Qwen3，尤其在指令遵循与Agent任务上排名领先；支持128k上下文、推理速度超100TPS、成本仅0.7美元/百万词元，已在Hugging Face和GitHub开源，MIT协议开放使用。\n10 DeepSeek被曝开发AI智能体模型：能自主完成多步工作\n9月5日，据媒体报道，DeepSeek正在研发一款更为先进的AI智能体模型，希望在与OpenAI等竞争对手在这一新兴技术领域展开竞争。据匿名人士透露，DeepSeek正在开发的模型只需用户给出简单指令，即可自动完成多步骤任务。这些人士还表示，该系统具备从以往操作中学习并自我改进的能力。\n上月 21 日，DeepSeek正式发布并开源了DeepSeek-V3.1，该模型将上下文窗口扩展至128K，参数量约为685B，用户可通过官方网页、APP及小程序进行测试，API接口调用方式保持不变。\n# 这些公司获得了新的融资 #\n1 斗象科技完成2亿元桥梁战略轮融资\n斗象科技是一家网络安全数据分析与在线安全运营提供商，新一代网络安全企业。斗象旗下业务品牌包括：安全数据分析与在线安全运营产品体系“斗象智能安全”，安全众测与安全运营服务平台“漏洞盒子”，网络安全行业门户“FreeBuf”网站和APP。斗象科技近日完成新一轮2亿元桥梁战略轮融资，由钟鼎资本独家投资。斗象科技CEO谢忱表示，本轮融资将进一步加大公司在AI安全技术与平台安全智能方向的研发投入，稳步推进长期战略布局，并为后续更大规模的资本计划和IPO进程奠定基础。\n2 高信资本战略投资星河动力\n星河动力是一家商业运载火箭研发商，定位于低成本商业火箭发射，其研制的固体运载火箭起飞质量30吨，近地轨道运载能力350公斤，采用三级固体推进加液体上面级构型，具备太空摆渡和主动离轨能力，可以满足微小卫星或试验载荷的发射。近日，高信资本完成对星河动力的战略投资，总投资金额超1亿元。\n3 Obita完成超千万美元天使轮融资\nObita是一家企业级跨境支付与数字金融网络开发商。公司以合规稳定币为核心，正在搭建Obita Mesh框架下的区块链原生支付网络，让全球企业享有低成本、实时到账、可监管的结算体验。Obita将企业级合规体系、跨境清算网络与一体化资金管理工具深度融合，重塑跨境贸易、跨境电商及供应链平台的资金流动方式，并率先布局东南亚、中亚、非洲与拉美等高增长市场。\n近日，Obita 宣布完成超千万美元天使轮融资，由元璟资本与Mirana Ventures联合领投，君联资本、HashKey Capital、Web3.com Ventures 等知名机构及个人跟投。本轮资金将重点用于核心系统研发、合规建设及市场拓展，加速全球稳定币跨境支付网络的布局。\n4 北京机器人产业发展投资基金完成对松延动力的数千万元人民币追加投资\n松延动力Noetix Robotics专注于人形机器人研发与制造，公司致力于通用人工智能本体，机器人仿生，以及具身操作系统等多个方向的研发。近日，首程控股旗下北京机器人产业发展投资基金宣布对人形机器人企业「松延动力」完成数千万元人民币追加投资，这是继2024年3月首轮投资后的再次加码。此次投资将用于支持松延动力在机器人本体优化、仿生人脸迭代及规模化应用推进。\n5 智动力机器人获得A轮融资，招银国际投资\n无锡智动力是一家专注于人形机器人核心部件和移动机器人动力模组研发、设计、生产及销售的国家高新技术企业。致力于为机器人行业提供高性能、高可靠核心动力模组以及人形机器人本体整体解决方案。已建立完善的机器人核心部件产品矩阵，涵盖人形机器人的高功率密度低压伺服驱动、高扭矩密度关节模组、高可靠力控关节模组、双差速线控底盘、高性能力控人形臂，以及工业移动机器人的智动轮、舵轮模组、AGV旋转模组、顶升模组等核心产品。近日，智动力机器人获得A轮融资，招银国际投资。\n6 汇创人力完成2850万元A轮融资\n汇创人力是一家面向全国的人力资源综合解决方案提供商，业务已全面覆盖劳务派遣、岗位外包、灵活用工、招聘猎头、培训咨询及社保代理等多维度服务，为各类大中小企业、政府机构及事业单位提供高度定制化的人力资源支持。近日，汇创人力完成2850万元人民币A轮融资，本轮投资由惠财资本独家注资。此次融资将主要用于加强技术研发、深化区域市场覆盖及完善人力资源全链条服务体系，标志着汇创人力在专业化与数字化并行的发展道路上迈出关键一步。\n7 脑韵科技完成千万级天使轮融资\n脑韵科技是一家横跨脑机接口与消费电子领域的创新科技公司。公司以“入耳式脑机接口”技术为核心，专注打造全球脑健康可穿戴AI设备。深度融合脑机接口、人工智能技术和消费电子产品形态，成功打造出全球首款入耳式脑电耳机。近日，脑韵科技宣布完成千万级天使轮融资。本轮投资方包括云米科技、伴飞脑科学孵化器以及上市公司的家办，山云资本担任公司的长期财务顾问。\n8 新研智材完成千万级种子轮融资\n新研智材是一家AI驱动材料研发商，以“材料大模型平台”为技术核心，致力于将AI for Science应用到新材料，清洁能源，半导体封装等产业研发领域。近日，新研智材完成千万级种子轮融资。本轮由晶瑞新材与基石浦江资本联合投资，资金将用于AI算法迭代、顶尖人才引进及半导体材料等场景的产业化落地，加速推进与行业龙头企业的深度协同。\n9 智用开物获得战略投资\n智用开物是一家多智能体解决方案厂商，核心产品 AI Agent Foundry 为企业应用 AI 提供强大中间平台支持，已在教育、制造业等多领域广泛应用。近日，智"
  },
  {
    "title": "DeepSeek的一次小更新，堪比发布新模型。-搜狐",
    "page_body": "一个好消息，时隔俩月， DeepSeek 终于更新了。\n就在昨天晚上， DeepSeek 一声不吭往 Hugging Face 上扔了个 DeepSeek -V3-0324 模型。\n模型参数 6850 亿，跟上一个版本的 V3 （ 6710 亿 ）相差不大，采用 MoE 架构，还支持了更开放的 MIT 开源协议。\n根据官方更新的版本说明， DeepSeek -V3-0324 主要是针对推理能力和前端开发能力进行了加强，写作风格实现了跟 R1 对齐，另外还有一些其他方面的小优化。\n现在打开 DeepSeek 官网， 把深度思考模式关掉就能直接用上 V3-0324 。\n不过有一说一，虽然 V3-0324 仅仅只是 V3 的小版本升级，并不是大伙儿期待已久的 V4 或者 R2 ，且官方账号也没有发布任何跟模型有关的信息。\n但也丝毫不妨碍， V3-0324 一上线，就有人说他的代码能力，直追克劳德。\n新版本的模型刚一上传，就登上了 Hugging Face 的趋势榜单。\n在国外大模型竞技场 KCORES 的测评中， V3-0324 的代码能力得分 328.3 ，超过了普通版的 Claude 3.7 Sonnet 的 322.3 分，接近 Claude 3.7 Sonnet 思维链版本的 334.8 分，排名第三。\n图源 @karminski 牙医\n重点是，排名在前面的模型压根就没几个开源免费的， V3-0324 可谓是一枝独秀。\n所以在 V3-0324 上线不到一天的时间里，就已经有很多老哥迫不及待上手测评了一波。\n这么说吧， V3-0324 在这些人手里，  已经成了拳打 o3-mini ，脚踢 Claude 3.7 Sonnet 的存在。\n经典的小球弹跳测试中，这位老哥把 V3-0324 、 o3-mini 和 R1 拉了个横评。\no3-mini 刚开始看着还不赖，但估计物理没学好，外面的六边形都转到垂直的位置了，球还不知道往下掉。\nR1 的表现，也是有些让人摸不着头脑。。\n相对来说， V3-0324 生成的结果是表现最好的，这位老哥丝毫不吝啬对它的夸奖，说它 “ 表现得像唯一排名第一的非推理模型 ” 。\n让 V3-0324 生成一个网页，模型一口气写了 800 多行代码，运行的时候还没有出错，这什么实力不用多说了吧。\n在评论区底下，有人仅仅下达了编写登录页面的简单指令，并没有任何其他的附加提示，同样也生成了一个完整的登录页面。\n还说 V3-0324 在编码上，能跟 Claude 3.7 Sonnet 掰一掰手腕。\n更别提其他的模型，性价比各方面相比下来，现在 OpenAI 的 o1-pro 和 GPT-4.5 ，都已经不香了。\n反正看了几个网友的测试案例之后，世超对 V3-0324 的前端代码生成能力，已经有了初步的判断。\n但不管咋说，没亲自上过手的东西，咱硬夸也有点心虚。所以这次世超也打算简单试一试，看看 V3-0324 到底有多能打。\n一上来，世超就让模型做了一个画板，提示词是 “ 帮我用 HTML 代码构建一个画板，支持鼠标绘制、橡皮擦功能和颜色选择 ” ，这次出战的模型是 V3-0324 和普通版 Claude 3.7 Sonnet 。\n只能说，这把 Claude 3.7 Sonnet 赢得很彻底。 光是有取色器这一点，就甩了 V3-0324 不知道几个车尾灯。\n更别提 UI 设计了， V3-0324 做出来的画板让世超不是很有创作的欲望。。。\n世超着实是没想到，这盆凉水来得这么快，都让我有点怀疑到底是我的提示词没写好，还是模型有问题了。。。\n不过，我后面又继续把小球弹跳的提示词，分别喂给了 DeepSeek-V3-0324 、普通版 Claude 3.7 Sonnet 还有 DeepSeek-V3 。\n这下味儿终于对了。V3-0324 生成的结果确实牛叉，能很清楚地看到小球在下落触底的时候，产生了小幅度的弹跳。\n就是吧，老版本的 V3 压根没运行起来。。。只能说两个版本之间的差距高下立判了。\n再来看普通版 Claude 3.7 Sonnet 的结果，优点是底下的转速、重力和摩擦力都是可调节的，弹跳看起来也没什么大问题，但小球有点出画面了。。。\n最后，世超又分别让 V3 和 V3-0324 生成一个 Saas 登录页面，提示词就一句话，没有任何的附加信息。\n可以看到， V3 的页面倒是做出来了，但没什么设计可言。\n反观 V3-0324 ，果然就跟官方的版本更新说明一样，生成的网页更美观了。\n综合看下来， V3-0324 的代码能力相比 V3 确实有了比较大的提升，而且在一部分测试案例中，也能够比肩普通版 Claude 3.7 Sonnet 。\n但如果要说完全超越 Claude 3.7 Sonnet ，那世超觉着暂时还不太行。\n不过大伙儿也别忘了，  V3-0324 在开源这个赛道里， V3-0324 已经算得上能打的了。\n而且 DeepSeek 的 API 价格业主打的一个便宜。世超对比了 Claude 3.7 Sonnet 和 V3-0324 的 API 价格， V3-0324 百万 tokens 输入的价格是 2 元，百万 tokens 输出的价格是 8 元，而同样的 tokens 数， Claude 3.7 Sonnet 的输入和输出价格分别是 36.6 元和 108.9 元，价差最多有 18 倍。\n所以在某种程度上， V3-0324 这个小更新，的确可以跟 Claude 3.7 Sonnet 媲美。\n特别是今天晚上，DeepSeek官方还发文，正式介绍了这波小更新，在数学、代码类的相关评测上， V3-0324比OpenAI目前最厉害的非推理模型GPT-4.5都要更胜一筹。\n去年 12 月底 V3 上线，紧接着 R1 就在过年的时候上桌吃饭了。如果按照 DeepSeek 之前发布模型的节奏，盲猜一波 R2 也快了。\n总之，小版本更新的 V3-0324 就已经如此强悍了，就是不知道，在 DeepSeek 猛烈的开源炮弹下， “OpenAI 们 ” 还遭不遭得住了。\n撰文 ：西西\n编辑 ：江江&面线\n美编 ：萱萱\n图片、资料来源 ：\nDeepSeek、X、Reddit"
  },
  {
    "title": "后GPT 3.0时代，主流大模型技术精要详解_澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "机器之心转载\n来源：知乎\n作者：张俊林\n洋洋洒洒近三万字，中国中文信息学会理事、中科院软件所博士、新浪微博机器学习团队新技术研发负责人的张俊林回顾了大型语言模型（LLM）的发展历程、技术迭代更新以及未来走向等方方面面的内容，并探讨了通过超大 LLM 实现通用人工智能（AGI）的可能性。\nChatGPT 出现后惊喜或惊醒了很多人。惊喜是因为没想到大型语言模型（LLM,Large Language Model）效果能好成这样；惊醒是顿悟到我们对 LLM 的认知及发展理念，距离世界最先进的想法，差得有点远。我属于既惊喜又惊醒的那一批，也是典型的中国人，中国人善于自我反思，于是开始反思，而这篇文章正是反思的结果。\n实话实说，国内在 LLM 模型相关技术方面，此刻，距离最先进技术的差距进一步加大了。技术领先或技术差距这事情，我觉得要动态地以发展的眼光来看。在 Bert 出现之后的一到两年间，其实国内在这块的技术追赶速度还是很快的，也提出了一些很好的改进模型，差距拉开的分水岭应该是在 GPT 3.0 出来之后，也就是 2020 年年中左右。在当时，其实只有很少的人觉察到：GPT 3.0 它不仅仅是一项具体的技术，其实体现的是 LLM 应该往何处去的一个发展理念。自此之后，差距拉得越来越远，ChatGPT 只是这种发展理念差异的一个自然结果。所以，我个人认为，抛开是否有财力做超大型 LLM 这个因素，如果单从技术角度看，差距主要来自于对 LLM 的认知以及未来应往何处去的发展理念的不同。\n国内被国外技术甩得越来越远，这个是事实，不承认也不行。前阵子网上很多人担忧说国内 AI 现在处于 “危急存亡之秋”，我觉得倒也不至于这么严重。君不见，这个世界上，具备这么超前眼光的只有 OpenAI 一家吗？包括 Google 在内，其实对于 LLM 发展理念的理解，明显都落后 OpenAI 一个身位。现实是 OpenAI 表现过于优秀，把所有人都甩开了，不仅仅是国内。\n我觉得，OpenAI 对 LLM 在理念及相关技术方面，领先国外的 Google、DeepMind 大约半年到一年的时间，领先国内大概两年左右的时间。在 LLM 这个事情上，感觉梯队很明显，Google 应该是排在第二位，最能体现 Google 技术眼光的是 PaLM 和 Pathways，推出时间大概在 22 年 2 月到 4 月间，同一时期，OpenAI 推出的却是 InstructGPT，从这里就可以看出 Google 和 OpenAI 的差距了，至于为何这么说，你看了我后面的正文后大概能理解。DeepMind 之前的重心一直在强化学习攻克游戏和 AI for science 这些方面，切入 LLM 其实很晚，应该是 21 年才开始重视这个方向，目前也处于追赶状态。Meta 就更不用说了，重心一直不在 LLM 上，目前感觉也发力开始追赶。这还是目前做得最好的一批机构，尚且如此，更何况国内呢？我觉得情有可原。至于 OpenAI 关于 LLM 的理念是什么，我在本文的最后一部分，会谈谈我的认知。\n本文梳理自 GPT 3.0 出现之后的主流 LLM 技术，在此之前的主流技术可以参考「」。\n我相信看完这两篇文章，能够让您对 LLM 领域的技术脉络，LLM 技术发展过程中出现过的不同发展理念，乃至未来可能的发展趋势，有比较清晰的认知。当然，很多地方讲的内容是我个人看法，有很大的主观性，错漏难免，所以还请谨慎参考。\n本文试图回答下面一些问题：ChatGPT 是否带来了 NLP 乃至 AI 领域的研究范式转换？如果是，那会带来怎样的影响？LLM 从海量数据中学到了什么知识？LLM 又是如何存取这些知识的？随着 LLM 规模逐步增大，会带来什么影响？什么是 In Context Learning? 为什么它是一项很神秘的技术？它和 Instruct 又是什么关系？LLM 具备推理能力吗？思维链 CoT 又是怎么做的？等等，相信看完，能让您对这些问题有一个答案。\n首先，在谈 LLM 技术现状前，先宏观地谈下我心目中的研究范式转换问题。这样，我们才能 “先见森林，再见树木”，对具体技术为何会是如此变化有个更清晰的认知。\n潮流之巅：NLP 研究范式的转换\n如果我们把时间线往前拉得更长一些，回到 NLP 领域的深度学习时代，在更长时间窗口内观察技术变迁及其影响，可能会更容易看清其中的一些关键节点。我个人认为，在最近 10 年来 NLP 领域的技术发展过程中，可能存在两次大的研究范型转换。\n范式转换 1.0: 从深度学习到两阶段预训练模型\n这个范式转换所涵盖的时间范围，大致在深度学习引入 NLP 领域（2013 年左右），到 GPT 3.0 出现之前（2020 年 5 月左右）。\n在 Bert 和 GPT 模型出现之前，NLP 领域流行的技术是深度学习模型，而 NLP 领域的深度学习，主要依托于以下几项关键技术：以大量的改进 LSTM 模型及少量的改进 CNN 模型作为典型的特征抽取器；以 Sequence to Sequence（或叫 encoder-decoder 亦可）+Attention 作为各种具体任务典型的总体技术框架。\n在这些核心技术加持下，NLP 领域深度学习的主要研究目标，如果归纳一下，是如何有效增加模型层深或模型参数容量。就是说，怎么才能往 encoder 和 decoder 里不断叠加更深的 LSTM 或 CNN 层，来达成增加层深和模型容量的目标。这种努力，尽管确实不断增加了模型层深，但是从解决具体任务的效果角度看，总体而言，不算很成功，或者说和非深度学习方法相对，带来的优势不算大。\n深度学习之所以不够成功，我认为主要原因来自于两个方面：一方面是某个具体任务有限的训练数据总量。随着模型容量的增加，需要靠更大量的训练数据来支撑，否则即使你能把深度做起来，任务效果也做不上去。而在预训练模型出现之前，很明显这是 NLP 研究领域一个严重问题；另外一个方面是 LSTM／CNN 特征抽取器，表达能力不够强。意思是就算给你再多的数据也没用，因为你不能有效地吸收数据里蕴含的知识。主要应该是这两个原因，阻碍了深度学习在 NLP 领域的成功突围。\nBert/GPT 这两个预训练模型的出现，无论在学术研究角度看，还是工业应用角度来看，都代表了 NLP 领域的一个技术飞跃，并带来了整个领域研究范式的转换。这种范式转换带来的影响，体现在两个方面：首先，是部分 NLP 研究子领域的衰退乃至逐步消亡；其次，NLP 不同子领域的技术方法和技术框架日趋统一，在 Bert 出现后一年左右，技术栈基本收敛到两种技术模式中。关于这两点，我们分头来谈。\n影响一：中间任务的消亡\nNLP 是一个宏观研究领域的统称，里面有五花八门具体的子领域与子方向，如果仔细分析，从任务的性质角度，可以把这些任务分成两大类：一类可以叫做 “中间任务”，一类可以称为 “最终任务”。\n典型的中间任务包括：中文分词、词性标注、NER、句法分析、指代消解、语义 Parser 等，这类任务一般并不解决应用中的实际需求，大多数是作为那些解决实际需求任务的中间阶段或者辅助阶段存在的，比如几乎没有需求说，我要一个句法 Parser，把这个句子的句法分析树给用户看看，用户不需要看到这些 NLP 的中间阶段处理结果，他只关心某个具体任务你有没有干好。“最终任务” 包括比如文本分类、文本相似性计算、机器翻译、文本摘要等等，有很多。这类任务的特点是每个子领域都解决某个实际需求，任务结果基本能直接呈现给用户，比如用户确实存在给你一句英文，告诉他中文是什么的需求。\n按理说，“中间任务” 就不应该出现，而之所以会存在，这是 NLP 技术发展水平不够高的一种体现。在技术发展早期阶段，因为当时的技术相对落后，很难一步做好有难度的最终任务。比如机器翻译，早期技术要做好机器翻译是很困难的，于是科研人员就把难题分而治之，分解成分词、词性标注、句法分析等各种中间阶段，先把每个中间阶段做好，然后再拼起来完成最终任务，这也是没办法的事情。\n但是自从 Bert／GPT 出现之后，其实就没有必要做这些中间任务了，因为通过大量数据的预训练，Bert／GPT 已经把这些中间任务作为语言学特征，吸收到了 Transformer 的参数里，此时我们完全可以端到端地直接解决那些最终任务，而无须对这种中间过程专门建模。这里可能争议最大的是中文分词，其实道理也是一样的，哪些字应该组成一个词，这个其实你不用管，让 LLM 自己当特征去学就行了，只要对于解决任务有帮助，它自然会去学该学的合理分词方式，也未必一定要和我们人类理解的分词规则相同。\n基于以上认知，其实在 Bert/GPT 一出现，你就应该得出这类 NLP 的中间阶段的任务，会逐步退出历史舞台这个结论。\n影响二：不同研究方向技术路线的统一\n在说明具体影响前，我们先讨论下另外一种 NLP 任务划分方式，这对于理解后面内容有帮助。如果对 “最终任务” 进一步进行分类，又大致可以分为两大不同类型的任务：自然语言理解类任务和自然语言生成类任务。如果排除掉 “中间任务” 的话，典型的自然语言理解类任务包括文本分类、句子关系判断、情感倾向判断等，这种任务本质上都是分类任务，就是说输入一个句子（文章），或者两个句子，模型参考所有输入内容，最后给出属于哪个类别的判断。自然语言生成也包含很多 NLP 研究子方向，比如聊天机器人、机器翻译、文本摘要、问答系统等。生成类任务的特点是给定输入文本，对应地，模型要生成一串输出文本。这两者的差异主要体现在输入输出形式上\n自从 Bert/GPT 模型诞生后，出现了明显的技术统一趋向。首先，NLP 中不同的子领域，其特征抽取器都逐渐从 LSTM/CNN 统一到 Transformer 上。其实，自 Bert 公开后不久，就应该意识到，这必然会成为技术趋势。至于其原因，在几年前我写的这篇「张俊林：放弃幻想，全面拥抱 Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较」中做了说明和分析，感兴趣的同学可参考。\n文章链接：https://zhuanlan.zhihu.com/p/54743941\n而且，目前 Transformer 不仅统一了 NLP 诸多领域，也正在逐步地替换图像处理各种任务中被广泛使用的 CNN 等其它模型的进程之中，类似的，多模态模型目前也基本都采用了 Transformer 模型。这种 Transformer 从 NLP 出发，攻城略地逐步统一 AI 越来越多领域的趋势，起始于 2020 年底出现的 Vision Transformer (ViT) ，之后蓬勃发展，到目前已大获成功，且其继续向更多领域拓展的势头会越来越迅猛。\n其次，大多数 NLP 子领域的研发模式切换到了两阶段模式：模型预训练阶段 + 应用微调（Fine-tuning）或应用 Zero／Few Shot Prompt 模式。更准确地说，NLP 各种任务其实收敛到了两个不同的预训练模型框架里：对于自然语言理解类任务，其技术体系统一到了以 Bert 为代表的 “双向语言模型预训练 + 应用 Fine-tuning” 模式；而对于自然语言生成类任务，其技术体系则统一到了以 GPT 2.0 为代表的 “自回归语言模型（"
  },
  {
    "title": "大模型out了，小模型（SLM）爆火，撕开99%企业市场？-36kr",
    "page_body": "大模型是能力上限，小模型是落地首选\n对于猎豹移动CEO傅盛来说，他今年最呼吁的一件事情，正在成为潮流——小模型逐渐成熟，成为企业落地商业化主力军，这令他十分开心。\n可能很多人会困惑，大模型（LLM）正火的当下，什么是小模型（SLM）？ 目前，市场通常将参数规模远少于GPT-4或Llama-13B的千亿大语言模型，一般参数只有1.5B、3B、7B的模型称为小大模型。\n要说小模型现在有多火，仅仅7月下半月，4家科技公司纷纷推出自己的小模型。\nHugging Face 推出了高性能的小型语言模型 SmoLLM，包括 135M、360M 和 1.7B，能够直接在浏览器中运行；\nOpenAI 紧随其后发布了GPT-4o mini，直接让GPT-3.5 Turbo成为历史；\nMistral AI 与英伟达合作推出了拥有 12 亿参数的 Mistral Nemo，多语言支持、128K 上下文，性能优于L3 8B和Gemma 2 9B；\n苹果也不甘示弱，发布了70亿参数的小模型 DCLM-7B，并立即将其全部开源。\n如果将时间线再往前推到今年上半年，可以发现小模型市场早已经开始“神仙打架“，比如微软4月发布了Phi-3、谷歌2月发布了Gemma-7B等。\n半年6款知名的小模型发布，行业挂起了小模型的旋风。\n而此前国内小模型的忠实拥趸，可能只有猎豹移动。 不同于其他大厂有大小系列模型覆盖，2023年猎豹直接发不了中小模型Orion-14B，应用于企业私有化模型落地。\n尽管小模型市场竞争不激烈，但 前赶集网技术总监、小晨科技 创始人 剻 义刚告诉 鲸哥： 企业部署私有大模型，服务的海外客户 最常见的模型是GPT-3.5 turbo，国内的百度文心多一些。\n现在情况大变，无论GPT3.5还是GPT-4，已经成企业市场的“旧爱”了，这些参数小能力大的小模型凭借超高性价比，一时成为市场的新宠。2024年会成为SLM元年吗？\n参数不如大模型，小模型凭啥火了？\n在Scaling Law（尺度定律）的信仰下，一直向着万亿大模型进军的科技巨头们，纷纷转向了小模型赛道，在市场看来可能有3大原因：\n第一大原因就是大模型实在太贵了。\n对于开发者而言，训练大模型和烧钱无异。剻义刚就说道：“好的大模型也十分贵，GPT-4的使用成本是GPT-3.5的10倍。 ”\n最先进的大模型，这么贵的原因，首当其冲的就是硬件训练成本，GPU、TPU和CPU集群都是基本军备。前有OpenAI用了25,000块A100芯片训练GPT-4，后有马斯克宣布要用10万块H100组成超级AI训练集群。其次就是能源消耗，有数据显示，全美AI数据中心的耗电量足以点亮整个纽约市。此外，人力成本、训练数据成本也都是一笔不小的开销。\n而随着模型的参数数量呈指数级增长，训练成本也在急剧上升。Anthropic首席执行官Dario Amodei在一档播客节目中表示，目前正在开发的人工智能模型的训练成本高达10亿美元。但未来三年AI模型的训练成本将上升到100亿美元甚至1000亿美元。至于GPT-4o“仅仅1亿美元的开发成本，已经不值一提。\n主流AI模型的训练和推理成本\n这种成本上的巨大负担，让巨头们纷纷放下参数执念，投身小模型。\n小语言模型可以理解是大语言模型的浓缩版本，参数更少，设计更精炼，自然需要更少的数据、训练时间以及硬件成本。\n比如可能仅仅聚焦于法律问题上的小模型，参数不到100亿，那它的训练成本往往可能不到1000万美元。\n而且小模型的性价比不仅体现在训练端，对于用户来说也是如此。\n由于小模型训练成本低、并且在相应过程中消耗的算力更少，因此小模型的使用价格也显得更加亲民可人。\n目前OpenAI的GPT-4o的百万Tokens输入和输出价格分别是5美元和15美元，而 GPT-4o mini的百万Tokens输入价格仅为15美分，输出价格仅为60美分，价格速降了96%～97%。\n从Artificial Analysis的统计中可以清晰看到大模型与小模型的成本差距。OpenAI CEO 山姆奥特曼对此的形容是：通往智能的成本已经「too cheap to meter」（便宜到无法计量 ）。\n第二，除了便宜，小模型的性能也已经拉满。\n最新发布的GPT-4o mini，在lmsys（测评榜单）的较量中展现出了超强实力，不仅与GPT-4o的满血版本并列榜首，还将Claude 3.5等强劲对手甩在身后。\nlmsys的排名机制是由用户自主出题，随机抽取两个模型进行一对一的较量。这种机制有效防止了模型通过“刷题”来获得虚高的评分，主打一个真实。\n分数不代表一切，实际使用体验也是效果不错。\n据OpenAI公布的案例显示，GPT-4o mini已与Ramp和超人等公司进行了合作，反馈发现在执行从收据文件中提取结构化数据，或在提供线程历史记录时，生成高质量电子邮件响应等任务时，GPT-4o mini的表现明显优于GPT-3.5 Turbo。\n更令人期待的是，GPT-4o mini 的API 现已支持文本（且大幅改善了非英文的效率）和视觉，未来还将支持文本、图像、视频和音频输入和输出。\n不仅是GPT-4o mini，其他几家的小模型也是争奇斗艳。\n主流小模型价格能力评价\n被誉为「欧洲版 OpenAI」的 Mistral AI 旗下小模型Mistral NeMo，从整体性能上也在多项基准测试中，击败了Gemma 2 9B和Llama 3 8B。并且该模型专为全球多语言应用而设计，在英语、法语、德语、葡萄牙语、中文方面等方面表现尤为突出。\n而苹果这次推出DCLM-7B 模型，在MMLU基准上的5-shot准确率达到了64%，与Mistral-7B和Llama 3 8B不相上下，但计算量只有后者的六分之一。在53个自然语言理解任务上，它的平均表现也可以与Llama 3 8B相媲美。\n此外，苹果这波格局了一把。不仅模型本身开源，连训练数据集都一并公开，让人们可以完整复现他们的工作。\n第三、小模型除了性价比杠杠的，也凭借着小巧的身姿进入了更多的应用场景。\n大模型在使用场景上有很多局限。比如智能手机、物联网设备等边缘设备，通常具有有限的计算能力和存储空间，无法承载大型语言模型，而这时候小模型则可以完美嵌入。\n又比如在对实时性有严格要求的应用领域，例如实时图像分析、语音识别和动态推荐系统，小模型由于参数少，能够迅速地进行推理，以极短的延迟满足用户的即时需求。\n性价比超高，为何小模型现在才爆？\n小模型有这么多优点，为什么巨头们现在才开始“真香”反转呢？\nOpen AI的产品主管Olivier Godement解释，这单纯是“纯粹的优先级”问题。之前公司专注于GPT-4这类大模型上，随着时间的推移，OpenAI才关注到开发者对于小模型的需求。\n但也有观点认为， 大模型是通往小模型的必经之路 。\n大型模型的训练就像是海绵吸水，尽可能把所有数据、信息囊括其中。而这样做，有利有弊。大型模型在海量数据的依托下，能够更好、更准确的处理新新任务，但同样也可能因为学的太杂，而出现不同知识的重叠、混合和冲突。\n而小模型则是站在大模型的肩膀上进一步优化。小模型接收的数据，则是由超大模型进行清洗的高质量数据。比如对于GPT-4o mini进行训练的数据，就是由GPT-4进行清洗的。\n而这种先做大模型，再进一步瘦身的训练模式正在成为新趋势。科技巨头们对于不再一味求大，而是求精。\n在2023年4月，OpenAI的首席执行官Sam Altman宣布了大型AI模型时代的结束。他指出，数据质量是AI训练的关键成功因素，并且认为关键问题是人工智能系统如何从更少的数据中学到更多的东西。而这个观点也得到微软、Hugging Face等其他玩家的认可。\n而这种不断精简优化的过程则会不断形成正循环。每一代模型都会帮助生成下一代的训练数据，直到获得“完美的训练集”。\n未来，和阶梯式上升的小模型质量形成对比的，则是不断下降的小模型价格。\n傅盛曾在WAIC中说道，“千亿参数大模型一年私有化授权费用就是几千万，到今天应该还是，然后私有化部署以后，买服务器的费用最低成本160万（当时的价格）”。\n大模型太贵了。剻义刚也和AI鲸选社说道，他们现在私有化部署一般是四五十万，为了成本考量几乎不太做微调。他们作为落地服务商没有赚太多，大头还是大模型企业的授权费用。\n现在企业使用大模型成本可能会大幅降低了。AI Grant 的两位合伙人 Daniel Gross 和 Nat Friedman在访谈中， LLM成本在质量不变差的情况下，每年可以降低 90% 的情况。\nOpenAI也确实基本在证明了这件事。OpenAI 基本是以每 3 个月作为一个周期，总会有其中至少一个模型成本下降 60% ，或者成本下降至少 60% 的情况下，质量还更高了。而一个模型基本上一年会经历两次的降本增效，每次降低 60%，两次过后就刚好是比之前降低了 90% 左右。\nGPT-4o mini就是这种逻辑的成果体现。而且随着高质量数据集以及训练方式的改进，这些小模型有些能力甚至更突出。\n正如 AI Grant 所说，没理由认为更小的模型不会有更好的表现。“最近这些 9B 的模型已经震撼到我们了，没有任何数学证明 3B 做不到同样的效果。如果 3B 做到了，没理由不运行在本地，那么那时候除了一些电耗问题外，我们更多的肯定是在做本地处理 + 云端模型的路由。”\n换言之，未来将不断涌现越来越多更精简、更高效、更便宜的小模型。未来就像OpenAI创始成员及研究科学家Andrej Karpathy所发言，未来大模型的尺寸竞争趋势即将逆转，尺寸竞争正在倒退。\n企业落地最爱，小模型加速商业化\n“企业专用大模型，百亿参数就够了。”是傅盛过去一年经常说的话。\n但实际上，2023年将小模型向垂直方向微调，打造出媲美大模型的效果，效果并没有那么好，百亿参数没那么够。\n但现在情况不一样了，gpt-4o-mini 在很多场景中不用微调，都不比Chat-4 turbo差。\n有AI创业者反馈：“gpt-4o-mini 的效果真的不错。首先是速度非常快，比 4o 快多了，几乎不需要等待，就可以读取结果了。其次是实际的表现， GPT-4o-mini 目前仅在复杂场景中还需借力, 只有比较复杂一点的编程没有搞定。“ 日常的需要搜索引擎+blog 或者教程才能解决的任务，基本GPT-4o-mini 都可以完成的不错。 ”\n在大模型的托举之下，小模型正在用更加轻盈的姿态落地。HuggingFace CEO Clem Delangue 甚至指出， 多达 99% 的使用场景可以通过 SLM 来解决，并预测 2024 年将是 SLM 元年。\n剻义刚说道，最近有家此前做了医疗和房地产领域的客户，都是用的大模型。4o-mini发布那天，他看了下资料，比 GPT-3.5 Turbo更好的性能，更长的输出，多模态支持 ，更低的费用，以及更好的非英语语言的支持，感觉是天赐的好模型。\n“最近谈的一个招聘客户，预计就是使用4o-mini。”生意预计会好做，也让他的笑声多了起来。\n但他也提到，看行业分析，未来大模型、小模型会相辅相成落地企业的部署。\n这意味着模型生态向着流动、精准进一步发展。而从使用场景上，大模型、小模型也将分工明确。\n大模型将继续在需要广泛知识基础和高级认知能力的领"
  },
  {
    "title": "全球AI治理报告发布，强调着力应对四大关键问题|全球人工智能治理倡议_新浪财经_新浪网",
    "page_body": "人工智能在带来发展机遇的同时，也引发了跨领域、多层次的系统性治理挑战。全球人工智能安全谁来监管如何防范？\n11月8日，《为人类共同福祉构建全球人工智能安全与治理体系》报告（以下简称《报告》）在2025年世界互联网大会乌镇峰会人工智能技术创新与治理论坛上正式发布。《报告》指出，人工智能技术发展迅猛，其安全与治理体系呈现出碎片化态势，国际社会亟需构建具有广泛共识的治理框架与标准。\n世界互联网大会人工智能专委会主任委员及安全与治理推进计划联合牵头人、中国科学院自动化研究所人工智能伦理与治理中心主任、北京前瞻人工智能安全与治理研究院院长曾毅，专委会安全与治理推进计划联合牵头人、剑桥大学教授及智能未来中心人工智能未来与责任项目主任肖恩·欧·海格缇（Seán Ó hÉigeartaigh）共同介绍了此项联合研究成果的形成过程及主要内容。\n《报告》系统性地证实了专家们的担忧。它指出，2019至2024年间，全球记录在案的人工智能风险事件由约400件跃升至7900余件，总量增长了近20倍。其中，涉及鲁棒性与数字安全、人权与隐私治理、透明度与问责制等问题的事件占比超过60%，显示技术安全性与伦理性议题已成为全球性挑战。\n《报告》回顾了联合国、各国政府、区域组织及产业界在人工智能治理上的积极努力。联合国通过成立咨询机构、通过联大决议等方式，推动全球治理议程；欧盟颁布《人工智能法案》，建成全球首部全面监管法律框架；中国发布《全球人工智能治理倡议》等文件，倡导发展和安全并重的原则。产业界和学术界也在积极探索自律机制，如Anthropic的“负责任扩展政策”和OpenAI的“应对准备框架”，旨在确保人工智能系统的安全部署。\n《报告》指出，当前在人工智能治理上仍存在结构性局限，如治理规则更新速度慢于技术迭代、工具上不完善，技术支撑有限、跨境协作机制薄弱、责任归属模糊等。\n《报告》强调，构建全球人工智能安全与治理体系需着力应对四大关键问题。第一，针对技术快速迭代与不确定性风险，报告建议建立技术跟踪与风险预警协同机制，推动治理规则实现动态更新。第二，在平衡各国发展诉求方面，呼吁构建包容性多边平台，以保障各国平等发展和利用人工智能的权利。第三，为明确多利益相关方的权责边界，报告提出建立履约审查、风险监测与争端调解机制，从而形成协同有序的治理格局。第四，面对地缘政治障碍，报告倡导以联合国为中心践行多边主义，推动共建人类命运共同体。另外，《报告》还借鉴了核安全、气候变化等领域的全球治理经验，提出具体机制举措。\n《报告》最后建议，形成应对人工智能技术失控风险共识，建立全球广泛参与的前沿人工智能模型检测与能力评估机制。此外呼吁国际社会凝聚“以人为本、智能向善”的共识，在联合国框架下整合资源，建立分级分类对话机制。联合国系统应发挥协调作用，推动价值共识、技术规范与风险治理的多维整合。\n曾毅表示，当前人工智能安全与治理的国际合作已成为重要的全球公共议题。面对技术的快速演进和各国发展的不平衡，国际社会需凝聚共同的风险认知，建立一致的行动框架，并通过机制的设计与完善，确保人工智能技术在安全、可控、包容的轨道上发展。\n澎湃新闻记者 喻琰"
  },
  {
    "title": "AI之HuggingFace：Hugging Face(AI社区抱抱脸/侧重存放开源模型及其数据集)的简介、使用方法、案例应用之详细攻略-CSDN博客",
    "page_body": "AI之HuggingFace：Hugging Face(AI社区抱抱脸/侧重存放开源 模型 及其数据集)的简介、使用方法、案例应用之详细攻略\n目录\nHugging Face的简介\n1、Hugging Face的发展\n(1)、Hugging Face发展历史——从开发聊天机器人→机器学习开源库平台、从NLP开源的大本营→涉及CV类的模型整合平台\n2、Hugging Face与GitHub区别——面向软件VS面向机器学习\n3、Hugging Face的产品定位、特点、盈利、未来竞争\n(1)、产品定位(具体功能)—存储、托管\n(2)、产品特点—社区驱动、用户共享实现迭代升级\n(3)、产品优势—成于Transformer终心于开源、开发者有想法即可测试、借助Hugging Face投入生产、助力模型迭代带来良性循环、平台可以集大智慧\n(4)、开源平台如何盈利——坚信、递延收入、技术敏感度、需求倒逼平台\n(5)、看待竞争、模型闭源趋势——用实力说服竞争者、迁移学习会更加开源\n(5)、未来挑战—多模态、持续助力功能升级、坚信敢比会重要\n4、Hugging Face的特点：Hub、Tasks、Open Source、Science\n(1)、Hub—机器学习之家\n(2)、Tasks—问题解决者\nComputer Vision\nNatural Language Processing\n Audio和Tabular\n Multimodal和Reinforcement Learning\n(3)、Open Source—Transformers\n(4)、On demand—推理的API\n(5)、Science—我们的研究贡献\n5、Models、Dataset、Spaces、Dcos\n(1)、Models\n(2)、Dataset\n(3)、Spaces\n(4)、Dcos\nHugging Face的使用方法\n1、如何在Hugging Face上上传自定义的数据集\n上传数据集\n查看加载的数据\nHugging Face的案例应用\nHugging Face的简介\n Hugging Face，抱抱脸，是AI"
  },
  {
    "title": "Taala AI新生态教育平台“踩准”Gartner发布的《2026年十大战略技术趋势》-百家号",
    "page_body": "Gartner简介\nGartner（高德纳公司）是全球最具权威的信息技术研究与顾问咨询机构，1979年在美国康涅狄克州斯坦福成立，其核心业务涵盖IT产业趋势分析、技术成熟度评估及市场战略咨询，旨在为客户提供客观、公正的论证报告及市场调研报告，一直是全球企业首席信息官、技术领袖和业务决策者制定未来战略的重要风向标。\n商业与技术洞察公司 Gartner 发布 2026 年重点关注的十大战略技术趋势。\n1、 AI超级计算平台\n2、 多智能体系统\n3、 特定领域语言模型（ DSLM）\n4、 AI安全平台\n5、 AI原生开发平台\n6、 机密计算\n7、 物理 AI\n8、 前置式主动网络安全\n9、 数字溯源\n10、 地缘回迁\n根据 Gartner发布的2026年十大战略技术趋势， Taala AI平台（新生态教育平台）正是围绕其强调重点关注的 多智能体系统 趋势构建 ，致力于技术创新为第一生产力，以 核心优势传递产品独特价值 。\n多智能体系统是什么？\n定义与概念： 多智能体系统 （ Multiagent Systems, MAS ） 是由多个自主或自主的智能体（ AI  Agent）组成的 集合。 这些智能体 通过交互实现复杂的个体或共同目标， 每个智能体扮演特定角色（如规划者、执行者、审查者），并通过精心设计的协调机制（如协调者 -工作者模式）共同解决问题 ， 可以相互协作、协商和竞争，以完成单个智能体无法完成的复杂任务 ， 被视为一个 “协作型AI团队” 。\n预测与价值 ： Gartner预测，到2026年将有40%的企业在一定范围内使用多智能体 系统，企业可实现复杂业务流程的自动化、提升团队技能并开创人类与 AI 智能体的新协作方式。 将企业自动化水平从执行重复性任务提升到解决动态、复杂的业务流程 ， 它能够以接近人类团队的方式处理问题，带来前所未有的运营效率和决策质量，尤其在需要多领域知识协同的场景中价值巨大。\nTaala AI平台 如何适配 ？\nTaala AI平台 并非功能堆砌，而是针对上述 多智能体系统 趋势提供 适应的 解决方案。\n适配一： Agent智能体架构\nAI驱动围绕 “自我认知-能力成长-求职转化”，针对个人成长目标形成自进化 的动态响应闭环，以打造的 全链路决策支持系统， 支撑 行为模式、能力基线、职业偏好特质 等 科学决策 。\n适配二：多智能体形成协同\n通过多模态分析加独研大模型，使 “生涯探索规划→能力锻造提升→职业资源智能体”三大模块深度协同 ，确保各个模块 在统一目标下共同规划、同步行动 ，打破 协作不畅 导致的壁垒。\n适配三：人机协作动态规划\n基于 AI决策引擎， 融合创新项目式学习和训练， 以游戏化交互设计动态校准路径， 实时反馈提升规划精度，以 “智能迭代” 应对用户变化， 核心解决了 “规划调整慢、落地僵化” 等 问题\nGartner研究副总裁 高挺（ Arnold Gao ） 表示： “2026 年的各项重要战略技术趋势将密切交织，折射出一个由人工智能（ AI ）驱动的高度互联化世界的现实图景，不仅代表了技术变革的方向，还是促进业务转型的催化剂。由于下一轮创新浪潮已近在眼前，只有当下采取行动的企业才能应对市场波动和决定未来数十年的行业走向。 ”\n2026年的十大战略技术趋势描绘了一个由AI深度驱动、以数字信任为基石、并在基础设施层面发生根本性变革的未来。这些并非是遥不可及的幻想，而是已经在技术和商业世界中萌芽并加速发展的现实， Taala AI正是探索和实践中的一员，以敏捷性和适应能力洞察趋势背后的逻辑，并果断采取行动。\n在 AI加快 变化的时代，选择一款像 Taala AI新生态教育平台这样 深刻理解 个人发展规划 并能落地行业趋势 的 产品， 无疑是 将自己期望的方向转化为可行的路线图，并注入持续的动力，现在，就是你开始规划和行动的最佳时机，建立起属于你的能力壁垒，才能最终在与他人的竞争中脱颖而出。"
  },
  {
    "title": "中国AI大模型“井喷”：全球开源榜单前15全被包圆，硅谷慌了吗？-今日头条",
    "page_body": "如果你还觉得AI开源这事跟中国没太大关系，那可能要重新考虑了。最近，国外有排名数据显示，现在全球开源AI模型的头部，前15名竟然全挂着中国机构的名字，这场局面变化比翻牌子还快，让不少人都傻眼。你听过DeepSeek、Qwen这些名字吗？现在人家直接领跑，连OpenAI都只能在第16名露脸。原来2023年中国开源模型的占比才区区17%，结果到2025年7月，蹭一下爬到了63%。增长这速度，属实有点让人跟不上。这背后其实不光是技术堆叠，更类似一次AI世界的“地壳运动”，估计下一站，AI生态怎么变，大家心里真说不好。\n美国那边的投资人像Benchmark的比尔·古尔利，也不得不承认，中国开放AI模型组合出来的力量太强。他们这些模型互相借鉴、优化，那种迭代升级的速度快得惊人，几乎改变了全球创新的玩法。于是AI这圈，不再只是看模型本身厉不厉害，这更像是在拼谁家的生态圈能拉拢更多开发者、能把AI普及得更广。像DeepSeek-V3训练一次只花900万美元，对比GPT-4动辄6300万美元，成本直接砍下一大截，具体便宜了多少？算一算，其实省了85%。阿里云的Qwen，直接做出从1.5B到480B参数的各种规格，Hugging Face上一阵薅，衍生出的模型都已经突破10万款。这些模型搞得灵活极了，无论你是要搞啥小程序还是走进大企业，都能挑到合适货色。还有智谱GLM-4.5，那API调用定价，输入0.8元/百万tokens，输出2元/百万tokens，比那些国际主流模型看下来便宜60%到80%，别说开发者了，就连中小企业都乐得合不拢嘴，行业格局都被迫被推着走，谁还敢乱收费？\n比较意外的是，很多分析认为东亚的数学教育基础成了AI崛起最大的底气。像Illya Gerasymchuk直言，这边的数学功底让AI算法创新有了厚实起点。国际数学奥林匹克上，最近十年中国、日本、韩国联合拿金的比例高达58%，这些数学天才，跳进AI池子里，创新自然不是盖的。这些机构玩开源还跟美国那套闭门造车完全不一样。他们把门槛降低，使用成本压到底，招来了全球各地开发者一起参与，产生了超大的网络效应。Kimi模型，你可能听说过，是月之暗面旗下一款主打长文本处理的模型。它的K2版本上下文长度能撑到200万字符，在法律、学术等专业场景表现相当硬核，给垂直领域AI打开了新路。\n中国机构的打法特别有意思：19家主力机构被外媒分了个梯队，从基础研究一路到商业落地，整条链基本齐活了。DeepSeek和Qwen是标准的技术“尖刀”，紧接着智谱、月之暗面这些在某些领域继续深耕，甚至腾讯、小红书、MiniMax也专门琢磨应用创新。大家比拼的不光是硬实力，还讲究团队配合。模型算法、数据来源、训练方式，各有侧重，不同公司之间开源社区一交流，创新步伐抬腿就走，谁都别想偷懒。Hugging Face平台的数据显示，中国模型平均下载量暴涨340%，这增速放到全球都是炸裂级别的。\n说到商业模式，现在流行那种“混合玩法”。过去都是“模型即服务”，现在公司干脆把模型拉去私人订制。客户根据自己需求，随心调参数、换架构，既能享用开源社区的好处，又能保住自家差异化优势。反正市场蛋糕越做越大，怎么玩都有人买单。\n但气氛热闹归热闹，问题还真不少。比如现在大部分模型都扎堆用Transformer架构，创新点哪怕有，也怕形成同质化。再有，开源模型啥数据都往里扔，数据质量和版权成了雷区，碰一下就可能出事儿。这定价策略虽然眼下打市场漂亮，可以后企业还愿不愿意持续烧钱搞研发，谁也说不好。一旦国际政策风向一改，比如美国那边开始盯紧AI出口管制、欧盟出台AI法规限制开源应用，到时候怎么玩下去，也需各家小心翼翼应对。\n这几年科技发展的新趋势就是开放、共享，各个国家和地区间技术壁垒越来越小，人才和知识流动也更频繁。谁能把全球资源整合得更顺溜，谁就能抢占下一个AI赛道的话语权。中国的公司确实展示了狠劲和决心，那能不能一直走在前面，还得看基础研究、人才培养和国际合作这几条线怎么走。有一点可以肯定，未来AI江湖可真是一天一个样，今天的大佬明天也许就被拍在沙滩上了，你说是不是挺刺激？"
  },
  {
    "title": "OpenAI升级API推出更强模型，加大开发者生态建设力度_新浪财经_新浪网",
    "page_body": "　　周一举办的开发者日活动上，OpenAI 公布了应用程序接口（API）的多项更新，包括推出最新语言模型 GPT-5 Pro、全新视频生成模型 Sora 2，以及一款体积更小、成本更低的语音模型。\n　　此次 API 更新是 OpenAI 一系列公告的组成部分，这些公告均旨在吸引开发者加入其生态系统，其他举措还包括推出智能体构建工具，以及支持在 ChatGPT 内开发应用程序的功能。\n　　OpenAI 首席执行官山姆・奥特曼表示，GPT-5 Pro 的推出可能会吸引金融、法律和医疗健康领域的应用开发者 —— 这些行业均需要 “高准确性和深度推理能力” 的技术支持。\n　　奥特曼还指出，语音功能在未来将至关重要，因为它正迅速成为人们与人工智能交互的主要方式之一。为此，OpenAI 正于 API 中推出 “gpt-realtime mini”：这是一款体积更小、成本更低的语音模型，支持音频与语音的低延迟流式交互。该新型号比 OpenAI 此前的高级语音模型便宜 70%，同时保证 “语音质量和表现力不变”。\n　　最后，参与 OpenAI 开发者生态的创作者如今可通过 API 预览版使用 Sora 2。上周，OpenAI 已发布其最新音视频生成模型 Sora 2，同时推出了Sora 应用 —— 这款应用内满是人工智能生成的短视频。用户可通过 Sora 应用，根据提示生成以自己、朋友或任意事物为主题的视频，并通过 TikTok 式的算法推荐流分享。\n　　奥特曼表示：“（开发者）如今可直接在自己的应用中，使用驱动 Sora 2 生成惊艳视频效果的同款模型。”\n　　Sora 2 在前代模型基础上进行了升级，能生成更逼真、物理逻辑更连贯的场景，实现声音与画面的同步，并提供更强的创意控制权 —— 从精细的镜头调度到风格化视觉呈现均涵盖在内。\n　　奥特曼表示：“例如，你可以先确定一个类似 iPhone 拍摄的视角，然后通过提示让 Sora 将其扩展为一个宏大开阔、具有电影质感的宽幅镜头。但我们目前正在研发的最令人兴奋的成果之一，是这款新模型能将声音与视觉完美匹配 —— 不仅限于语音，还包括丰富的音景、环境音效，以及与画面内容紧密关联的同步特效。”\n　　Sora 2 定位为一款概念开发工具，其应用场景广泛：既可以根据产品的整体风格，为广告打造视觉起点；也能帮助美泰（Mattel）的设计师将草图转化为玩具概念。奥特曼在开发者日活动中举了这个例子，这也间接揭示了 OpenAI 与这家芭比娃娃制造商达成的合作 —— 双方将把生成式人工智能整合到玩具开发流程中。"
  },
  {
    "title": "能力与可信度可以兼得？GPT-4、Gemini等多模态大模型评测报告来了-澎湃",
    "page_body": "机器之心专栏\n机器之心编辑部\n2023 年我们正见证着多模态大模型的跨越式发展，多模态大语言模型（MLLM）已经在文本、代码、图像、视频等多模态内容处理方面表现出了空前的能力，成为技术新浪潮。以 Llama 2，Mixtral 为代表的大语言模型（LLM），以 GPT-4、Gemini、LLaVA 为代表的多模态大语言模型跨越式发展。然而，它们的能力缺乏细致且偏应用级的评测，可信度和因果推理能力的对比也尚存空白。\n近日，上海人工智能实验室的学者们与北京航空航天大学、复旦大学、悉尼大学和香港中文大学（深圳）等院校合作发布 308 页详细报告，对 GPT-4、Gemini、LLama、Mixtral、LLaVA、LAMM、QwenVL、VideoChat 等热门的 LLM 和 MLLM 进行评测。根据 4 种模态（文本、代码、图像及视频）和 3 种能力（泛化能力、安全可信能力和因果推理能力）形成了 12 个评分项，并通过 230 个生动案例，揭示了 14 个实证性的发现。\n*作者顺序按照字母顺序排名\n评测报告：https://arxiv.org/abs/2401.15071\n榜单地址：https://openlamm.github.io/Leaderboards\n后续会持续对最新多模态大语言模型及多模态生成大模型进行评测，如GeminiUltra，SORA 等，结果会更新到榜单地址，敬请期待！\n结论速览\n文本和代码能力：总体来说，GPT4>Gemini>Mixtral>Llama-2 等其他模型。值得一提的是多语种翻译的能力，谷歌的 Gemini 大放异彩，其能准确捕捉成语和复杂结构的微妙差异，甚至超越了 GPT-4，展示出信达雅的中文翻译能力。\n领域知识：通过医学、经济学等学科知识测评发现，Gemini 的领域知识和 GPT-4 都非常丰富，但它在 “学以致用 \" 的能力上稍显欠缺，而且偏科医学。GPT-4 则在解决各种专业领域问题方面都都略胜一筹。\n安全与可信度：GPT-4 相比于 Gemini Pro，以及 Llama-2 等其他开源模型，展现出显著优势。在涉及道德敏感性问题和安全可信问题时非常谨慎，但可能由于其安全防护机制过强，导致部分正常问题也拒绝回答，这一点有待更多讨论。\n视觉能力：通过对图像和视频两种模态的输入进行评测，发现开源模型甚至在部分维度上与闭源模型的视觉能力评分不相上下，没有明显的差距，视觉的细节感知均有待提高，视觉能力可能将成为多模态大模型能力竞争的焦点。\n因果关系分析：文本、代码、图像和视频四种模态中，Gemini 语言表达非常简洁，GPT-4 在各模态输入时都能深入理解和解释复杂场景。对于视频输入，需要对时序有理解能力的因果推理问题上，特别是在处理多轮交互和理解事件序列因果关系方面，所有模型在都处于起步阶段。\n图 1：通过四种模态对各 LLM/MLLM 在通用性、可信度和因果关系上的评测结果\n实验性发现\n1. 文本和代码总体能力概括：总体而言，Gemini 的性能远不如 GPT-4，但优于开源模型 Llama-2-70B-Chat 和 Mixtral-8x7B-Instruct-v0.1。对于开源模型而言，在文本和代码方面，Mixtral-8x7B-Instruct-v0.1 的表现优于 Llama-2-70B-Chat。（GPT4>Gemini>Mixtral>Llama-2）\n图 2：创意写作，在这个评测样例中，让模型使用数学理论写一首情诗，GPT 非常有创意，π 代表无穷，指数曲线代表上升，常数代表始终如一，可见其融合多学科知识的能力非常不错。\n图 3：语法结果。绿色文字表明合理的回答。红色文字表明不合理的回答。GPT-4 表现最好，而 Mixtral 在 7 个问题中有 2 个错误的答案，Gemini 表现最差。\n2. 多语言翻译能力：在多语言翻译能力方面，Gemini 表现出色，甚至超越了 GPT-4 和最好的开源模型。Gemini 能够准确理解成语和英语句子的微妙差异以及复杂的结构，然后准确翻译它们，而 GPT-4 和开源模型通常只翻译字面意思。此外，Gemini 生成的中文翻译通常更加优雅。\n图 4：多语言翻译结果。绿色文字表明更优秀的回答。红色文字表明明显错误的回答。在将中国成语翻译成英文时，这三个模型都存在很多问题，但 Gemini 的表现稍好一些。\n3. 数学计算和推理能力：无论是多解数学问题、定理证明还是常识推理，Gemini 的表现通常较差，结果接近开源模型 Mixtral-8x7B-Instruct-v0.1 和 Llama-2-70B-Chat，而 GPT-4 一如既往的表现最好。Gemini 有时在引用定理和知识方面出现明显错误；即使使用正确的知识，它也经常因计算错误而失败。\n图 5：方程推导结果。绿色文字表明合理的回答。红色文字表明错误的回答。GPT-4 表现最好，其次是 Gemini，Mixtral 作为开源模型和这两个闭源模型仍有差距。\n4. 领域知识应用能力：Gemini 通常只具有某些领域知识的表面理解。无论是在医学、经济还是其他学科领域，Gemini 可以理解这些领域的专业术语和问题。然而，当将这些知识应用于解决具体问题时，它经常会犯错。相比之下，GPT-4 不仅具备专业知识，还知道如何应用它，通常能够较好解决专业领域的问题。至于图像输入，在医学专业领域（GPT-4 避免回答这一系列问题的领域），与开源 MLLMs 相比，Gemini Pro 在医学图像模态识别和内容理解方面表现出良好的能力，并在某些情况下提供有价值的诊断建议。然而，根据案例的评估结果，目前正在测试的 MLLMs 在提供有效的医学诊断和全面报告方面仍然面临重大挑战。\n图 6：领域知识应用能力。绿色文字表示合理的回答。红色文字表示不合理的回答。GPT-4 表现最佳，而 Gemini 和 Mixtral 提供了相互矛盾的解释和错误的答案。\n5. 文本和代码的可信度和安全性：与 GPT-4 甚至开源模型 Llama-2 相比，Gemini Pro 在这方面缺乏足够能力。Gemini Pro 难以熟练识别测试提示中的诱因和陷阱，如歧视、刻板印象和非法行为的实例。此外，研究者发现 Mixtral 的文本可信度能力不够稳健。有时它可以识别提示中的陷阱并给出安全的回应，但有时会失败。在极端风险方面，研究者关注潜在的化学威胁。Gemini Pro 对化学有很好的了解，可以准确地提供化合物的合成方法等。然而，它经常无法识别给定的化合物是危险的。相比之下，GPT-4 和 Llama-2 在这方面做得更好，会发出化合物是危险的警告。Mixtral 可能受到自己的化学知识的限制。虽然它也会回应，但不够详细。在代码的可信度方面，Llama-2 和 GPT-4 明显优于 Gemini Pro。Gemini Pro 具有强大的代码生成能力，但难以识别测试提示中的安全风险，如违反社会伦理、安全极端风险，甚至直接给出危险的答案。\n图 7：绿色文字表示安全的回应。红色文字表示不安全的回应。蓝色文字表示我们对这个回应的简短评论。只有 Gemini Pro 给出了危险爆炸化合物的具体名称。\n6. 文本输入时的推理能力：在文本因果关系场景中，研究者的分析揭示了不同模型响应的明显模式。具体而言，Gemini Pro 倾向于提供直接且符合规定的答案，特别是在问题明确要求简单的 “是或否” 回答或涉及从多个选择中进行选择时。Gemini Pro 的这一特点使其在更倾向于简洁回答的大规模评估中成为更实际的选择。相比之下，其他模型倾向于在回答中包含解释性细节。虽然这种方法可能对批量处理不太高效，但它为理解模型背后的推理过程提供了更清晰的洞察，这在需要理解决策背后逻辑的案例研究中特别有益。\n图 8：反事实推理的结果。绿色文字表示合理的回应。红色文字表示错误的回应。蓝色文字展示了 Llama2-70B-chat 的道德考量。它强调了在评估假设场景时道德推理的作用，这些场景虽然是假设的，但植根于现实世界的伦理困境。\n7. 代码输入时的因果推理能力：GPT-4 显示出评估给定问题的可行性并提供逻辑一致的解释的特殊能力。这种技能对于准确识别和解决问题至关重要。然而，其他三个模型在这个方面没有展示出同样的熟练水平。它们难以准确识别问题的可行性，通常导致生成与预期结果或要求不符的代码。\n图 9：代码生成结果。绿色文字表示正确的回应。红色文字表示错误的回应。\n8. 图像能力：MLLMs 已经展示出熟练理解图像主要内容的能力，能够基于提出的查询分析图像中的大部分信息。然而，在需要精确定位的任务，如检测，或需要精确信息提取的任务，如涉及 OCR 功能的图表分析方面，仍有改进的空间。\n图 10：图像计数结果。绿色文字表示更优秀的回应。红色文字表示错误的回应。所有的多模态大型语言模型（MLLMs）都无法准确地计算图像中物体的数量，这可能是由于遮挡问题，阻碍了它们在计数时准确识别物体，导致错误。\n9. 多图理解任务：MLLMs 在处理涉及复杂推理的多图任务方面仍面临挑战。例如，机器人导航等任务，需要空间想象力，以及漫画分析等任务，涉及到图像之间的关系分析，对 MLLMs 来说都具有困难。\n图 11：图像上下文学习结果。绿色文字表示合理的回答。红色文字表示错误的回答。所有 MLLMs 都无法准确读取时针指向的数字\n10. 处理图像时的安全性和可靠性评估：在测试模型对视觉干扰的抵抗力时，Gemini 和其他模型表现差别比较大。尽管 Gemini 能够在加入高斯噪声的图片中识别出物体，但其准确度仍低于其他开源模型。在极亮或逆光条件下进行的测试中，Gemini 展现了一定的图像识别能力。它可以正确辨认高速公路上的夜景，但对于在明亮的日落背景中的剪影，它就难以识别。当面对没有具体信息的空白图片时，Gemini、开源模型 LAMM 和 LLaVA 倾向于给出类似幻觉的回答。与之相比，GPT-4 通过表明图片内容的缺失来展现了更为可靠的视觉能力，保证了事实上的准确。在图像安全性方面，与 GPT-4 相比，Gemini Pro 有明显的不足，用户可以相对容易地操纵 Gemini Pro 生成有害的回答。目前的开源模型和 Gemini Pro 在图像输入时的安全护栏方面都需要进一步改进。\n图 12：一个关于食品安全的例子。绿色文字表示合理的回应。红色文字表示错误的回应。值得注意的是，GPT-4 和 Qwen-VL 都提供了合理的回应。然而令人不安的是，Gemini Pro 建议使用这些食物来伤害朋友，这种回应具有一定的危险性。\n11. 图像因果推理能力：与 GPT-4 的能力相比，Gemini 的明显更弱，且它与其他开源模型如 LLaVA 等能力接近。Gemini 在复杂场景中，如城市中发生洪水等，辨别复杂细节方面存在很大的局限性。相比之下，GPT-4 擅长处理这些复杂场景，展示了更好的理解和分析能力。Gemini 的比较独特的一点是它倾向于对给定问题提供简洁但常常非常有限的回答，猜测可能和其训练策略有关。相反，GPT-4 的回复通常更加全面广泛，其有能力提供更富有洞察力的回应，并充分考虑上下文信息。\n图 13：关于图像输入的因果推理能力的示例。绿色文字表示合理的回应。红色文字表示不合理的回应。开源模型 LLaVA 在视觉识别方面存在问题，而 Gemini Pro 和 GPT-4 能够识别 “燃烧”、“灭火” 和 “倒塌” 等关键词。此外，GPT-4 的回答更详细、包含更多内容。\n12. 视频处理能力：针"
  },
  {
    "title": "gpt和github怎么配合•Worktile社区",
    "page_body": "GPT（Generative Pre-trained Transformer）是一种强大的自然语言处理模型，而GitHub是一个代码托管平台。将GPT和GitHub配合可以实现许多有趣的应用，包括代码生成、文本生成和自动化文档等。以下是一些使用GPT和GitHub配合的常见方法：\n1. 代码生成与检查：使用GPT模型生成代码片段，然后将其提交到GitHub。你可以编写一个小的应用程序，读取GPT生成的代码并将其自动提交到GitHub仓库。这样可以加快开发速度，同时确保生成的代码符合语法规范和工程实践。\n2. 文本生成与项目文档：在GitHub项目中，文档对于项目的成功非常重要。你可以使用GPT来生成项目文档的初始草稿，然后将其提交到GitHub供项目成员查阅和完善。这样可以节省时间并提高文档的质量。\n3. 问题回答：使用GPT将GitHub的代码库转化为机器可读的格式，并使用这些数据训练一个模型。然后，根据用户提出的问题，使用GPT模型生成答案。这样可以快速响应用户的问题，提高问题解决效率。\n4. 代码仓库管理：你可以使用GPT模型来自动化一些代码仓库管理任务，如自动创建分支、合并请求、提交代码等。这可以大大简化代码管理过程，并减少手动操作的繁琐性。\n需要注意的是，使用GPT和GitHub配合需要谨慎操作，以确保生成的代码和文本的质量。在使用GPT生成代码的情况下，建议通过使用预训练模型进行微调来确保生成的代码符合预期。另外，不要完全依赖GPT生成的结果，仍然需要人工审核和修改。\n将GPT（Generative Pre-trained Transformer）和GitHub配合使用，可以实现许多有趣和实用的功能。下面是五个建议的用例来展示如何配合使用GPT和GitHub：\n1. 代码自动补全：GPT可以用于代码自动补全，通过训练模型使其能够根据上下文预测下一个可能的代码片段。你可以将GPT模型与GitHub的代码库结合起来，利用已有的代码进行训练，并通过GitHub的API调用来进行实时自动补全。这种方式可以极大地提高代码编写的效率。\n2. 自动Issue生成：利用GPT生成自动Issue，可以在编写提交代码时节省开发人员的时间。通过分析GitHub上的开源仓库和Issue的内容，可以训练一个GPT模型来生成描述问题的文本。这样，当用户提交代码时，系统可以自动生成相应的Issue，减轻开发人员的负担，并帮助团队更好地跟踪和解决问题。\n3. 自动代码审查：GPT可以用于自动代码审查，通过训练模型让其了解常见的代码风格和最佳实践。将GPT模型与GitHub的Pull Request集成，可以自动生成代码审查意见和建议，帮助开发人员提高代码质量。这种自动化审查还可以减轻人工代码审查的工作量，提高开发效率。\n4. 项目文档的生成：利用GPT生成项目文档，可以减轻项目文档编写的负担。根据代码库和注释，训练一个GPT模型，使其能够生成符合项目要求的文档。这样，在将代码提交到GitHub时，可以自动生成相应的文档，并将其与项目关联起来，方便他人了解和使用代码。\n5. 代码推荐和搜索：将GPT模型与GitHub的代码库结合，可以实现更智能的代码推荐和搜索功能。通过训练模型使其了解代码结构、语法和上下文，可以根据用户的输入和需求，提供更准确的代码推荐和搜索结果。这种方式可以帮助开发人员快速找到他们需要的代码片段和相关资源，提高开发效率。\n以上只是一些GPT和GitHub配合使用的示例，实际上还有许多其他的应用场景。通过将GPT与GitHub的数据结合起来，可以进一步发掘两者的潜力，提高软件开发和协作效率。\n配合GPT和GitHub可以实现以下几点：\n1. 在GitHub上使用GPT生成代码注释：通过将GPT模型训练成代码注释生成器，可以将其与GitHub上的代码仓库连接起来。当有人提交代码时，GPT会自动生成代码注释，从而提高代码可读性和可维护性。\n2. 在GitHub上使用GPT生成Issue模板：通过使用GPT模型生成Issue模板，可以自动生成标准化的Issue描述。这样可以提高Issue的质量，并让开发人员更专注于解决问题。\n3. 使用GPT训练代码评审工具：通过使用GPT模型训练代码评审工具，可以自动化代码评审，提供关于代码质量和最佳实践的反馈。通过与GitHub集成，可以将评审结果直接显示在pull request上，提供给开发人员作为改进代码的参考。\n4. 使用GPT生成文档：通过将GPT模型训练成文档生成器，可以自动生成项目文档。这会极大地简化开发人员的工作，并提供一致性的文档样式。\n下面是一种将GPT和GitHub配合使用的操作流程：\n1. 获取代码数据集：在GitHub上选择一个合适的代码仓库，然后使用GitHub的API或者其他方式，将代码仓库中的代码文件下载下来。可以选择一个特定的编程语言，或者选择一个特定领域的代码仓库。\n2. 数据清洗和预处理：对于下载的代码文件进行数据清洗和预处理工作，例如移除注释、格式化代码等。这一步的目的是为了提高GPT模型的训练效果。\n3. 训练GPT模型：将数据集输入到GPT模型中进行训练。可以使用已有的GPT模型，也可以自己训练一个。训练的过程可能需要较长的时间和大量的计算资源。可以使用GPU来加速训练过程。\n4. 集成到GitHub：将训练好的模型部署到GitHub上。可以使用GitHub Actions来实现自动化的代码生成和评审。\n5. 测试和调试：在实际使用之前，对集成到GitHub的GPT模型进行测试和调试。确保模型能够正常工作，并且生成的结果符合预期。\n6. 应用场景：根据具体的需求，将GPT模型应用到合适的场景中。可以是代码注释生成、Issue模板生成、代码评审等。\n7. 监控和改进：对于集成到GitHub的GPT模型，需要进行监控和改进。根据用户反馈和模型表现，对模型进行调整和改进，以提供更好的用户体验。\n注意：在将GPT模型集成到GitHub中时，需要遵守GitHub的使用规范和法律法规，确保不违反任何版权和法律要求。另外，保护用户的隐私也是非常重要的。在使用GPT模型生成代码注释或其他内容时，要注意避免泄漏敏感信息和隐私。"
  },
  {
    "title": "AI开源狂飙，OpenAI们慌了！GenAI大洗牌，2025趋势深度解读|谷歌|智能体|知名企业|openai|高吞吐量内核_网易订阅",
    "page_body": "新智元报道\n编辑：KingHZ 英智\n【新智元导读】2025年，ChatGPT依旧领跑，但DeepSeek、Qwen等开源劲敌正加速追赶。从「推理革命」爆发到 DeepSeek开源，一场围绕算力、架构与生态的战争已悄然打响，开源势力正以星星之火之势挑战闭源巨头。\n2025年，AI江湖风云再起！\n第一季度过去了，OpenAI仍然处于全球领先地位。\n但其他公司正在迅速追赶，尤其是国内开源AI模型紧追不舍，且接近顶尖水平。\n独立机构Artificial Analysis，发布了2025年第一季度AI报告，总结了六大趋势，涵盖技术突破与市场格局演变。\n报告亮点如下：\n过去两年中，GPT-4级别推理成本下降了1000倍。\n三大驱动力引发AI成本革命：更小的模型、推理优化和新一代硬件。\n目前，智商天花板全是推理模型，但非推理模型还是性价比之王。\n现在的AI能自主浏览代码库、创建文件、写代码、跑测试，不止补全代码。\n多模态和智能体让AI从「单一工具」变成「全能助手」，离日常生活越来越近。\n根据Artificial Analysis的官方分析，2025年初的AI有六大定义性结论：\n1. 前沿 AI 竞赛持续升温 ：顶级实验室正以每8-12周的速度推出新模型。\nOpenAI仍处于领先地位；在其身后，不仅有谷歌和Anthropic等传统挑战者，xAI、DeepSeek和阿里也已加入，形成了紧密的追赶梯队。\n2. 推理模型投入实际应用 ：那些「先思考后回答」的模型，牺牲了一定的速度和成本，换取了更高的智能水平，使用的token数量和成本是非推理模型的10倍左右。\n3. MoE模型已无处不在 ：混合专家模型（MoE）在为每个生成的token进行计算时，仅激活其总参数不到10%。目前，大多数顶级的开源权重模型均采用了MoE架构。\n4. 中国顶级实验室差距显著缩小 ： DeepSeek等中国公司正纷纷推出极具竞争力的模型，并常常选择公开模型权重。\n5. AI 智能体走向实用化 ： 由LLM驱动、能自主行动并使用工具端到端完成任务的系统，正开始在实际工作中显现成效。新兴的AI智能体类别包括编程智能体、深度研究智能体（Deep Research Agent）以及计算机辅助使用智能体。\n6. 大语言模型原生支持多模态 ： 大语言模型如今的输出已远不止于文本。GPT-4o目前在图像生成方面独占鳌头，同时各类语音到语音（Speech to Speech）模型也已相继问世。\nAI大洗牌\n推理模型称王\n2024年末，OpenAI利用大规模强化学习训练的推理模型o1，将性能差距彻底拉开，颠覆了全球AI格局。\nOpenAI全球领先，但竞争对手紧追不舍\n如今，Llama Nemotron Ultra、Qwen3等开源模型，已成燎原之势。\n私有模型和开源模型的差距变化\n推理模型能够逐步拆解任务、自我校验，尤其在复杂问题如数学推理、研究辅助中表现出明显优势。\n比如，Gemini 2.5 Pro遇到问题会先拆解步骤、自我纠错，像解数学题一样一步步来，虽然花21秒，输出1967个token，但答案准；而非推理模型（如GPT-4o）4秒输出185个token，结果答错了。\n可以看到，在目前的Artificial Analysis智能指数中，最聪明的全是推理模型。\n其中，o4-mini(high)排名第一，谷歌Gemini 2.5 Pro和Grok 3紧随其后。\n开源模型（如DeepSeek R1、Qwen 3、Llama 3.1）性能虽然落后闭源模型，但两者非常接近。\n「高情商」的推理模型，背后是高成本：要达到相同的性能 ，推理模型 要使用非推理模型 10倍以上的输出token！\n尽管在效率方面取得了显著进展，推理速度比过去更快，但推理模型和智能体应用每次请求生成的token是过去一年平均水平的10多倍。\n综合下来，用户反而要等待更长的时间。\nLLM输出速度变化\n非推理模型也没被淘汰，需要快速响应或省钱的场景，还是性价比之王。\n开发者不能仅看单token定价，还需综合考虑token总使用量，才能准确评估推理成本。\n实际上，如今的顶级AI模型参数规模更大，每次请求需要的token数总更多，现在的AI应用需要更多的算力。\n因此，最新的模型开始探索如何在智能和成本之间取得平衡。\n其中，最引人注目的进展来自架构上的权衡优化。\nEpoch AI对每种算法进步的计算等效增益的估计\n混合专家\n省钱又提速\nDeepSeek-V3的混合专家（MoE）架构，如今已无处不在。\nDeepSeek-V3基本架构\n传统模型像全科医生，不管啥问题都调动全部知识；MoE像专科门诊，遇到不同问题找对应的专家（激活部分参数）。\n如果说全连接模型是「广撒网捕鱼」，MoE则是「精准出击」，不仅能减少参数激活量，还大幅提升推理效率。\n近期开源的前沿模型越来越多地使用MoE架构，每次输入仅激活部分参数。\n前沿模型采用更稀疏的MoE设计，仅激活不到10%总参数，早期模型通常激活约25%的参数。\n在推理和训练上，参数规模相同的MoE模型比稠密模型更高效。\n此外，英伟达是算力领导者，Cerebras、SambaNova、Groq这些新玩家将「芯片+云服务」打包卖，通过垂直整合提供高性能推理，输出速度更快。\n但开发者需要在性能、成本和上下文窗口之间权衡。\n虽然服务速度更快，但这些芯片新玩家有时比其他服务商价格更贵，且上下文窗口更短。\n智能体\n自主干活的「虚拟员工」\n智能体是2025年AI领域的重要趋势。\n凭借LLM的推理能力，通过高效的工具使用和自主流程管理，大幅提升了任务完成的效率和智能化水平。\n它们能自主完成复杂任务，尤其是编程、深度研究、操作计算机和客户支持。\n从自动补全（2021年）到现在能自主浏览代码库、创建文件，比如让它搭个OAuth认证系统，它能自己写代码、跑测试，还能告诉你改了哪些文件。\n比如问「AI对就业的影响」，它会自己拆分问题、查资料、整合答案。还能批量处理表格，打工人看了想流泪。\n原生多模态\n图像、视频、语音全面升级\nOpenAI的GPT-4o画出的图又逼真又贴合需求。\n字节跳动的Seedream 3.0、MiniMax的HiDream-I1-Dev一发布就冲进第一梯队。\n以前OpenAI的Sora是视频界扛把子，现在谷歌Veo 3超越了它，MiniMax和快手也推出了能追上Sora的模型。\nElevenLabs的Scribe模型把语音转文字的错误率降到8%，比OpenAI的Whisper还准；文本转语音也更像真人了。\n大型科技公司持续在所有领域全面发展，而较小的竞争者通常专注于特定的AI领域。\n谷歌是AI价值链中垂直整合度最高的企业（从TPU加速器到Gemini模型）；NVIDIA、微软、亚马逊等在硬件、云推理和应用层各有侧重。\n未来AI会怎么发展？大概率会更全能、更聪明，也更接地气。\n说不定下次开会，你的会议纪要就是AI智能体帮忙写的。\n开源\n大势所趋\n随着越来越多的企业在业务中构建和部署AI驱动型解决方案，日益丰富的开源技术正成为首选，包括Meta的Llama系列、谷歌Gemma系列、艾伦人工智能研究所Ai2的OLMo系列、英伟达的NeMo系列、DeepSeek-R1等众多选择。\nMozilla基金会等机构联合开展了一项开创性调研，覆盖41个国家700多位技术负责人和资深开发者。\n调研结果显示，企业在AI工具选择上日益偏向开源方案：\n总体而言，超过四分之三的受访者预计他们的组织将在未来几年内增加对开源人工智能技术的使用。\n这在一定程度上得益于开源工具在企业软件生态中的活跃表现，且长期以来始终是开发者社区的基础资源。\n在Sequoia合伙人Lauren Reeder主持的一场圆桌讨论，揭示了关于开源AI模型当前状况和未来趋势的诸多关键见解。\n目前在OpenRouter平台上运行的推理任务中，只有大约20%-30%使用的是开源模型。尽管如此，与会者对未来的增长充满信心。\n本月OpenRouter的token使用总量排行榜\n当被问及五年后开源与闭源模型在推理任务中的占比预估时，Jeffrey和Dmytro认为 开源AI将和闭源AI分庭抗礼 。\nJeffrey预测开源与闭源将各占一半，但也提到可以在开源与闭源模型之间智能切换的技术。\nDmytro也倾向于50/50的预测，但他指出开源生态将更加多样化：「闭源可能仍由少数几家主导……而开源则不会只有一个模型，会是更多的模型家族、微调版本和定制化方案。」\n独立机构Artificial Analysis最近的报告，也印证类似的AI发展趋势。\nArtificial Analysis认为虽然闭源推理模型整体上领先，但开源模型和闭源模型与2022年相比，差距已经变小。\n而在非推理模型方面，开源模型反而比闭源的商用模型更具优势。\n特别是国产开源AI模型，已经成为一股不容忽视的力量。\n参考资料：\nhttps://x.com/ArtificialAnlys/status/1924845419315777572"
  },
  {
    "title": "全球工业AI发展趋势是什么？从Geega OS平台看技术演进方向",
    "page_body": "一、全球工业AI竞争格局重塑\n当前，全球制造业正经历从数字化向智能化的深刻变革。国际工业巨头如西门子、施耐德电气等纷纷加码人工智能技术布局：西门子将GPT-4集成到TIA Portal开发环境，推出零代码PLC编程工具；施耐德则联合微软开发自动化应用助手，强化其EcoStruxure平台的智能分析能力。据权威机构预测，到2024年全球工业AI市场规模将突破400亿美元，其中离散制造和流程制造的智能化改造需求占比超六成。\n在这场全球技术竞赛中，中国企业广域铭岛数字科技凭借自主研发的Geega OS工业AI平台崭露头角。该平台以\"场景定义智能\"为核心理念，构建了覆盖制造全流程的AI解决方案体系，为制造业转型升级提供了全新路径。\n二、工业AI落地的关键挑战\n不同于消费级AI应用，工业领域对人工智能技术有着特殊要求：\n1. 专业壁垒高： 需要深度融合生产工艺知识与AI算法\n2. 数据复杂度大： 涉及设备参数、工艺指标等多维异构数据\n3. 价值闭环难： 必须实现从数据采集到决策执行的完整链条\n广域铭岛通过长期实践发现，传统工业软件存在三大痛点：数据孤岛导致模型训练困难、行业知识缺乏造成场景适配不足、业务流程割裂影响价值转化效率。这些因素严重制约了工业AI的实际应用效果。\n三、Geega OS平台的架构创新\n为解决上述问题，广域铭岛打造了\"双引擎驱动\"的工业AI中枢平台：\n1. 后端能力中枢：\n智能数据引擎：支 持300+工业协议解析，实现毫秒级时序数据处理\n弹性算力引擎： 采用云边协同架构，GPU资源利用率提升至90%\n模型服务引擎： 预置200+工业算法组件，支持低代码化快速部署\n2. 前端交互革命：  突破传统工业软件的数据看板模式，创新性地融合了自然语言交互能力。现场工程师可通过语音或文本直接查询实时生产数据波动、设备异常根因分析、工艺优化建议文档。\n四、场景化应用的实践成果\n广域铭岛将技术优势转化为具体行业的解决方案，形成多个标杆案例：\n1. 电解铝智能工厂：  在广西某大型铝厂，通过Geega Ask系统构建了电解槽全生命周期管理平台。该系统能够实时监测槽电压、效应系数等18项关键指标；自动预警异常并推送处置方案；生成能耗优化建议，综合能效提升5.3%。\n2. 汽车制造质量管控：  针对汽车生产的核心工艺环节，开发了系列专业化APP：\n（1）车身尺寸管理： 整合三坐标测量数据，实现尺寸偏差智能溯源，问题排查效率提升96倍。\n（2）点焊质量监控： 基于50000+传感器数据实时分析，焊点合格率提升至99.5%。\n（3）涂装工艺优化： 通过漆膜厚度预测模型，使色差问题处理时效提高30%。\n这些应用并非孤立工具，而是与Geega OS平台深度集成，形成\"监测-分析-优化\"的完整闭环。\n目前，广域铭岛的数字化服务网络已覆盖全球40余个城市，在东南亚设立多个技术服务中心。这种全球化布局不仅强化了本地化服务能力，更通过多元场景数据反哺，持续提升工业大模型的准确性和适应性。\n工业AI的真正价值不在于技术本身，而在于其对制造本质的重塑。当人工智能能够切实提升冲压线节拍、稳定焊接质量、降低涂装能耗时，智能制造才真正落地生根。广域铭岛通过\"平台+场景\"的创新模式，正在将工业AI从概念验证阶段推向规模化应用，为中国制造业的智能化转型提供可复制的实践样本。未来，随着更多垂直场景的持续深耕，工业AI必将成为驱动制造业高质量发展的核心引擎。"
  },
  {
    "title": "2025-2029年中国未来产业之模型即服务（MaaS）行业深度调研及投资前景预测报告_发展_数据",
    "page_body": "报告简介\n模型即服务（Model as a Service，MaaS）是一种依托云计算的服务模式。在这种模式下，机器学习、深度学习等各类模型借助网络提供给用户，如此一来，用户无需自行构建和训练模型，便能利用它们解决实际问题。这种模式有效降低了模型应用的难度，让更多企业和开发者能够从先进的人工智能技术中获益。\n图表　2022-2027年中国AI大模型应用市场规模及增速\n数据来源：中投产业研究院整理\n随着互联网的广泛普及以及物联网的蓬勃发展，数据量呈现出爆炸式的增长态势。海量的数据为模型训练提供了极为丰富的素材，使得模型能够学习到更全面的特征和模式。MaaS提供商可以充分利用这些数据来训练出高质量的模型，并将其提供给有相应需求的用户。对于中小企业而言，自行建立和训练模型需要耗费大量的人力、物力和财力，比如需要招聘专业的数据科学家，还要购买昂贵的计算设备等。而MaaS模式使得它们能够以较低的成本获取模型，进而满足自身的业务需求，像客户细分、预测性维护等业务都可以借助MaaS模式实现。\nMaaS提供了一种成本效益高且部署迅速的解决方案，无论是大型企业、中型企业还是小型企业，都可以利用先进的AI模型。与此同时，以百度智能云为代表的服务商，通过降价和免费策略，有力地推动了企业对大模型产品的试用和采纳，加快了大模型在产业中的落地速度。 2024年上半年，中国MaaS市场规模达到2.5亿元， 中国AI大模型解决方案市场规模达到13.8亿元，百度智能云在这两个市场中均位居榜首，其市占率分别为32.4%和17%。在未来，随着企业数字化转型进程的加速，对MaaS的需求将会持续攀升。预计在未来五年内，中国MaaS和AI大模型解决方案市场将以超过50%的增速快速增长。\n图表　2024-2028年中国模型即服务（MaaS）市场规模预测\n数据来源：IDC、中投产业研究院整理\n在数字经济蓬勃发展的今天，数据已成为驱动经济社会发展的新燃料。 2024年12月28日，国家发展改革委等部门印发《关于促进数据产业高质量发展的指导意见》，提出支持企业面向人工智能应用创新，开发高质量数据集，大力发展“数据即服务”“知识即服务”“模型即服务”等新业态。这一举措旨在激发数据产业创新活力，推动数据产业高质量发展，为构建数字中国提供坚实支撑。\n中投产业研究院发布的《2025-2029年中国未来产业之模型即服务（MaaS）行业深度调研及投资前景预测报告》共七章。首先，报告阐述了模型即服务行业的相关概念，同时对AI大模型行业的发展状况展开分析。接着，报告着重剖析了模型即服务的发展情形以及其在各个行业的应用案例。随后，报告针对国内外重点服务商的布局状况进行了详尽分析。之后，分析了模型即服务行业发展所面临的挑战并给出相应建议。最后，报告对模型即服务行业的发展前景做出了科学的预测。\n报告目录\n第一章　模型即服务（MAAS）相关概述\n1.1　MaaS定义及技术架构\n1.1.1　MaaS起源与概念\n1.1.2　MaaS技术架构\n1.1.3　MaaS产业结构\n1.2　MaaS框架与能力要求\n1.2.1　MaaS框架说明\n1.2.2　模型平台层能力架构\n1.2.3　模型层能力架构\n1.2.4　应用开发层能力架构\n1.2.5　模型服务协议框架\n第二章　2023-2025年AI大模型行业发展状况分析\n2.1　AI大模型行业综述\n2.1.1　AI大模型发展背景\n2.1.2　AI大模型基本类型\n2.1.3　AI大模型发展历程\n2.1.4　AI大模型的必要性\n2.1.5　AI大模型发展特点\n2.1.6　AI大模型应用市场规模\n2.1.7　大模型与MaaS协同发展\n2.2　AI大模型重点行业应用情况\n2.2.1　重点行业应用总览\n2.2.2　金融行业\n2.2.3　泛消费行业\n2.2.4　能源行业\n2.2.5　制造行业\n2.3　AI大模型行业发展前景展望\n2.3.1　AI大模型发展展望\n2.3.2　AI大模型发展趋势\n2.3.3　模型公司发展潜力\n2.3.4　模型公司颠覆场景\n第三章　2023-2025年模型即服务（MAAS）行业发展状况分析\n3.1　MaaS产业发展综述\n3.1.1　MaaS支持政策\n3.1.2　MaaS标准体系\n3.1.3　MaaS产业图谱\n3.1.4　MaaS市场规模\n3.1.5　MaaS竞争格局\n3.1.6　MaaS重塑AI商业\n3.2　MaaS落地方式分析\n3.2.1　对比分析\n3.2.2　公有云\n3.2.3　私有云\n3.3　MaaS供给能力分析\n3.3.1　平台服务\n3.3.2　模型服务\n3.3.3　数据集服务\n3.3.4　AI应用开发服务\n第四章　2023-2025年模型即服务（MAAS）在各行业应用案例分析\n4.1　MaaS落地条件及优势场景\n4.1.1　落地条件\n4.1.2　优势场景\n4.2　MaaS行业应用产品分析\n4.2.1　聊天机器人\n4.2.2　语音终端\n4.2.3　智能座驾\n4.2.4　文章写作\n4.3　MaaS行业实践案例及成效\n4.3.1　银行业金融MaaS平台实践\n4.3.2　电网领域MaaS实践\n4.3.3　电信运营商私域领域MaaS实践\n4.3.4　金融风控领域MaaS实践\n第五章　2023-2025年模型即服务（MAAS）关键技术发展状况分析\n5.1　模型技术发展\n5.1.1　神经网络模型\n5.1.2　决策树模型\n5.2　安全技术发展\n5.2.1　数据加密技术\n5.2.2　访问控制技术\n5.3　集成与部署技术发展\n第六章　2023-2025年模型即服务（MAAS）主要服务商布局状况分析\n6.1　云服务商\n6.1.1　阿里云\n6.1.2　腾讯云\n6.1.3　百度智能云\n6.2　人工智能企业\n6.2.1　商汤科技\n6.2.2　科大讯飞\n6.2.3　云从科技\n6.2.4　华为\n6.3　电信运营商\n6.3.1　中国移动\n6.3.2　中国电信\n6.4　国际巨头\n6.4.1　亚马逊\n6.4.2　OpenAI\n6.4.3　微软\n6.4.4　谷歌\n第七章　2025-2029年模型即服务（MAAS）行业发展建议及前景趋势预测\n7.1　MaaS行业发展面临的挑战\n7.1.1　模型服务规范缺失\n7.1.2　模型服务易用性差\n7.1.3　MaaS基建成本高\n7.1.4　管理体系亟需完善\n7.2　MaaS行业发展建议\n7.2.1　对政府的建议\n7.2.2　对企业的建议\n7.3　MaaS行业发展前景及趋势分析\n7.3.1　MaaS行业发展前景\n7.3.2　MaaS行业发展机遇\n7.3.3　MaaS行业发展趋势\n公司介绍：\n本文作者为中投顾问下属机构： 中投产业研究院 。\n【中投顾问】 是中国领先的产业研究咨询专业机构，提供产业研究、产业规划和产业招商的全流程服务，还开发了产业研究咨询的大数据平台 【中投顾问产业大脑】 。有任何专业问题欢迎互动交流。"
  },
  {
    "title": "苹果M芯片福音！Hugging Face 直接用 MLX-LM 跑 AI 大模型，速度杠杠的！-AITOP100",
    "page_body": "最近有个好消息， MLX-LM 已经直接“入驻”  Hugging Face 平台啦！这可真是个里程碑式的更新，给那些用 Apple Silicon 设备（像M1、M2、M3、M4芯片这些）的小伙伴们带来了大大的便利。以后啊，大家不用再依赖云服务，也不用费劲巴拉地等模型转换，就能直接在本地设备上以超快的速度跑超过4400种大型 语言模型 （LLM）了！\n本地化 AI 开发更普及，工具更高效灵活\n这次集成，无疑又给本地化AI开发添了一把火，让开发者和研究人员们有了更趁手的工具。这工具啊，不仅高效，还特别灵活，能让大家的工作更顺手。\nMLX-LM与Hugging Face的“天作之合”\n说到  MLX ，这可是Apple机器学习研究团队专门为Apple Silicon设备量身打造的机器学习框架。它的目标就是充分利用M系列芯片里的神经引擎（ANE）和Metal GPU的强大性能，让机器学习跑得更快、更稳。\n而  MLX-LM  作为MLX的“得力助手”，主要负责大语言模型的训练和推理。这几年，它因为高效又易用，可是受到了不少人的追捧。现在好了，它跟Hugging Face一集成，直接就能从Hugging Face Hub上加载模型，再也不用多走一步转换模型的路了，工作流程一下子就简化了不少。\n想试试？直接点这里！\n想体验一下这个新功能的小伙伴们，赶紧戳这个链接：** https://huggingface.co/models?library=mlx**。在这里，你能找到各种适合Apple  Silicon设备运行的大型语言模型，让你的设备发挥出最大的潜力！\n总的来说，MLX-LM和Hugging Face的这次集成，真是给Apple Silicon设备的用户们带来了福音。以后啊，咱们在本地设备上跑大模型就更方便、更高效了！\n更多AI行业最新资讯新闻信息（ ai界最新新闻 ）请关注 AI 人工智能 网站-- AITOP100 平台-- AI资讯"
  },
  {
    "title": "“政策东风”劲拂AI赛道—南山区发布30亿元“AI基金群”全链条“托举”AI科创企业-深圳政府在线_深圳市人民政府门户网站",
    "page_body": "　　“双节”后首个工作日，深圳市南山区推出重磅举措——总规模30亿元的“AI基金群”正式发布，这不仅仅是南山区对人工智能赛道的精准“加码”，更标志着其在构建AI产业生态、破解科创企业发展难题上迈出重要一步。\n　　10月9日，在深圳大学城国际会议中心举行的“X-Day”西丽湖路演社模力营AI项目专场上，深圳市人工智能和具身机器人产业基金、力合人工智能和具身机器人产业基金、首汇智源基金三只基金完成签约，共同构建起一个覆盖人工智能、具身机器人等关键领域的资本矩阵，为不同发展阶段与技术路径的AI科创企业提供金融支持。\n　　精准滴灌 三只基金各展所长\n　　回溯今年3月，南山区前瞻性发布《支持科技型企业千亿融资计划》，为科技企业注入金融“活水”；时隔半年，“AI基金群”发布，既是对千亿融资计划的深化延伸，更是南山区锚定AI产业细分赛道、抢占全球科技竞争制高点的战略布局。\n　　作为基金群的“主力军”，深圳市人工智能和具身机器人产业基金以20亿元目标规模领跑，拟由汇通金控联合深圳市引导基金、深创投红土发起设立。该基金将聚焦人工智能和具身机器人基础层、技术层、应用层等细分领域进行投资，推动AI技术商业化落地，激活产业发展新动能。\n　　另外两只各5亿元规模的基金，则各有侧重、形成互补。其中，力合人工智能和具身机器人产业基金拟由汇通金控公司联合力合科创发起设立，将通过力合科创体系深度链接全国高校和科研院所的科技成果转化资源，深挖优质人才和硬科技项目，与市人工智能基金协同，全力支持AI项目从实验室走向应用场景。\n　　力合创投总经理隋建锋介绍说，本次拟设立的5亿元基金100%投向AI与具身机器人产业链企业，更重要的是，将有一半以上投向中早期项目，真正实现“精准滴灌”。\n　　首汇智源基金则拟由首程控股、源创智投资与汇通金控共同发起，不仅开创了北京、深圳两地国资“南北互动”的跨区域协同投资新模式，更开辟了深圳村集体资本参与股权投资的新路径，为AI产业发展拓宽了资金来源，未来将重点布局人工智能、机器人、智能制造等领域，加速“科技创新”与“产业创新”的深度融合。\n　　当日路演环节，埃睿智慧、追梦每刻科技等6家模力营优质企业登台亮相，展示了AI技术在建筑设计、3D生成、三维视觉、机器人等领域的创新应用。\n　　“今年5月，我们推出的开源版本登顶HuggingFace 3D模型排行榜。”追梦每刻科技（深圳）有限公司产品负责人蒋磊介绍，该公司专注打造全球首个多模态交互3D大模型DreamTech，自主研发了全球首个采用3D Diffusion Transformer架构的3D大模型，可通过文本/图像生成高质量3D模型，广泛应用于AR/VR、游戏、动漫、影视、3D设计等领域。\n　　然而，AI产业高速发展的背后，仍面临“成长的烦恼”。有分析认为，在初创阶段，AI创业公司易陷入“估值生意”陷阱，技术沉迷、融资依赖、规模不经济、护城河脆弱等问题突出，尤其在算力、数据、人才等方面的巨额投入，以及技术迭代的持续消耗，让不少企业面临现金流断裂风险；同时，部分企业过度追求技术参数，忽视市场需求，导致实验室成果难以变现。\n　　今年以来，南山辖区众擎机器人、智平方等AI初创企业已相继完成多轮规模不等的融资。随着企业逐步进入技术迭代、市场拓展的关键发展阶段，其对持续性投融资支持的需求愈发迫切。\n　　在此背景下，南山区“AI基金群”的落地，犹如一场“及时雨”，为AI初创企业搭建起跨越“死亡谷”的桥梁。\n　　生态基石 构筑南山AI产业“硬核矩阵”\n　　此次“AI基金群”的落地，并非偶然，而是南山区AI产业实力的主动延伸。作为全国知名的AI产业高地，南山区已形成从技术研发到产业应用的完整生态链。深圳市统计局数据显示，2024年深圳市规上人工智能企业2607家，增加值747.53亿元。其中，南山区拥有人工智能规上企业1351家，数量占全市超一半；人工智能产业增加值达449.07亿元，占全市超60%。全市人工智能产业增加值百强企业中，南山区56家，占比超五成。\n　　这些企业中，既有腾讯、中兴、商汤科技等具有国际竞争力的龙头企业，也有优必选、地平线、奥比中光、第四范式等行业领先企业，更不乏大象声科、贝格迈思、智能思创等行业“新秀”，共同构成了南山AI产业的“硬核矩阵”。\n　　此外，南山区还汇聚了3个省级人工智能产业园，更打造了大湾区首个垂直领域大模型生态社区——深圳模力营AI生态社区。自2024年6月揭牌以来，模力营以“供应十万平方米产业空间、孵化百家创新主体、催生千项智能应用、撬动万亿级经济增量”为战略导向，初步形成具身智能、模型基础、AI+硬件和AI+应用四大板块，成为AI企业成长的“沃土”。\n　　“模力营”虽然被定位为一个生态社区，但并非传统意义上的孵化器或产业园。据南山区科技创新局相关负责人介绍，“模力营”旨在发挥深圳新一代信息技术产业链优势，重点围绕人工智能端侧产业链布局，形成一个产业链的闭环和生态，通过提供差异化的服务，如算力优惠、合规指导、高质量语料等，有效支持降低企业成本，提升产业浓度和生态的活跃度。\n　　“目前模力营已吸引超500家企业申报，200家企业正在排队，102家企业完成入驻，近40家企业在办理手续。”模力营负责人贺飞说，符合条件的企业即可实现拎包入驻，这正是南山对AI企业的诚意。\n　　此次政府引导设立的产业基金并非单纯“给钱”，而是以“耐心资本”的角色，与现有生态形成协同——既为不同阶段的AI企业提供长期稳定的资金支持，缓解其研发与商业化过程中的“失血”压力，更通过资源整合、场景对接，帮助企业打通从实验室研发到市场应用的全流程堵点，最终形成“生态支撑资本、资本反哺生态”的良性循环。\n　　全域赋能 从政策到场景的“超级创新场”\n　　值得一提的是，“AI基金群”并非南山区支持AI产业的“孤举”。今年以来，为破解“从0到1”的创业难题，南山区出台支持创新创业“六个一”行动方案。其中，设立总规模为5亿元的战略直投专项种子基金和天使基金，对经认定的人工智能、机器人、生物医药、低空经济等南山区重点扶持和发展的战略性新兴产业和未来产业的初创企业给予领投支持，基金内单个项目最高允许100%亏损。同时，鼓励企业参与人工智能和机器人应用场景“揭榜挂帅”项目，对参与项目的发榜方、揭榜方根据项目实际建设情况分别给予最高300万元、500万元资助。\n　　政策的“东风”，已催生出AI应用在南山各领域的“遍地花开”。作为名副其实的“超级创新场”，南山的AI技术已深度渗透至智慧城市、医疗健康、智能制造等核心领域，落地成效清晰可感。\n　　在智慧城市领域，南山区利用人工智能、云计算与大数据等技术，启动了人工智能算法超市平台项目建设，今年7月启用的“AI智办”专区，可办理卫健、城管、民政等9个部门的高频事项，实现“智能直达、一站通办”；小马智行等企业在核心路段开展自动驾驶示范运营，累计服务订单超50万单。\n　　在医疗健康领域，AI技术被用于疾病诊断、药物研发等方面。其中，南山区人民医院与迈瑞医疗携手打造的AI智慧联合实验室正式落地，双方围绕急救5G一体化、启元重症大模型、实验室临床验证和研发、数字化影像学等相关领域展开攻关。\n　　在智能制造领域，AI技术则帮助企业实现了生产流程的智能化升级和效率提升。以南山企业索威尔为例，该公司于今年4月在纳斯达克证券交易所挂牌上市，成为南山区第217家上市公司。作为全球领先的机器视觉与人工智能解决方案提供商，2025年6月，索威尔首批出口韩国的精准AI喷涂机器人在韩国某汽车维修中心完成安装并投入运营，帮助其实现了转型升级。\n　　从30亿元“AI基金群”的精准布局，到“模力营”的生态搭建，再到“政策托底+场景赋能”的全域支撑，南山区正以“敢为人先、走在前列”的担当，构建起覆盖AI企业“从孵化到出海”的全链条服务体系。未来，随着各项举措的深化落地，南山区将进一步培育现象级AI领军企业与产业中坚力量，持续打通创新孵化“第一公里”与“出海”创业“最后一公里”的服务闭环，为粤港澳大湾区乃至全国AI产业生态的完善，源源不断贡献“南山力量”。"
  },
  {
    "title": "【行业深度】洞察2025：中国人工智能代理行业竞争格局及市场份额（附市场集中度、企业竞争力评价等）行业研究报告-前瞻网",
    "page_body": "2025-2030年全球 人工智能芯片（AI芯片） 行业市场调研与发展前景研究报告 2025-2030年中国 AIGC（人工智能生成内容） 产业发展前景与投资战略规划分析报告 2025-2030年中国人工智能数据中心（AIDC， 智算中心 ）行业发展前景与投资战略规划分析报告 2025-2030年全球及中国 人工智能芯片（AI芯片） 行业发展前景展望与投资战略规划分析报告\n行业主要上市公司 ： 科大讯飞 (002230)、第四范式(06682)、 拓尔思 (300229)、 用友网络 (600588)、云从科技(688327)、出门问问(02438)、迈富时(02556)等\n本文核心数据 ：人工智能代理竞争派系，竞争分布热力图，市场集中度等\n1、中国人工智能代理行业竞争派系\n中国人工智能代理行业已经形成了较为清晰的竞争梯队，头部效应显著，而垂直领域和新兴企业正在快速崛起中，其中竞争派系主要分为三个梯队：科技巨头类企业、垂直领域类企业、创新初创型企业。\n从各梯队的代表性企业上来看，在不同梯度上的企业实际上的关键业务布局方向并不统一，企业之间更多以差异化布局来实现技术上的突破，同时在科技巨头和垂直类领域的布局上更注重对B端和较为专业的市场，这是由于企业本身所持有的技术布局和壁垒决定的。相反，初创企业则更注重对C端的市场，通过开源吸引专业领域平台的一些技术人员，变现则靠相对技术水平没有那么高的付费用户。\n2、中国人工智能代理行业市场份额\n根据企业公开报告和市场信息，在非专注市场上，CR4高达约78%，而CR5约为88%，这表明人工智能代理市场属于高度集中的市场，而后以 科大讯飞 、用友、商汤科技等二线阵营占据约10%，其余初创企业与垂直领域企业整体份额不足3%，单家普遍地于0.5%，呈典型“头部集中、尾部分散”的马太效应格局。\n3、中国人工智能代理行业细分领域集中度\n而按现有主要应用领域划分，主要分为政务、金融、制造、智能客服四个板块，其中政务方面CR3最高，高达60%，而最低的是智能客服CR3为40%，政务方面的应用主要集中在政策解读，智能审批，而集中度较高的原因主要是因为招投标的要求所导致的市场壁垒较高。反观智能客服方面，市场进入壁垒较低，所以集中度相对而言就比较低。\n按照技术类型划分，目前市场上主要分为反射性代理、目标驱动型代理、自学习型代理，反射性代理主要应用于智能客服、智能家居等场景，而目标驱动型代理则主要用于金融风控和工业调度。自我学习型代理作为年增速最高的技术类型，集中在医疗诊断和科学研究领域。\n4、中国人工智能代理行业企业布局及竞争力评价\n如前面的分析所说，中国头部企业主要呈现一种“多点开花，协同发展”的局势，百度主要布局 数字人 与智能体协作平台、华为则重点布局政务和工业方面的智能体、阿里和字节则更侧重销售方向的学习和响应类型的智能体。\n5、中国人工智能代理行业竞争状态总结\n中国人工智能代理行业已呈现“寡头垄断、垂直深耕、资本加速”的三重竞争态势：百度、阿里、腾讯、华为、字节跳动凭借算力、数据与生态优势牢牢占据八成以上市场份额，形成高壁垒的寡头格局;科大讯飞、商汤、云从、第四范式等二线厂商则在教育、金融、安防等垂直场景深耕差异化模型，以行业 Know-how 和快速落地换取生存空间;与此同时， 地平线 、思必驰、追一科技等三线及大量初创公司依靠细分技术或场景创新切入，但在融资收紧、算力成本高企的背景下正加速出清，行业并购窗口已现，整体竞争从“技术赛跑”转向“生态卡位+场景盈利”的淘汰赛阶段。\n更多本行业研究分析详见前瞻产业研究院《 中国人工智能行业发展前景预测与投资战略规划分析报告 》\n同时前瞻产业研究院还提供 产业新赛道研究 、 投资可行性研究 、 产业规划 、 园区规划 、 产业招商 、 产业图谱 、 产业大数据 、 智慧招商系统 、 行业地位证明 、 IPO咨询/募投可研 、 专精特新小巨人申报 、 十五五规划 等解决方案。如需转载引用本篇文章内容，请注明资料来源（前瞻产业研究院）。\n更多深度行业分析尽在 【前瞻经济学人APP】 ，还可以与500+经济学家/资深行业研究员交流互动。更多企业数据、企业资讯、企业发展情况尽在 【企查猫APP】 ，性价比最高功能最全的企业查询平台。"
  },
  {
    "title": "大模型免费是“赔本赚吆喝”新华网",
    "page_body": "  据央视新闻报道，近日，国内外多家大模型厂商纷纷宣布免费开放其大模型服务，这一举措引发了行业的广泛关注。\n  百度2月13日发布消息，文心一言将于4月1日0时起全面免费，所有PC端和App端用户均可体验其最新模型，包括超长文档处理、专业检索增强、高级AI绘画、多语种对话等功能。同日，OpenAI也宣布免费版ChatGPT将在标准智能设置下无限制使用GPT-5进行对话。此外，谷歌最新人工智能模型套件也于近期宣布正式向所有用户开放使用。\n  中国信息通信研究院技术与标准研究所工程师龚正表示，像DeepSeek等开源模型的崛起，其灵活、低门槛的特性正在重构行业生态，迫使头部玩家必须打破封闭生态。当开源模型能实现商用模型80%甚至90%的功能，而成本仅为10%时，闭源系统的护城河自然瓦解，免费开放成为巩固用户黏性的战略选择。\n  在过去的几年中，人工智能大模型的商业运营模式主要围绕付费使用展开。随着大模型训练技术越来越成熟，硬件效率的提升，让模型训练和推理的成本大幅降低。\n  技术的成熟、开源生态的倒逼，让大模型厂商纷纷加入免费的行业。人工智能大模型免费，听起来像是“赔本赚吆喝”，免费背后隐藏着怎样的商业逻辑？\n  龚正介绍，头部厂商的技术优势为免费铺平了道路。无论是DeepSeek、百度、阿里还是OpenAI，当技术领先者能够以更低成本提供更高性能的服务时，“免费”反而成为巩固市场地位的利器。\n  免费潮将加剧行业洗牌。中小厂商若无法承担长期免费所需的技术迭代成本，可能被迫退出市场，而头部企业则通过用户数据积累反哺模型优化，形成“技术升级—用户增长—成本下降”的循环。这种模式下，资源会进一步向具有算力、数据和资金优势的企业集中。\n  龚正表示，免费的基础服务将成为流量入口，通过技术输出、企业级解决方案等增值服务实现商业闭环。这场竞争的本质，是争夺下一代人机交互标准的制定权。\n  免费模式的推出，让人工智能行业进入了一个新的发展阶段。随着技术的不断进步和成本的降低，未来人工智能大模型的商业运营模式如何演变？\n  专家告诉记者，免费会吸引更多用户和开发者，推动AI技术的普及和应用。另一方面，这也会引发新的竞争格局，促使其他企业跟进或探索新的商业模式。\n  赛迪顾问人工智能与大数据研究中心分析师白润轩表示，基础功能免费是大势所趋，但对于企业级需求，还是会按需收费。随着各国对AI监管的加强，比如欧盟的AI法案、数据溯源、安全审核这些要求会让厂商面临更高的隐性成本。这也可能导致一些新的收费模式出现，比如“合规增值服务”。"
  },
  {
    "title": "一觉醒来，GitHub没了？CEO辞职，微软接管，开发者天塌了",
    "page_body": "新智元报道 \n 编辑：Aeneas KingHZ \n 【新智元导读】GitHub变天了！今天起，它不再独立。它再也不是那个为开发者的自由而生的平台，而成了微软AI代理工厂的一部分。CEO宣布辞职，出走创业。终于，一个时代落幕了。 \n 一觉醒来，独立的GitHub没了！CEO也没了！这也太戏剧性了。 \n 今天一早，一则重磅新闻震撼了整个开发者圈子—— \n GitHub CEO Thomas Dohmke突然宣布辞职，并透露GitHub将不再独立运营，而是整体并入微软新成立的CoreAI工程集团。 \n 并且，微软也不会再为GitHub寻找新的CEO。 \n 简而言之：GitHub，从此不再是一家「独立运营」的公司了。\n自2018年微软以75亿美元收购以来，GitHub首次失去「子公司」身份，成为CoreAI的一部分。 \n Dohmke将留任至年底协助交接，随后重启创业。 \n CoreAI由前Meta高管Jay Parikh掌舵，目标是打造面向企业与开发者的「AI智能体工厂」。 \n 这就传递出一个重大信号：GitHub的独立旗帜正式降下，全球最大代码托管平台正沦为微软AI时代的「武器库」。\nGitHub，将成为AI工厂的一环 \n 昨日，GitHub首席执行官Thomas Dohmke宣布，将卸任这一职位。\n而不再有继任CEO的GitHub将何去何从？媒体披露的备忘录显示，微软会直接从上到下调整它的管理架构！ \n 此后，GitHub将由多位微软高管分管： \n 微软开发者部门负责人Julia Liuson，将负责GitHub的营收、工程及支持工作； \n GitHub首席产品官Mario Rodriguez，将向微软AI平台副总裁Asha Sharma汇报。 \n 这场大整合背后的主导人，就是微软CoreAI团队的负责人——前Meta高管Jay Parikh。 \n 他一早就放出豪言：「我希望我们的平台，能变成所有公司和组织的AI智能体工厂。」 \n 也就是说，从此，GitHub将不只是一个代码托管平台，而是成为微软专属的「AI智能体流水线」。 \n 回顾今年，微软的一系列动作背后的用意，已经非常明显了。 \n 首先，微软把OpenAI的Copilot深度接入了GitHub，现在又收紧了控制权，直接把GitHub吞并进了AI部门。 \n 这一连串的操作，就是为了让GitHub不只是写代码的地方，而成为微软的AI训练兵工厂。 \n 被微软收购七年，GitHub终于到了这一天 \n 自2018年被微软收购以来，GitHub一直保持相对独立运作。 \n 但在微软整体战略中，它的地位正变得愈发重要——不仅是吸引开发者使用Windows和Azure的关键平台，也已成为微软AI工具生态的重要组成部分。 \n 在离职声明中，Dohmke表示：从移动开发工具，到参与并推动GitHub收购，再到担任CEO，领导GitHub进入Copilot与AI的新时代，这是一段终生难忘的旅程。 \n 不过，创业的心又开始呼唤他。他决定离开GitHub，再次创业。 \n Dohmke称，自己是在GitHub「状态最佳」时离开的： \n 如今GitHub已有超过10亿个代码库与分支，开发者数量突破1.5亿。正是因为大家的不懈努力，GitHub Copilot带来了自个人电脑问世以来软件开发领域最大的一次变革。 \n 微软收购GitHub已过去七年。当初外界认为，这笔交易是微软从「抗拒」到「拥抱」开源的标志。而如今，随着生成式AI的崛起，GitHub已成为全球开发者的核心工作场所。 \n 对微软而言，GitHub也站在了「Copilot化」AI战略的最前沿——将AI助手嵌入旗下几乎所有产品。 \n Copilot从一个简单却神奇的自动补全工具，发展成拥有Copilot Chat&Voice的对话式编程助手，再到能审查与修复代码、用GitHub Spark构建全栈应用。\n如今，GitHub Copilot已是AI时代最成功、最繁荣市场的领导者，用户数超过2000万。\nGitHub被IDC评为2025年AI编码和软件工程技术供应商领导者 \n 过去一年，它与Anthropic、谷歌和OpenAI合作，成为微软首个多模型解决方案。 \n Github为数百万用户提供了免费版Copilot，并在VS Code中推出同步Agent模式，在GitHub中推出原生异步编码Agent。 \n 开发者工具的未来，是什么样子？微软的答案是——AI first。 \n 总之，今后的GitHub，很可能会变成这个样子—— \n Copilot更深入控制工作流 \n 自动生成代码不再是辅助，而是主角 \n GitHub+Azure成为微软AI工具闭环中的一环 \n 也就是说，未来所有的开发者，可能都不再是写代码的人，而是监督AI写代码的人。 \n 突如其来还是激流勇退？ \n 早在2021年，GitHub的汇报架构就有过变化。 \n 当时前任CEO Nat Friedman卸任， Dohmke开始向微软开发者部门主管Julia Liuson汇报。而今年初，随着CoreAI 团队成立，Liuson又改为向Parikh汇报。 \n 就在上周， Dohmke还接受采访，畅谈Copilot、「氛围编程」（vibe coding）以及AI的未来。\n当时，他还在思考竞争格局和GitHub在软件开发未来中的角色，而现在，他将离开，或许去打造可能与微软AI形成竞争的新项目。 \n CEO的诀别信 \n Thomas Dohmke在这封告别信中，充满不舍地写道—— \n 十多年前，我的初创公司被微软收购后，我和我的家人毅然从德国搬到了美国。 \n 此后的几年里，我有幸与许多杰出人士共事，我们一起塑造了GitHub。 \n 作为一个遍布全球的远程优先组织，我为我们所做的一切感到无比自豪。\n由于你们的不懈努力，GitHub Copilot为软件开发带来了自个人计算机问世以来最伟大的变革。 \n 虽然我为来之不易的业务增长感到自豪，但纯粹为了自身利益而构建的技术，除非服务于更伟大的目标，否则也不过是虚荣而已。 \n 只有世界成功，我们才能成功。通过开启开发者人工智能的新时代，世界很快就会迎来十亿开发者，他们将由数十亿AI智能体赋能，每个智能体都将人类的智慧转化为新的软件金矿。 \n 当那一天到来时，我们就会知道这条路的起点：GitHub。 \n 谢谢你，Hubbers。能成为你们的同事和领导是我的荣幸，我会珍惜我们共度的美好时光。 \n 再见，谢谢所有的鱼。 \n 一个时代结束了 \n 可以说，GitHub的这波大变身，远远不是简单的人事更迭，而是一场软件开发范式的彻底转向。 \n 当年，比尔·盖茨希望用微软的软件改变全世界，而今，微软希望用GitHub+AI改变写代码这件事本身。 \n 开发者们，也不得不适应这个新世界—— \n 如果你还认为，GitHub是程序员的乐土，那这场变革，可能让你再也回不去了。"
  },
  {
    "title": "AI应用上云指南：全球三大平台优劣势全解析-百家号",
    "page_body": "在生成式 AI 全面兴起的当下，企业间的竞争正从 “谁先用 AI”，转向 “谁能用好 AI”。\n无论是智能客服、预测分析、内容生成，还是供应链优化，\nAI 已成为企业提升效率、降低成本、拉动增长的核心引擎。\n但要让 AI 真正落地，企业需要的不只是算法，而是一整套 高性能、可扩展、安全可信的云计算基础设施。\n它既要能支撑模型训练的庞大算力需求，又要能在生产环境中快速部署、弹性扩展、稳定运行。\n在这一赛道上，AWS（Amazon Web Services） 凭借领先十余年的 AI 基础设施建设、完善的工具链生态与全球安全合规体系，\n成为全球企业部署 AI 应用的首选平台。\n从模型开发到部署运营，AWS 提供了覆盖全链路的服务能力，\n帮助企业以最低的技术门槛快速搭建 AI 生产力。\n与此同时，华为云 与 阿里云 也在本地市场深耕行业化 AI 解决方案，\n为政企与制造业客户提供更贴近场景的部署支持。\n但在全球算力规模、AI 工具生态与跨区域合规标准上，AWS 依旧代表着企业 AI 部署的 “技术上限”——\n它让 AI 不只是概念，更是真正可落地的生产力。\n一、AWS—— 企业部署 AI 应用的全球首选平台\n在全球云计算市场中，AWS（Amazon Web Services）是较早布局 AI 基础设施和智能应用生态的云平台之一。\n它不仅提供强大的算力和灵活的资源架构，更为企业构建了一个从模型训练到部署、从应用落地到安全管理的完备 AI 生态体系。\n无论是中小企业的 AI 转型，还是大型组织的生成式 AI 战略落地，AWS 都能为不同阶段的企业提供精准赋能。\n算力层：AI 计算的全球基础设施\nAI 的核心是算力。AWS 拥有全球规模最大的计算资源网络，提供包括 Trainium、Inferentia 在内的专属 AI 芯片，以及 P5 GPU 实例集群，支持从轻量 AI 模型到大型语言模型（LLM）的高强度模型训练任务。其 EC2 Auto Scaling 架构让企业按需调用计算资源，实现 “高峰不掉速，低谷不浪费”。全球领先的企业如 Anthropic、Stability AI、Netflix 都选择在 AWS 上训练并部署模型。\n模型层：SageMaker 与 Bedrock 打造端到端 AI 平台\nAWS 的 Amazon SageMaker 是全球应用范围最广的机器学习平台之一，提供模型训练、调参、自动化部署和性能监控的完整闭环。它让开发者可在数小时内构建 AI 模型，而无需组建庞大的 AI 团队。\n而 Amazon Bedrock 则面向生成式 AI 领域，可直接调用业界主流大模型（如 Claude、Llama、Titan），并允许企业将自有数据安全地接入，实现专属 AI 应用。从代码生成到客服自动化，从文本摘要到图像识别，企业都能在 AWS 上快速落地 AI 业务场景。\n应用层：让 AI 真正服务业务增长\nAWS 提供了丰富的 AI 应用服务：Amazon Comprehend（自然语言理解）、Rekognition（视觉识别）、Transcribe（语音识别）、Lex（对话生成）。这些服务无需复杂开发工作，即可通过 API 直接嵌入企业系统。无论是智能营销、客服机器人，还是制造质量检测，AWS 都能实现 “AI 即服务” 的快速部署。\n安全与合规层：AI 落地的全球信任基线\n在 AI 的落地过程中，安全与隐私是企业最重视的部分。AWS 通过 ISO、SOC、GDPR、FedRAMP 等多项全球认证，确保 AI 模型的训练、部署和数据使用都符合国际标准。其加密管理（KMS）与身份权限控制（IAM）系统，帮助企业在多地区、多团队协作中维持严格的访问与数据安全管理。\n凭借算力、模型、应用与安全的全链整合，AWS 已成为企业 AI 应用部署的 “首选标准平台”。它不仅让 AI 更易落地，更让 AI 真正创造可衡量的商业价值。\n华为云与阿里云的本地化补充\n在全球云计算格局中，AWS 以其领先的 AI 算力、模型生态与安全体系，成为企业部署 AI 应用的首选平台。但在中国市场，华为云与阿里云也在行业落地和本地化支持方面，形成了对 AWS 的互补作用，尤其在政企、制造、零售等垂直领域表现突出。\n华为云依托自主研发的昇腾系列 AI 处理器和 ModelArts 平台，构建了端到端的 AI 开发与训练环境。该平台支持模型训练、自动调优、推理部署与可视化管理，在金融、制造、能源等高安全行业中应用广泛。其优势在于 “国产化生态兼容” 和 “本地数据可控”，对需要私有化部署、信创适配的政企客户尤为友好。不过在全球算力规模、跨区域协同与模型开放度方面，华为云仍以 AWS 为技术对标与参考标准。\n阿里云则依托通义大模型（Qwen）与 PAI 平台，在内容生成、营销自动化、智能客服等应用场景中表现突出。其 “云上大模型服务” 能让企业快速构建 AI 应用，并与阿里生态（钉钉、淘宝、MaxCompute）形成数据闭环。这让阿里云成为互联网与电商企业进行 AI 实践的重要平台。然而在 AI 芯片层自主可控性、跨国合规和生态开放程度上，AWS 的技术体系仍处于领先水平。\n总体而言，华为云与阿里云强化了 AI 的行业深度与本地化能力，帮助中国企业更快地在场景中实现 AI 落地；而 AWS 则代表了全球 AI 应用部署的标准化与智能化高度，让企业能够在全球任意市场保持一致的算力体验与合规安全。\n可以说：华为云、阿里云在 “行业纵深” 中发力，而 AWS 掌握 “全球标准”。三者共同推动了 AI 云生态的全面繁荣。\n二、全球 AI 云平台对比 ——AWS 定义 AI 部署标准\nAI 应用要落地，需依托强大的算力支撑、完善的模型生态与成熟的安全体系。当前全球主流的 AI 云平台 ——AWS、华为云、阿里云 —— 在核心能力上各有特色，但在整体架构完整度、技术成熟度和全球通用性方面，AWS 依然确立了行业的技术上限。\n华为云与阿里云则在本地场景形成补充。\n2025全球AI云平台对比图\n从表中能看到，AWS 在 AI 算力、模型生态、安全合规及全球化部署四个关键维度全面领先。它不仅提供计算支持，更提供 “AI 落地的完整方法论”：从算法训练、模型微调到生产环境部署，企业可在同一平台内实现全流程管理。\n此外，AWS 的开放架构让企业在生成式 AI 时代能灵活选择模型，无论是调用自研模型，还是集成第三方大模型（如 Anthropic、Meta、Cohere），都可实现安全、快速的集成体验。\n相比之下，华为云 和 阿里云 分别在政企数字化和电商智能化方向上构建特色优势，深化了 AI 在本地场景的行业深度。但在全球部署、模型开放度及跨区域 AI 协同能力上，AWS 依旧是企业 AI 部署的 “全球基准线”。\n可以说，AWS 定义了 AI 应用的部署标准 —— 不仅能跑 AI，更能让 AI 跑得稳、跑得远。\n结语 ——AWS 让企业 AI 落地更快、更稳、更安全\n在生成式 AI 高速发展的时代，企业想要真正让 AI 创造业务价值，不仅需要算法和模型，更需要可长期支撑的云计算底座。这个底座，必须既能承载海量训练算力，又能保障部署安全与持续扩展。\n从全球视角来看，AWS（Amazon Web Services）已成为企业部署 AI 应用最具代表性的云平台。它通过 Trainium 与 Inferentia 芯片 搭建起高性能的 AI 算力网络，以 SageMaker 和 Bedrock 打造出完整的 AI 开发与生成式应用生态，同时以 ISO、GDPR、FedRAMP 等国际认证体系 建立了行业最全面的安全标准。无论企业处于 AI 探索期还是全球扩张期，AWS 都能提供灵活的算力弹性与稳定的运行保障。\n相比之下，华为云 与 阿里云 在本地行业深耕领域，分别通过国产化生态和垂直场景创新，为企业提供了多元的 AI 落地路径。但在 AI 开放生态、全球合规支持与跨区域部署能力上，AWS 仍是企业对标与参考的首选平台。\n如今，AI 已不再是 “未来趋势”，而是 “当下竞争力”。选择一个真正懂 AI 的云平台，意味着让企业的创新速度与 AI 技术进步保持同步。\nAWS 用全球标准和智能算力，让 AI 不再仅是概念，而是企业的核心生产力。对于任何想要迈入 AI 时代的企业来说，AWS，不只是部署 AI 的最佳起点，更是通向未来的长期伙伴。"
  },
  {
    "title": "大模型开闭源争吵不休：开源落后闭源一年，决定模型能力的不是技术？腾讯新闻",
    "page_body": "作者 | 华卫\n开源和闭源之争，在大模型时代依然延续着。前不久，百度创始人李彦宏在内部讲话中发出“开源模型会越来越落后”的言论，再次将这一话题引爆。\n不仅有许多业内人公开提出不同看法，似乎还接连迎来市场层面的“回应”：Meta 时隔两日发布性能直追 GPT 4 的开源大模型 Llama 3，苹果、微软又各自开源了针对手机等移动设备的语言模型 OpenELM 和 Phi-3 Mini。\n然而，尽管开源模型在今天的崛起有目共睹，其背后的问题依然不可回避。由于本身的黑盒属性，开源的“众人拾柴火焰高”优势并不能完全显现在大模型上，甚至成本和效率更受影响。那么对于各个行业的厂商来说，身处如今的大模型市场，该做出怎样的选择？\n带着这一问题，InfoQ《极客有约》特别邀请了零一万物开源负责人林旅强担任主持人，与 Data Strato 副总裁史少锋、华为 AI 科学家张敏、LLMFarm 创始人 & CEO 宜博， 在 AICon 全球人工智能与机器学习技术大会即将召开之际，一同探讨开源与闭源模型的现状、差异及未来发展。部分亮点如下：\n整体开源落后于闭源，以 GPT 为代表大概是一年时间的差距；\n模型能力的差异不在于开或闭，而是背后的人与团队；\n自建模型还是购买第三方服务，企业要根据各自的商业场景选择成本和合规需求最适合的部署方式；\n企业使用大模型可能不止一套，会像今天使用云一样是混合架构；\n正确认识大模型的能与不能才是避坑最好的条件。\n在访谈的第一部分，四位专家分别对开源、闭源大模型的成本能力和效益进行了分析；第二部分分析了两类大模型面临的技术和合规挑战；第三部分则是从实际应用与效果角度进行了分析。以下为访谈实录，经编辑。\n完整视频参看：\nhttps://www.infoq.cn/video/pKua6PxVgxvdDygcgrWd\n开源、闭源哪家强？\n林旅强： 目前从模型能力的角度来说，开源阵营和闭源阵营之间整体是什么样的情况？\n张敏： 大模型是从 ChatGPT 热起来以后，被越来越多的人和公司关注到，现在看是有开源、闭源之说。闭源的代表是 OpenAI，以及 Claude 也有一部分模型是闭源的。开源来看，从 Llama 1 到最新的 Llama 3，效果越来越好，大家也越来越认可这些模型，最近看到 Meta 的 400B 大模型，效果已经和 GPT 4 非常接近了。从开发者角度，我们希望能看到更多效果更好的开源模型，这实际上对整个大模型领域的繁荣可能会有更多帮助。\n宜博： 个人认为，整个开源和闭源社区的模型分为三个阶段：小于 GPT 3 或者 3.5 的，接近于 GPT 3 和 3.5 的，接近于 GPT 4 的。去年上半年， OpenAI 发了 GPT3.5 和 GPT 4 之后遥遥领先于整个开源社区；到去年下半年时，开源社区的情况有了很大改变，发布了很多接近于 GPT 3-3.5 能力的新模型，今年上半年开始有一些部分能力已经靠近 GPT 4 的开源模型。\n整体来讲，开源社区当前还是落后于闭源社区，如果以 GPT 为标准呢，大概是一年时间的差距。开源社区其实一直处在追赶闭源社区的态势，但这种差距在缩小。今年上半年又发了 Sora，开源社区开始追 Sora，到现在为止虽然做了很多努力，但效果还差很多。\n史少锋： 刚才两位老师发表了他们的观点，我觉得整体上大家的感觉差不多，就是一开始闭源模型遥遥领先或让人眼前一亮，但随着更多的开源模型被放出来，开源的能力也在快速跟上。作为模型使用者，今天我们主要还是通过 API 的方式来用大模型，但现在新的开源模型能力越来越强，同时对计算资源的要求在不断降低。我们期待不远的将来，开源模型可以在本地跑起来，能够完全私有化地去支撑一些应用，这对我们有很大的吸引力。\n林旅强： 那什么因素会严重影响开源和闭源模型的能力差异呢？\n针对这个问题，我个人认为开源和闭源模型的能力差异，重点不在于它开源或闭源，而是它的研发团队的能力差异。至于做出来的模型要开源还是闭源，是进一步从该公司的整体商业模式去考虑的点。之前 Llama 推出的时候，我非常兴奋，觉得终于有人运用开源来突围闭源的大模型了，因为训练模型成本实在太高，要开源本来就不容易；虽说至今二者仍有些差距，但如果不开源就没机会给开发者和产业界有另一种选择了。\n史少锋： 的确，模型会很依赖于开发团队的工程能力，并不在于开源还是闭源。今天的开源模型也并不是真正的开源，正如百度创始人李彦宏所说，大模型本身就是一个黑盒子，并不能指望社区有多少贡献。除此之外，模型还依赖于掌握的数据语料质量、丰富程度以及算力规模。这也是为什么今天我们看到，只有非常大型的公司才能开发出让整个业界为之一亮的大模型。\n宜博： 我认同开源和闭源对模型能力的影响并不在于形式，而在于背后的人，和背后的团队所持有的资金、算力、数据。\n林旅强： 大模型跟开源软件有一点很不一样的地方，就是开源软件有可能因为社区不断有代码贡献而变得更好，但现在业内所谓的开源大模型则是把权重 open 出来，没办法以开源社区贡献上游的模式让算法和数据质量更好，确实很依赖出品团队的能力，如数据、框架算法调优、算力门槛还有最新方法的挑选。所以在我们看来，模型能力的差异不在于开源或闭源，而在于团队的人才密度有多高。\n张敏： 数据、算力和算法对大模型都至关重要，算法是与团队是强相关的，这对于模型最终效果的提升是非常重要的。\n林旅强： 刚才我们讨论到开源、闭源模型的能力，那它们的差距到底是逐步缩小还是增大？开源是不是会越来越不好？闭源越来越领先？\n宜博： 我认为差距并不是持续扩大和缩小，而是永远在动态平衡变化的状态。\n林旅强： 那照你的描述是不是永远闭源走在前面，开源在追赶？\n宜博： 这一点其实是由行业现状决定的，比如在服务器领域，Windows 现在很难追得上 Linux，iOS 有一些领域也追不上安卓。大模型领域是由 OpenAI 开始主导的，所以在其领头羊位置不变的情况下，不管是闭源还是开源的，只要落后于 OpenAI 都是在追赶。\n林旅强： 所以这个问题应该调整为，GPT 跟其他模型的能力是逐渐缩小还扩大。\n史少锋： 站在百度文心一言的角度来说，我理解他们在思考的是有没有必要做开源，开源模型并不一定能像普通开源软件那样有“众人拾柴火焰高”的效果，反而要花费更多的时间和精力去做各种合规、对外发布、问题收集等流程。在这种情况下，他们认为开源没有必要，闭源的话效率更高，可以使团队更加聚焦于训练下一代模型。某一天 OpenAI 把大模型开源了，是否能代表开源打倒了闭源呢？我觉得也不是。\n林旅强： 那从成本、能力、效益分析的话，部署自己的大模型与使用第三方大模型在初期成本上有什么不同？长远来看，自建模型与购买模型服务在成本上又会如何变化？\n宜博： 我们做了很多轮实践发现，假如第一次去验证模型，用 API 调用是最划算的，因为 API 用量很少。但如果要跑数据，一定要用自己的服务器和开源模型去做，否则成本太大了。比如我们曾经有个项目，大概算下来，全部跑 API token 比自己购买服务器的成本要贵 200 多万。再就是推理部署的未来环境，用户量大到一定程度后会有个临界点，可能就用自己的服务器比较划算了。所以，要根据大家各自使用的场景去选择不同的成本策略。\n张敏： 从我们对接的客户来看，他们是更希望通过本地的私有化部署来做业务支撑，这对数据安全是非常有好处的。\n史少锋： 站在用户的角度，我觉得今天的 SaaS 大模型服务已经非常便宜，如果自己去搞部署，那成本就高了去了。目前 Open AI 的价格不代表以后，大家都在卷，很多价格会更低，国内甚至有免费开放给公众使用的。对于 To B 领域，可能第一考虑的是数据安全，To C 没有看到用私有化部署的。\n林旅强： 确实，除了部署成本外还有一些隐性的成本，比如客户是不是愿意模型平台把他通过 API 所调用的数据拿出去再训练。个人去使用的话， API 确实门槛比较低，现在各家的价格都还算是比较便宜。\n那如果从总体的成本控制方面，企业应该如何去选择适合自身的大模型策略？\n我个人认为要看企业本身想怎么用大模型，如果单 API 就能够解决且量没有很大的情况下，先去把 API 稳定地搞起来；但如果要结合非标的数据场景去做，那只能加上开源的部署。\n宜博： 企业真正在用的时候，一般是一个递进的验证过程，首先用最便宜的 API 去验证 POC，甚至直接在 ChatGPT 上免费验证，之后如果有开源的部署需求，再去验证场景。过程中需要企业自己想清楚，如何在满足场景的情况下选择成本和合规需求最适合的部署方式。\n林旅强： 我想补充一点，之前有人问国内是需要私有部署的多还是调 API 的多，我就说要先看合规问题。因为现在有政策要求用国产服务，但还有一些人是用了“套壳网站”调外网大模型的 API 。\n张敏： 大模型也有参数量的大小区别，我们真正在给客户在做应用时，还是要根据业务领域的效果来看。在百度的文心一言里，也是用大模型和小模型一起来支持用户需求。\n史少锋： 企业使用大模型后，可能也会像今天使用云一样是混合架构，根据不同需求一部分可能会放在公有云上，一部分放在私有云。为了确保应用端的用户无感，可以把 SaaS 版的大模型作为一个 Plan B，相当于做了一层保护机制。综合而来的话，以后企业可能不止一套大模型。\n林旅强： 我也想补充一下，现在所谓的大模型到底多大？从成本能力与效率分析来讲，我们也得把大模型分为不同档次。虽然 scaling law 是存在的，但越大的模型性价比越往下；而小模型现在要做出效果的门槛其实也很高。目前不管多大的模型都有各种不同的成本要去考虑，所以最终还是需要回到具体场景和商业产品的本质来看。\n技术与合规挑战\n林旅强： 在技术实现层面，自建大模型与采用第三方模型在技术难度和支持上有何不同？\n宜博： 现在自建大模型一般有几种难度：第一种是买一个小机器放在办公室，如果要买高算力机器放在机房或者自建机房，难度指数是很高的；第二种，有了算力去部署时，也会遇到各种各样的问题，如推理框架选择、速度、机器使用等，这些对于没有专业技能团队的非技术企业消耗很大，过程中虽然所有技术人员学了很多东西，但公司的环境部署和上线成本非常大。\n史少锋： 我觉得这个问题并不是很精确，自建大模型和用第三方模型的技术难度和配置不同。今天大家都在用第三方模型，但自建大模型还是偏少，大家更多还是用外部做得好的模型，区别就是自己部署的大模型和第三方"
  },
  {
    "title": "DeepSeek发布Janus-Pro-7B：开源多模态大模型的技术突破与部署指南",
    "page_body": "简介： DeepSeek发布开源多模态大模型Janus-Pro-7B，支持本地与Colab部署，实现图像识别与生成，基准测试超越DALL·E 3，为开发者与企业提供高性价比解决方案。\n引言：开源多模态模型的战略意义\n在人工智能领域，多模态 大模型 （支持文本、图像、视频等跨模态交互）已成为技术竞争的核心赛道。OpenAI的DALL·E 3和GPT-4V等闭源模型凭借强大的生成能力占据市场，但高昂的API调用成本、数据隐私风险以及技术黑箱问题，限制了中小企业和研究机构的创新空间。\n2024年3月，DeepSeek正式发布开源多模态大模型 Janus-Pro-7B ，以70亿参数的轻量化设计，实现了 图像识别 （Understanding）与图像生成（Generation）的双模态能力，并在基准测试中超越DALL·E 3。更关键的是，其支持 本地部署 与 Colab免费部署 ，大幅降低了技术门槛，为 开发者 、 教育 机构及初创企业提供了高性价比的AI工具链。\n一、Janus-Pro-7B的核心技术突破\n1. 多模态架构创新：统一编码器-解码器设计\nJanus-Pro-7B采用 双塔式Transformer架构 ，通过共享的文本-图像编码器（Encoder）提取跨模态特征，再由独立的解码器（Decoder）完成识别或生成任务。这种设计避免了传统多模态模型中“模态间干扰”的问题，显著提升了小参数模型下的任务精度。 \n图像识别路径 ：输入图像经Vision Transformer（ViT）编码后，与文本查询通过交叉注意力机制对齐语义，输出分类标签或描述文本。  图像生成路径 ：文本提示通过语言模型编码，与噪声图像（扩散模型初始输入）在潜在空间融合，经U-Net解码器逐步去噪生成图像。 \n2. 训练数据与算法优化\nDeepSeek团队通过以下策略提升模型性能： \n数据多样性 ：构建包含1.2亿张图文对的多模态数据集，覆盖艺术、科学、日常场景等200+类别，解决长尾分布问题。  两阶段训练 ： \n预训练阶段 ：使用对比学习（CLIP目标）对齐图文语义，强化跨模态理解能力。  微调阶段 ：采用LoRA（低秩适应）技术，仅调整0.7%的参数完成生成任务的专项优化，降低计算成本。 \n高效扩散模型 ：在生成路径中引入 潜在扩散模型（LDM） ，将图像压缩至64×64潜在空间处理，速度较原生扩散模型提升3倍。\n二、性能对比：超越DALL·E 3的基准测试\n在权威多模态评估集 MM-Bench 中，Janus-Pro-7B以 综合得分89.7 超越DALL·E 3（87.2），尤其在以下场景表现突出：\n| 评估维度 | Janus-Pro-7B得分 | DALL·E 3得分 | 优势分析 |\n|————————|—————————|———————|———————————————|\n| 文本-图像一致性 | 92.1 | 88.5 | 对复杂提示（如“戴眼镜的蓝色恐龙”）理解更精准 |\n| 图像细节质量 | 88.3 | 86.7 | 生成物体纹理（如毛发、金属反光）更逼真 |\n| 推理效率 | 12.4 img/s | 8.7 img/s | 本地部署时响应速度提升40% | \n三、部署方案：从本地到云端的灵活选择\n方案1：本地部署（推荐硬件：NVIDIA RTX 3090/4090）\n步骤1：环境配置\n# 创建Conda虚拟环境 conda create  - n janus_pro python = 3.10 conda activate janus_pro # 安装 PyTorch 与依赖库 pip install torch torchvision transformers diffusers accelerate\n步骤2：模型加载与推理\nfrom  transformers  import AutoModelForCausalLM , AutoTokenizer from  diffusers  import StableDiffusion Pipeline import  torch # 加载文本编码器（识别与生成共用） tokenizer  = AutoTokenizer . from_pretrained ( \"DeepSeek/janus-pro-7b-tokenizer\" ) text_encoder  = AutoModelForCausalLM . from_pretrained ( \"DeepSeek/janus-pro-7b-text-encoder\" ) # 图像生成示例 pipe  = StableDiffusionPipeline . from_pretrained ( \"DeepSeek/janus-pro-7b-generator\" ,     torch_dtype = torch . float16 ,     safety_checker = None # 关闭NSFW过滤（需自行把控内容） ). to ( \"cuda\" ) prompt  = \"A cyberpunk city at night, rendered in Unreal Engine\" image  =  pipe ( prompt ). images [ 0 ] image . save ( \"cyberpunk_city.png\" )\n优化建议 ： \n使用 bitsandbytes 库开启4/8位量化，将显存占用从28GB降至14GB。  通过 torch.compile 加速推理，实测速度提升1.8倍。\n方案2：Colab免费部署（零硬件成本）\n步骤1：开通Colab Pro （免费版显存12GB，Pro版16GB）\n步骤2：运行一键部署脚本\n# 安装依赖 ! pip install transformers diffusers xformers # 加载模型（Colab自动分配GPU） from  diffusers  import DiffusionPipeline import  torch pipe  = DiffusionPipeline . from_pretrained ( \"DeepSeek/janus-pro-7b-generator\" ,     torch_dtype = torch . float16 ,     use_safetensors = True ). to ( \"cuda\" ) # 生成图像 prompt  = \"A photorealistic portrait of a cat wearing a top hat\" image  =  pipe ( prompt ,  num_inference_steps = 30 ). images [ 0 ] display ( image )\n注意事项 ： \nColab会话时长限制为12小时，需定期保存生成结果至Google Drive。  使用 xformers 库优化注意力计算，避免显存溢出。\n四、应用场景与行业价值\n1. 创意产业：低成本内容生产\n某独立 游戏 工作室利用Janus-Pro-7B本地部署，将角色概念设计成本从$500/幅降至$20（含人力），开发周期缩短60%。\n操作建议 ：结合ControlNet插件，通过边缘检测图控制生成图像的构图。\n2. 医疗影像：辅助诊断与报告生成\n上海某三甲医院部署Janus-Pro-7B识别X光片，自动生成结构化报告，诊断准确率达92%（经临床验证），医生审核时间从15分钟/例降至3分钟。\n关键代码 ： \n# 医疗影像分类示例 from  PIL  import Image import  numpy  as  np def  preprocess_xray ( image_path ):     img  = Image . open ( image_path ). convert ( \"L\" ) # 转为灰度     img  =  img . resize (( 256 , 256 )) return  np . array ( img ) / 255.0 # 归一化 # 加载预训练的医疗识别模型（需微调） # model = load_medical_model(\"DeepSeek/janus-pro-7b-medical\")\n3. 教育领域：个性化学习材料生成\n某在线教育平台通过Colab部署Janus-Pro-7B，为K12学生动态生成科学实验示意图，用户留存率提升22%。\n部署优化 ：使用 gradio 库快速构建Web交互界面： \nimport  gradio  as  gr def  generate_image ( prompt ): return  pipe ( prompt ). images [ 0 ] gr . Interface (     fn = generate_image ,     inputs = \"text\" ,     outputs = \"image\" ,     title = \"Janus-Pro-7B 图像生成器\" ). launch ()\n五、挑战与未来方向\n尽管Janus-Pro-7B表现优异，但仍面临以下挑战： \n长文本理解 ：当前模型对超过512词的提示处理能力较弱，需结合记忆增强机制。  视频生成 ：暂未支持时序建模，团队计划在2024年Q3推出Janus-Pro-Video版本。  伦理风险 ：需完善内容过滤模块，防止生成暴力或歧视性图像。 \n开发者建议 ： \n参与社区微调：通过Hugging Face Dataset平台获取行业特定数据，定制专属模型。  监控硬件状态：本地部署时使用 nvidia-smi 实时查看显存占用，避免OOM错误。\n结语：开源生态的变革力量\nJanus-Pro-7B的发布标志着多模态大模型从“巨头垄断”向“普惠创新”的转变。其开源协议（Apache 2.0）允许商业使用，结合本地与云端的灵活部署方案，为全球开发者提供了与闭源模型竞争的利器。未来，随着模型轻量化与效率优化，AI技术将更深入地赋能各行各业，而DeepSeek的这一步，无疑为行业树立了新的标杆。"
  },
  {
    "title": "OpenAI全面开放深度研究模型API，开发者迎来重磅福利与降价新机遇-搜狐",
    "page_body": "近日，OpenAI迈出了一个重要的步伐，正式向全球开发者开放其深度研究模型的API访问权限。这一举措不仅为开发者的工具箱增添了新的利器，还包括了自动网页搜索、数据分析、模型通信协议（MCP）及代码执行等一系列先进功能。值得一提的是，此次开放的模型中包含了o3和o4-mini的深度研究版本，这两款模型在ChatGPT中已展现了非凡的实力，如今开发者可以直接通过API进行调用。\n在处理复杂任务、获取最新信息以及进行高级推理方面，这些模型展现了超越以往的能力。尤其是在功能扩展方面，o3、o3-pro以及o4-mini等模型均新增了网页搜索功能，极大提升了它们的实用性。开发者可以利用这一功能，在多种应用场景中更快速、高效地获取信息。\n与此同时，OpenAI还对其定价策略进行了重大的调整。推理网页搜索服务的起始费用被设定为每千次调用10美元，而GPT-4o和GPT-4.1的网页搜索价格也大幅降至每千次调用仅需25美元。这一措施不仅降低了开发者的使用成本，更是为他们的项目提供了更具经济性的选择。\n为了进一步优化开发者的使用体验，OpenAI推出了Webhook功能。该功能允许在任务完成时自动向开发者发送通知，避免了手动频繁检查任务状态的繁琐。这一创新尤其适用于深度研究等耗时较长的任务，提升了系统的稳定性和开发工作的效率。\n这一系列的更新标志着OpenAI在API服务领域取得了显著的进展，为开发者提供了更为强大且经济的AI工具选项，毫无疑问，这将推动人工智能技术在更多领域的应用与发展。\n深度研究模型API的重大意义\nOpenAI此次开放深度研究模型API的意义深远。首先，这一举措标志着OpenAI对开发者社区的重视，向全球开发者展示了其在人工智能领域的开放态度。通过提供API访问权限，OpenAI不仅增强了开发者的创新能力，还鼓励更多的开发者参与到AI应用的开发中来。\n其次，o3和o4-mini模型的开放，意味着开发者能够在各自的项目中利用最先进的AI技术。这些模型在自然语言处理、数据分析和复杂推理等方面的强大能力，将为开发者提供更高的工作效率和更优质的用户体验。\n降价策略的影响\nOpenAI的降价策略无疑是开发者们最为关注的部分。通过降低推理网页搜索的费用，OpenAI不仅帮助开发者节省了成本，更在一定程度上降低了技术门槛，使得更多中小型企业和独立开发者能够利用这些强大的工具进行创新。这一变化将推动更多新兴应用的诞生，激发市场的活力。\nWebhook功能的优势\nWebhook功能的推出则是OpenAI对开发者需求的精准回应。对于需要频繁检查任务状态的开发者来说，Webhook的自动通知功能将大大提高工作效率，减少不必要的时间浪费。这一创新不仅提升了开发者的体验，也为OpenAI的系统稳定性提供了保障。\n未来展望\n展望未来，OpenAI的这一系列更新与开放政策将为开发者带来更多可能性。随着API服务的逐步完善，越来越多的行业和领域将能够借助这些强大的AI工具实现数字化转型和技术创新。无论是在金融、医疗、教育还是娱乐等领域，OpenAI的深度研究模型都将发挥重要的作用。\n总结而言，OpenAI此次深度研究模型API的全面开放，结合降价策略和Webhook功能的推出，标志着人工智能技术在开发者社区的进一步普及与应用。这一系列的变革不仅将推动开发者的创新能力，还将为人工智能的未来发展注入新的活力与动力。"
  },
  {
    "title": "2024过半，AI卷到哪儿了？澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "定焦（dingjiaoone）原创\n作者 | 黎明\n编辑 | 魏佳\nAI创业者陈冉，发现行业里有一些“怪现象”。\n很多客户向他反馈，自己很困惑。一方面，大模型更新速度太快，搞不清楚到底哪个好用；同时，自己也不知道大模型怎么跟业务结合；另外，自己的数据集究竟能不能精调出一个好用的大模型，心里也没谱。\n最后的结果就是，愿意投入大模型，但不知如何下手，即便下定决心了，也抠抠搜搜拿不出太多预算来。\n这进而导致，大模型公司开始卷价格，打起了价格战。“拼到最后就是，又烧钱、价格还低、还没人用的状态。”\n陈冉是人工智能社区和生态公司开放传神（OpenCSG）的创始人、CEO，他认为大模型行业的无效内卷是一种消耗。去年一哄而上做大模型的公司们，最终没能避免掉进当年ofo们踩过的陷阱。\n这逼得行业大佬、零一万物创始人李开复放话，“如果中国市场就是这么卷，大家宁可赔光、通输也不让你赢，那我们就走外国市场”。\n做了多年技术开发，很早就开始AI创业的李友峰，同样对今天的现象感到不解。“以前我们讨论一个项目，会关注它有什么价值，但到了AI大模型，大家很少讨论价值，都在讨论领先。”\n铺天盖地的榜单，五花八门的排名，自吹自擂的营销，让这个行业显得浮躁喧嚣。厂商们最后花了很多钱，产品落地不了，技术实际上也没有太领先。\n5月下旬，清华系大模型公司衔远科技被曝换帅，创始人周伯文将离开公司。消息传出后，有创业者称：聚焦算法，或许是一条弯路。\n大模型创业，在中国是一条窄路，对某些团队也许是不归路。\n如今，2024年过半，“百模大战”也过去一年多了，行业发展到哪了？接下来又会往哪卷？\n卷技术：考高分的太多，能干活的太少\n国内大模型行业，今年明显比去年“安静”。去年是“阿猫阿狗”都来参与，几百个大模型面世，今年除了几个科技大厂和头部的创业公司，其他大部分都消停了。\n因为大家发现，吆喝再大声，落不了地都是白搭。\n国内的大模型不是太少，而是太多，尤其是吹牛的多。\n“厂商总是宣传大模型能干啥，却不说不能干啥，客户就有点被误导，以为大模型什么都能干，想着把原来的业务颠覆重做一遍，这不现实。”陈冉对「定焦」说。\n回看过去一年大模型行业的发展，我们会发现，最先打起来的不是价格战，甚至也不是技术战，而是营销战。\n营销是为了抢声量。开发布会、刷榜、投广告甚至碰瓷对手，能吸引更多关注，让大家“觉得”自己领先。至于好不好用，真实的技术实力如何，可以后期再补课。\n李友峰告诉「定焦」，现在国内所有的所谓自研大模型，基本都是基于开源架构改的，没有真正意义上的原创和全自研。这意味着，大模型公司之间的技术差距并不大。\n这也是为什么一家创业公司，能在两三个月内从零到一推出一款全新大模型。最好的例证是，去年李开复的零一万物发布“Yi”系列模型，被指使用了LLaMA的架构，只对两个张量进行了重命名。\n陈冉认为，国内大模型还没有形成完整的创业生态，大家一蜂窝冲上来，发布几个模型证明不了什么。他以智能汽车行业早期做类比：大家都想造车，做轮胎的、造发动机的、甚至做雨刷的，都想亲自下场，但最基本的电池、电控甚至轮子座椅都还没准备好。\n单纯从技术层面，时至今日，国内没有哪个团队处于绝对领先位置。\nAI大模型有三大要素：算法、数据、算力，国内厂商们过去一直在啃算法，大家发布模型，本质上是发布一套算法和系统。大家比拼谁的算法更先进，谁的模型参数更大，推理效率更高。但现在越来越多从业者发现，算法其实没有壁垒。陈冉更是直言“大模型不值钱”。\n“我认为企业级的大模型没意义，开源企业级就行了，因为最重要的是数据。”他说。\n数据是比算法更稀缺的资源。算法可以通过修改开源模型和人海战术迭代，算力可以通过砸钱买卡获得，但优质的数据没有渠道售卖，花钱不一定能买来。\n训练模型跟训练学生类似，数据相当于教材或教育资源，过程就叫预训练。偏远山区的孩子和一线城市的孩子，从小获得的教育资源不同，训练过程不同，最后高考考上重点大学的概率也必然不同。某种意义上，拥有优质数据，预训练就成功了一半。\n过去一年，行业里评估一个大模型好坏的标准，是通过测评，相当于考试。既然是考试，就有作弊的空间，或者可以通过刷题得高分。这就导致，很多大模型其实是“应试教育”的产物——参数大、得分高、性能强，但没啥实践能力。\n李友峰认为，算法有很大局限性，如果脱离具体的应用场景，算法没有意义。“比如模型的参数大，计算能力很强，做数学题也许表现很好，但这并不意味着它能在实际业务里产生价值。”\n今年以来，大模型拼参数的风气有所改观，各种杂七杂八的“野榜”也有所收敛，说明公众不好糊弄了。问题是，如果不比参数，大家还能比啥？\n卷价格：C端不敢收，B端收不起\n一个模型或一个项目要证明自己有价值，最直接的方法是从市场上赚到钱。今年以来，越来越多AI创业者和投资人，开始将商业模式挂在嘴边。\n大模型行业的商业化有两大类——To C和To B，即向个人用户收费，和向企业（包括政府、开发者）收费。去年行业达成共识，To C收费很难，先从B端入手。\nB端企业是大模型的最大客户。一家做系统集成公司的员工曾对「定焦」说，他们很早就接入了百度的千帆大模型平台，拥抱大模型的意愿很强，不过他们不是因为模型效果好而使用，仅仅是怕被AI落下。而一旦模型收费，他们就得再考虑考虑了。\n这代表了很多企业的心态：能白嫖就白嫖，付费就必须得看到效果。用陈冉的话说：“让客户花钱，就得让他看到成倍的增效，不见兔子不撒鹰。”\n李友峰认为，真正用大模型的企业，都关注业务数据而不是算法指标。“比如转化率、点击率和其他关键指标，分别提升了几个百分点，如果不能做到这些，即便算法有1万亿参数，价格低至1毛钱，客户也不会买单。”\n5月的这一波价格战，大模型API的调用价格直降超过90%。以字节跳动、阿里、百度为例，每百万token推理输入量的价格，降到了8毛、5毛和免费。\n然而这更多被市场解读为营销行为，有点清仓大甩卖的意味。\nLepton AI创始人、阿里原副总裁贾扬清说：“今天不是说API贵才没有人用，而是因为，企业首先得搞清楚到底怎么用起来产生业务价值，否则的话，再便宜也是浪费。”\n出门问问创始人李志飞更是直言：“将API价格降到无限逼近零，说明OpenAI对消费者收费和对企业收费的两种商业模式在中国竞争环境下都不可持续。”\n百度是C端B端两手抓，其中面向C端的文心一言4.0是付费版，连续包月49.9元，百度一直没有公布文心一言的付费率数据。据AI产品榜的数据，后起之秀月之暗面的Kimi，网页版的访问量在4月超过了文心一言。Kimi没有选择用收会员费的形式“自废武功”，而是非常另类地推出了打赏功能，非强制，在高峰期算力不足时可获得优先使用的权益。\n这还是C端大模型的头部选手，由此可见收费之难。归根到底，当前的大模型产品还不够好用，不是那么刚需，需要给人们一个付费的理由。\nAI初创公司语核拿到了奇绩创坛的投资，它一开始的产品都是面向C端，解决各种实用需求。创始人池光耀告诉「定焦」，其中一款主力产品CopyAsk，既能免费使用，也可以付费解锁更多功能，但超过99%的用户在白嫖免费额度，收上来的钱很难养活公司。\n今年初，语核进行转型，开始做面向B端的Agent产品，目前已经拿下两个订单，“客户付费意愿还不错，现在有钱赚了蛮好。”不过，要彻底跑通某个垂类的B端业务，还需要一段时间探索。\n有极少部分公司，抓住了市场需求，并打通了业务场景，率先赚到钱。\n陈冉想做生态，他的OpenCSG线上做社区，线下卖软件CSGHub和Starship，客户以B端企业和D端开发者为主，已探索出应用分佣和用户订阅两个变现模式，未来还可以增加算力分佣模式。他告诉「定焦」，公司今年预期营收几千万，盈利大几百万。\n卷应用：爆款应用未出现，产品和工程落地难\n大模型发展到今天，从业者一方面想办法赚钱，同时也在等待爆款应用出现。之前我们见证了妙鸭相机、Kimi、Suno等应用的走红，但这都还称不上爆款。而只有出现爆款，才能说明AI不是纸上谈兵。\n大模型厂商打响API价格战之时，有人不以为然，有人嗤之以鼻，也有人格外兴奋。\n作为一个独立应用开发者，池光耀认为API降价是巨大利好。API降价之前，他每个月要花200元左右的预算在模型调试上，现在他调用降价之后的深度求索DeepSeek-V2模型，半个多月只花了1.11元。\n他去年开发了好几款应用，受限于高频调用带来的高额推理成本，而用户又不愿意付费，导致至今产品没有推出去。现在他迫不及待想让这些应用“跑”起来，“要不是现在手上有B端的单子推不掉，我就直接去做C端产品了。”同时，那些以前因为负担不起API调用费而做不了的B端订单，现在也可以做了。\n他认为，接下来几个月，会有海量关于大模型的应用场景的探索，很可能会带来应用场景的大幅增加。一些过去需要依靠人工或工程化的手段判断的高频的、低逻辑需求的，且延时不敏感的应用场景，或许可被免费的大模型API取代掉。\n大模型落地，一定是从场景开始突破。无论大模型API是否降价，找场景都会成为下半年的共识。\n李友峰认为，下半年出圈的应用会越来越多，找到合适的场景，在规模产出的基础上覆盖规模的成本。“大家应该拼命去找价值，而不是卷价格。”\n目前的AI应用中，有两类已经显现出了价值，并获得了不错的反馈。\n一类是提效，Kimi帮助职场打工人搜索资料、整理文献；造物云给品牌用AI做产品设计和营销物料，创始人邱懿武告诉「定焦」，他们用AI给某咖啡品牌做了2000个杯子的设计方案，不算模型投入，算力成本只要10块钱。\n另一类是娱乐，比如Suno这种AI写歌软件，以及很多创业公司在做的AI陪伴、角色扮演。\n目前行业里普遍认为，Agent AI是下半年行业的重点，国内外从业者都在往这方面卷。\n随着对产业的探索加深，李友峰发现，AI真正难的是产品和工程（指构建、开发和部署大型机器学习模型的一系列技术和实践）。“不断让大模型走向产品、工程、商业、产业，是中国创业公司成长的唯一路径。”\n一旦工程问题解决了，模型反而不重要了，用户在使用产品的过程中，不关心底层用的是哪个模型，自研占多大比重，效果好比说啥都强。\n现在的情况是，大模型在具体应用时，还不能百分"
  },
  {
    "title": "OpenAI的首届开发者大会，把一堆初创企业炸成了炮灰-今日头条",
    "page_body": "昨晚，估计是最近 AI 圈子里最热闹的一次。\n原因大家估计也都知道了， 凌晨两点， OpenAI 开了自家的第一届开发者大会 。\n在会上，它接连放出大招，给了所有人一点小小的 AI 震撼。\n媒体们也都用 “ 王炸更新 ”“ BAT 沉默 ” 来形容这次大会。\n甚至有初创 AI 企业的老板在看完发布会后，连夜发出叹息：\n“ 我那值 300 万美元的初创公司，现在就只剩会上 OpenAI 给的 500 美元积分。 ”\n世超也跟着熬夜看了这次的发布会，不得不感叹：搞 AI ，还是得看 OpenAI 。\n刚开始当然是老戏码，花了几分钟先讲讲自己有多牛，像什么已 有 200 万开发者参与其生态建设、世界五百强企业中，有 92% 的企业使用其产品、并且周活跃用户数已达 1 亿 。。。\n之后的四十分钟，就全都是妥妥的干货，全是更新亮点。\n先来说下我觉得最厉害的更新—— GPTs  。\n就跟这名字一样， OpenAI 打算搞个自己的 GPT 应用商店， 月底上线 ，里面的 GPT 们，都是 专精各个领域的行家 。\n就比如奥特曼现场展示的那个 Canva GPT ，一句话就能让它设计一个开发者大会的邀请函，还整出了两套方案。\n还有能帮人协调工作流的 Zapier GPT ，安排日程，写短信、发短信都是洒洒水。\n等于说搞现在这一套，就是准备 搭建一个自己的 GPT 软件生态 了。\n这波更新真就应了业内一句话， “ 所有软件都能用 AI 再做一遍 ” ，而现在 OpenAI 准备自己做这个先行者。。。\n但这还没完，除了拆分各种 GPT 软件，它还开发了工具，让 每个人都能训练一个自己的 GPT ，上架到 GPTs ，然后收费。\n并且，训练的过程，一句代码都不用懂，直接大白话给 GPT Builder 说出你的需求就行了。\n后续呢，你要做的就当一个合格的  “ 甲方爸爸 ”  ，有需求就提，不满意也提，直到它做出你满意的为止。\n奥特曼现场也演示了一通，和 GPT Builder 交流了三四个回合之后，一个给初创企业领导者建议的软件就整出来了。\n正儿八经问他一个问题：初创企业招人时应该看重那三个部分？\n“ 聪明、能独立完成工作、文化背景一致 ” ，唰唰唰这个软件秒给了三点回复，每个特点后面都还加了一大段解释。\n不知道大家看完是什么感觉，反正世超当时已经是跪着bushi 在听了。。。\n除了搞出个 GPT 版应用商店外，和大家预测的差不多， OpenAI 这波还 公布了最新的模型  ——  GPT-4 Turbo  。\n这个新模型，用奥特曼的演示 PPT 来讲， 就是疯狂 6+1 ，六个功能大更新再加上大降价：\n首先就是支持的文本长度更长了，从原来的 32k tokens 升级到了 128k ，折合成中文相当于 是 64000 字 ； 对于开发者来说，有了更多的设置，调用函数也会更加方便； 更新知识库到今年的 4 月份 ； 开发者们也能调用多模态的 API 了，像 图片识别、 DALL·E 3 作画以及文本转语音 等等； 用户也能微调自己的模型； 调用 GPT-4 的速率翻倍。\n虽然这波大更新性能提升很大，但价格上，依旧不妨碍 OpenAI 降价，算是给双十一添把火了。\n这个降价针对开发者们，文本输入的单价（ 每 1k tokens ） 从原来的 0.03 美元降到了 0.01 美元，输出从 0.06 美元降到了 0.03 美元。\n另外， OpenAI 还给各位开发者们准备了个重头戏 Assistants API ， 不少开发者现在都已经用上了 。\n主要功能，就是帮开发者们能搞出一个类似 Agent 的应用来当助手。\n“ Agent ” 有人把它翻译成 “ 智能体 ” ，也有人直译成 “ AI 代理 ” ，但其实说人话的话， Agent 更像是一种能够 在与外界环境交互时，模拟人类智能行为的程序 。\n打个比方，自动驾驶的控制系统，就是个 Agent 。\n发布会现场， OpenAI 员工就亲自展示了下效果，比如上一秒上传一个航班信息的 PDF ，下一秒它就整理好票务信息展示在网页上了。\n甚至在展示这个 “ 助手 ” 是怎么思考的时候，员工 直接让它给在座的各位开发者们发 500 美元的账号额度 。\n除了这些比较硬核的更新之外，针对现在越来越受争议的版权问题， OpenAI 还给出了自己的解法，整了个 “  Copyright Shield  ”  （ 版权盾 ） 的项目。\n凡是大家用 OpenAI 生成的东西引发了版权纠纷，最后的这个责任， 无论是打官司还是赔钱，都由那个版权盾给担了 ，简直自带保护甲。\n世超发现这法子 ，似乎也成大模型版权问题的标准答案之一了。\n毕竟，之前 Adobe 给自家图像生成工具 Adobe Firefly 提供类似的侵权包赔服务。\n有意思的是，中途微软 CEO 纳德拉还跑来客串了一波，整了出我微软搞基建，你 OpenAI 专心做 AI 的戏码。。。\n这也算变相破了之前网传他们之间不和的传闻吧。\n最后，在世超看来， OpenAI 这次的发布会并不像往常更新那样，简简单单炫耀一下自身的肌肉。\n因为最近一年来，人们都在不断地思考大模型到底应该怎么应用，到底会开启一个什么样的时代。\n伴随着这样的疑问，市面上各种各样的大模型也层出不穷，根据北京市经济和信息化局的数据，今年截止到上个月，单是中国国内公开的大模型数量，就已经达到了 238 个。\n可以说，整个行业处于疯狂且迷茫的状态。\n而作为 AI 圈儿话事人的 OpenAI  ， 交出了一个属于他的答案，就是 “ 建生态 ”。\n虽然关于类似大模型落地的探索，包括 建应用商店 这点子。。。国内 BAT 等大厂都在做，甚至还做得更早。\n但 OpenAI 一旦开始做这事儿，背靠着 GPT-4、GPT-4 Turbo 强大的模型能力，目前多少有些降维打击了。\n不过这也至少证明了，大伙们都认为“ 建生态 ”这条路靠谱。\n当然与此同时， AI 创业公司也可能要面临一次大的变革，就像一个月前，奥特曼在 YC 校友会上讲的那句话：在未来，简单模仿、套壳 OpenAI 的产品注定会消亡。\n不然就只能像开头提到的那个初创企业一样， 一等 OpenAI 更新，自家公司就凉凉了。"
  },
  {
    "title": "开源浪潮席卷全球，大模型亟需转型“商业化2.0”？-网易",
    "page_body": "作者｜第一新声 琳玉\n如果说2024年，我们见证了大模型从科技前沿走向大众视野，那么2025年，最明显的变化则是——开源逐渐成为行业趋势。\n据不完全统计，仅今年3月至今，OpenAI、谷歌、Meta、英伟达、阿里、DeepSeek、智谱AI、群核科技、阶跃星辰等全球9家科技巨头已密集发布超10款开源 大模型 。并且，开源模型性能不断突破，全球最大AI开源社区Hugging Face的模型榜单持续刷新……无论是科技巨头还是初创企业，都在加速拥抱开源。\n但值得注意的是，当前市场中，闭源模式已在商业化上初显成效，甚至已有厂商在企业端收获了数亿元的订单，为何大模型巨头们仍要纷纷转向开源？开源之后，新的商业模式将如何演进？\n\"开源派\"加速开放，\"闭源派\"纷纷倒戈\n实际上，早在去年大模型价格战、市场竞争进入白热化阶段后，关于大模型\"开源\"和\"闭源\"的交锋已经逐渐变得激烈。\n\"闭源派\"主张通过技术封闭实现商业变现、保护知识产权和确保服务质量。这种路径能够集中资源优化模型性能和安全性，避免技术泄露；而\"开源派\"则主张过开放模型代码、数据和算法，推动技术普惠、加速创新和构建协作生态。这种路径能够降低技术门槛，吸引全球开发者参与改进，并形成开发者社区，推动工具链和基础设施发展。\n长期以来，闭源模式一直是 商业化 AI领域的主导范式，企业通过技术封闭实现商业变现、保障数据安全并维持竞争优势。然而，2025年成为行业发展的关键转折点——随着DeepSeek等开源模型的崛起，全球AI行业迅速掀起了一场前所未有的\"开源浪潮\"。\n首先，开源阵营近期的开源速度和技术迭代节奏明显加快。\n3月初，在持续五天的\"DeepSeek开源周\"结束后，开源领域领跑者DeepSeek再次发布了V3模型的最新更新版本——V3-0324模型，在保持原有技术框架的基础上，V3-0324模型针对性能、用户体验和实用性进行了优化。\n而早在DeepSeek引发开源 浪潮 之前，美国科技巨头Meta一直是开源模型的领先玩家及重要奠基者。在ChatGPT问世仅7个多月后，Meta就率先宣布开源Llama 2，并且可免费商用。这也成为大模型发展的分水岭和开源模型社区的历史性时刻。\n4月6日，Meta再次推出开源人工智能模型Llama 4。据介绍，该模型目前有Scout和Maverick两个版本，是Meta迄今为止最先进的模型，也是同类产品中多模态性最强的模型。\n在国内，中国互联网三巨头BAT之一的阿里，也是押注开源的典型代表。2022年11月，阿里发布了中文AI大模型开源社区\"魔搭\"（Model Scope）。2023年8月，阿里云在AI模型社区魔搭ModelScope上开源Qwen-7B和Qwen-7B-Chat，这是阿里首批开源的大语言模型，随后，阿里逐步扩大开源规模，并持续更新迭代，先后开源和更新了Qwen-14B、Qwen2系列、Qwen2.5-Omni等数十个参数版本的模型。\n相比于阿里，腾讯的开源之路虽然要滞后一些，但目前\"混元大模型\"也于去年开始，陆续开源了文生图、视频生成、多专家混合（MoE）和3D内容生成等多款大模型。\n同时，受开源趋势的持续影响，近期，众多长期坚持闭源策略的企业也陆续宣布开源计划。\n今年2月，一直坚持闭源的百度宣布文心一言于4月1日起免费，并将于6月30日正式开源；字节跳动方面，虽然核心模型豆包尚未开源，但团队近日开源了一项名为COMET的MoE架构优化技术，可将大模型训练效率提升1.7倍。论文显示，该技术已实际应用于字节的万卡集群训练，实现数百万GPU小时训练算力的节省。\n在国际上，坚守闭源路线的OpenAI，凭借GPT系列模型在商业AI领域占据主导地位，如今受开源冲击，其市场份额和行业影响力面临严峻挑战。\nDeepSeek发布以后，OpenAI CEO山姆·奥特曼罕见松口，公开承认公司过去在开源策略上\"站在了历史错误的一边\"。这一表态迅速引发连锁反应：今年1月，OpenAI\"试水\"开源，向公众免费开放了轻量级推理模型o3-Mini；4月1日，公司再次宣布将在未来数月内发布一款\"具备强大推理能力的开放权重（open-weight）模型\"这将是OpenAI自2019年GPT-2以来的首个开源项目。\n近期同样在开源方面迈出重要一步的还有英伟达。它们曾以闭源硬件和软件为主，构建了强大的生态系统。但3月20日，英伟达在GTC 2025 大会上发布了全球第一个开源的人形机器人基础模型——GROOTN1，这成为推动具身智能发展的重要力量，此后开发者可以直接使用这个模型来改造机器人。\nAI巨头们为何选择加速开源？\n百度创始人李彦宏曾断言\"开源大模型会越来越落后\"。当时的市场判断依据是，OpenAI的闭源模式是黄金标准，开源并不便宜，且技术会越发落后。\n但DeepSeek以开源模式实现技术突破和商业生态的双赢，使这些行业依据变得不那么奏效，也第一次令中国企业看到了开源模式的商业价值和影响力、看到了产业格局变化的可能性、看到了生态开放的冲击力。\n随着开源从概念、尝试到如今成为巨头厂商们发展策略的必选项，其背后主要有双重驱动力：\n一是技术发展趋势，二是市场需求。\n从趋势来看，FutureLabs专家胡延平指出，中国大模型开源的爆发源于四大驱动力，就像四股强大的浪潮，推动着开源的巨轮滚滚向前。\n第一波浪潮是端侧智能崛起。如今，个人与企业对本地化AI 部署的需求就像被点燃的火焰，越烧越旺。想象一下，你在自己的电脑上就能拥有一个智能助手，它能根据你的需求快速响应，无需依赖网络连接到遥远的云端服务器，是不是感觉超酷？这就是端侧智能的魅力。它的兴起，推动了模型轻量化与灵活性升级，就像给模型穿上了一件轻便的运动装，让它能够在各种设备上自由奔跑，发挥出最大的效能。\n第二波浪潮是行业定制化需求。通用云端模型虽然强大，但就像一把万能钥匙，很难打开每一扇特定的锁。金融、医疗等领域有着严格的隐私要求和独特的场景化需求，通用模型很难满足这些\"特殊客户\" 的需求。这时候，开源就像一把神奇的魔法棒，成为企业差异化竞争的 \"秘密武器\"。企业可以根据自身需求，对开源模型进行定制化开发，打造出专属于自己的 \"秘密武器\"，在激烈的市场竞争中脱颖而出。\n第三波浪潮是生态化分工加速。头部企业就像技艺精湛的大厨，专注于基础模型研发，精心烹制出一道道美味的\"基础模型大餐\"。而中小企业则像是各具特色的小吃摊主，基于开源模型构建细分应用，将这些 \"基础模型大餐\" 进行创意加工，变成各种美味的小吃，满足不同用户的口味需求。这样一来，就形成了 \"巨头搭台、百家唱戏\" 的热闹产业格局，整个 AI 生态系统变得更加丰富多样，充满活力。\n第四波浪潮是技术跨越临界点。模型能力从\"可用\" 迈向 \"高可用\"，就像一个孩子从蹒跚学步走向健步如飞。用户与应用进入爆发期，开源成为技术落地的 \"最短路径\"。当模型变得足够强大和好用时，人们迫不及待地想要将其应用到各个领域，而开源则为这种应用提供了最便捷的通道，让技术能够迅速地走进千家万户，为人们的生活带来改变。\n总结来看，有三点因素将大模型企业推向了开源化：\n一是技术民主化：从垄断到共创闭源模式曾是大厂建立技术壁垒的核心手段。例如，百度文心大模型长期闭源，通过\"闭源+公有云\"模式占据B端市场。但DeepSeek的开源证明，社区力量能够加速模型迭代——其开源模型DeepSeek-R1在发布后吸引了3000万月活用户，并推动接入企业数量激增。开源带来的不仅是代码共享，更是全球开发者的智慧聚合，这种\"群体智能\"让技术突破不再依赖单一团队。\n二是成本与生态：开源降低准入门槛。大模型的训练成本动辄数千万美元，而开源模型允许企业复用基座，只需针对垂直场景微调。例如，医疗、法律等数据敏感的行业，可利用开源模型在本地部署，既保障隐私，又节省算力开支。阿里通义千问、腾讯混元等开源模型，正是通过降低技术门槛，吸引开发者构建应用生态，最终反哺核心业务。\n三是政策与竞争：开源成国家战略。中国多地政府将开源写入人工智能发展规划。北京、上海、广东等地通过政策补贴、算力支持等措施，推动大模型开源生态建设。与此同时，国际巨头如Meta（Llama系列）、xAI（Grok）也加速开源布局，倒逼国产厂商加入这场\"开放竞赛\"。\n从需求来看，这场开源浪潮的终极价值分配中，真正的受益者还有生态链末端的开发者与中小企业——他们既是技术普惠最直接的受惠者，也将成为创新反哺的核心驱动力。\n对开发者和中小企业而言，过去，构建AI模型需要巨额资金和技术积累，因此他们被迫成为市场的\"追随者\"。开源大模型实际上改变了这样的游戏规则，通过降低技术门槛，让AI技术通过开源变得触手可及，开发者可以在此基础上快速迭代，将创意转化为现实。有数据显示，一家专注于电商服务的初创公司，利用通义千问开源模型开发企业的智能客服系统使成本降低了80%、迭代周期缩短了一半、客户满意度大幅提升。\n同时，开源模型也正在重塑各行各业。比如，过去受限于技术和资金短缺的基层医疗机构，如今借助开源方案成功部署了本地化病历分析系统。这些系统能快速解析患者病历数据，为医生诊断提供精准辅助，显著提升了基层医疗服务质量。这一突破不仅缩小了不同层级医疗机构的技术差距，更推动了基层医疗AI 的普及。\n开源=免费？商业化如何走通\n开源模式给大模型的产业生态带来了很大的变化，这些影响在商业化方向上则表现为：市场可能认为开源免费的模型一定可以节省投入。\n但实际上并非如此。\n智谱AI张鹏曾在接受媒体采访时表示：\"历史经验表明，包括像MySQL也好，还有RedHat，其实已经证明了开源并不等于完全免费，还有自己后期技术人员的投入、维护的成本，包括探索怎么把DeepSeek做本地化等等，成本一点都不低。当然未来的使用情况我们不知道，当前的情况是大家清醒过来了，开源免费并不等于真的免费，这件事情是大家有共识的。\"\n那么，在开源模式下，如何平衡技术普惠与商业回报？已经有部分领先的大模型厂商开始探索商业化2.0方案。\n一是\"开源基础模型+商业API增值服务\"\n这种模式的核心逻辑是：开放基础模型权重吸引开发者生态，通过高性能API服务实现变现。比如，免费开源中等参数规模的基础模型，以供个人端和企业端的基础需求，而针对更高性能的闭源大模型接口、专属领域微调、企业级SLA保障等业务则提供付费的云端API服务。\n典型案例是DeepSeek开源DeepSeek-R1基础模型，同时运营收费的DeepSeek-V3 API服务，其商业API的推理速度比开源版快3倍。根据测算，其日营收峰值达可达56万美元；智谱AI开源ChatGLM3-6B，但企业客户需付费接入其GLM-130B商业API，后者支持私有化部署和定制微调；\n二是\"开源社区版+企业专属版\"\n这种模式的核心逻辑是：通过功能差异化"
  },
  {
    "title": "国内如何访问 OpenAI 的 api-今日头条",
    "page_body": "这个问题甚至我的一些大厂的朋友也不太清楚，所以我觉得有必备写一篇文章来简单盘盘它，希望能帮助到有需要的人\n众所周知，由于大陆与 OpenAI 双方互相封锁，大陆是无法直接访问 OpenAI api 的\n不过由于 GPT 4 的统治地位，国内很 AI 应用都首选 OpenAI，那么问题来了，这些应用该怎么访问 OpenAI 的 api 呢\n其实主要有两种方式\n1. 通过代理\n大陆无法直接访问 OpenAI，那我能不能通过一种间接的方式来访问 OpenAI 呢\n学习 HTTP 时我们都学过代理的概念，我们可以先把请求打到这个代理上，再由这个代理把请求转发到 OpenAI，这样就可以访问 OpenAI 了\n代理只是起到了一个转发流量的作用，所以除了 host 外，其他像 query，body 等与直接访问 OpenAI api 无异，这样使用者只需要把 host 替换一下（比如把 api.openai.com 换成 api.openai-proxy.com），其他请求格式不变，就可访问 OpenAI 的 api 了，很方便\n当然了这个代理国内必须可以访问，比如 Cloudflare，DigitalOcean 等平台上的 server 都可以充当代理\n那有人可能会问了，为了访问 OpenAI，我得额外花钱搭一个这样的代理，好像也有点不划算呢\n你想到的别人也考虑好啦，目前市面上已经有一些搭建好的代理了，如  api.openai-proxy.com ，你在使用的时候把 host 替换成这个，其他不变就可正常使用啦\n当然了，第三方代理存在一定的安全隐患，比如虽然第三方代理号称只是转发，不保留数据，但谁知道呢，如果你的业务对安全性要求很高，估计自建代理才是最佳选择\n2. 通过 vercel 等云服务平台\nvercel 是全球非常知名的一个免费网站托管平台，无论是动态（如 api 服务）还是静态网站都可免费部署，而且部署非常方便，是很多开发者的首选\n我们可以先把访问 OpenAI api 的服务部署在 vercel 上，但是问题来了，部署在 vercel 上的应用（通常是 xxx.vercel.app）国内也是没法访问的，那该怎么办？\n这里就需要简单了解一下 HTTP 和 DNS 的原理了\n假设我有一个域名叫 api.example.com，这个域名在国内是可以访问的，我想在访问这个域名时，最终经过 DNS 解析后打到的是我部署在 vercel 上的 访问 OpenAI 的 api 应用，该怎么办\n实际上只要在访问 api.example.com 时解析出 vercel 平台上的 IP ，然后再通过 IP 来访问部署在 vercel 平台上的应用即可\n那怎样才能在访问 api.example.com 时解析出 vercel 平台上的 IP 呢，答案是 CNAME（以下的记录值 cname.vercel-dns.net. 是我随便写的，实际上 vercel 提供了另一个正确的可被国内 DNS 解析的域名，比较敏感，不方便放，网上可找到哦）\n通过以上的记录值就可最终解析出 vercel 平台上的 IP，假设为 76.86.22.62（能解析出 IP 的原因在于 cname.vercel-dns.net. 可正常被解析，现在你知道为啥我要放这样一个随便写的值了吧，有风险）\n注意这只是 vercel 平台的对外 IP，光凭 IP 是无法确定要打到哪个应用的，IP+Host 才可以哦\n所以我们要在 vercel 上的应用设置中先配置一下域名\n这样请求的时候有了 IP，有了 host：api.example.com，通过 api.example.com 访问的流量就可以转发到正确的应用上来啦"
  },
  {
    "title": "11、瑞典AI领域的研发活动与企业参与度分析-CSDN博客",
    "page_body": "瑞典AI领域的研发活动与企业参与度分析 \n 1. 引言 \n 随着 人工智能 （AI）技术的快速发展，各国都在积极布局这一前沿领域。瑞典作为一个在技术创新和研究方面表现突出的国家，自然也不例外。为了深入了解瑞典在AI领域的研发活动和企业参与度，本文将基于2011年至2017年期间瑞典公共就业服务（Arbetsförmedlingen）的职位列表 数据库 、Nordic Tech List的人工智能公司信息、个别公司网站信息以及公开媒体报道等资料，探讨瑞典在AI相关专利活动中的参与情况，并对不同类型的公司参与AI发展的状况进行描述和分析。 \n 2. 数据来源与分析方法 \n 2.1 数据来源 \n 本文的数据来源主要包括以下几个方面： \n Arbetsförmedlingen职位列表数据库   ：涵盖了2011年至2017年的职位招聘信息，特别是与AI相关的职位。   Nordic Tech List   ：提供了瑞典AI公司的详细信息。   个别公司网站   ：收集了各公司在AI领域的最新动态和发展情况。   公开媒体报道   ：提供了行业内外的最新趋势和技术进展。 \n 2.2 分析方法 \n 为了确保分析的准确性和全面性，我们采用了以下几种方法： \n 文本挖掘与自然语言处理   ：用于从大量的职位描述中提取与AI相关的关键信息。"
  },
  {
    "title": "开源智能体AI框架全面对比：构建智能工作流的深度指南_开源智能工作流-CSDN博客",
    "page_body": "人工智能领域正经历从简单的提示-响应交互向具备自主决策能力的智能体系统的重大转变。近年来，智能体AI框架如雨后春笋般涌现，为开发者构建能够推理、规划和执行复杂任务的AI工作流提供了强大支持。本文将深入剖析当前主流的开源智能体AI框架，从技术架构、核心功能、适用场景等多个维度进行全面对比，为不同需求的开发者提供极具价值的选型参考。\n智能体AI工作流的核心内涵\n智能体AI工作流代表了一种范式变革，它超越了传统的简单交互模式，赋予AI系统以下关键能力：将复杂任务拆解为可管理的步骤、基于中间结果做出决策、灵活使用工具和外部API、在多次交互中保持状态，以及自我修正和调整策略。这些能力使得AI系统能够胜任现实世界中的复杂任务，如学术研究、项目规划、代码生成和多步骤问题解决等。\n与传统的AI应用相比，智能体工作流的核心优势在于其\"自主性\"和\"连续性\"。例如，在进行市场分析时，传统AI可能仅能根据单一提示生成报告，而智能体工作流则能够先制定研究计划，调用财经API获取数据，分析数据后发现信息缺口，自动触发补充调研，最终整合所有结果生成全面报告。这种闭环能力极大拓展了AI的应用边界。\n主流开源智能体AI框架深度解析\nLangGraph（LangChain生态）\n作为LangChain框架的延伸，LangGraph专注于构建有状态的多智能体应用，通过循环图结构来表示智能体工作流。其核心设计理念是将工作流抽象为节点和边的组合，节点代表具体功能（如数据获取、分析），边则定义状态转移逻辑。\n核心特性与技术架构\n有状态图工作流设计\n：采用图论模型定义工作流，支持节点间的条件路由和状态共享，非常适合建模复杂的多步骤流程。\n全生命周期管理能力\n：内置持久化和检查点机制，支持工作流的暂停、恢复和回滚，这对于长时间运行的任务至关重要。\n多智能体协同\n：提供智能体编排功能，可协调不同角色智能体（如研究员、分析师）的协作流程。\n强大的调试工具\n：支持时间旅行调试和可视化工作流监控，大幅提升开发效率。\n典型应用场景\nLangGraph在需要复杂状态管理的场景中表现突出，例如：\n企业级数据分析流水线：从数据采集、清洗到多维度分析的全流程自动化\n学术研究助手：文献检索、内容摘要、观点对比的闭环研究流程\n软件开发辅助：需求分析、代码生成、测试用例创建的协同开发工作流\n代码实现示例\nfrom langgraph.graph import StateGraph, END from langgraph.prebuilt import ToolExecutor from langchain_core.messages import HumanMessage from typing import TypedDict, List  class AgentState(TypedDict):     messages: List[HumanMessage]     next_action: str  def research_node(state):     # 调用工具执行研究任务     return {\"messages\": state[\"messages\"] + [research_result]}  def analyze_node(state):     # 分析研究结果     return {\"messages\": state[\"messages\"] + [analysis_result]}  def should_continue(state):     return \"analyze\" if \"research_complete\" in state else \"research\"  # 构建状态图 workflow = StateGraph(AgentState) workflow.add_node(\"research\", research_node) workflow.add_node(\"analyze\", analyze_node) workflow.add_conditional_edges(\"research\", should_continue) workflow.set_entry_point(\"research\") app = workflow.compile() \n优缺点分析\n优势\n：与LangChain生态深度整合，拥有完善的文档和活跃的社区支持，企业级功能（如LangSmith集成）成熟。\n挑战\n：对于简单场景略显复杂，图模型的学习曲线较陡，性能上存在一定抽象层开销。\nCrewAI：角色驱动的智能体协作框架\nCrewAI的设计理念聚焦于多智能体的角色扮演与协作，强调智能体的专业化分工和团队动态。它通过定义不同角色（如研究员、作家）的智能体，并编排它们的协作流程来完成复杂任务。\n核心特性与技术架构\n基于角色的智能体系统\n：每个智能体可定义专属角色、目标和背景故事，实现专业化分工。\n任务委派机制\n：支持结构化的任务分配和执行流程，可建立任务间的依赖关系。\n灵活的工作流模式\n：支持顺序、并行和分层工作流，适配不同复杂度的协作场景。\n多LLM提供商集成\n：兼容OpenAI、Anthropic等多种大语言模型，提供选择灵活性。\n典型应用场景\nCrewAI特别适合需要团队协作的场景，例如：\n内容创作流水线：研究员负责资料收集，作家负责内容撰写，编辑负责润色的协同流程\n项目规划与执行：项目经理制定计划，各领域专家负责具体模块的实施协作\n教育辅导系统：不同学科导师协同为学生提供个性化学习方案\n代码实现示例\nfrom crewai import Agent, Task, Crew from langchain_openai import ChatOpenAI  # 定义智能体角色 researcher = Agent(     role='高级研究分析师',     goal='对给定主题进行深入研究',     backstory='拥有10年以上经验的专家分析师',     verbose=True,     allow_delegation=False,     llm=ChatOpenAI(model=\"gpt-4\") )  writer = Agent(     role='内容作家',     goal='基于研究结果创建引人入胜的内容',     backstory='具有技术专长的创意作家',     verbose=True,     allow_delegation=False,     llm=ChatOpenAI(model=\"gpt-4\") )  # 定义任务 research_task = Task(     description='研究AI领域的最新趋势',     agent=researcher,     expected_output='详细的研究报告' )  writing_task = Task(     description='基于研究结果撰写博客文章',     agent=writer,     expected_output='引人入胜的博客文章' )  # 创建智能体团队 crew = Crew(     agents=[researcher, writer],     tasks=[research_task, writing_task],     verbose=True )  result = crew.kickoff() \n优缺点分析\n优势\n：角色化设计直观易懂，多智能体协作场景的搭建效率高，对LLM提供商的支持灵活。\n挑战\n：相比LangGraph成熟度稍低，高级工作流模式支持有限，调试工具相对较少。\nAutoGen：多智能体对话协作框架（微软）\nAutoGen是微软推出的多智能体对话框架，专注于通过多方对话解决复杂任务，支持智能体之间以及人机之间的协作交互。\n核心特性与技术架构\n多智能体对话系统\n：支持群聊、两两对话和嵌套对话等多种模式，模拟真实协作场景。\n代码生成与执行\n：内置安全的代码执行环境，可自动生成并运行Python、SQL等代码。\n灵活的对话编排\n：提供多种对话模式配置，支持自定义对话策略和流程控制。\n人机协作集成\n：支持人类介入工作流的特定环节，实现人机协同决策。\n典型应用场景\nAutoGen在需要对话驱动的场景中表现优异，例如：\n软件开发协作：架构师与开发人员通过对话共同设计和实现代码\n数据分析项目：分析师与数据科学家对话式地探索数据并生成分析报告\n客服与问题解决：多个智能体协作处理复杂客户咨询，必要时转接人类专家\n代码实现示例\nimport autogen  config_list = [{\"model\": \"gpt-4\", \"api_key\": \"your-key\"}]  # 定义智能体角色 assistant = autogen.AssistantAgent(     name=\"assistant\",     llm_config={\"config_list\": config_list}, )  user_proxy = autogen.UserProxyAgent(     name=\"user_proxy\",     human_input_mode=\"NEVER\",     max_consecutive_auto_reply=10,     code_execution_config={\"work_dir\": \"coding\"}, )  # 启动对话 user_proxy.initiate_chat(     assistant,     message=\"创建一个Python脚本用于分析销售数据\" ) \n优缺点分析\n优势\n：对话机制设计强大，代码生成能力突出，与微软生态（如Azure）集成紧密。\n挑战\n：复杂场景的配置较为繁琐，工作流状态管理能力有限，非对话类工作流的学习曲线较陡。\nSemantic Kernel：语义函数驱动的企业级框架（微软）\nSemantic Kernel是微软推出的SDK，专注于将AI服务集成到应用程序中，核心在于语义函数的编排和规划能力。\n核心特性与技术架构\n语义函数编排\n：支持将自然语言定义的函数与传统代码函数混合使用，实现\"自然语言编程\"。\n多语言支持\n：原生支持C#、Python、Java等多种编程语言，适应企业多技术栈环境。\n自动规划系统\n：内置规划器，可根据目标自动生成工作流执行计划。\n企业级安全\n：提供完善的安全机制和合规支持，满足企业应用需求。\n典型应用场景\nSemantic Kernel适合企业级智能应用开发，例如：\n智能办公助手：处理邮件、日程安排、文档生成等多任务协同\n金融智能分析：结合市场数据和业务规则生成投资建议报告\n企业知识管理：从多源文档中提取信息并构建知识图谱\n优缺点分析\n优势\n：多语言支持和企业级安全特性突出，自动规划能力降低工作流设计门槛。\n挑战\n：简单场景使用略显复杂，生态发展依赖微软推动，社区活跃度有待提升。\nTaskWeaver：代码优先的智能体开发框架（微软）\nTaskWeaver是一个以代码为中心的框架，通过代码生成和执行来构建有状态的智能体，处理复杂任务。\n核心特性与技术架构\n代码优先方法\n：工作流以代码形式定义，支持动态生成和执行Python代码。\n插件系统\n：提供灵活的插件架构，可自定义领域特定功能。\n丰富的数据处理\n：支持复杂数据类型的处理和转换，适合数据分析场景。\n交互式调试\n：内置调试工具，方便追踪和优化代码执行流程。\n典型应用场景\nTaskWeaver在需要编程能力的场景中表现出色，例如：\n数据科学工作流：从数据清洗、特征工程到模型训练的全流程自动化\n自动化测试框架：根据需求文档生成测试用例并执行测试\n科学计算应用：模拟实验设计、数据处理和结果可视化的集成流程\n优缺点分析\n优势\n：代码生成能力强大，数据分析场景适配性好，插件架构灵活。\n挑战\n：需要编程知识，非技术用户使用门槛高，社区规模较小。\nLlamaIndex Workflows 1.0：事件驱动的智能工作流框架\n作为LlamaIndex最新推出的框架，Workflows 1.0实现了从简单RAG（检索增强生成）管道到复杂智能体编排系统的重大升级。\n核心特性与技术架构\n事件驱动架构\n：采用发布-订阅模式管理工作流状态转移，支持灵活的流程控制。\n自动并行化\n：智能识别独立步骤并并行执行，大幅提升工作流效率。\n类型安全设计\n：使用Python类型提示确保工作流定义的严谨性，减少运行时错误。\n深度LlamaIndex集成\n：与LlamaIndex的RAG组件无缝衔接，优化检索增强生成场景。\n典型应用场景\nLlamaIndex Workflows特别适合RAG相关应用，例如：\n企业知识库问答系统：结合文档检索和智能回答的闭环流程\n学术文献分析平台：文献检索、内容摘要、观点对比的一体化流程\n客户支持系统：根据历史对话和知识库信息生成精准回复\n代码实现示例\nfrom llama_index.core.workflow import (     Event,     StartEvent,     StopEvent,     Workflow,     step, ) from llama_index.core.llms import LLM from llama_index.llms.openai import OpenAI  class QueryEvent(Event):     query: str  class ResearchEvent(Event):     research_results: str  class AnalysisEvent(Event):"
  },
  {
    "title": "三大AI开发平台终极对比：Dify、Coze、LangChain选型指南！-CSDN博客",
    "page_body": "简介\n文章对比了三大AI开发平台( Dify 、Coze、LangChain)的 技术架构 、性能与扩展性，并通过实际案例展示各自优势。针对不同用户类型提供了选型建议，强调企业应基于\"编程能力-数据敏感度-场景复杂度\"动态评估，必要时组合使用多平台优势。\nAI平台解析\n一、引言：AI开发平台的选型困境\n随着生成式 AI技术 的成熟，企业在选择开发平台时面临三重核心矛盾： 效率与定制化的冲突 、 成本与性能的平衡 、 易用性与扩展性的博弈 。当前市场主要分为两类平台：以Dify、Coze为代表的 低代码/可视化平台 ，和以 LangChain 为代表的 通用开发框架 ，覆盖了从零基础开发者到专业技术团队的全谱系需求。\n市场格局数据透视\n截至2025年8月，三大平台呈现差异化竞争态势：\n•  Dify ：109K GitHub Star，开源社区优势显著 •  Coze ：字节生态加持，开源4天即获10.8K Star •  LangChain ：110K+ Star，技术团队中保持稳定影响力\n二、技术差异深度解析：七大维度全面对比\n核心架构与技术定位\n三平台技术对比\n平台\n核心架构特点\n技术定位\nDify 模块化架构，融合BaaS与LLMOps理念 企业级AI应用工厂\nCoze 微服务架构，分Studio/Loop/Eino三大组件 零代码AI快车道\nLangChain 链式组件框架，支持Memory/Tool集成 开发者工具链\nDify 的模块化设计支持插件热部署，适合金融、医疗等强合规场景； Coze 的微服务架构实现极速上线，适配自媒体、营销团队； LangChain 的组件化框架则释放深度定制能力，适合复杂系统开发。\n性能与扩展性\n科技性能对比图\n•  响应时间 ：Dify <2s（RTX 3060环境），Coze比第三方模型快300ms，LangChain需优化资源 •  并发处理 ：Dify支持500QPS，Coze适合中小规模场景，LangChain需手动设计缓存策略 •  扩展能力 ：Dify模块化扩展，Coze插件生态丰富，LangChain组件化灵活\n三、实际开发案例分析\nDify：银行智能客服系统\n场景 ：日均10万+客户咨询，需数据本地化存储\n方案 ：私有化部署+多 模型 混合推理\n效果 ：响应时间<2秒，客户满意度提升至92%，满足银保监会合规要求\nCoze：跨境电商营销助手\n场景 ：抖音评论自动回复与多语言咨询\n方案 ：30秒创建+60+插件集成\n效果 ：人力成本降低60%，转化率提升30%，支持日均8000+跨境咨询\nLangChain：法律文档解析系统\n场景 ：判例报告结构化提取\n方案 ：RetrievalQA链+向量存储技术\n效果 ：处理效率提升50%，结构化数据准确率达90%\n选型决策树\n无需编程  → Coze（零代码+生态插件）\n数据敏感  → Dify（私有化部署+开源）\n复杂场景  → LangChain（组件化+代码可控）\n用户类型匹配建议\n用户类型\n推荐平台\n核心优势\n个人开发者 Coze 免费版+60+内置插件\n中小企业 Dify/Coze 平衡成本与功能，支持快速迭代\n大型企业 Dify/LangChain 合规性+定制化，支撑复杂业务场景\nAI开发平台正朝着 插件化生态 与 低代码化 双轮驱动方向发展。企业选型需遵循“三不原则”：不盲目追求技术前沿、不忽视数据安全、不低估运维成本。 没有最好的平台，只有最适合的方案 ，建议根据“编程能力-数据敏感度-场景复杂度”动态评估，必要时组合使用多平台优势。\n原则”：不盲目追求技术前沿、不忽视数据安全、不低估运维成本。 没有最好的平台，只有最适合的方案 ，建议根据“编程能力-数据敏感度-场景复杂度”动态评估，必要时组合使用多平台优势。\n四、AI大模型学习和面试资源\n我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。\n我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。\n这份完整版的大模型 AI 学习和面试资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【保证100%免费】\n第一阶段：  从大模型系统设计入手，讲解大模型的主要方法；\n第二阶段：  在通过大模型提示词工程从Prompts角度入手更好发挥模型的作用；\n第三阶段：  大模型平台应用开发借助阿里云PAI平台构建电商领域虚拟试衣系统；\n第四阶段：  大模型知识库应用开发以LangChain框架为例，构建物流行业咨询智能问答系统；\n第五阶段：  大模型微调开发借助以大健康、新零售、新媒体领域构建适合当前领域大模型；\n第六阶段：  以SD多模态大模型为主，搭建了文生图小程序案例；\n第七阶段：  以大模型平台应用与开发为主，通过星火大模型， 文心大模型 等成熟大模型构建大模型行业应用。\n    学会后的收获：    \n• 基于大模型全栈工程实现（前端、后端、产品经理、设计、 数据分析 等），通过这门课可获得不同能力；\n• 能够利用大模型解决相关实际项目需求： 大数据时代，越来越多的企业和机构需要处理海量数据，利用大模型技术可以更好地处理这些数据，提高数据分析和决策的准确性。因此，掌握大模型应用开发技能，可以让程序员更好地应对实际项目需求；\n• 基于大模型和企业数据AI应用开发，实现大模型理论、掌握GPU算力、硬件、LangChain开发框架和项目实战技能， 学会Fine-tuning垂直训练大模型（数据准备、数据蒸馏、大模型部署）一站式掌握；\n• 能够完成时下热门大模型垂直领域模型训练能力，提高程序员的编码能力： 大模型应用开发需要掌握机器学习算法、深度学习框架等技术，这些技术的掌握可以提高程序员的编码能力和分析能力，让程序员更加熟练地编写高质量的代码。\n1.AI大模型学习路线图\n 2.100套AI大模型商业化落地方案\n 3.100集大模型视频教程\n 4.200本大模型PDF书籍\n 5.LLM面试题合集\n 6.AI产品经理资源合集\n    获取方式：\n    有需要的小伙伴，可以保存图片到wx扫描二v码免费领取【保证100%免费】"
  },
  {
    "title": "拆解 “十五五” AI 规划：从战略到落地，三大核心逻辑重塑产业格局-知乎",
    "page_body": "“十五五” 规划将人工智能提升至 “综合性国家战略” 高度，8 次提及 AI、2 次聚焦算力的顶层设计，背后是 “技术自主 - 产业赋能 - 安全治理” 的三重逻辑闭环。这一规划不仅明确了未来五年的发展路径，更预示着人机协同的生产生活形态将全面到来。\n 核心逻辑一：技术攻关从 “单点突破” 到 “体系化突围”。规划依托新型举国体制，聚焦大模型、高端芯片、算法框架等 “卡脖子” 环节，鼓励龙头企业牵头创新联合体。从 DeepSeek 的出圈到宇树机器人的迭代，我国已在基础层形成国际竞争力，“十五五” 将进一步推动从 “跟跑” 到 “领跑” 的跨越。\n 核心逻辑二：“人工智能 +” 行动重构产业价值。不同于单一技术应用，这一行动覆盖制造、交通、消费等六大领域，设定 2027 年普及率超 70%、2030 年超 90% 的硬性目标。汽车产业从 “电动化” 迈向 “智能化”，制造业通过柔性产线、智能检测实现效率跃升，传统行业与新兴产业将形成协同发展格局。\n 核心逻辑三：安全与发展的双向协同。规划首次将 AI 纳入国家安全能力建设，强调 “AI 驱动安全革新、安全保障 AI 落地”。奇安信等企业的实践表明，只有构建技术监测、风险预警体系，才能为创新划定安全边界，实现可持续发展。\n 对企业而言，这是抢占智能赛道的战略机遇；对个人而言，掌握 AI 技能、适应人机协同模式将成为核心竞争力。政策、技术、市场的三重合力，将推动中国 AI 产业在全球格局中占据更重要的位置。"
  },
  {
    "title": "江苏省数据局（江苏省政务服务管理办公室）市县动态 苏州打造OPC专区，赋能AI创业浪潮",
    "page_body": "近日，苏州数智科技集团正式上线OPC专区，基于苏州市公共算力服务平台，致力于构建一个覆盖基础要素支撑、全流程工具链赋能、培育孵化加速的全链条服务体系，为敢于探索的个体创新者提供一站式、低门槛、高效率的创业环境，助力其将创意快速转化为市场成果，让“一人一AI，成就独角兽”的梦想照进现实。\n夯实创新底座：集成四大基础支撑要素。OPC专区通过系统整合创新活动所必需的四大核心资源（政策解读与匹配、算力优惠聚合、大模型即插即用、上层应用与生态），为个体创业者构建起坚实的创新底座。算力服务上，专区直接接入苏州市算力公共服务平台，实现对超过4800P智能算力资源的统一纳管与弹性调度，使创新者能够根据需求灵活获取高性能计算支持。政策服务上，专区提供专业的政策解读与精准匹配服务，助力企业将政策红利切实转化为发展动力。模型服务上，专区支持包括GPT-4、文心一言在内的国内外主流大模型API便捷调用，降低了技术使用门槛，使创新者能够快速集成先进AI能力。生态服务上，通过引入法律咨询、财税管理和知识产权等专业生态服务，专区构建起完善的配套支持网络，进一步扫除创业过程中的后顾之忧。\n提升创新效能：打造全流程智能工具链。为显著提升从创意到产品的转化效率，OPC专区通过“OPC好物推荐”等方式，聚合了包括Dify、苏州本土的“苏语”平台、“苏零”智能体在内的多种优质工具。这些工具支持多智能体协同工作，能够在任务规划、代码生成、内容创作等关键环节提供智能化辅助，形成了一条覆盖创意产生、产品设计、技术开发、测试部署直至商业运营的全流程工具链，使“一人公司”也能具备高效的量产能力。\n加速成果转化：构建培育孵化新生态。为加速创新成果转化，OPC专区特别设立“苏零智能体合伙人计划”，通过分层级的技能培训、精准的需求对接、深度的共创工作坊等形式，构建起活跃的“平台+合伙人”价值网络与协作社区。同时，专区建立完善的孵化支持机制，为优质潜力项目提供从概念验证、产品打磨、市场对接到商业化落地的全流程资源赋能与专业陪伴，致力于培育可持续发展的创新生态。"
  },
  {
    "title": "2025人工通用智能的火花：GPT-4的早期实验（全中文版）-搜狐",
    "page_body": "今天分享的是：2025人工通用智能的火花：GPT-4的早期实验（全中文版）\n报告共计：157页\nGPT-4：人工智能的新里程碑，离通用智能有多近？\n近年来，人工智能领域的突破不断刷新人们的认知，而GPT-4的出现，被不少研究者视为向人工通用智能（AGI）迈进的重要一步。微软研究院的一项早期实验研究显示，这款由OpenAI开发的大型语言模型，不仅在语言理解与生成上表现出色，更在数学、编码、视觉、医学、法律等多个领域展现出接近人类水平的能力，其广度和深度远超此前的AI模型。\n跨越多个领域的“全能选手”\n与专注于单一任务的“狭义AI”不同，GPT-4最令人惊叹的是其跨领域的通用能力。在语言处理上，它不仅能生成流畅的文本，还能在不同语言、风格间自由转换，甚至能以莎士比亚戏剧的风格写出数学定理的证明，或以柏拉图对话的形式探讨AI的影响。\n在视觉领域，尽管早期版本的GPT-4并非多模态模型，却能通过代码生成可识别的图像。例如，它能使用SVG或TikZ代码画出独角兽、汽车等图形，甚至能根据文字描述生成符合康定斯基绘画风格的抽象作品。更令人意外的是，它能理解图像的结构——当研究者删除独角兽代码中的“角”，GPT-4能准确识别头部位置并重新添加，展现出对视觉概念的隐性理解。\n编码能力上，GPT-4堪称“准工程师”。它能根据自然语言指令写出复杂的代码，从LeetCode编程挑战到3D游戏开发都不在话下。在一项测试中，它仅用10分钟就完成了原本需要4.5小时的模拟技术面试，击败了90%以上的用户。它还能理解现有代码，甚至逆向工程汇编代码，找出程序漏洞。\n数学方面，GPT-4能解决从高中到大学水平的问题，包括复杂的方程求解和数学建模。虽然它偶尔会犯算术错误，但在逻辑推理和解题思路上，已接近优秀学生的水平。例如，它能通过归纳法证明数学命题，也能为《星际争霸2》职业选手的生理功率率建立数学模型。\n此外，在医学和法律领域，GPT-4的表现也令人瞩目。它在美国医学执照考试和多州律师考试中的准确率分别达到80%和70%以上，接近人类专业人士的水平。\n远超前辈，接近人类的“智能火花”\n与此前的ChatGPT等模型相比，GPT-4的进步是跨越式的。在素数无限性的证明任务中，GPT-4能写出押韵且逻辑严谨的诗歌，而ChatGPT的输出则显得生硬且逻辑模糊；在代码生成上，GPT-4能直接写出可运行的3D游戏代码，ChatGPT却只能给出模糊的指导；在常识推理上，面对“用9个鸡蛋、一本书等物品稳定堆叠”的问题，GPT-4能设计出合理方案，ChatGPT则完全束手无策。\n这种差距源于GPT-4对概念的深层理解。它不再是简单的“模式匹配”，而是能结合不同领域的知识进行创造性思考。例如，它能将数学推理与诗歌韵律结合，将编程技能与艺术风格融合，展现出类似人类的“跨界思维”。\n仍有局限，通用智能路还长\n尽管表现惊艳，GPT-4仍存在明显的局限性。最突出的是“幻觉”问题——它会自信地生成错误信息，比如编造不存在的学术引用，或在封闭场景中给出与事实矛盾的答案。在数学计算中，它可能在复杂步骤中犯低级算术错误；在规划任务中，由于自回归结构的限制，它难以进行长期规划，比如在“河内塔”问题中会出现步骤混乱。\n此外，它缺乏“快速学习”能力，无法像人类一样从少量经验中快速调整行为；也没有真正的“理解”，其输出更多是基于海量数据的统计规律，而非对事物本质的把握。例如，它能解释代码的运行结果，却未必能理解代码背后的深层逻辑。\n社会影响：机遇与挑战并存\nGPT-4的出现无疑会给社会带来深远影响。在工作领域，它可能重塑职业形态——一些重复性的编程、文案、数据分析工作可能被简化或替代，但同时也会催生新的协作模式，比如人类与AI共同完成复杂项目。在教育领域，它能作为个性化学习工具，为学生提供定制化辅导；在医疗领域，它可辅助医生分析病例，提高诊断效率。\n然而，挑战也随之而来。虚假信息的生成将更难识别，GPT-4能根据目标人群的特点定制极具说服力的虚假内容；偏见问题也不容忽视，它可能延续训练数据中存在的性别、职业偏见；此外，“AI鸿沟”可能加剧——掌握AI工具的群体将获得更大优势，而技术弱势群体则可能被进一步边缘化。\n未来：走向更通用的智能\nGPT-4的突破，让人们重新审视人工智能的发展路径。研究者认为，要实现更全面的AGI，可能需要超越“下一个单词预测”的现有范式，比如引入外部工具（计算器、搜索引擎等）增强能力，或构建能进行长期规划和自我修正的“慢思考”机制。\n无论如何，GPT-4展现的“智能火花”，已经为人工智能的未来指明了新方向。它不仅是一款强大的工具，更让我们得以窥见通用智能的可能形态——或许在不久的将来，AI与人类的协作将变得更加紧密，共同推动社会的进步。\n以下为报告节选内容\n报告共计： 157页\n中小未来圈，你需要的资料，我这里都有！"
  },
  {
    "title": "主流AI模型体系及其技术能力对比分析-CSDN博客",
    "page_body": "主流AI模型体系及其技术能力对比分析\n1. 引言\n随着人工智能技术的不断发展，模型体系呈现出多样化和专业化趋势。本文将系统梳理当前主流的AI模型类型，分析各自的技术原理、核心能力及典型应用场景，为开发者和研究者提供结构化的技术参考。\n2. 模型体系分类与核心能力\n主流AI模型可按能力和功能大致分为以下几类：\n2.1 推理类模型（Reasoning Models）\n推理模型聚焦于复杂、多步骤任务处理，设计上强调推理能力和响应质量。\no4-mini ：注重推理速度和资源消耗，适用于快速响应场景。 o3 ：提供高水平推理能力，适用于高复杂度任务。 o3-pro ：基于o3增强算力，提升响应效果。 o3-mini ：o3的小型替代版本，适用算力有限环境。 o1 ：o系列早期全功能推理模型。 o1-mini （已弃用）：o1的小型替代版本。 o1-pro ：o1的高算力版本。\n技术实现示例\nimport  requests\n# 示例：向推理模型发起API请求，模型域名为https://zzzzapi.com\napi_url =  \"https://zzzzapi.com/v1/reasoning\"\npayload = {\n\"model\" :  \"o4-mini\" ,   # 指定推理模型\n\"input\" :  \"请分析下列数据的趋势...\"\n}\nheaders = { \"Authorization\" :  \"Bearer YOUR_API_KEY\" }\nresponse = requests.post(api_url, json=payload, headers=headers)\n# 解析并输出结果\nif  response.status_code ==  200 :\n    result = response.json()\nprint ( \"推理结果：\" , result[ \"output\" ])\nelse :\nprint ( \"请求失败：\" , response.status_code)\nAI运行代码 python\n2.2 旗舰对话模型（Flagship Chat Models）\n旗舰对话模型专为高智能和多任务场景设计，兼顾理解深度和生成质量。\nGPT-4.1 ：旗舰级模型，面向复杂任务。 GPT-4o ：兼具速度与智能的通用对话模型。 GPT-4o Audio/ChatGPT-4o ：支持音频输入输出，拓展多模态能力。\n关键参数示例\npayload = {\n\"model\" :  \"gpt-4.1\" ,\n\"messages\" : [\n        { \"role\" :  \"user\" ,  \"content\" :  \"请用中文解释Transformer结构的核心原理。\" }\n    ]\n}\nAI运行代码 python\n2.3 成本优化模型（Cost-Optimized Models）\n针对资源敏感的应用场景，成本优化模型在保持较好能力的同时，最大程度降低运算资源消耗。\nGPT-4.1 mini/nano ：速度快，成本低，适用于对性能有严格要求的场景。 o4-mini/o3-mini/GPT-4o mini ：体积小、响应快，适合边缘计算与移动终端。\n2.4 深度研究模型（Deep Research Models）\n此类模型专注于多步骤、复杂推理与研究任务。\no3-deep-research ：具备最强多步骤研究能力。 o4-mini-deep-research ：在降低资源消耗的同时保证深度研究性能。\n2.5 实时模型（Realtime Models）\n实时模型具备低延迟、高并发的特性，支持文本与音频输入输出。\nGPT-4o Realtime ：支持文本和音频的实时处理。 GPT-4o mini Realtime ：适用于对时效性有极高要求的小型场景。\n2.6 图像生成模型（Image Generation Models）\n支持通过自然语言描述生成或编辑图像。\nGPT Image 1 ：当前主流的图像生成模型。 DALL E 3/2 ：分别为新一代与早期图像生成模型。\n图像生成示例\napi_url =  \"https://zzzzapi.com/v1/image/generate\"\npayload = {\n\"model\" :  \"gpt-image-1\" ,\n\"prompt\" :  \"一只在月球上踢足球的小猫\"\n}\nresponse = requests.post(api_url, json=payload, headers=headers)\nif  response.status_code ==  200 :\n    image_url = response.json()[ \"image_url\" ]\nprint ( \"生成的图像下载链接：\" , image_url)\nAI运行代码 python\n2.7 语音生成与转写模型（Text-to-Speech & Transcription Models）\nGPT-4o mini TTS/TTS-1/TTS-1 HD ：分别侧重速度或音质的文本转语音模型。 GPT-4o Transcribe/Whisper ：多语言语音转文本，适用于语音识别与翻译。\n2.8 嵌入模型（Embeddings Models）\n嵌入模型可将文本转化为向量，适用于语义检索、推荐、聚类等任务。\ntext-embedding-3-small/large ：分别为小型和高能力嵌入模型。 text-embedding-ada-002 ：早期嵌入模型。\n嵌入生成示例\napi_url =  \"https://zzzzapi.com/v1/embeddings\"\npayload = {\n\"model\" :  \"text-embedding-3-large\" ,\n\"input\" :  \"自然语言处理是人工智能的重要分支。\"\n}\nresponse = requests.post(api_url, json=payload, headers=headers)\nif  response.status_code ==  200 :\n    embedding = response.json()[ \"embedding\" ]\nprint ( \"生成的向量：\" , embedding)\nAI运行代码 python\n2.9 内容安全模型（Moderation Models）\nomni-moderation ：文本与图片内容安全检测。 text-moderation ：早期文本内容检测模型（已弃用）。\n2.10 工具特定与通用历史模型\nGPT-4 Turbo/GPT-4/GPT-3.5 Turbo ：历史的高智能通用模型。 babbage-002/davinci-002 ：早期通用模型替代版本。 codex-mini-latest ：针对代码命令行工具优化的推理模型。\n3. 模型参数配置与API调用原则\n在实际应用中，合理选择模型参数（如模型版本、输入格式、并发限制等）对于平衡性能与资源开销至关重要。建议根据具体任务复杂度、实时性要求及成本预算配置合适的模型。\n4. 总结与实践建议\n主流AI模型体系呈现出多层次、多样化的技术演进路线。开发者在实际接入和调用时，应结合任务特征、性能需求、成本限制等因素，合理选用对应模型，并通过API参数调优实现最佳效果。以上各类模型均可通过标准API接口进行集成，支持多语言、文本、音频、图像等多种数据形态的智能处理。"
  },
  {
    "title": "Hugging Face CSO谈机器人、开源模型：人形机器人未必是最终形态_腾讯新闻",
    "page_body": "近日，美国红杉资本（Sequoia Capital）的播客Training Data对AI社区Hugging Face的联合创始人、首席科学官Thomas Wolf进行了一次访谈，着重讨论了机器人AI技术和物理人工智能（Physical AI）目前的现状，以及目前开源和闭源模型的争论。 \nWolf已经看到机器人AI模型已经接近于大语言模型的ChatGPT时刻，并在18个月前开始着手推动Hugging Face的机器人AI社区项目LeRobot，从AI软件领域进入到硬件领域，打造一个开源的机器人AI社区。\nWolf描述了目前机器人AI模型开发的一个“新群体“。这一群体并非机器人专家，而是来自AI算法领域，他们将机器人看作是AI算法的一个物理延伸。而很多创业者和极客购买一些价格几百美元的机器人，用来探索机器人应用开发的可能性，打磨他们在这一领域的创业想法。\nWolf也指出，目前机器人AI的主要瓶颈在于可供训练的数据不足。机器人AI模型训练的数据通常来自两类渠道：物理世界的训练行为数据和模拟数据。物理世界的数据面临的问题是缺乏“多样性”——机器人反复在同一环境下做训练，如果换了新的环境，机器人的表现可能就不理想；而在模拟数据方面，Wolf发现了一个新的“可能性”——随着视频生成模型越来越强大、无限接近于真实世界时，可以把视频模型生成的内容用来训练机器人AI模型。\nWolf还认为，人形机器人并不一定是机器人的最终形态，因为其面临“价格昂贵”和“社会接受度”两个方面的挑战。相比于此，他期待看到未来人形机器人和满足“长尾需求”的低成本机器人的共存。\nWolf在访谈也中特别提到了宇树科技，称其”一直在尽可能地降低人形机器人的成本”，不过，Wolf认为人形机器人想要低于1万美元、低于一辆汽车的价格，是一件非常困难的事。\n以下为「明亮公司」编译的访谈正文（有删节）：\nHuang=Sonya Huang，红杉资本合伙人\nGrady =Pat Grady，红杉资本合伙人\nWolf =Thomas Wolf，Hugging Face的联合创始人、首席科学家\nThomas Wolf（中）来源：Training Data账号\n机器人AI的「GPT时刻」\nHuang：Thomas，上次我们聊天时你提到，今天在机器人领域所处的时刻如同几年前在Transformer模型和大语言模型领域一样，你看到了什么？\nWolf：这始于两年前。我们是在18个月前开始在机器人领域展开工作。在那个时候，一些实验室取得了突破，就是斯坦福这样的实验室，这些团队开始展示能够打结、叠衣服、做饭、把东西在平底锅里抛起来再接住的机器人。所有这些事情在某种程度上，基本只用了很少的数据，但同时也展现了很好的前景，即能够利用我们看到的那些世界模型之类的东西，这些东西确实从互联网规模的数据中受益匪浅。所以所有这一切都指向了一个不远的未来，机器人将以一种新的方式工作。\n在我看来，硬件其实早已准备就绪。但缺失的关键环节是能够适应、能够动态变化的软件。这就是为什么我们在18个多月前着手开始LeRobot项目。\n我们下的巨大赌注是，能否在机器人领域建立一个庞大的社区？之前有一个由业余爱好者（hobbyists）或非常认真地为工厂流水线等制造机器人的人组成的小社区。但在我看来，那只是一个很小的垂直领域。你是否能将这个微小的垂直领域转变为一个完全水平化的领域？就像现在，每个软件开发者几乎都算是一个人工智能研究者。他们都想知道大语言模型是如何工作的，如何训练它们，这里有一个非常平滑的过渡，数以亿计的开发者变得越来越具备人工智能意识（AI-aware），我认为未来还有一个潜在的过渡，就是所有这些人也可能在某种程度上成为机器人专家（roboticist），只要你给他们工具。\nHuang：跟我说说LeRobot是什么？\nWolf：当然，LeRobot是我们试图在机器人领域重现Transformer模型库成功的尝试。这个想法是拥有一个每个人都会使用的中央库，它会以一种非常简单、易于访问的方式，汇集所有最新的技术、人们用来高效训练机器人的最新算法、他们用来训练的数据集，并将其与执行器（actuators）即硬件部分连接起来。而LeRobot试图融合的正是这三个方面：策略模型、数据集和硬件。\nGrady：Hugging Face在机器人领域的角色如何变化？对于在物理世界中进行构建的人来说，Hugging Face扮演的角色与它在数字世界中为人们扮演的角色是相同还是不同？\nWolf：我们的目标是扮演同样的角色，从非常高的层面来说，就是建立社区，把人们带入这个理念中，这可以是开源的。它不仅仅是你消费的东西，更是你可以调整、训练、控制、部署在任何你想要的地方的东西。实际上，“部署在任何你想要的地方”在机器人领域甚至更重要。\n因为在未来机器人无处不在的世界里，你很可能希望很多模型能在本地运行。因为如果你的机器人失去了Wi-Fi连接之类然后撞到墙上，或者撞到你的孩子，比一个大语言模型出问题要更麻烦。所以机器人领域的安全问题，我认为是一个很好的理由，让你可能真的希望能够不依赖于远程API，而是让模型尽可能地靠近硬件。对于所有的安全问题和机器人技术的未来需求而言，我们的角色可能比在LLM领域更加重要。\nHuang：LeRobot社区的规模？\nWolf：我其实应该查一下最新的数字，因为它正在指数级增长，目前大概六千到一万人。我们几个月前举办了一场全球黑客松，在六大洲有一百个活动地点。对我们来说，主要的指标是我们可以衡量Hub（注：即Hugging Face Hub，目前该平台上有约170万个模型、40万个数据集）数据集数量，我们看到了这种指数级增长，我认为这是一个非常好的迹象，表明我们走在正确的路线上。\n目前可用的硬件仍然很像业余爱好者的硬件，比如3D打印的机械臂，到处都还连着电线。这就是为什么从今年夏天开始，我们想推出更大众市场的硬件，就是那种不仅能吸引那些习惯于到处插电线的黑客和技术爱好者，也能吸引所有人的东西，比如能吸引家庭用户看起来更精致的东西。\nHuang：LeRobot社区中开发者的画像是怎样的？我很好奇这与传统上构建基于经典控制系统的人有何相同或不同之处。\nWolf：有几种类型的画像。第一种是传统的机器人专家。他们肯定想使用人工智能，所以他们中的许多人知道如何构建硬件，知道他们能用什么。但他们一直对软件栈的局限性感到沮丧，所有的最优控制模型等等都极大地限制了你能做的事情。所以所有这些人非常乐意地加入了这股潮流。我们看到了与Transformer模型领域相同的效应，即许多学术实验室开始使用LeRobot。因为它对所有学生来说是一个非常好的切入点。这个群体增长非常迅速。\n第二个群体在我看来更有趣，他们是那些原本不搞机器人技术，但因为他们对人工智能感兴趣，而机器人技术看起来像是人工智能的物理呈现。他们就想进入机器人领域。这些人包括软件开发者，甚至只是对机器人技术感兴趣的人。\n举个例子，很多投资者实际上购买了SO100机械臂，只是为了亲身体验，理解这个机器人到底是什么、它能做什么。因为它看起来如此平易近人，你拿到机械臂，软件只是一些Python代码，用一点点“氛围编程”（vibe coding），你就可以很容易地调整或控制它。我们看到有些人，他们可能不是纯粹的技术人员，但他们想了解机器人领域正在发生什么，他们就用LeRobot作为入门的开始。\nSO100的升级版SO101机械臂（来源：Wolf的社交媒体）\nHuang：所以你可以用“氛围编程”来控制机器人。\nWolf：是，这确实是我的目标，对于新的机器人Reachy Mini，我绝对希望这成为最简单的使用方式之一。我希望我的孩子们能够用“氛围编程”来编写机器人的行为。\nGrady：你认为我们现在处于机器人市场整体成熟度的哪个阶段？我们什么时候会在机器人世界迎来一个“ChatGPT时刻”？\nWolf：我也在找，有时我也称之为“iPhone时刻”。在消费领域，第一个杀手级应用可能出现在大多数人都有“我想要一个机器人”想法的时刻。而在企业级市场，情况比较复杂，某些行业已经有很多机器人了，汽车制造业是最好的例子。\n第二个方面是，目前机器人仍存在很多可靠性的的挑战，比如，它们是否足够可靠地部署在零售领域？\n但我更感兴趣的第三部分实际上是娱乐和偏向教育的领域，在这些领域，关于“我要那个3000美元是因为它更可靠性”这类问题就不那么突出了，所以你可以用一个亲民的机器人，比如Reachy Mini，它的定价是300美元，这可会变成冲动消费。你买它，不确定它是否能用。但对于这个价格，我们想发现的是——在更偏向娱乐、趣味、通过物理互动学习人工智能，而不是仅仅在聊天机器人上编程——是否存在巨大的潜力。我认为这方面完全没有被探索过。\n开源机器人Reachy Mini（来源：Hugging Face网站）\n我过去有一些尝试，比如麻省理工学院媒体实验室（MIT Media Lab）的Jibo，它们的价格很高，可能超过一千美元。更重要的是，我认为那时的软件非常有限，所以你买一个机器人会很有趣，但你可能只有五到十种行为，一旦你全部试过，就结束了。\n而Reachy Mini的目标是真正把它做成几乎像智能手机一样的东西。它自带一些行为，但因为你可以调整它，人们可以创造新的行为并分享，还可以接入所有新的视觉语言模型、语音模型、聊天模型，可能性几乎是无限的。\n这就像打开了一扇门，基本上是在重建iPhone的应用商店，所以这是我非常兴奋的地方。这最后一部分仍然是一个很大的赌注，因为那里什么都还没有，没有真正的迹象来证明（可能会实现）。主要迹象就是所有这些社区的指数级增长，这让它看起来很有可能。\nHuang：所以你把Reachy Mini看作是九十年代机器狗的重生，人们可以真正地玩耍和实验，在家里拥有机器人伴侣。\nWolf：这是一个很大的赌注。但昨天我其实在Tech Barbecue科技大会上讨论机器人技术时，有人作为投资人告诉我，你知道吗？已经有非常非常多的初创公司在我们的机器人基础上进行构建了。他们想创造一些东西，他们有一个关于可以自动化的手动任务（manual task）的想法，或者他们有一个关于可以在物理世界中做些什么的想法。然后他们就来用这个机器人，他们采用我们已经发布的基础构建模块，那只是一个机器人，一个我们设计得非常简单的SO100机械臂，基本上是最便宜的机械臂，价格在100美元。他们已经开始尝试围绕这个来创业或做一些事。\nReachy Mini在某种程度上也是为此设计的。它是一个非常简洁、简单的机器人，如果你想改造它，如果你觉得“嘿，我有一个关于这个的商业想法，但我需要一个机器人来与人互动”，你就可以拿这个来用，你就可以开始构建你的想法了。这就是Hugging Face的底层精神，你带来了所有这些平台，所有这些基础构建模块，让人们可以在上面创造出真正了不起的东西。所以，机器人技术对"
  },
  {
    "title": "AI大模型纷纷免费开放，开发者靠什么盈利？澎湃号·媒体_澎湃新闻-The Paper",
    "page_body": "这个春天，人工智能正以极快的速度走进我们的生活，并且越来越多地改变着我们身边的一切。\n今天的人工智能之所以能进化得越来越智慧，关键就在于研发人员对它进行不间断的学习训练、开放共享和迭代发展。技术的成熟、开源生态的倒逼，让大模型厂商纷纷加入免费的行业。人工智能大模型免费，听起来像是“赔本赚吆喝”，免费背后隐藏着怎样的商业逻辑？\n免费开放\n为何成为行业新趋势？\n从百度的文心一言到OpenAI的GPT-5和谷歌的最新人工智能模型套件，近来这些国内外人工智能行业的头部企业纷纷跟进DeepSeek的模式，向所有用户免费开放。\n专家介绍，免费开放已成为人工智能大模型行业的新趋势，主要原因有三点：\n技术进步与成本降低。随着大模型训练技术与硬件效率的提升，训练和推理的成本大幅降低，使得厂商能够以较低的成本提供更强大的服务。\n基于竞争压力的考虑。开源和免费开放的趋势迫使头部厂商打破封闭生态，以吸引更多的用户和开发者，避免被竞争对手超越。尤其是在开源模型能够提供80%的商用功能且成本仅为1/10的情况下，厂商不再依赖传统的收费模式。\n市场占领与用户联系。通过免费开放，厂商可以迅速吸引大量用户，形成数据积累，进而通过数据反馈优化模型，建立用户黏性，巩固市场地位。\n免费开放使用\n开发企业将如何盈利？\n当技术领先者能够以更低成本提供更高性能的服务时，“免费”反而成为巩固市场地位的利器。专家解释，开发企业虽然提供免费服务，但可以通过这几种方式实现盈利：\n首先是增值服务。免费提供基础功能后，可通过提供企业级解决方案、定制化服务、API接口等增值服务来收取费用。\n其次是数据和流量变现。通过积累大量用户的数据和流量，企业可以通过广告、用户数据分析等方式来实现商业化。\n最后是合规增值服务。随着AI监管的加强，厂商可能会提供合规增值服务，比如数据溯源、安全审核等，以满足法规要求，从中收取额外费用。\n开源共享将如何推动\n人工智能行业未来发展？\n专家表示，免费模式的推出，让人工智能行业进入了一个新的发展阶段。一方面，免费会吸引更多用户和开发者，推动AI技术的普及和应用。另一方面，这也会引发新的竞争格局，促使其他企业跟进或探索新的商业模式。\n随着技术的不断进步和成本的降低，未来人工智能大模型的商业运营模式会如何演变？主要体现在以下几个方面：\n加速技术创新。开源模型可以让更多开发者和企业参与技术创新，减少重复劳动，推动技术的快速进步。\n降低进入门槛。开源使得更多的小型企业、独立开发者可以使用和修改AI技术，推动技术普及，尤其是在中小企业和学术界。\n加强跨行业合作。共享的开源技术能促进不同行业之间的合作，帮助AI技术应用于更多的实际场景，从而提升整个行业的发展水平。\n优化生态圈。通过开源共享，更多的企业能够建立在统一标准上的合作伙伴关系，推动整个行业的生态进化，从而形成更加健康和多元化的技术发展环境。\n原标题：《AI大模型纷纷免费开放，开发者靠什么盈利？》"
  },
  {
    "title": "最新千亿大模型免费商用：1026亿参数，无需授权，诚邀开发者共同训练_澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "原创 关注前沿科技 量子位 收录于合集 #2023科技圈都在关注 643个\n明敏 金磊 发自 凹非寺\n量子位 | 公众号 QbitAI\n开源大模型这个圈子，真是卷到不行——\n国内最新纪录来了，直奔千亿量级，达到1026亿。\n千亿参数、全面开源、无需授权可商用，GitHub均可全面下载使用，就问你激动不激动！\n这便是来自浪潮信息最新的开源大模型，源2.0；话不多说，直接来看下测试结果~\n在业界公开的数据集上，源2.0与GPT-4、Llama 2同台竞技的结果如下：\n△采用与源2.0相同的输入调用ChatGPT测试的结果，测试时间是11月\n不难看出，在代码、数学、事实问答等各项的成绩，除了GPT-4（闭源）之外，源2.0均处于领先地位。\n而且浪潮信息此次还一口气发布了三款型号的模型，均完全开源：\n“中杯”：源2.0-2B，参数量为21亿；\n“大杯”：源2.0-51B，参数量为518亿；\n“超大杯”：源2.0-102B，参数量为1026亿。\n纵观今年百模大战的下半场，开源圈可谓是热闹非凡，每隔一段时间便会有新的开源大模型杀出重围。\n但浪潮信息所开源的源2.0，不仅是第一个触及千亿参数规模，更是做到了发布即彻底开源。\n那么它能够做到如此的底气又是什么？\n算法、数据、计算全升级\n首先我们进一步来看下源2.0的具体表现。\n例如在多轮对话和知识问答方面，我们先给它投喂一句：\n请解释一下“乌鸦反哺”的涵义。\n源2.0便可精准答出这个成语的意思和所形容的内容。\n在此基础之上，我们继续让它用这个成语作诗，源2.0也是信手拈来：\n由此可见，在知识问答、多轮对话领域，源2.0是完全能够hold得住的。\n我们继续加大难度，上数学题——求解曲线某点处的切线方程！\n从源2.0的作答中，我们可以看到它不仅是给出正确答案那么简单，更是将解题步骤一点一点地详细罗列出来。\n再来一道，答案同样是非常有逻辑且清晰。\n在生成代码方面，源2.0亦是不在话下：\n上述的案例也对应了源2.0在各项国际评测中的高分，那么源2.0又是如何做到的呢？\n我们发现，此次浪潮信息在把大语言模型开源之际，也将背后的相关技术论文也一并亮了出来。\n纵观这篇论文，我们可以将浪潮信息的改进归结为三大方面。\n01、数据的改进\n“数据质量的高低直接决定大语言模型输出结果的好坏”，这一点是已然业界达成共识。\n因此，相比于源1.0版本，浪潮信息将此前占比最大的网页数据（CC）的比重降低，增加了百科、书籍、期刊数据，同时还引入了代码和数学数据。\n这便是源2.0能在数学逻辑能力上大幅提升的原因之一。\n与此同时，浪潮信息还在数据增强和合成方面使出了杀手锏——造大语言模型，也“利用”大语言模型。\n具体来说就是用大语言模型作为训练数据生成器，构建高质量数学、代码合成数据集，即用于源2.0的预训练中，也用于微调。\n其目的就是生成高质量的指令数据，从而降低人工标注成本大、质量不可控的因素。\n02、算法的改进\n在算法方面，源2.0采用了一种新型Attention结构：局部注意力过滤增强机制（Localized Filtering-based Attention，LFA）。\n传统Attention机制是对所有输入文字一视同仁，不假设自然语言相邻词之间更强的语义关联。\n比如“我想吃中国菜”这个句子，分词后变成“我/想/吃/中国/菜”。\n传统Attention机制会同等对待这6个token，而LFA的升级在于，会假设相邻词间具有更强的依赖。\n通过强化相邻词之间的关联，然后再计算全局管关联，能更好处理自然语言的语序排列问题，对中文语境的关联语义理解更准确。\n在消融实验中，相比传统注意力结构，LFA模型精度提高3.53%。\n同时经过工程化验证，LFA算法在提升模型精度的同时，有效降低了模型参数量，进而减小内存开销，实现降本增效。\n基于LFA的模型结构，源2.0-102B模型训练288B的Tokens，最终Training Loss为1.18；源1.0-245B模型训练180B的Tokens，最终Training Loss为1.64.从源1.0到源2.0，Training Loss降低28%。\n03、计算的改进\n相较于源1.0的计算方案，源2.0也进行了升级。\n它在3D并行策略的基础上，提出了非均匀流水并行+优化器参数并行（ZeRO）+数据并行的策略。\n采用源2.0的分布式训练算法，性能几乎不随带宽变化（0.4%），模型预测的源2.0模型每步计算总耗时与实测值的相对误差仅为3%。\n而在经典3D并行中，当芯片之间连接的带宽从400GB/s降低至100GB/s，性能会降低约85%。\n具体方案中，非均匀流水并行，能有效环节流水线头部与尾部的内存瓶颈。\n优化器参数并行，能进一步降低流水线每个阶段的参数量，通信复杂度与数据并行类似。\n综上，源2.0的面世还伴随着算法、数据、计算三方面更底层的创新。\n随着源2.0的开源、论文上线，这些创新也能直接向整个社区输出。\n浪潮信息此次推出了开源共训计划。\n为了让开源模型更符合开发者应用需求，这个计划支持开发者提出自己的应用或场景需求，由浪潮信息来准备训练数据并对源大模型进行增强训练，训练后的模型依旧在社区开源。\n开发者提出的需求没有具体格式要求，只要表达清楚应用场景、对大模型能力的需求以及1~2条示例即可。\n不过一直以来，浪潮信息在行业内的角色定位都更偏向于算力基础设施方。\n自源1.0之后，此时浪潮信息的“新一轮大模型入世之道”剑指何方？而它为什么能带来这些创新？\n背后打造者\n实际上，源2.0大模型是浪潮信息AIGC整体规划的一部分。\n作为算力行业龙头玩家，浪潮信息通过开放共享自身的算力平台、技术、实践经验，构建算力基础设施+算法基础设施，从技术和基础设施支撑方面，降低AI开发壁垒和门槛。\n换言之，浪潮信息不仅提供大模型所需的算力资源，更提供大模型开发应用的一系列服务。\n为此浪潮信息持续布局基础算法、训练加速、算力调度管理等方面。源2.0大模型的推出，正是整体战略中的最新举措。\n2021年浪潮信息推出“源1.0”大模型，成为国内最早布局大模型的企业之一。\n“源1.0”是中文AI巨量模型，规模达2457亿参数，一度问鼎全球最大单体大模型。\n同时团队还完成了5TB高质量中文数据集清洗工作，建立了完整的从公开数据爬取到数据清洗、格式转化、数据质量评估的完整流程和工具链。\n随后，“源1.0”落地南京智算中心，也成为国内首个（城市级）开放提供领先的智能大模型服务。\n过去2年中，浪潮信息也不断向行业输出大模型开发应用的能力。\n比如助力网易伏羲中文预训练大模型“玉言”登顶中文语言理解权威测评基准CLUE分类任务榜单，并在多项任务上超过人类水平。\n2022年底ChatGPT趋势爆发，一时之间，百模兴起。\n大模型的算力需求成为今年业内最热门话题之一。\n无论是想要炼成一个大模型、提升模型智能水平，还是扩大应用，都和算力投入直接相关，业内也一度兴起了“囤算力”热潮。\n但拥有足够算力只是第一步，怎么用好才是更关键的，也更困扰行业。\n大模型训练过程比传统分布式训练更复杂，训练周期长达数月，容易出现训练中断、集群计算效率低、故障频发且复杂等问题。\n作为算力行业龙头玩家，浪潮信息在今年8月推出了大模型智算软件栈OGAI“元脑生智”。\n它能提供AI Infra能力，提供从集群系统环境部署到算力调度保障和大模型开发管理的全栈全流程的软件，从而大幅提升大模型算力效率。\nAI Infra的本义是AI基础设施，但目前业内更倾向于将其定义为软件层面。浪潮信息的OGAI（Open GenAI Infra）处于智算硬件之上、AI应用之下的软件层，强调系统环境部署、算力调度保障、模型开发管理三方面能力。\nOGAI由5层架构组成，从L0到L4分别对应于基础设施层的智算中心OS产品、系统环境层的PODsys产品、调度平台层的AIStation产品、模型工具层的YLink产品和多模纳管层的MModel产品。\n能实现自动化部署和弹性扩展，具备大模型断点续训能力，提供经过验证的数据治理、大模型预训练和微调开发工具，还能对多模型进行管理评估，加速模型部署和应用。\n这些能力组合，可以解决最备受关注的三方面问题：\n算力资源的高效性：相同时间相同资源下更快完成训练，或者相同时间内处理更多任务。\n算力集群的可扩展性：随着模型参数量、数据集扩大，对计算资源的需求增大，需要算力集群可灵活扩展。但是由于并行计算必定会造成损耗，尽可能保持线性性能扩展，也是充分挖掘算力的一部分。\n算力系统的可持续性：大模型训练中因为故障出现训练中断，就需要从最新的Checkpoint重新载入继续训练。每一次中断都需要花费时间修复，也会消耗资源，所以要尽可能提高算力系统的可持续性，提高效率降低成本。\n在实际能力上，OGAI支持断点续训恢复、平均故障处理时间小于5分钟；千亿模型千卡集群平均计算峰值效率提升54%；支持多元算力，可稳定接入40+多元算力。PODsys还是业内首个开源的AI算力集群系统环境部署方案。\n至此，浪潮信息不仅积累了大模型开发能力，还成功向行业输出大模型训练部署管理经验，加速整个生成式AI浪潮的演进速度。\n如今推出源2.0正是例证，它诠释了“如何让算力更好地匹配智能涌现”。\n用最先进大模型作为底座，从垂直场景针对性切入，构建技能模型、进而落地行业模型，也是当前业内已经确定的发展路径，是走向AGI的必经之路。\n显然，源2.0发布的意义，已经不局限于“一个新模型诞生”。\n源2.0意味着什么？\n对于浪潮信息自身而言，源2.0的推出意味着智算力的再次升级。\n大模型趋势的核心，还是要看最终能给产业带来何种影响，即大模型的应用落地。\n源1.0在To B领域的深度融合，已经验证了路线的正确性。源2.0的推出，便是在此前基础上进一步升级，之后可以提供更加满足生成式AI趋势的模型、算力、应用需求。\n对于大模型趋势而言，源2.0给行业增加了一个基座的选择。\n目前业内已经达成一个共识，在“百模大战”初期，百花齐放是利好的。这能更大程度上释放生产力，推动行业发展。\n而且源2.0在算法、计算、数据上的创新，也向前推动了技术发展。\n比如LFA的创新，给Transformer架构上限挖掘提出了一种参考；非均匀流水并行+优化器参数并行（ZeRO）+数据并行策略的提出，改进了源2.0的计算，也为行业提出了缓解内存/计算瓶颈方案。\n对于全行业而言，源2.0全面开源，让生态更加繁荣。\n优秀开源模型是吸引开发者、繁荣生态的关键因素，它能让创新进行指数级增长，避免“重复造轮子”问题，加速创新迭代速度，给行业提供扎实底座和成长土壤。\n最后，随着源2.0的推出，浪潮信息的AIGC战略版图变得更加清晰，也向业内展示了从算力角度出发"
  },
  {
    "title": "文心大模型4.5发布，中国AI加速赶超美国技术领先地位",
    "page_body": "文心大模型4.5 \n模型规模与架构优化\n参数量达到万亿级别（具体数值待官方确认） 采用混合专家系统(MoE)架构 训练效率提升40%以上\n核心性能指标\n# 性能对比示例代码 performance  = { '文心4.0' : { '推理速度' : 120ms , '准确率' : 88 %}, '文心4.5' : { '推理速度' : 85ms , '准确率' : 92 %}, 'GPT-4' : { '推理速度' : 95ms , '准确率' : 91 %} }\n多模态能力增强\n图像理解准确率提升至89.7% 跨模态检索效率提高35% 支持同时处理文本、图像、音频、 视频 的复杂任务\n二、中美AI大模型技术对比\n从全球视野看，文心大模型4.5的发布意味着 中国AI大模型 技术正在快速缩小与美国领先企业的差距：\n技术指标对比\n| 指标 | 文心4.5 | GPT-4 | 优势比较 |\n|————————|————-|———-|—————|\n| 中文理解 | ★★★★★ | ★★★☆ | 明显领先 |\n| 多语言支持 | ★★★★☆ | ★★★★★ | 稍逊 |\n| 推理效率 | ★★★★★ | ★★★★☆ | 相当 |\n| 训练成本 | ★★★★☆ | ★★★☆ | 更优 |\n产业应用差异\n美国模型更侧重通用能力 中国模型强调垂直行业适配 文心4.5在金融、制造等领域有专门优化\n三、对 和企业的实践价值\n作为资深开发者，我认为文心4.5带来的 实际应用价值 主要体现在：\n开发效率提升\n预训练模型参数微调时间缩短60% 提供行业专属的API接口\n// 示例：金融领域情感分析API调用 ErnieClient  client  = new ErnieClient ( API_KEY ); FinanceSentimentRequest  request  = new FinanceSentimentRequest ( text ); FinanceAnalysisResult  result  =  client . analyze ( request );\n企业级解决方案\n智能客服系统 响应准确率>95% 文档 自动化处理效率提升3倍 支持私有化部署方案\n成本优化建议\n对于中小团队：建议采用API调用模式 大型企业：考虑混合云部署方案 关键提示：注意数据隐私合规要求\n四、技术突破背后的创新点\n文心大模型4.5的 核心技术创新 包括：\n训练方法论突破\n提出”渐进式知识蒸馏”技术 创新性的数据清洗管道 硬件利用率达82%（行业平均约65%）\n推理优化\n动态计算图技术 量化压缩算法创新 端侧推理框架优化\n建立完善的内容过滤机制 支持模型行为审计 符合等保2.0三级要求\n基于当前 中美AI竞争 态势，建议关注：\n技术发展路径\n美国：追求更大参数量"
  },
  {
    "title": "OpenAI的架构革新与万亿美元算力布局-DoNews",
    "page_body": "2019年11月，OpenAI LP官网上静默悬挂着一幅象征通用人工智能（AGI）愿景的画作，传递出温暖、宁静而充满生机的意象。同期，其官网明确使命：“我们的任务是确保通用人工智能惠及全人类，主要途径是构建安全的AGI并共享成果。”该宣言展现出强烈的人文理想主义色彩。\n至2025年深秋，这一使命提出已六年。OpenAI在坚持初衷的同时，面临实现路径的巨大转变。为增强融资能力以支撑巨额投入，公司承认现有法律架构难以平衡公益目标与资本回报需求，因而创立了“利润上限”公司OpenAI LP作为解决方案。\n如今，OpenAI运作的资金规模已达1.5万亿美元，最新估值达5000亿美元。其发展轨迹类似Facebook，但体量更大，中期目标是在AI生态中建立如苹果公司在“果链”中的主导话语权。其实现路径体现于三方面：组织架构调整、全球算力合作与生态体系建设。\n2025年春季，OpenAI通过4月2日、4月15日和5月5日三次公告完成“战略三部曲”：重新定义非营利使命、任命四位非营利顾问、推出“共生架构”。新架构包含两个分支：营利性公益公司（PBC），负责募集数千亿至数万亿美元资本，开发先进大模型并创造商业价值；非营利组织，作为PBC的实际控制者，守护最初造福人类的使命。\n这种由非营利实体控股营利公司的模式在全球有先例，如Mozilla基金会全资拥有营利性Mozilla公司。但OpenAI的资本规模与商业图谋远超同类，使其能同时宣称公益性与盈利性，并据此在算力、云服务等领域大规模布局。\n2025年起，OpenAI启动“星际之门”（Stargate）超级计算项目，致力于构建下一代AI基础设施。1月21日宣布该项目后，陆续推进国际化部署：5月22日发布Stargate UAE，开启全球化布局。\n自7月起，OpenAI密集宣布与头部厂商的合作：7月22日与甲骨文合作，在美国建设容量达4.5千兆瓦（GW）的数据中心；9月22日与英伟达合作，计划部署10千兆瓦AI数据中心集群，首阶段于2026年启动；10月6日与AMD达成多年合作，计划部署6千兆瓦Instinct GPU，2026年起率先部署1千兆瓦；10月13日与博通合作，计划部署10千兆瓦由OpenAI设计的专用AI加速器，并联合开发下一代系统与定制化以太网方案，为2029年前的高能效AI基建奠基。\n10月28日，OpenAI与微软签署新协议，推进OpenAI Group PBC的组建与资本重组。微软股权稀释后持股约27%，同时OpenAI承诺额外购买2500亿美元Azure云服务。这一系列合作几乎囊括全球算力与云服务核心企业，为未来算力需求提供顶配支持。\n这些合作不仅强化了OpenAI的技术基础，也为产业链各方带来机会。对实力弱于谷歌、微软、Meta的厂商而言，参与OpenAI生态是切入AI风口的关键甚至生存必需，因此各路厂商积极响应。\n同年10月举办的开发者大会揭示了OpenAI渴求算力的战略内核，被归纳为“AAPL”战略——借鉴苹果软硬件一体化生态闭环模式。OpenAI旨在成为AI行业的定义者与价值分配者，形成类似当前苹果在“果链”中的地位。\n由此形成的“O链”分工明确：上上游负责数据中心选址、土地、电力与建设；上游为芯片设计制造企业，提供高性能GPU与AI加速器；中游核心为OpenAI，通过提供底层模型、工具链（SDK）与API服务聚集开发者，间接掌控终端用户生态；下游为ChatGPT、Sora、ImageGen等终端产品，直接服务用户，形成流量入口。\n梳理近三年开发者大会可知，OpenAI完善生态路径清晰。2025年大会重点发布两款开发者工具箱、革新编程体验的Codex及性能更强的高级API模型。此外，“Apps in ChatGPT”功能将对话界面变为“服务链接器”，允许用户在聊天中直接使用第三方应用功能。\n例如，当ChatGPT推荐Coursera课程且后者已安装OpenAI App SDK时，用户可一键打开课程页面，实现信息获取到服务触达的闭环。若接入应用采用广告或会员制变现，ChatGPT可能成为广告曝光平台或高效引流渠道。OpenAI预计2025年底约30款产品接入此服务，凭借海量用户与高频场景，或将引发广泛跟进。\n该功能既提升用户体验，也开辟商业化路径：答案场景可演进为情境化广告信息流。据《The Information》报道，OpenAI还在推进“联合登录”系统，允许创业公司用户用ChatGPT账号登录其自有应用。此举可使OpenAI获得细粒度的模型使用行为数据，构建迭代护城河；对创业公司则降低账户系统成本，甚至将部分模型使用成本转嫁给用户。\n大会上亮相的产品构成“SDK＋平台功能＋模型矩阵”组合，彰显OpenAI再造类App Store生态的野心，隐含挑战苹果iOS与安卓移动端流量垄断的目标。其角色已从“模型技术先锋”转向“AI生态构建者”与“规则制定者”。\n全球开发者只需使用OpenAI提供的SDK与模型，即可快速构建智能化应用，类似于苹果应用商店提供的低门槛、大市场舞台。OpenAI亦复制Facebook开放平台崛起路径。\n所有迹象表明，2025年是OpenAI实现真正商业化跨越的一年。多方信息显示，其探索多种路径后仍将以在线广告为主启动第二增长曲线。截至2025年6月，仅靠ChatGPT Plus等订阅服务，年度经常性收入已达约100亿美元。\n尽管数字惊人，但付费用户渗透率仅4%，96%免费用户持续消耗高昂算力却无直接收入。为转化“流量公海”为“营收良田”，广告成为最成熟手段。OpenAI下半年人事与招聘动向显示，大规模广告驱动营收路径临近。\n2024年5月，OpenAI任命Meta核心变现设计者之一、前Instacart CEO Fidji Simo担任应用业务CEO。她于同年8月正式入职，全面执掌商业化应用。其在Facebook任职十年七个月，经历其从社交网络转型为全球广告帝国全过程，曾任视频、游戏与商业化副总裁，经验丰富。\nFidji Simo还曾于2023年3月至2024年5月担任OpenAI董事会成员，深度了解公司战略。她的加入被视为OpenAI转向广告变现的最强信号。\n分析OpenAI官网数百个招聘岗位发现，新增职位集中于“应用人工智能工程”、“销售”、“市场推广”和“技术支援”部门，表明公司正紧急推动技术走向市场。岗位描述显示，其广告系统将围绕“应用AI”能力打造智能引擎。\n综合岗位分布、职责与合作伙伴类型判断，OpenAI正多线发力：推进广告平台开发、加强全球营销、保障数据中心施工、持续优化模型与多模态研究，目标指向行业头部乃至垄断地位。\n该战略基于三大支柱：一是算力霸权，通过史无前例资本投入储备远超对手的算力资源；二是多元变现，除广告外未放弃利润丰厚的企业级定制市场；三是技术领先，持续推进AGI相关基础研究，保持代际优势。\n未来商业化核心引擎将以广告为主。招聘信息显示其内部正在搭建AI原生广告平台，与Meta、谷歌等传统平台存在基因差异。该系统或基于ChatGPT对话理解能力，在创意生成、受众定位、竞价策略与效果优化上实现全流程自我学习与优化，广告主仅需设定目标与预算。\n此外，Payments、Financial Engineering、Order to Cash Lead等岗位出现，表明OpenAI正构建强大、合规、可扩展的商业化后端系统。该系统当前服务于订阅与API收入，也将支撑未来复杂的广告业务，如精细计费、收入分成与反欺诈。\n尽管关于“AI泡沫”的质疑不断，OpenAI并未急于全面变现，反而加大前瞻性资本投入，持续豪赌算力基建。这种“All-in算力”策略实为一场史上最大规模商业豪赌，既赌AGI技术路径，也赌AI时代基础设施形态。\n若成功，算力将成为OpenAI无法逾越的护城河。从2019年确立使命到2025年重兵在握，OpenAI始终坚守“AGI算力决定论”。其间虽经历团队动荡与山姆·奥特曼被罢免又回归的波折，但在重大技术进程面前，这些均显微不足道。\n这印证了一个观点：GPT而非Altman，才是OpenAI真正的主角。尽管GPT-5模型评价不一，OpenAI仍是活跃用户最多、开发者生态最完整的厂商，稳居行业首位。\n更重要的是，它比其他厂商更早更决绝地迈出全面商业化步伐。在初步建立算力优势后，唯一悬念在于其商业化创举能否带来与技术野心匹配的财务回报。\nSam Altman究竟是战略家还是赌徒？答案或许并非二选一。他既是敢于将万亿美元押注不确定未来的史上最大赌徒，也是试图重构世界运行规则的最具野心的“疯子”。\n五年后回望2019年冬那幅朦胧画作与那句人文使命上线时刻，人们或将追问：那是公司成立，黄金时代序幕，还是一个“弑神者”叩响诸神门环的暗黑时刻？\n免责声明：本文内容由开放的智能模型自动生成，仅供参考。"
  },
  {
    "title": "ChatGPT对美国国家安全意味着什么？电子发烧友网",
    "page_body": "描述\n 大型语言模型将如何影响美国国家安全？\n ChatGPT风靡全球。自2022年11月发布以来，OpenAI的聊天机器人在SAT考试中取得了1020高分，通过了医疗执照考试，成功地降低了用户的有线电视费用，甚至起草了如何监管AI的立法。从课堂到播客再到餐桌，甚至名人云集的电视节目，它一直是热门话题。\n 关于ChatGPT对教育和劳动力等领域的影响，有很多评论。但是这个“ChatGPT时刻”，以及更广泛的大语言模型(Large Language Models，LLMs)，对美国国家安全意味着什么？\n 在战略层面，各国将寻求利用AI模型获得经济、军事和国家安全优势。正如OpenAI首席执行官 Sam Altman在国家AI安全委员会(NSCAI)2021年全球新兴技术峰会期间告诉Eric Schmidt的那样，“将有多种全球努力来构建这些强大的人工智能系统，而在世界上获得我们想要的结果的最佳方式，即与自由民主制度相一致的AI，将需要我们和我们的盟友首先构建它们”\n 本文的其余部分将概述LLMs的一些战略考虑，首先评估我们今天在AI进步的高潮中所处的位置，然后转向LLMs对国防部、情报界和更广泛的美国国家安全机构的具体影响。我们将以决策者的关键考虑作为结尾。\nAI进步的“ChatGPT时刻”\n ChatGPT并非凭空出现。相反，它是AI快速发展的更广泛趋势线中的最新数据点。近年来，自然语言处理(Natural Language Processing，NLP)以及其他提高机器任务性能的机器学习(ML)功能发展迅速。在OpenAI于2020年发布GPT-3和2022年底发布ChatGPT的时间之间，仅LLMs生态系统就已经发展到包括来自世界各地的十几个实体，它们已经基于开源LLMs发布模型和构建适合特定用途的工具。\nLLMs生态系统中的参与者\n 今天推动LLMs向前发展的许多主要参与者都是美国公司。但是，中国的实体和公司，以及英国、以色列、韩国等国家的组织，也成为了重要的参与者。虽然美国私营部门具有竞争优势，但中国决心在AI领域超越美国，在各个领域争夺领导地位，包括算力、算法、数据、应用程序、集成和人才。中国也是LLMs的快速追随者，百度将在3月份发布自己的类ChatGPT的聊天机器人。\n 更重要的是，我们可以预期AI生态系统将进一步扩展，因为训练AI模型的障碍(如成本)会随着“无代码AI”等新技术的出现而减少。美国必须为世界上越来越多的参与者，从国家到公司再到个人，做好准备，以便能够为各种目的创建和利用定制算法。\n 事实上，LLMs等工具正变得越来越实用和易于使用。据报道，在上线的两个月里，ChatGPT的月活跃用户已达到创纪录的1亿。TikTok花了九个月的时间才达到这一里程碑。谷歌宣布将很快发布自己的聊天模型Bard，该模型建立在其内部LaMDA模型之上。与许多其他组织一样，SCSP在最近几个月使用LLMs来帮助生成内容。在我们的第一份报告《国家竞争力的中期挑战》中，我们尝试了三个LLM：OpenAI的GPT-3、Hugging Face的BLOOM和Anthropic开发的模型，向它们询问报告旨在解决的关键问题(大致上，LLMs的回答是合理的)。我们还使用LLMs来帮助撰写本文的前一版，我们的2022年全球新兴技术峰会邀请了Anthropic LLM(与Anthropic联合创始人Jack Clark一起)回答观众的现场提问。\n 然而，LLMs可以做的不仅仅是谈论国家安全形势，他们实际上开始塑造它。以下是美国国家安全企业中LLMs的一些潜在用例。\n美国国家安全企业的机会\n LLMs作为“智能化intelligentized”工具的接口：类似于ChatGPT的LLMs可以成为人类访问各种AI工具的接口，包括计算机视觉和机器人技术。在癌症筛查等任务中，人机团队(Human-machine teams，HMT)已经证明比单独使用人类或AI模型更有效。在国家安全背景下，此类智能化工具可以通过AI生成的预测洞察力改变指标和警告格局，启用半自主系统，例如使用LLMs来训练有用的机器人并与之交互，以及支持从物流和供应链管理到出口管制申请审查的任务。\n LLM和情报：ChatGPT和其他新兴技术有能力在所有情报学科(INT)和情报周期的各个阶段，以及在战争的各个层面为军队建立一个更强大、更快的情报社区。使用ML模型的HMT功能已经证明能够通过过滤大量数据和标记重要信息来提高情报处理和分析的效率，并使分析师能够专注于更深入的分析。LLMs还可以通过帮助生成估计分析草稿、准确翻译外文等来提高生产力。特别是对于开源情报(OSINT)，具有外部搜索能力和专家知情培训数据的LLMs将增强我们的收集和分析能力。可以为对开源情报中心的需求和情报目的训练和开发这些工具。\n 决策支持：决策优势将归于领导人最有能力利用AI模型作为决策支持工具的国家。通过将AI、数据、建模和仿真功能以及预测洞察力正确组合，模型将能够制定出各种政策选项，并向人类决策者提供分析。最近的成就，例如AI模型在战略游戏“强权外交Diplomacy”中的表现优于人类，其中涉及与对手互动和讨价还价，以及在战争游戏中展示了这一技术向量的相当大的进步，即使还有更多的工作要做。LLMs在做出操作决策的半自治系统中应扮演的角色有明显的局限性。然而，这些“专家”可能是房间里的另一个声音，提供关于政策或战争选择的实时、数据知情的观点。\n其他重要的国家安全考虑\n 信息格局：ChatGPT增加了NSCAI最终报告第1章中描述的风险，即在我们制定适当的对策之前，我们的对手转动了启用AI的信息操作的表盘。诸如ChatGPT之类的LLMs可用于以速度和规模生成独特的文本，从而避开现有的过滤系统。也许最重要的是，尽管这些技术能力在ChatGPT之前就已经存在，但随着公众的关注，更多人可能会质疑他们在社交媒体等上阅读的内容是否由AI生成。我们可能确实正在进入一个我们消费的大部分内容都是AI生成的世界，为国家和非国家行为者创造新的载体来塑造信息格局。令人欣慰的是，最近合成内容检测功能的激增，包括OpenAI发布的文本分类器和C2PA的规范标准，提高了国家安全专业人员和知情公民等人将拥有可用于帮助识别合成媒体的工具的前景。\n 数据和训练是基础：LLMs近年来取得了长足的进步，但它们不是神谕。它们最终只能与训练它们的数据一样好，并且可以产生没有事实依据的“幻觉”信息。它们的使用总是会带来相关的风险，人类必须仔细考虑。尽管如此，LLMs将继续激增，因为国家、公司和其他参与者推动了最先进的技术水平，并且人们将ChatGPT等工具集成到他们的日常生活中。任何拥有全球技术野心的国家都不会在生态系统向前发展时转身离开。\n AI对抗AI：随着AI功能被整合到国家安全设备中，我们的LLMs可能会与我们的对手进行测试，无论是在特定情况下还是为了整体信息优势。美国将需要利用私营部门的竞争优势来确保我们的LLMs是世界上最好的。此外，我们需要确保美国军方和情报界的AI工具在适当情况下能够与我们的盟友和合作伙伴的AI工具进行互操作。\n 黑匣子问题：随着我们越来越依赖AI系统，我们需要一种方法来解释和理解它们。“注意力建模attention modeling”和“思维链推理chain-of-thought reasoning”方面的进步是有前途的，但我们仍然无法“查询”AI应用程序以“讨论”其思维过程。这一领域的突破将使人类用户能够理解AI系统做出特定决定的原因，从而有助于建立对AI系统的信任。\n 网络安全和代码：LLMs将通过代码生成在基础计算机科学层面影响国家安全，对国家安全机构、企业和消费者产生影响。Copilot是针对代码生成进行微调的GPT-3版本，已经大大提高了编码准确性和生产率。类似的技术开始用于检测和防止零日攻击，并且通常可以帮助强化代码。LLMs还将为网络安全创造新的风险载体，例如降低恶意网络参与者的进入门槛。这些风险将使大规模部署有助于确保我们的网络系统安全的AI工具变得更加重要。\n 跟上技术的发展速度：无论是制定AI法规还是将AI能力整合到人类劳动力中，政府都将努力跟上技术快速发展的步伐。例如，欧盟委员会正在努力解决欧盟即将出台的AI法案将如何处理ChatGPT等系统的问题，这凸显了设置适用于最新功能的治理模型的难度。同样，工具和技术的快速变化可能会导致政府部门和机构采取保守的态度并继续使用时已经过时的系统。唯一的前进方向是让采购流程和治理框架等变得足够灵活，以便它们能够跟上AI的步伐。\n 归根结底，无论我们的领导者和组织是否倾向于“ChatGPT时刻”，LLMs和AI都将更广泛地重塑国家安全格局。今天，美国在LLMs研发的前沿具有关键的竞争优势。但长期优势将通过采用此类工具来塑造，而那些无法适应和落后的人将面临风险。\n 编辑：黄飞\n打开APP阅读更多精彩内容"
  },
  {
    "title": "Hugging Face高管警告：AI模型无法突破！电子工程专辑",
    "page_body": "Hugging Face联合创始人Thomas Wolf警告称，当前的AI模型不太可能带来重大科学突破，并指出聊天机器人存在两大问题 。\n随着科技巨头相继“砸重金”投资人工智能（AI），有关“AI泡沫”的警告声也愈发响亮。投资者们担心，AI估值过高，以及海量投资能否在预期时间内取得回报等问题。\n一位顶级科技行业高管最新警告称，OpenAI等实验室目前开发的人工智能模型不太可能带来重大的科学突破， 这又给围绕该技术的一些炒作和该领域主要人物的说法泼了一盆冷水，例如OpenAI首席执行官萨姆·奥尔特曼（Sam Altman）和Anthropic首席执行官Dario Amodei。\n这是估值45亿美元、全球最大的AI开源社区Hugging Face联合创始人Thomas Wolf的最新言论。当他谈到科学突破时，他指的是那些诺贝尔奖级别的新想法。例如，Nicolaus Copernicus提出太阳是宇宙的中心，其他行星都围绕太阳运行的理论。\nWolf解释了目前聊天机器人存在的几个问题。首先，像ChatGPT这一类产品通常会同意或认同提出问题的人的观点。他说：“回想一下，如果你向聊天机器人提出一个问题，它会告诉你这个问题有多有趣或多棒。”\n其次，支撑这些聊天机器人的模型旨在“预测句子中最有可能出现的下一个符号”或“单词”。\n然而，Wolf认为，科学家首先得具有两个关键特征。首先，取得重大突破的科学家往往持相反的观点，并质疑他人的观点。\n“科学家并不是试图预测最有可能出现的下一个单词。他会试图预测非常新奇的事情，这个事情在别人看来不太可能发生，但实际上是真的（会发生），”他补充说。\nWolf指出，他之所以会思考这个问题，是因为Amodei日前发文称，“人工智能支持的生物学和医学将使我们能够将人类生物学家在未来50-100年取得的进展压缩到5-10年”。而在Wolf看来，以目前的模型，这是不可能的。\n他指出， 这些聊天机器人和工具只可能会被用作“科学家的副驾驶”，用于研究，帮助人类产生新的想法。 在某种程度上，这种情况已经发生了。DeepMind的AlphaFold产品有助于分析蛋白质结构，该公司承诺这可以帮助科学家发现新药。\n崩盘无可避免\n另一方面，资管公司Smead Capital Management的创始人兼首席执行官、巴菲特式的价值投资者比尔•斯米德（Bill Smead）最新警告称， 由AI泡沫破裂带来的崩盘似乎已无法避免。\n他指出，人工智能热潮是由英伟达等股票飙升的“势头”推动的“泡沫”。他对此比喻称：“狗追车，人追股票。”\n自2023年初以来，英伟达的股价飙升了12倍，使这家人工智能芯片制造商的市值达到了前所未有的4.5万亿美元。Palantir的股价在同一时期飙升了28倍，这家人工智能数据分析软件制造商的估值约为4300亿美元。\n斯米德说：“我们正处于疯狂的阶段，现在是99年末。”他指的是2000年3月互联网泡沫达到顶峰之前的时期。\n“从基本观点来看，这与过去所有的重大狂热如出一辙。我们现在正艰难地与历史碰撞。”他补充说。\n斯米德还指出， 问题不在于人工智能公司是否意识到这项技术的潜在好处，而是“无论他们可能取得什么样的成功，都已经被大量过度投资了。”\n他说，“当这件事破裂时，人们只愿意以当前价格的一小部分购买人工智能股票。”斯米德还说，他“非常担心”这么多人把这么多积蓄都投在了大型科技股上，因为如果它们崩盘，金融后果可能是巨大的。"
  },
  {
    "title": "小米大模型首度曝光，华为小艺抢先交卷，手机GPT时刻近了？澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "原创 云鹏 智东西\nAI大模型，手机厂商们不得不面对的一场硬仗。\n作者 | 云鹏\n编辑 | 心缘\n手机厂商们的大模型之战，山雨欲来。\n刚刚，小米大模型突然亮相刷屏，并在C-Eval、CMMLU两个大模型测试平台中分别取得了第十名和中文向第一名的成绩，其C-Eval排名在阿里云的通义千问之前。\n▲C-Eval榜单\n要知道，C-Eval和CMMLU是目前业内公认的权威中文大模型基准测试，主要考察的就是大模型在中文领域的综合知识储备和语言理解能力。\n▲CMMLU评估榜单\n就在上周，华为的语音助手小艺也融入了自家盘古大模型的部分能力，用语音助手写个文章摘要、会议邀请邮件或者用自己的照片做个性化设计，都已经成为了现实。\n国内手机厂商们在大模型这条赛道上，颇有“不鸣则已，一鸣惊人”的架势。一个已经落地应用，一个首次亮相就刷屏霸榜。\n此前不论是自研芯片还是充电快充，手机厂商们似乎都是将“新技术”推向消费市场，让普罗大众都开始接触新技术的“排头兵”。\n在基于大模型的生成式AI浪潮中，手机厂商们势必将迎来一场新的战事。\n海外谷歌苹果都已经开始对自家的智能语音助手“动刀”，酝酿大模型的应用，国内这边，在小米大模型成绩公布之前，小米AI实验室主任王斌就已经对外讲述了小米在大模型领域的规划和进展，小米CEO雷军和小米总裁卢伟冰也多次在公开场合谈及小米大模型及相关布局。\n荣耀这边，其CEO赵明提到荣耀已经就网络大模型方面的需求跟互联网公司进行合作，而看似低调的OPPO和vivo实际上也在AI领域布局多年，分别有AI模型在一些中文基准测试中名列前茅，并与一些AI大厂有所合作。华为这边，小艺已然落地。\n虽然表面上波澜不惊，但手机厂商们的大模型之战已一触即发。各家明修栈道暗度陈仓，一场激烈的AI技术博弈好戏，或许即将上演。\n本文福利：大模型和知识图谱是相互依赖的知识处理与应用技术，知识图谱发展激发了深度学习的需求和发展，深度学习和大模型也成为知识图谱构建的基础能力，并共同面对未来多模态知识相关的挑战。推荐中国电子技术标准化研究院精品报告《知识图谱与大模型融合实践研究报告》，可在公众号聊天栏回复关键词【智东西384】获取。\n01.\n小米组建大模型团队\n荣耀OV或采用“自研+合作”模式\n手机厂商用上大模型，无非两种方式，其一，自己做大模型自己用，其二，别人做大模型我来用。\n目前来看，在华为、小米先行一步，自做自用之外，荣耀、OPPO和vivo并没有大模型相关布局的官方信息流出，其中OV两家均与其他厂商在大模型上有相关合作信息，但具体两者将采用什么方式，仍未可知。\n首先我们来看今天刷屏的小米，其实小米的智能语音助手小爱同学，在各家的语音助手中应该说是名气最高的，也是用户范围最广的，小米的各类IoT设备几乎都已经接入小爱同学，而小米的IoT生态设备数量，又是各家智能手机厂商中最多的，小米曾明确表示小米AI大模型未来可能会与小爱同学结合。\n不论是在财报电话会中，还是在一些公开采访中，小米相关高管都对于大模型有着积极表态，并详细解释了小米在大模型方面的布局和规划。\n今年4月，小米CEO雷军亲自发文称，小米对于大模型技术将坚决拥抱，次月财报电话会中，小米总裁卢伟冰宣布公司已组建AI实验室大模型团队，AI领域相关人员超过1200人。\n小米这个大模型团队的负责人是栾剑，向小米AI实验室主任王斌汇报，而王斌曾在中科院进行了20多年的NLP（自然语言处理）相关研究，于2018年加入小米。\n在接受深燃采访时候，王斌提到，他们团队的目标是通用大语言模型，参数规模在几百亿，用于训练的设备投入是几千万人民币级别。而小米大模型落地产品会采用“混合模式”，传统模型和大模型各自解决其擅长的问题。\n根据王斌所说，在ChatGPT之前，小米就做过大模型相关研究和应用，不过模型规模在几十亿级别，也并非通用大模型，主要是对话专用模型，用于人机对话。\n小米这边，高管频繁透露信息，荣耀这边，其CEO赵明也没少在采访中透露荣耀对于生成式AI以及大模型的看法。\n赵明在上海世界移动通信大会提到荣耀正在就网络大模型方面的需求跟互联网公司进行合作，当时他们已经在和有意向的公司进行接触。\n目前百度的文心一言、阿里的通义千问、讯飞的讯飞星火都是国内互联网大厂和AI大厂推出的几个三方大模型，做自研大模型对于刚刚成立三年的荣耀来说并不是最重要的事，将市场份额和出货量做上去显然更为关键，因此合作可能会是荣耀应用大模型技术的方式。\nOPPO这边，OPPO中国区总裁刘波曾在接受采访时提到，OPPO内部在思考大模型在手机端的应用。\n今年4月，阿里云宣布将与OPPO安第斯智能云联合打造OPPO大模型基础设施，基于通义千问完成大模型的持续学习、精调及前端提示工程，建设服务于OPPO终端用户的AI服务。\n从华为小艺的例子来看，将通义千问进行精调、优化，做出一个能够用于OPPO智能语音助手中的轻量版模型，是可行的。\n不过有小米相关人士透露，OPPO和vivo可能也在做自己的大模型。\n对此，我们也能从OV此前的一些动作中看出一些迹象。例如OPPO的小布助手团队此前一直在AI技术领域开展着大量研究，包括语音识别、语义理解、对话生成、知识问答系统、开放域聊天、多模态等等，而这些都是生成式AI相关的关键技术。\n小布助手团队此前对预训练模型进行过探索和落地应用，自研了一亿、三亿和十亿参数量的预训练模型OBERT，OBERT也曾一度跃居中文语言理解测评基准CLUE1.1总榜第五名、大规模知识图谱问答KgCLUE1.0排行榜第一名。\n去年OPPO未来科技大会上，小布作画功能就用到了生成式AI技术，可以通过用户描述、上传的图片创作图画作品。\nvivo这边，其AI团队在今年5月研发了面向自然语言理解任务的文本预训练模型3MP-Text，在中文语言理解测评基准CLUE榜单上，3MP-Text拿到了1亿参数模型效果排名同规模第一。\n02.\n大模型落地手机\n智能语音助手成为尝鲜排头兵\n手机厂商们这样积极踊跃地拥抱大模型，是要做什么？目前已经能够确定的一件事，就是将大模型用在各家的智能语音助手中，让大模型成为自己手机的“系统级”能力，让手机的智能化程度更高，小助手们不再“智障”。\n三星这边，正在考虑将手机、平板的默认搜索引擎从谷歌更改为微软的新必应，而新必应则支持AI聊天。谷歌在5月的I/O大会上发布了四个不同参数规模的新一代大语言模型PaLM 2，其中最小的“壁虎”大模型就可以运行在手机上。\n苹果这边，有外媒曝料称其正在为Siri开发项目代号为“Bobcat”的AI新功能，而新项目的技术框架被称为“Siri Natural Language Generation”，如果曝料属实，Siri与生成式AI技术的融合也将成为必然。\n大模型在智能手机语音助手中应用的潜力，是有目共睹的。\n对于消费者来说，从现有的智能语音助手与大模型结合的案例中我们能清晰地看到，大模型能力的融入，解决了用户养成语音助手使用习惯中最大难题之一——不够自然的对话、无法随心所欲的自然交流。\n简单来说，就是让智能语音助手从好玩、新奇变得好用，甚至成为一种“习惯动作”。大模型让智能语音助手真正能够读懂、听懂我们，其易用性的提升是极为显著的。\n在一些终端厂商看来，ChatGPT等大模型的应用，更多集中在创意类文案写作、信息整理、问答聊天、文章摘要等，但语音助手的定位是“智能私人助理”，从设备控制、个性化的咨询服务提供到提升我们日常办公的效率，智能语音助手在消费场景中的应用要更加广泛。\n与此同时，相比OpenAI的ChatGPT、谷歌的Bard这些生成式AI聊天机器人，智能语音助手会成为终端厂商的“系统级”能力，从语音对话、图文识别、服务建议到设备互联管理。\n有相关AI专家告诉智东西，系统级能力意味着系统级的入口跟操作系统结合地更加紧密，跟生态的互联也做到了系统生态底层，这种互联才是真正高效的，体验才能做到最好，这种互联远非ChatGPT与App之间一对一的SDK调用可以相比的。\n此外，不论是华为、小米、荣耀还是OV，这些厂商都已经开展了广泛的IoT业务布局，而智能语音助手已经成为串联起他们这些智能设备的关键AI服务入口，终端厂商可以通过语音助手端大模型的融入，将大模型的能力快速扩展到自家的整个软硬件生态体系当中，这对于厂商们来说也十分重要。\n03.\n把大模型塞进手机里，这事难不难？\n把大模型用在智能语音助手里，想到这件事并不难，甚至从ChatGPT出现的第一天起，所有做语音助手的公司就都想到这件事了。\n但关键是，到底怎么实现？成本与带来的回报是否成正比？GPT-4这样的大语言模型，动辄千亿级的参数量，想要用在一部整机功耗仅几瓦的手机中，技术层面的挑战要如何解决？\n关于这些问题，前文提到的华为小艺的例子中我们或许可以找到一些答案。\n总体来看，在智能语音助手上应用大模型，至少要做两件事，第一，把通用大模型优化出一个适合语音助手使用的版本，第二，在算力和功耗上把这件事跑通。\n从华为的例子来看，华为是在盘古L0大模型的基础上，对平时消费者场景中所涉及的数据进行了精调优化，构建了一个L1层对话模型，用在了小艺中。\n对这些消费者场景，厂商需要构造对应的语料数据，设计让系统能够理解和可执行的模型输出，同时还要给大模型输入可信的结构化、非结构化知识，从而让大模型能够学习到通识、逻辑关系。\nChatGPT不能帮你设置你的手机或者操控你家里的各类智能设备，但语音助手需要具备这样的能力，这也是智能语音助手非常重要的一个功能。\n所以厂商还需要通过技术优化实现大模型和系统的有效解析、高效对接，并且针对复杂场景给大模型先“培训学习”，让大模型学会这些操控技能，最后再把大模型推理成本和推理时延方面的问题解决好。\n做出适合语音助手使用的大模型版本还不够，为了解决功耗和算力问题，端云的结合也是比较要的。\n如今ChatGPT应用程序都是依赖云端算力，但真正用到语音助手里，涉及用户个人信息的使用和处理，势必需要本地化运行，但完全本地化运行又无法解决功耗和算力不足的问题。\n华为是做了不同的大模型版本，有终端侧的也有云侧的，根据任务的不同，两侧协同处理。\n作为移动芯片厂商的高通此前也一直在重点推广他们的“混合AI”理念，其实意思就是移动侧生成式AI的应用必然涉及端侧和云侧的协同。从产业各方的行动来看，这也基本上成为了业内的共识。\n当然，在智能语音助手用上大模型，绝对不是我们三言两语提到的这样简单，背后涉及诸多技术以及产业层面的挑战，从华"
  },
  {
    "title": "新基建的浪潮下，中国需要什么样的开源天团?澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "天元、MindSpore、计图、OneFlow……一连串国产开源深度学习框架的相继问世，让中国的开源AI迎来了迟到的“暖春”。\n早在2016年的时候，国内的开源AI还只有百度飞桨一股力量，不少开发者被迫在Google的TensorFlow和Facebook的PyTorch之间做选择。特别是在“断供华为”的阴影下，深度学习框架是否会被“断奶”，一度成为外界热议的焦点。在过度依赖国外开源框架造成的不确定中，“框架自由”成了国内不少开发者的夙愿。\n2020年国产的深度学习框架逐渐填补了空白，可人工智能的“开源之战”也愈演愈烈，早已上升为争夺人工智能话语权的较量。中国需要的不仅是越来越多的参与者，还需要在世界舞台上拼刀法的撒手锏。\n01 开源的自由与国界\n关于深度学习框架的价值，还要从算法开始说起。\n在人工智能的三要素中，如果说数据是燃料、算力是发动机，算法就是催化剂，直接决定着发动机对燃料的利用率，也是深度学习研究中的基本功。在深度学习的初级阶段，每位研究者都要花大量的时间写算法。\n深度学习框架的出现，大大降低了开发者入门的门槛，不再需要从零开始写一套机器学习的算法，可以直接使用框架中已有的模型进行组装，或者在已有模型的基础上训练自己的模型，让算法的规模化生产成为可能。\n打一个比方的话：优秀的深度学习框架给开发者的价值，可以让开发者在项目训练中告别手工时代，就像拖拉机之于农民，原先需要一锄头接着一锄头平整土地，自动化的拖拉机可以让一个人完成原来数十人的工作。\n其实业界对深度学习框架的价值早已形成了共识，争议在于“开源”二字。无论是Google的TensorFlow，还是Facebook的PyTorch，无不披着开源的外衣，在“开源自由”的互联网世界里，中国是否有必要推崇所谓的“国产”？\n长江商学院经济学教授、人工智能与制度研究中心主任许成钢，曾经分享过这样一组数据：中国关注人工智能开源软件包的人数在2017年秋就超过了美国，但93%的中国研究者使用的是TensorFlow等美国企业提供的开源框架。\n某种程度上说，这是一组相当恐怖的数据，芯片和开源框架分别代表了算力和算法，在芯片已经被国外卡脖子的局面下，倘若继续高度依赖国外的开源框架，算力和算法两大基石都受制于人，等同于彻底把游戏规则的制定权交到了美国手中。一旦游戏规则掌握在别人手里，中国永远都是缺少话语权的弱者。\n当然，国内仍然有不少理想主义者为开源唱赞歌，一群工程师、科学家、法学家为了开源自由对抗执法部门的故事，时常出现在国内的舆论场中。但现实终究拗不过强权，一向以开源社区自居的GitHub，屡屡传出封禁伊朗、俄罗斯等国籍开发者的消息，开源背后的国界意识也是不争的事实。\n况且中国并不缺少过度信奉开源的教训，典型的例子就是华为。在美国政府的封杀下，谷歌虽然照旧向华为开源了AOSP项目，可配套的GMS服务却把华为拒之门外，直接影响了华为手机在海外市场的销量。\n开源深度学习框架是否存在同样的隐忧？可能在枪响之前，我们永远都不知道下一个陷阱在哪里。\n02 中国开源的冰与火\n回到开源深度学习框架的话题上，在各种不确定风险的作用下，势必要燃起属于中国的星星之火。\n从浅的层面来说，深度学习框架的自立是避险的需要，连亚马逊、苹果、微软等都在自主研发深度学习框架，避免被谷歌牵制的时候，中国的人工智能企业应该有最基本的风险意识，尽可能避免芯片产业的覆舟之戒。\n进一步思考的话，创新通常不是靠砸钱、堆人就能发生的，最大的魅力还是创新的偶然性，可能发生在少数人身上。如果中国有越来越多的开发者、越开越多的企业参与到深度学习框架中来，创新的概率也将被提高。\n但同时需要理性认识的是，虽然深度学习框架关乎人工智能赛道的制高点，可本质上还是一款“软件”，它的难度并不在开发层面——伯克利、清华等一些顶级高校的博士生，往往也能开发出不错的深度学习框架。\n开源深度学习框架的重心在于产业化和长期维护，能否建立起一套完整的开源体系，进入门槛远没有想象中低。\n一个典型的例子，美国大大小小的开源深度学习框架有几十个，最终脱颖而出的却是谷歌、亚马逊、Facebook等巨头，除了自身过硬的实力外，还在于巨头们有充足资金进行技术、团队、社区等方面的建设。一些刚刚起步的创业型公司，常常因为资金、技术、人才等方面的压力而自缚手脚。\n另一个层面来看，开源深度学习框架的用户是开发者，所追求的是框架的易用性。在人们的固有认知中，习惯倾向于信赖被大众认可的事物，在情感上更偏向于有巨头背景的开源深度学习框架。即使一些初创企业可以提供有亮点的产品和服务，开发者也会出于安全、稳定等考量选择抢先培养了用户习惯的产品。\n中国开源深度学习框架的行业现状，也是如此。\n一面是行业越来越热闹，来自清华大学计算机系图形实验室的计图、国内计算机视觉领域的独角兽旷视推出的天元，再到创业公司一流科技打造的OneFlow，已然呈现出一副百花齐放的景象。与2015年前后的美国市场如出一辙，短时间中涌现出了大大小小、各种各样的开源深度学习框架。\n一面是开源生态的贫瘠，开源深度学习框架的核心价值在于生态，需要向下对接芯片，向上支撑各种应用，进而打造深度学习的标准，也就需要持续的资源投入。华为的MindSpore还处于婴儿状态，阿里、腾讯等互联网巨头没有太大的声音，深度介入上下游生态的还只有百度飞桨一家而已。\n03 抓住产业的窗口期\n然而在新基建的浪潮下，留给中国开源深度学习框架试错的时间已经不多。\n诸如智慧医疗、智慧社区、智慧金融、智慧交通等市场需求的爆发，正倒逼中国的开源AI形成一个完整的闭环，加速人工智能的产业化。确切地说，深度学习框架已经不仅仅是个开源的问题，还是一个商业化问题。\n毕竟开源的目的就是在商业化的过程中，以一个结构化的、开放的底层系统，同时兼容存量市场和新增需求，降低客户和合作伙伴的使用门槛，继而为开发者提供快速实现商业化落地的路径。\n不少人尝试对飞桨、天元、计图等开源深度学习框架进行横向对比，试图找到最有吸引力的产品。或许并不需要复杂的对比，仅仅是这些开源框架在GitHub上的星级就能一较高下，百度飞桨的星数为12.5K，计图、OneFlow和天元分别为1.6K、1.7K和2.5K，浏览量和服务端的代码仓库克隆数上，飞桨也远远领先其他国内开源架构。\n之所以将不同的开源深度学习框架进行对比，并非是为了渲染“春秋战国”的对抗气氛，而是当深度学习走向与产业结合的深水区，深度学习框架逐渐在产业智能化进程中扮演核心角色的时候，应该多探讨一下生态该怎么建设。\n中国的开源深度学习框架需要的不仅是百花齐放，在加速应用落地、摆脱外部依赖的大背景下，还应该鼓励一枝争春。\n比如重点扶持一两家开源深度学习框架，推动上下游产业的联动，就像百度飞桨与华为麒麟芯片的深度合作，尝试打造深度学习的中国标准；\n再比如推动不同开源框架的兼容，一些创业公司和大学实验室不缺少天才程序员，也适合一些创新性的探索，而百度、华为等科技巨头则擅长开源生态的建设。至少从PyTorch引入TensorFlow的可视化来看，谷歌和Facebook已经开始了合作。\n何况留待中国开源AI的核心挑战在于能否抓住产业化的窗口期，不同平台间合作的契机远大于商业上的冲突。\n04 写在最后\n百度CTO王海峰曾经这样形容深度学习框架的价值：\n在智能时代，深度学习框架起到承上启下的作用，下接芯片和大型计算机系统，上承各种业务模型与行业应用，是“智能时代的操作系统”。\n假如中国无法在智能时代打造出属于自己的“操作系统”，被Windows、安卓卡脖子的故事将再次上演。想要在这场全球性的AI争夺战中胜出，中国企业势必要在基础和关键技术上下苦功，避免在沙滩上起高楼。\n幸运的是，在无数有识之士的呼声奔走下，国内也有了自己的开源深度学习框架“天团”，既有百度飞桨这样在技术和应用上全面领先的C位担当，也有计图、天元、MindSpore、OneFlow等新兴势力。\n只是就目前来看，从开源深度学习框架的遍地开花，到整个开源AI生态的持续繁荣，再到中国人工智能应用的行稳致远，还需要不同领域开发者的协同努力，以及在政策层面进行适当的引导。"
  },
  {
    "title": "生成式AI落地的经济学：云计算厂商的成本与性能对比-今日头条",
    "page_body": "开篇\n生成式 AI 已从技术热点转变为企业竞争的核心驱动力。但随之而来的，是计算成本的持续增长与资源压力的不断加大。对大多数中国企业来说，“能够负担” 比 “知晓原理” 更为重要。如何在性能、成本与合规之间达成平衡，正成为企业部署生成式 AI 时面临的关键难题。\n从 LLM 训练到推理环节，算力与存储的开销是企业的主要经济负担。无论是自主构建模型，还是使用公有云服务，若缺乏科学的架构设计与计费机制，AI 项目往往会因成本失控而被迫终止。为此，各大云厂商纷纷推出具有 “成本效益” 的生成式 AI 解决方案，希望在企业级应用场景中开辟出可持续的实施路径。\n本文将从第三方角度出发，对比中国市场主流云计算平台在生成式 AI 部署上的性价比区别，并重点分析 AWS 如何依靠专用芯片、弹性架构与多模型支持，在确保性能的同时显著减少企业成本，为生成式 AI 落地提供一条经济实惠、可扩展且合规的新途径。\n一、AWS 方案：高性价比的企业级生成式 AI 架构\n在生成式 AI 落地的成本考量中，AWS 凭借底层硬件创新与多模型生态，成为兼顾性能与预算的代表性平台。其核心优势在于 —— 通过架构优化与算力效率提升，帮助企业实现成本可控。\n首先，AWS 自研的 Inferentia 与 Trainium 芯片，从底层提升推理效率，针对大语言模型（LLM）的计算过程进行优化，使得每次推理请求的能耗与费用较传统 GPU 方案降低了高达 40%。这意味着企业无需增加算力投入，就能获得更高的吞吐量和更低的延迟，从而降低总体拥有成本（TCO）。\n其次，Amazon Bedrock 允许企业 “即开即用” 地访问多家顶级模型（如 Claude、Llama 3、AI21 Jurassic、Titan Text 等），实现 “多模型共用一个平台”。企业按调用次数付费，无需购买固定算力资源，也无需承担自建模型的维护费用。这种 API 级服务模式，不仅让中小企业也能负担生成式 AI 应用，还避免了算力浪费与资源闲置。\n此外，Amazon SageMaker 提供完整的训练与推理流程，支持 Spot 实例与自动伸缩功能。企业可在算力空闲时利用低价资源进行模型微调，在业务高峰时自动扩容，实现真正的 “弹性成本管理”。结合 AWS 的成本监控工具（Cost Explorer 与 Compute Optimizer），企业能够实时评估每个模型运行的成本占比，进而做出精细化决策。\n最后，在合规层面，AWS 在华由光环新网与西云数据合规运营，为企业提供符合中国网络安全与数据安全法规的本地化环境。通过这一体系，企业既能运用全球领先的 AI 技术，又能在合规范围内实现高性价比的智能部署。\n总结来看，AWS 的优势在于：以更低的算力成本支撑更丰富的 AI 能力。对于注重长期投入产出比的中国企业而言，这种 “结构性降本” 的能力，是生成式 AI 落地过程中最具实际价值的竞争力。\n二、其他云厂商方案对比：成本与生态的不同取向\n中国市场的云计算生态呈现多元化且活跃的态势，各大厂商在生成式 AI 领域均推出了自有解决方案。它们在中文语义处理、行业化适配能力上各有亮点，但在成本可控性与生态开放度方面，与 AWS 仍存在结构性差异。\n华为云 —— 盘古系列 AI 套件\n华为云的盘古 α 系列以自研算力（昇腾）为核心，构建了从芯片、框架到模型的完整闭环体系。在政企、科研及工业制造领域，该模型在中文语义理解、知识图谱构建和智能问答方面表现突出。\n但该方案的局限性在于开放性：盘古模型的接口及二次开发权限相对有限，外部企业进行定制需承担较高成本。加之对硬件依赖度高、部署灵活性不足，导致整体拥有成本（TCO）偏高，更适合对性能与数据主权要求极高的大型国企或科研机构。\n阿里云 —— 通义千问与 PAI 平台\n阿里云的通义 Qwen 系列在中文语言流畅度与上下文理解能力上名列前茅，尤其适用于内容生成与客服场景。配合 PAI 平台，可支持模型训练、部署与可视化管理。\n然而，其成本结构较为复杂：部分 API 按 Token 计费，部分计算资源需购买预留实例；跨云兼容性较低，使得中小企业在迁移或混合云场景中成本增加。若缺乏精细化的资源调度，成本优势难以长期保持。\n百度智能云 —— 文心大模型与千帆平台\n文心 Ernie 4.0 聚焦于搜索、问答、代码生成等中文场景，具备较强的知识问答能力。千帆平台提供企业级接入服务与行业模板，对互联网、金融、教育等行业用户较为友好。\n但由于其模型部署与计费高度依赖百度生态，缺乏跨平台扩展能力，且在大规模应用时推理成本较高，不利于企业开展跨云或多模型整合工作。\n综合比较：AWS 方案的差异化优势\n与上述平台相比，AWS 的最大不同之处在于 “多模型统一管理 + 弹性成本架构 + 本地合规支持” 的三重叠加：\n企业可在 Bedrock 上访问多个国际顶级模型，而非受限于单一自研体系；\n通过 Inferentia/Trainium 芯片降低推理单价，实现行业领先的成本效益比；\n结合 SageMaker 的私有化训练能力与中国本地合规架构，兼顾安全性与灵活性。\n对于多数希望 “以最少预算实现 AI 转型” 的企业而言，AWS 提供的是一条兼具全球能力与本地落地可行性的路径：以云服务的价格，获取企业级 AI 的产出。\n三、企业成本优化策略：从算力到架构的系统降本\n生成式 AI 的落地成本，并非仅由模型价格决定，而是由 “算力 + 存储 + 调用 + 架构管理” 构成的综合体系。许多企业在试点阶段因缺乏系统化的成本策略，导致支出远超预算，ROI 难以衡量。以下四个方向，是企业部署生成式 AI 时普遍可执行的降本路径。\n算力优化：选对芯片，降本 40% 不是幻想\n生成式 AI 的最大成本来自模型推理阶段。相较于传统 GPU 方案，AWS 的 Inferentia 和 Trainium 专用芯片在推理性能与能耗比上更具优势，平均可节省 30–40% 的计算费用。企业无需为大规模 GPU 集群投入固定成本，只需通过 Bedrock 按调用计费，按需扩展推理任务，大幅提升成本利用率。\n此外，AWS 还支持 AutoScaling 与 Batch Inference 机制，在请求高峰时自动扩容，低峰时释放算力，实现真正意义上的 “随用随省”。\n弹性计费：从固定预算到动态成本结构\n传统云服务多采用固定租用模式，即便模型闲置，企业仍需持续支付算力费用。而 Amazon Bedrock 与 SageMaker 均支持按调用计费（Pay-per-use）与 Spot 实例计费。\n企业可在闲置时段以 7 折以下的价格租用 Spot 算力进行模型微调或实验性训练，并在业务峰值时按需扩容。这种动态计费方式让预算结构更灵活，避免了 “资源闲置” 造成的资金浪费。\n模型与数据共用：避免重复部署与训练\n不少企业在项目间重复训练模型或复制存储数据，导致成本叠加。AWS 的 Bedrock 与 SageMaker Notebook 支持模型版本管理与参数复用，同一数据集可被多个 Agent 或业务线调用，从而减少 30% 以上的数据存储与训练成本。\n同时，统一的 API 接口让企业能在 Claude、Llama 3 与 Titan 等模型间快速切换，根据任务场景匹配性价比最优的模型。\n混合云与私有部署：兼顾安全与开销\n在金融、制造等对安全性要求较高的行业，完全上云并非最佳选择。AWS 通过 SageMaker 支持 VPC 内私有部署，还可将部分推理任务保留在本地，降低跨境传输成本。\n企业可构建 “训练在云端、推理在本地” 的混合架构，在合规要求与成本控制间找到平衡。这种结构尤其适合对数据敏感的行业，既能保障数据安全，又能最大化算力利用率。\n结论：成本优化是一种体系化能力\n在生成式 AI 时代，降本已不再是单一的采购问题，而是架构层面的系统设计。\nAWS 凭借其在算力、弹性、模型复用与混合部署方面的系统能力，帮助企业从 “成本管理” 转向 “成本创新”。\n换句话说，当其他平台还在比拼模型性能时，AWS 已在助力企业实现性能与成本的双赢。\n四、中国市场的特殊考量与未来趋势\n中国企业在推进生成式 AI 部署时，面临的挑战不仅体现在技术实力和资金投入上，还涉及合规准则、数据主权界定、跨境业务运作以及生态适配等多个层面。相较于其他地区，中国市场的生成式 AI 实施更像是一场 “多维度协调的工程”：既要确保性能卓越，又要保持价格平稳，同时必须达成合法、安全、可管控的目标。\n合规准则与本地化运营成为 AI 落地的前置要素\n在中国，生成式 AI 应用需遵守《生成式人工智能服务管理暂行办法》等监管要求，企业必须保障数据来源合规、输出内容可管、模型备案可查。\nAWS 在中国通过光环新网与西云数据开展独立运营，所有计算流程与数据存储均在国内完成，完全符合国家网络安全和数据安全相关法律规定。\n对于金融、制造、教育等行业，这种以合规为优先的云基础架构，有效规避了企业后续整改与迁移产生的高额成本。\n此外，AWS 支持多区域架构规划，助力企业在合规框架内实现跨区域部署与备份，既满足监管需求，又保留了全球协作的能力。\n成本结构的重点转移：从一次性投入到持续改进\nAI 建设初期，“大投入获取大模型” 是典型特征，而当前，企业更看重具备可持续性的成本架构。\nAWS 的弹性计费模式、专用推理芯片以及多模型管理能力，让企业能够逐步迭代应用，无需进行一次性大额投入。\n比如，某制造业客户可先在 Bedrock 上调用 Claude 模型开展文本生成试点，之后在 SageMaker 中对 Llama 3 进行优化以适配行业语料，整个过程按实际需求计费，且规模可随时调整。\n这种 “先试用再扩展、以应用推动成本节约” 的模式，正成为越来越多中国企业的主流选择。\n多模型与多智能体发展方向：从单一 AI 到 AI 系统\n未来，企业将不再依赖单个模型，而是依靠多个 AI 智能体协同完成复杂任务。\nAWS 的 Bedrock 生态天生支持多模型接入，企业可在同一平台上让 Claude 负责摘要生成、Llama 负责语义理解、Titan 负责文案优化，搭建起 Multi-Agent 协作体系。\n这种架构不仅增强了业务灵活性，还能让企业根据任务类型灵活切换不同模型，从而在性能与成本之间找到最优平衡。\n出海拓展与全球布局成为增长引擎\n越来越多的中国企业将生成式 AI 作为推动出海业务增长的核心动力。\nAWS 在全球 30 多个地理区域提供统一的 API 与模型服务，使企业能在国内采用同一技术栈测试，在海外复制部署方案。\n在语言支持、合规要求及基础设施建设方面，这种一致性大幅降低了企业出海过程中的技术阻力与重复投资。\n从长远来看，选择兼具全球服务能力与中国本地合规运营的云平台，是企业控制成本、实现持续增长的关键策略。\n小节结语\n生成式 AI 领域的竞争已不再是较量 “谁最强大”，而是比拼 “谁更划算、更稳健”。\n当模型性能趋同、算法公开化、生态融合后，真正"
  },
  {
    "title": "AIUI开放平台",
    "page_body": "AIUI平台助手\n 尊敬的开发者，您好。我是科大讯飞AIUI平台助手，您可以通过语音或者文本同我交流。 \n热门问题\n换一批\n联系我们\n邮箱\naiui_support@iflytek.com\n意见反馈\n您的每一条建议，我们都认真对待\n满意度调查\n为提高质量和服务，诚邀您参与调研\n产品动态\nAIUI平台开放交互大模型的体验 AIUI平台新推出AR眼镜交互解决方案 AIUI平台多模态语音增强方案上线\n平台能力\n全链路人机交互能力硬件模组快速接入支持业务自由定制\n通用能力\n 多模态交互  HOT 视频输入、极速响应  虚拟人交互  HOT 实时的对话动作互动  虚拟人形象资产  丰富形象、个性化定制  免唤醒语音交互  适用无网、弱网环境  离线语音交互  \n硬件模组\n 多模态交互开发套件  NEW 高算力 效果优 NEW  大模型离线交互套件  \n 技能商店  覆盖常用场景及内容资源\n智能硬件解决方案\n 提供纯软接入，协助适配算法，有效提升智能硬件语音交互体验。\n 提供AIUI麦克风阵列、声卡、降噪板、语音交互评估版和多模态\n 交互盒子等开发套件，让硬件接入更简单。 \n合作咨询\nAI赋能\n 语音技能涵盖生活、娱乐、游戏、办公、搜索导航、 AIOT控制，一键配置，让你的产品生而智能 \n闹钟\n成语词典\n百科问答\n古诗词\n闲聊\n免唤醒\n提供低功耗唤醒，多\n模态唤醒及免唤醒交互\n远距离拾音\n支持1-3-5米远距离拾音\n定向拾音\n支持全向或指定方向拾音\n声纹识别\n支持成人、儿\n童、老人音质辨别\n高效降噪\n提供多领域、\n多场景降噪引擎\n人脸识别\n提供人脸检测、活体\n检测、人脸跟踪等能力\n手势识别\n支持20+常用动\n态手势动作识别\n唇形识别\n支持唇形检测、唇形识别\nOCR\n用与各种场景图像文\n字识别，支持多个语种\n手指检测\n检测出手指在图\n像上的位置坐标\n多发音人\n100+发音人，男女\n老少，风格随心选\n方言语种\n支持19个语种，11种方\n言，中英混合自然合成\n动态调参\n随心调节语调/语速/音量\n等参数，满足复杂场景需求\n定制音库\n赋予产品声音形象，定制发音\n人，为产品量身打造专属音库\n个性化变声\n将源发音人的声音转\n换为目标发音人音色\n 1500万首曲库，10余个视频品牌，有声内容1200万+小时，100余家内容提供方 \n喜马拉雅听说\n酷我音乐\n新浪新闻\n爱奇艺\n哔哩哔哩\n 语音技能涵盖生活、娱乐、游戏、办公、搜索导航、 AIOT控制，一键配置，让你的产品生而智能 \n闹钟\n成语词典\n百科问答\n古诗词\n闲聊\n免唤醒\n提供低功耗唤醒，多\n模态唤醒及免唤醒交互\n远距离拾音\n支持1-3-5米远距离拾音\n定向拾音\n支持全向或指定方向拾音\n声纹识别\n支持成人、儿\n童、老人音质辨别\n高效降噪\n提供多领域、\n多场景降噪引擎\n解决方案\n儿童教育产品解决方案\n 利用讯飞的语音技术、手指检测、绘本检测引擎、口语评测等多项AI能力，让机器人快速实现语音交互及教学能力 \n穿戴式设备解决方案\n 提供系统级的语音助手，支持免唤醒交互，让产品轻松实现语音打电话，语音导航，语音查天气等多场景语音交互 \n服务机器人解决方案\n 为机器人厂家提供从前端拾音、语音交互，图像识别全链路、全场景软硬件一体化AI能力，基于高效降噪算法及多模态技术，让机器人在公共场所下轻松完成人机交互 \n健身按摩设备解决方案\n 提供离线命令词识别服务，支持200条语法，零流量实时响应，满足不同终端快速稳定的本地化语音服务 \n方案优势\n免唤醒交互\n无需说出唤醒词，直接交互打造自然流畅的语音交互体验\n多模态融合\n 支持图像、手势、声纹等多模态技术与语音的融合，满足不同终端、不同场景应用需求 \n多种接入方式\n 提供Android、iOS、Linux、WebAPI、软硬件一体化产品等接入方式，助力开发者以最小的成本快速接入AI能力 \n一对一指导\n 针对智能硬件前端声学设计、语音交互设计、系统能力集成、技能开发等提供专业的技术支持，一对一贴身指导"
  }
]