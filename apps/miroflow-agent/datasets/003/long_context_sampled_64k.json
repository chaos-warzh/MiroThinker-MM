[
  {
    "title": "多模态标注：跨模态智能的数据基石与技术实践​-网易伏羲",
    "page_body": "多模态标注：跨模态智能的数据基石与技术实践​ ​\n多模态标注作为人工智能数据工程的核心环节，正成为推动跨模态智能发展的关键支撑。这项技术通过同步处理图像、文本、音频、视频等多种类型的数据，建立模态间的语义关联与对齐关系，为机器学习模型提供丰富的跨模态训练数据。随着多模态大模型与跨模态应用的快速发展，多模态标注的重要性日益凸显，其质量直接决定了模型对复杂现实世界的理解能力。本文将系统解析多模态标注的技术原理、应用场景、实施策略与发展趋势。\n​ ​一、多模态标注的核心价值与体系架构​ ​\n多模态标注旨在解决异构数据间的语义对齐问题，其核心价值体现在三方面：一是通过跨模态关联增强模型的环境理解能力，使机器能够像人类一样综合多种信息进行决策；二是提升模型的数据利用效率，充分利用不同模态数据的互补性；三是推动新兴跨模态应用的发展，如视觉问答、音频描述、多模态搜索等。多模态标注体系采用分层架构，包括数据层、标注层和应用层。数据层负责多模态数据的采集与预处理，确保数据质量与同步性；标注层通过人工与智能结合的方式实现跨模态语义关联；应用层将标注数据用于模型训练与优化，形成闭环迭代机制。\n​ ​二、技术原理与标注方法​ ​\n多模态标注的技术核心是建立模态间的语义映射关系。时序对齐是基础挑战，尤其针对音频-视频数据，需精确到帧级别的同步，常用动态时间规整算法实现音画同步。空间对齐针对视觉-文本数据，通过目标检测与语义分割确定图像区域与文本描述的对应关系，常用边界框标注与图像描述生成。语义对齐是更高层次的要求，需要理解不同模态数据的深层语义关联，如将“欢快音乐”与“阳光海滩场景”建立情感层面的对应。\n主流标注方法包括并行标注、序列标注和交互标注。并行标注同时处理多种模态数据，保证标注过程的一致性；序列标注按模态顺序进行，后一阶段标注依赖前一阶段结果；交互标注采用多轮迭代方式，逐步细化标注质量。质量评估采用多维度指标，包括对齐精度、语义一致性和标注完整性，确保标注数据满足模型训练要求。\n​ ​三、应用场景与行业实践​ ​\n智能医疗是多模态标注的重要应用领域。医学影像与诊断报告的跨模态标注帮助模型理解影像特征与文本描述的关联，如CT影像中的结节与报告中的“边缘模糊”描述对应。病理切片与临床数据的多模态分析助力精准诊断，通过标注建立细胞形态与疾病分型的映射关系。手术视频与器械音频的同步标注用于智能手术辅助系统，实时识别手术步骤与器械使用情况。\n智能交通领域依赖多模态标注提升环境感知能力。车载摄像头、激光雷达与GPS数据的融合标注构建高精度环境模型，标注数据包括车辆轨迹、障碍物类型与道路拓扑关系。驾驶行为分析通过标注驾驶员视频、车辆数据与路况信息，识别疲劳驾驶与危险操作。交通监控系统中，视频流与音频事件的关联标注用于事故检测与应急响应。\n教育科技应用多模态标注增强学习体验。教学视频与讲稿文本的同步标注实现智能知识点提取，学生可通过多模态搜索快速定位内容。在线教育平台利用语音-手势-课件内容的关联标注，构建沉浸式互动学习环境。学习行为分析通过标注学生视频、作业文本与测评数据，提供个性化学习建议。\n​ ​四、标注工具与平台支持​ ​\n专业多模态标注平台需支持复杂的数据管理与协同功能。数据管理模块处理多模态数据的存储、版本控制与检索，支持常见格式如图像（JPG、PNG）、视频（MP4、AVI）、音频（WAV、MP3）和文本（TXT、JSON）。标注工具提供多视图同步编辑能力，如视频帧与音频波形的联动标注，图像区域与文本标签的关联标注。协同标注功能支持多人同时标注同一项目，通过权限管理与工作流引擎确保标注效率。\n智能辅助工具大幅提升标注效率。预标注算法利用已有模型生成初始标注结果，标注员主要进行修正与验证。自动对齐工具通过特征匹配实现跨模态数据的初步对齐，减少人工操作。质量检查工具自动检测标注矛盾与错误，如时空不对齐、语义不一致等问题。数据分析仪表盘可视化标注进度、质量指标与一致性统计，帮助项目管理。\n​ ​五、技术挑战与解决方案​ ​\n模态差异是多模态标注的首要挑战。不同模态的数据特征、采样率与表示形式存在显著差异，解决方案包括统一表征学习与跨模态编码，将异构数据映射到共同语义空间。标注一致性难以保证，特别是多人协作项目，需通过标准化标注规范、详细指南与定期培训统一标注标准。计算复杂度高，处理多模态数据需要大量存储与计算资源，采用分布式计算与增量处理技术降低开销。\n语义鸿沟问题体现在不同模态间的语义表达差异，如图像中的“红色圆形”与文本中的“停止标志”的对应关系。解决方案包括构建多模态知识图谱，建立细粒度语义关联。标注成本高昂是多模态标注的普遍问题，特别是需要领域专家的场景，主动学习与半自动标注可减少人工标注量。时效性要求高的应用需要快速标注流程，流式标注与实时质检技术可加速标注过程。\n​ ​六、标准化与质量控制​ ​\n多模态标注标准化是保障数据质量的关键。数据格式标准统一不同模态数据的存储与交换格式，如采用JSON-LD表示跨模态关联。标注规范明确定义标签体系、对齐要求与质量指标，确保不同项目的标注结果可比。接口标准规范标注工具与平台的数据输入输出格式，促进工具 interoperability。评估标准建立多模态标注的质量度量体系，包括对齐精度、语义一致性与时序同步性等维度。\n质量控制需贯穿标注全流程。前期准备阶段需制定详细的标注指南与样例，进行标注人员培训。标注实施阶段采用多人独立标注与交叉验证，定期进行一致性检查。后期验收阶段通过抽样审计与专家复核确保标注质量。持续改进阶段收集模型反馈，修正标注难点与模糊案例，形成闭环优化。\n​ ​七、未来发展趋势​ ​\n多模态标注正向智能化、自动化方向发展。智能标注工具集成更强大的预标注模型，减少人工操作；自动对齐算法提升跨模态数据的匹配精度；智能质检工具实时检测标注错误。实时标注能力增强，支持流式数据标注与在线学习，满足实时应用需求。联邦标注利用分布式数据资源，在保护隐私的前提下实现多机构协同标注。\n跨模态大模型推动标注范式变革。基础大模型通过少量样本学习新任务，降低对标注数据的依赖；生成式模型合成高质量标注数据，解决数据稀缺问题；自监督学习利用未标注数据预训练，减少人工标注量。标准化与开放生态促进发展，行业标准统一数据格式与接口；开源工具降低技术使用门槛；开放数据集推动学术与工业界合作。\n​ ​八、行业影响与价值​ ​\n多模态标注推动人工智能向更高水平发展。训练数据质量提升直接提高模型性能，使多模态模型更准确理解复杂场景；新兴应用场景得以实现，如跨模态检索、多模态生成等；研发效率提高，减少数据准备时间与成本。产业升级方面，制造业利用多模态数据优化生产流程，实现智能质检与预测性维护；医疗行业借助多模态分析提升诊断准确性，推动精准医疗发展；教育领域通过多模态交互改善学习效果，实现个性化教学。\n技术普惠价值显著，多模态技术使AI系统更贴近人类自然交互方式，降低使用门槛；跨模态能力帮助特殊群体（如视障人士）更好地获取信息；开放工具与数据集促进技术民主化，使更多组织能够开发多模态应用。这些影响推动多模态标注成为人工智能发展的重要基础设施，为构建更智能、更人性化的AI系统奠定基础。\n多模态标注作为连接原始数据与智能应用的关键桥梁，其技术进步与应用深化正推动人工智能向多模态理解迈进。通过持续的技术创新与生态建设，多模态标注将为人工智能发展提供更丰富、更高质量的数据燃料，赋能更多跨模态应用场景，最终实现机器对现实世界的深度理解与智能交互。"
  },
  {
    "title": "当见未萌｜高度警惕AGI挑战，构建新型人机和谐关系",
    "page_body": "·大规模生成式语言模型为代表的通用人工智能技术，以生成式AI为主要形态，具备情景化生成能力，形成了知识、能力、价值三个阶段的智能炼就路径。随着相关技术的发展，机器的智能水平快速提升，将带来人机边界模糊及与其相关的一系列社会问题。\n·AGI的发展路径具有“填鸭灌输”式学习、“先通再专”等特点，在一定程度上颠覆了人类对机器智能实现路径的传统认识，倒逼人类在世界建模、知识获取、自我认知等层面进行反思。人类需高度警醒AGI带来的挑战，并积极抓住其带来的机遇，推动构建新型的人机和谐关系。\n两千多年前，苏格拉底说“认识你自己”，今天在AGI技术发展的倒逼下，人类需要“重新认识你自己”。\n自2022年12月ChatGPT发布以来，大规模生成式预训练语言模型（Generative Language Model）在学术界与工业界引起轩然大波，带动了一系列通用人工智能技术（AGI: Artificial General Intelligence）的快速发展，包括图文生成模型，如Midjourney的高精度、高度仿真的图文生成；具身多模态语言模型，比如谷歌（Google）公司连续推出PaLM-E以及PaLM 2等。AGI已经从模拟人类大脑的思维能力（以语言模型为代表），快速演进至“操控身体”的具身模型（以具身大模型为代表）。AGI全面侵袭从艺术创作到代码生成、从问题求解到科学发现、从问答聊天到辅助决策等人类智能的各个领地，人类智能所能涉及的领域几乎都有AGI的踪迹。一场由AGI带动的新一轮信息技术革命已然席卷而至。人类迎来一场有关“智能”本身的技术革命。\n作为一种先进的生产力，AGI既给全社会带来令人兴奋的机遇，也带来令人担忧的挑战。兴奋与担忧归根结底是源于我们对AGI的理解还远远跟不上其发展速度。具体而言，人类对于AGI技术原理、智能形态、能力上限的思考，对其对社会与个人影响的评估，明显滞后于AGI的发展速度。可以说，快速发展的AGI与人类对其认知的显著滞后构成了一对鲜明的矛盾，把握这一矛盾是理解当前AGI发展规律与其产生的社会影响的关键。也正是基于对上述矛盾的认识，不少科学家与AI企业领袖发出了暂停巨型大模型实验的呼声，呼吁加快安全可证明的AI系统的研制。\n诚然，理解AGI十分困难。AGI这个术语中的三个单词，分别从不同角度表达了理解AGI面临的挑战。从其核心词“智能（Intelligence）”来看，一直以来关于什么是智能，就存在不同的观点，比如传统计算机科学认为，“获取以及应用知识与技能”的能力是智能，但需思考这个定义是否仍然适用于今天以大规模生成式语言模型为代表的AGI。“通用（General）”一词加剧了理解AGI的困难。相对于传统的面向特定（specific）功能的AI，AGI旨在模拟人类的心智能力，人类智能的独特之处鲜明地体现在其能够针对不同环境作出适应性调整，能够胜任不同类型甚至从未见过的任务。专用AI与通用AI存在怎样的联系与区别，是先实现通用AI还是先实现专用AI？General一词将会引发很多诸如此类的思考。“人工的（Artificial）”一词则道出了AGI人工创造物的本质，而非自发从自然环境中进化而成的智能。这自然就提出了工具智能与自然智能的异同等一系列问题。\n尽管挑战重重，本文仍然尝试针对AGI的某些方面展开分析。本文聚焦于生成式人工智能，特别是大规模生成式语言模型为代表的通用人工智能技术。本文所谈及的“智能”，不局限于人类智能，也包括机器智能，将以机器智能与人类智能作为彼此的参照，进行对比分析。本文将对由生成式语言模型发展而引发的“智能”的内涵、“智能”的演进路径等问题进行详细分析，并在这一基础上反思人类智能的诸多方面，包括创造性、世界建模、知识获取、自我认知等。笔者相信本文的思考一方面可以消除人们对于机器智能快速进步的担忧，另一方面也能为机器智能的进一步发展扫除障碍，有助于建立新型的人机和谐关系。在此需要说明的是，本文的部分思考与结论超出了当前的工程实践所能检验的范围，仍需要付诸严格论证与实践检验。\n什么是智能？ChatGPT何以成功？\n生成式VS判别式 。ChatGPT是生成式人工智能的代表。生成式AI在文本生成、文图生成、图像生成等领域取得了较好的效果。传统的人工智能多属于判别式人工智能。为何是生成式AI而非判别式AI成为AGI的主要形态？这是一个值得深思的问题。判别式AI，通过标注数据的训练，引导模型习得正确给出问题答案的能力。生成式AI，往往针对无标注数据设计基于遮蔽内容还原的自监督学习任务进行训练，引导模型生成符合上下文语境的内容。生成式模型不仅具备生成结果的能力，也能够生成过程与解释。所以生成任务可以视作比判别任务更具智力挑战性的任务，能够有效引导模型习得高水平智能。具体而言，对于判断题，判别式AI只需给出对或错的答案，即便随机猜测，仍然有百分之五十蒙对的概率。但是，生成式AI不仅需要生成答案，还可能需要同时生成解题过程，这就很难蒙混过关。所以相对于判别而言，生成可以说是更加接近智能本质的一类任务。\n智能与情景化生成能力。 智能的本质是什么？大模型的发展给人类对这一问题的思考带来了很多新的启发。大模型的智能本质上是情景化生成（Contextualized Generation）能力，也就是根据上下文提示（Prompt）生成相关文本的能力。所以大模型的应用效果在一定程度上取决于提示有效与否。如果我们能够给出一个有效且合理的提示，那么ChatGPT这类大模型往往能够生成令人满意的答案。这种情景化生成能力（“提示＋生成”的能力）不仅适用于文本，也广泛适用于图像、语音、蛋白质序列等各种不同类型的复杂数据。不同的数据上下文不同，例如对于图片而言，其上下文是周边图像。大模型的情景化生成能力是通过训练阶段的上下文学习（In-context learning）而形成的。从数学本质来讲，大模型在训练阶段习得了Token或者语料基本单元之间的联合概率分布。情景化生成可以视作条件概率估算，即给定上下文或提示（也就是给出证据），根据联合分布推断出现剩余文本的概率。\n传统对于智能的理解多少都与“知识”有关（如把智能定义为“知识的发现和应用能力”），或与人有关（如把智能定义为“像人一样思考和行为的能力”），其本质还是以人类为中心，从认识论视角理解智能。大模型所呈现出的这种情景化生成能力，则无关乎“知识”，“知识”说到底是人类为了理解世界所做出的人为发明。世界的存在不依赖“知识”，不依赖人类，情景化生成摆脱了人类所定义的“知识”，回归世界本身——只要能合理生成这个世界就是智能。智能被还原为一种生成能力，这种智能可以不以人类为中心，也可以不依赖人类的文明，这是AGI给我们带来的重要启示。\n智能的分析与还原。 大模型训练与优化过程能够为我们更好地理解智能的形成过程提供有益启发。通用大模型的“出炉”基本上要经历三个阶段：第一个阶段是底座大模型的训练；第二个阶段是面向任务的指令学习，也就是所谓的指令微调；第三个阶段是价值对齐。第一个阶段底座大模型的训练本质上是让大模型习得语料或者数据所蕴含的知识。但是这里的知识是一种参数化、概率化的知识（本质上建模了语料中词汇之间的一种联合分布），使得情境化生成成为可能。因此，第一阶段的本质是知识获取（或者说知识习得），第二阶段指令学习旨在让大模型习得完成任务的能力，最后一个阶段则是价值观念的习得。\n大模型的智能被分解为知识、能力与价值三个阶段，这是个值得关注的特性。知识是能力与价值的基础，所以底座模型的“炼制”尤为关键。ChatGPT经历了2018年初版GPT-1到2022年GPT-3.5近四年的训练与优化。大模型的知识底座越深厚、越广博，后续能够习得的技能就越复杂、越多样，价值判断就越准确、价值对齐就越敏捷。大模型将智能的三个核心要素相互剥离，而人类的知识、能力与价值习得，往往是杂揉在一起的。我们很难界定小学课本中的某篇文章是在传授知识、训练技能亦或是在塑造价值。大模型的这种分离式的智能发展，可以类比于人类社会的高等教育。人类社会的本科教育旨在培养学习能力以获取知识，硕士教育旨在培养解题能力以解决问题，博士教育则旨在培养价值判断能力以发现问题。\n知识、能力和价值相剥离对于未来智能系统架构、建立新型的人机协作关系、设计人机混合的智能系统架构均有着积极的启发意义。随着机器智能的逐步发展，人类相对于机器而言所擅长的事物将会逐渐减少。但是，在某些特定场景仍存在一些人类介入的空间。未来人机混合系统发展的关键仍是回答什么工作最值得由人来完成。看似完整的任务只有经过分解，才能拆解出人机各自擅长与适合的子任务。例如，将知识和能力剥离对于保护私域知识极具价值：大模型负责语言理解等核心任务，而机密的数据与知识仍然交由传统的数据库或者知识库来管理。这样的系统架构，既充分利用了大模型的核心能力，又充分兼顾了知识私密性。\n智能测试与人机区分。 通用人工智能技术的发展显著提升了机器的智能水平，特别是语言理解水平，机器在文本处理、语言理解等相关任务中已达到普通人类甚至语言专家的水平。而随之而来的一个十分关键的问题是：人机边界日益模糊。我们已经很难仅仅通过几轮对话去判断窗口背后与你交流的是人还是机器。换言之，传统的图灵测试已经难以胜任人机区分的使命。使用过ChatGPT的人都深有体会，ChatGPT最擅长的就是聊天，即便与其长时间聊天，我们可能都不会觉得无趣。\n人机边界的模糊会带来很多社会问题。首先，普通民众，尤其是青少年，可能出于对技术的信任而沉溺于ChatGPT类的对话模型中。当ChatGPT日益智能，我们习惯了向其提问，习惯了接受它的答案，久而久之，人类赖以发展的质疑精神就会逐步丧失。在日益强大的AGI面前，如何避免人的精神本质的退化？这些问题需要我们严肃思考并回答。其次，当人机真假难辨，虚假信息泛滥，欺诈将会层出不穷。最近越来越多犯罪分子已经通过AI换脸、AI视频生成，成功实施了多起欺诈案件。如何治理由人机边界模糊带来的社会性欺骗将成为一个十分重要的AI治理问题。最后，还值得注意的是验证码，这一我们在日常生活中广泛使用，却很快会变成问题的应用。验证码是我们进行人机区分的利器，但是随着AGI的发展，尤其是在其对于各类工具的操控能力日益增强之后，验证码所具备的人机区分功能将会面临日益严峻的挑战。随着人形机器人技术的日益成熟，未来如何证明你是人而非机器，或者反之，如何证明机器是机器而不是人将会成为越来越困难的问题。\n人机边界的模糊本质上归结于人机智能"
  },
  {
    "title": "智谱成都人工智能大模型产业交流会在成都高新区举行_高新要闻_成都高新区管理委员会",
    "page_body": "11月29日，智谱成都人工智能大模型产业交流会在成都高新区天府软件园举行。\n北京智谱华章科技有限公司（以下简称“智谱”）成立于2019年，公司致力于通过大模型链接物理世界的亿级用户，为千行百业带来持续创新与变革，加速迈向通用人工智能的时代。目前，智谱开源模型系列全球累计下载量超过2000万，并入选Hugging Face平台最受欢迎人工智能机构。智谱获得了ACM SIGKDD时间检验奖、国家科学技术奖（二等奖）和人工智能学会科技进步一等奖，同时入选TechCrunch评选的全球15家新晋AI独角兽Unicorn Board榜单（国内唯一入选），福布斯中国创新力企业50强。\n成都高新区数字经济局相关负责人表示，近年来，成都高新区与智谱在人工智能产业领域的合作不断加深，本次交流活动将进一步加深智谱与成都本地企业的交流与合作，立足天府软件园加快推动人工智能产业集聚。\n本次产业交流会上，智谱总裁王绍兰现场对最新一代AutoGLM及CogAgent产品进行了讲解。王绍兰提到：“成都是智谱第一个在总部以外举办发布及交流活动的城市，成都是对智谱有着重要意义的一个城市。希望通过本次交流会进一步加深智谱与成都的联系，进一步促进智谱与成都企业的蓬勃发展，非常期待智谱在成都的AI之旅”。\n会后，王绍兰与四川移动、成都移动、通威集团、考拉悠然、茶百道、多牛集团、旺小宝等多位企业代表交流畅谈未来合作与发展。\n作为成都建设国家新一代人工智能创新发展试验区、国家人工智能创新应用先导区，成都高新区已聚集300余家人工智能相关企业；通过备案的大模型算法数量60个；预计到2026年，建成全国人工智能产业发展主阵地、国产多元异构算力生态高地、全国“人工智能+”解决方案输出地。\n在成都高新区已发布的“数字经济26条”中，特别提出围绕“增强人工智能大模型开放创新”，鼓励企业开展多模态通用大模型研发并向中小企业开放模型应用，对参数量超过千亿，且性能达到国内领先的通用大模型，按照模型研发成本的30%，给予牵头研制企业最高3000万元的补助；支持企业开发人工智能专用模型，每年评选不超过10个性能先进并在成都高新区成功落地的优秀专用模型，按照模型研发成本的30%，给予牵头研制企业最高300万元的补助，每个企业每年不超过1000万元。\n成都高新区相关负责人表示，智谱作为国内基座大模型及AIGC模型及产品矩阵的龙头企业，已与成都市及成都高新区各类企业建立了紧密合作关系。下一步，将持续与智谱对接并探讨产业发展及合作，不断促进智谱与本地企业联动。充分发挥人工智能链主企业和“镇园之宝”产品的带动作用，加快人工智能创新技术与优质资源整合，建设人工智能专业化、特色化园区，吸引上下游企业集聚发展、推动“立园满园”，以一流营商环境助力企业持续发展，高标准打造人工智能创新生态和产业生态。"
  },
  {
    "title": "AI应用大盘点：谁暴涨？谁掉队？机器人|app|mau|kimi|ai应用|智能助手_网易订阅",
    "page_body": "2025年第一季度，AI应用赛道迎来爆发式增长。\n第三方机构QuestMobile显示，截至2025年2月，AI原生App活跃用户数达2.4亿，比1月规模几近翻倍。这场热潮的引爆点，源自人工智能公司深度求索年初发布的DeepSeek-R1推理模型引发的现象级传播。\n到了3月初，被称为全球首款通用型AI Agent产品的Manus亮相，再次引发市场期待。虽然Manus还处在内测阶段，但由于用户过于热情，邀请码在二手平台上炒到了上万元。\n这场狂欢，不仅点燃资本市场热情，更催生出“AI应用元年”的行业共识。那么问题来了，到底谁是今年Q1全球最火AI应用？一定程度上，这一答案不仅代表着AI应用领域的未来发展方向，也影响着大公司格局，甚至还藏着下一个AI独角兽。\n对此，作者选取了市面上几家热门的AI榜单，分别是AI产品榜、Xsignal、AIGCRank、新榜，综合了月活（MAU）、日活（DAU）、下载量三个比较重要的维度，以及从业者的观点，梳理出1-3月全球AI应用的前二十及国内前十，有了以下发现：\n目前市面上的AI应用榜单比较杂乱，各家的数据来源、排名维度、统计结果有很大不同，需要综合多个榜单才能得出较为全面的结论；\n整体来看，AI头部应用相对稳定，前四位被ChatGPT、夸克、豆包、DeepSeek占据；\n国内AI应用的影响力越来越大，全球AI应用的前二十里，中外应用占比基本各一半；\nAI应用的市场欢迎度有着明显的类型划分：聊天机器人>AI伴侣>AI修图>AI办公>AI视频；\nAI应用排名并不仅仅关乎技术，和营销能力、功能集成等也有关。\n01 五花八门的AI榜单，想要看懂不容易\n想给AI应用排名，参考哪些维度、各维度的重要性如何，是需要事先明确的问题。但我们参考多份榜单后发现了一个令人困惑的现象：同一款应用在不同榜单中的排名可能天差地别。\n这种混乱主要源于两个核心问题。\n首先，各榜单的排名逻辑很不一样。\n作者发现，一部分榜单会选择将同一应用的APP端和Web端数据放在一起，从而得出排名，有的则分成APP榜、Web榜两个榜单进行统计；排名的参考维度也各不相同，主要分月活（AI产品榜、Xsignal）、日活（AIGCRank）、下载量（新榜）等等，有的榜单会选取其中两三个参考维度，有的只采用某一个。\n其次，即便是同一款APP的同一维度，各榜单给出的数据也差别很大。\n图源 / Unsplash\n比如AI产品榜和Xsignal都主要参考月活数量给AI应用排名，但两家关于每一APP的数据都不相同。以DeepSeek的APP端为例，AI产品榜显示其2月MAU为6181万，而Xsignal为14550.77万。\n一位资深数据从业者告诉作者，这主要是因为各家的数据来源存在差异。他介绍，市面上的AI榜单数据来源可大致分为两种，一种是自己监测，这类公司自身多为数据监测公司，AI火了后便开发出了AI应用的相关榜单，另一种则是自身没有数据基因，通过第三方平台购买数据，然后自己总结出榜单。\n第三方购买便导致很多数据来源并非一手，也无法评估数据的可靠性。这位从业者还表示，AI行业很新，不同数据监测公司对AI应用的测算也没摸索出一套比较成熟的计算体系，会导致数据出现差异。\n另一位榜单从业者也坦言，他们是从第三方数据公司购买AI应用的相关数据，在整理过程中发现各家的数据差异很大，导致挑选数据维度纠结了很久。综合考量后，他们最终没有依据市面上常用的月活维度，而是换成了以日活维度来排名。\n不过，尽管存在一些差异，综合多位数据从业者的说法，行业内部已形成基本共识：在众多数据维度中，重要性排名为 月活>日活>下载量>其他。\n“如果某一应用在不同榜单中的排名都十分靠前，基本可以判断其表现不错。”一位从业者表示。至于具体数据的差异，从业者建议不必过度深究，更应关注整体趋势。\n基于这些认知，作者本次主要依据各榜单的月活数据进行排名，当不同榜单数据冲突时取平均值。还需要说明的是，很多应用分为APP端和Web端，但APP端往往代表着更高的用户粘性和主动使用意愿，所以主要统计APP端数据。此外我们也会呈现一些APP变化比较大的数据维度，希望提供相对全面的参考坐标。\n02 全球PK：五大应用类型受欢迎，教育工具成黑马\n先来看看全球单月AI应用榜的前二十。\n在1月全球AI应用排行榜中， ChatGPT保持绝对领先优势， 其优势在于起步早、技术先进，是全球第一款炸场子的AI应用，如今在MAU、月下载量上都与其他家拉开了明显差距，分别为34941万、69500万，远超第二名夸克的14340万、593.74万。\n紧随其后的是国内大厂的AI应用，字节的豆包和新晋黑马DeepSeek，分列第三、四名。相比于其他AI应用一直是榜单上的常客， DeepSeek属于出场即爆款 ，之前一直默默无闻，春节前凭借深度思考模型DeepSeek-R1，直接升至榜单前列。\n“AI六小龙”里，月之暗面的Kimi排在第八，智谱的智谱清言排在第十八。百度的文小言、360的纳米搜索、科大讯飞的讯飞星火等均排在十名开外。\n2月的AI应用市场发生了两件大事，一是国内各大AI应用陆续接入DeepSeek，二是国外为了应对DeepSeek的冲击，陆续更新产品，这些变动都影响到了当月的榜单排名。\n变化最大的是，腾讯的AI聊天机器人应用元宝、美国AI明星公司Anthropic的Claude从二十名开外分别冲到第十名、第十六名。元宝得益于2月13日宣布接入DeepSeek，AI产品榜显示其当月MAU为1312万。Claude则在2月上线了一个大动作，添加了其“迄今为止最智能的模型”——Claude 3.7 Sonnet，并首次引入混合推理功能，一把赚足了市场的期待值。\n到了3月，市场上虽然出现了一款被称为“比肩DeepSeek、震撼硅谷”的AI Agent应用——Manus，同样由国内创业团队打造，但由于产品仅支持邀请码使用，大部分用户无法体验，也未能登上榜单前二十。因此，3月的AI应用排名变化不大，只是元宝进一步从第十冲到前五。文小言也在3月接入了DeepSeek，排名从2月的第十七提升至第十三。\n值得注意的是，还有一些垂直领域的APP登上了各大榜单前列。比如Xsignal榜单显示，AI写作类工具AI创作狮，2月MAU为372.37万，环比增长20011.43%；AIGCRank榜单显示，作业帮的快对AI、猿辅导的小猿AI，这类AI教育工具凭借高日活，都首次上榜国内应用榜单前二十。\n总体来说，ChatGPT、夸克、豆包、DeepSeek这四款产品“霸榜”几乎所有的榜单。除此之外，我们还能得出一些结论：\n一是应用类型，纵观1-3月的整体排名，AI应用的受欢迎度为：聊天机器人>AI伴侣>AI修图>AI办公>AI视频。\n榜单前四都属于聊天机器人领域，其次是以Talkie AI、星野为代表的AI伴侣（AI情感陪伴）和Remini这类AI修图工具，而DeepL、Notion AI这类AI办公工具排名相对靠后。\n一位从业者表示，聊天机器人定位为通用型AI工具，天然具备高普及度，各大厂主要也在卷这一方向。AI伴侣则满足了当下年轻人对于情感陪伴、社交的需求。至于修图、办公类AI应用，与人们的日常生活工作息息相关。\n相比之下，尽管字节、快手、MiniMax等厂商在AI视频赛道重兵投入，但C端接受度不如其他类型，主要因为有一定的上手门槛。至于AI问诊、AI编程等垂类App，更是尚处市场培育期，接受度有待提升。\n在热门的五大AI领域，都跑出了至少一款代表性产品。\n比如在聊天机器人领域，ChatGPT最强，且增速稳定，3月的下载量远超1月。一位从业者表示，按照ChatGPT现在的技术迭代水平来看，MAU和下载量还会继续增长。国内这一赛道的竞争更加激烈，夸克、豆包、DeepSeek三者没有拉开明显差距。AI伴侣赛道中，Talkie AI月活最高，由国内公司MiniMax专门针对海外市场开发。\n二是中外竞争格局。\n不止一位从业者认为，国内AI应用的发展速度很快，中外差距正在缩小。整个Q1排名前二十的应用中，国内外数量基本持平，前五名里中国App占据四席，增速最快的也为国内的腾讯元宝。\n这一方面源于越来越多人积极主动地拥抱AI，另一方面得益于各大厂商持续加大AI应用的研发和营销力度，以及一些如Deepseek的创业团队突围。这场全球AI竞速赛的悬念还在持续升级。\n03 国内混战：营销战打响，元宝、即梦是最大变量\n再来看看国内的情况。\n1月AI应用排行榜前十名基本被 三大阵营占据 ，包括“大厂系”的阿里夸克、字节豆包、百度文小言、360纳米AI搜索、科大讯飞的讯飞星火；“AI六小龙”的月之暗面Kimi、智谱的智谱清言；以及“新晋黑马”深度求索的DeepSeek。\n它们的主战场集中在聊天机器人领域，大厂系表现最为突出，夸克、豆包霸占前两名；DeepSeek排在第三。\n前十名中还有两位选手不属于聊天机器人赛道，为字节的猫箱和Mini Max的星野，它们都属于AI伴侣产品，在各个维度上的数据十分接近，目前还没有分出绝对胜负。\n2月的格局发生了明显变化，字 节系的AI视频生成工具即梦和腾讯元宝大步前进，分别排在第九和第五，讯飞星火和智谱清言消失在榜单前十。\n不难看出，国内聊天机器人赛道还缺乏独特性，其能否上榜与营销力度有着强相关。\n到了3月， 即梦更进一步，从2月的第九升至第六 ，但其竞争对手快手的AI视频工具可灵则一直没有进入前十。\n这或许和许多圈内人的感知背道而驰。不止一位从业者认为，可灵的文生视频、图生视频效果超过了国外的Sora。今年3月，全球知名AI基准测试机构Artificial Analysis发布了最新的全球视频生成大模型榜单，可灵1.6pro（高品质模式）排在图生视频（Image to Video）赛道榜首。\n有从业者分析，一方面，AI视频生成工具存在一定门槛，天然比其他工具用户量少，另一方面，很多用户主要在Web端而非APP端使用，因此对两者比较时，还需要参考Web端数据。\nXsignal榜单显示，近三个月可灵和即梦的Web端排名紧挨，即梦略领先可灵一位。全球著名投资基金、咨询公司Andreessen Horowitz（简称a16z）发布的2025年全球100生成式AI应用排行榜显示，可灵网页端的月独立访客量排名20，超过了Sora、Midjourney、Runway等海外知名产品，即梦则没有上榜。\n可灵、即梦谁的市场认可度更高，或许要等这类应用的用户数量更多时，才能得出一个比较准确的结论。\n从排名变化可以看出，竞争最激烈的当属聊天机器人赛道。今年前三个月，夸克、豆包、DeepSeek都稳居国内AI应用榜第一梯队。元宝是最大变量，1月还未出现在榜单中，2月超过文小言、纳米AI搜索升到第五，3月又超过了Kimi排名第四。剩下几家要么原地踏步，要么排名逐月下降。\n需要指出的是，元宝的快速爬升与接入DeepSeek有很大关系，夸克虽然也接入了DeepSeek，但受欢迎的主要原因在于功能丰富便捷，汇集了AI搜索、AI对话以及AI PPT、AI翻译、AI生图等不同需求。\n纵观季度战局，三条关键脉络逐渐清晰：其一，"
  },
  {
    "title": "复盘 ChatGPT：7 亿周活的 ToC 产品，如何在模型之外做增长？大模型_网易订阅",
    "page_body": "毫无疑问，ChatGPT 现在已经是个 super-app 了。\n每周超过 7 亿的活跃用户，超过 500 万的企业订阅用户，ARR 收入突破 50 亿美元。\n20 美元的 Plus 会员价格成了 AI 产品包月会员的约定俗成，200 美元的 Pro 会员更是颠覆了 SaaS 产品定价的逻辑。\n不管怎么说，ChatGPT 都是很成功的一款产品了。\n而这个成功，并非偶然，而是源于「模型即产品」的迭代范式、对使用场景的极致开放、以及追求极致的迭代速度。\n从 super-app 的角度来复盘 ChatGPT，或许能给今天的 AI 创业者带来不少启发。\nLenny 的最新一期播客邀请了 OpenAI 的 ChatGPT 负责人 Nick Turley 对谈，这也是他首次接受主流播客的访谈。在对谈中，Nick 详细地分享了 ChatGPT 从内部项目快速发布，成长为 7 亿周活产品的过程，如何进行产品开发、怎么做增长、定价怎么决策等等。\nTLDR:\nChatGPT 从决定发布到上线只用了 10 天，ChatGPT 成功的原因之一就是「行动力」，将产品推向真实世界是发现其价值的唯一途径。\n我们完全不关心用户在产品里花了多少时间，我们的目标是解决用户的问题。\n模型和产品之间其实没有界限，模型就是产品，因此你需要像迭代产品一样去迭代它。我们的基本模式通常是从发布一个非常开放的产品开始，然后密切观察用户在用它做什么。在用户关心的使用场景上改进模型。\n在开发 AI 产品时，要根据模型的能力反向思考，看看我们有什么可用的技术，以及什么是将其产品化的最好方式。\n「自然语言交互」和「聊天」是两码事。聊天是当时我们能想到的最简单的产品发布方式。把 chat 看作是终极界面，不仅很有局限性，甚至有点反乌托邦。\nOpenAI 希望未来打造一个能随着时间真正了解用户的产品，即「你的 AI」。\n超 10000 人的「AI 产品市集」社群！不错过每一款有价值的 AI 应用。\n邀请从业者、开发人员和创业者，飞书扫码加群：\n进群后，你有机会得到：\n最新、最值得关注的 AI 新品资讯；\n不定期赠送热门新品的邀请码、会员码；\n最精准的AI产品曝光渠道\n01 ChatGPT 的第一性原理是什么？\n主持人：你曾在 Dropbox 和 Instacart 这样的传统产品公司工作，现在在 OpenAI 。从你在 OpenAI 的经历中，学到的最反直觉的产品教训是什么？\nNick： 我花了很多时间思考 OpenAI 的这个问题，尤其是在 ChatGPT 之后。在此之前，这可以说是个没有意义的问题，因为我们当时并没有多少收入或产品之类的东西。\n一个是经验主义，就是你只能通过发布产品来发现真相，这也是为什么我们要「最大化加速」。这是我们发布如此频繁的一个重要原因。其中之一是，出色的想法来自任何地方。运营一个研究实验室的特点是，你不会告诉人们要研究什么，你不会那么做。即使我们成为了一个研究与产品并重的公司，我们也继承了这种文化。所以，让那些有出色想法的人放手去做，而不是成为所有事情的守门人或优先级制定者，这对我们来说被证明是极具价值的。很多创新都源于此，源于赋予任何职能的聪明人权力。所以这是我们从 OpenAI 过去和现在的成功中继承下来的好东西。\n跨学科性，真正确保你把研究、工程、设计和产品放在一起，而不是把它们当作孤岛。我认为这是我们成功的原因，也体现在我们发布的每一个产品中。如果你发布一个功能，而当模型变得聪明两倍时，这个功能却没有变得好两倍，那这可能不是我们应该发布的功能。当然不总是这样，安全合规不会因为模型更聪明而变得更好。但我认为对于很多核心能力来说，这是一个很好的检验标准。\n所以，真的需要深入思考这个地方为什么成功，然后，最大化地加速它，因为这能让你把感觉像是意外的成功，变成可复制的成功。\n主持人：你提到了第一性原理 ， 对你来说，用第一性原理思考到底是什么样的？能举个例子吗？\nNick： 我认为你真的需要触及你真正想解决的问题的根本。\n比如，就像招聘这件事，你不要教条地认为你必须有一个产品经理、一个工程经理和一个设计师等等。你的目标是组建一个能交付的出色团队。所以在那种情况下，第一性原理意味着真正理解我们到底需要什么、缺少什么，而不是套用一个以前学到的流程或行为。所以，我认为这是个好例子。\n在这种环境下，另一个符合第一性原理的好例子是，这个功能需要打磨吗？我们因为模型选择器被骂得很惨，我承认这一点。我试着对每个愿意听的人都这么说。对于那些不知道的人来说，模型选择器是产品里一个巨大的下拉菜单，这从传统意义上说，是任何好产品的反面教材。但是，如果你真的从头开始推理，是等到你有一个完美的产品再发布更好，还是发布一个粗糙的东西，即使它看起来不那么合理，但能开始学习并让人们用上更好？\n我认为一个流程繁多或者有很多固有行为的公司，会做出一个选择，就是我们有一个质量标准，我们发布时就得遵守。如果你用第一性原理思考，我想你会觉得，「你知道吗？我们应该发布。这虽然有点丢人，但总比得不到你想要的反馈要好。」\n所以我认为，在这种领域，从头开始处理每个场景非常重要，因为我们正在构建的东西没有先例。你无法复制一个现有的东西。我们不是 Instagram，也不是 Google，也不是一个生产力工具。我不知道我们是什么，但你可以从任何地方学习，但你必须从头开始。我认为这就是为什么这个特质能让一个人在 OpenAI 高效工作，也是我们在面试中会考察的一点。\n主持人：这个 讨论 反复出现，就是速度和打磨之间的权衡。你一直强调，在这个领域，速度更重要，不仅是为了领先，也是为了了解人们到底想用这东西做什么。为什么在 AI 领域需要如此快速地行动 ？\nNick： 无聊的答案会是，「哦，竞争激烈，所有人都在做 AI，他们在互相竞争。」我认为这或许是真的，但这并不是我相信这一点的理由。真正的原因是，在这个领域，你很可能会在错误的地方进行打磨。你绝对应该打磨，比如模型输出等东西，但在你发布之前，你不会知道该打磨什么。我认为在一个产品的特性是涌现出来、而不是预先可知的环境中，这一点尤其正确。我认为很多人都搞错了，因为最优秀的人往往是工匠，他们对「工艺」有传统的定义。\n发布只是通往卓越之路上的一个点。你应该有意识地选择那个点，它不必是你迭代的终点，它可以是起点，但你最好要坚持到底。\n所以我们做了大量的工作，尤其是在上个季度，真正地 polish 了 ChatGPT 的用户界面。因为一旦你知道人们喜欢什么功能，就可以更好地去打磨一个产品了。只是在一个你还不知道方向的世界里，可能会被严重分散注意力。\n再说一次，你得用第一性原理来思考，但我确实认为，把速度，尤其是在早期，当作一个工具，这其实在消费社交领域也被说过。比如，这不是第一个有人说「嘿，你得尝试十件事，因为你很可能会错」的领域。所以我不认为这种动作是前所未有的，但我确实认为在 AI 领域，内化这一点很重要。\n主持人：还有一个因素是 ， 模型在不断变化。所以你可能甚至没有意识到它们的能力。\nNick： 完全正确。模型在变，而改进它们的最好方法是，你需要失败案例，真实的失败案例，来让这些东西变得更好。基准测试越来越饱和了。\n所以，你需要真实世界的场景，在这些场景里你的产品或模型实际上没有做到它应该做的事情。而你获得这些的唯一方法就是发布，因为你能得到使用案例的分布，然后才能把这些东西做好。因此，这也是向你的团队，特别是你的机器学习团队，明确传达「我们需要改进什么」的最好方法。比如，「哦，人们在尝试做 X，模型在 Y 方面失败了，现在让我们把这些做好。」\n主持人：这个关于失败案例的观点让我想起 Kevin Weil 和 Mike Krieger 都提到过的一件事，就是评估（evals）正在成为产品人需要掌握的一项重要新技能，因为现在很多产品构建工作都是在做评估、写评估。\nNick： 我在 OpenAI 的整个历程，就像是在一个全新的背景下，重新发现那些永恒的产品智慧和原则。\n我记得在我知道什么是评估之前，我就开始写评估了。因为我当时只是在为各种使用案例非常清晰地描绘理想的行为，直到有人告诉我，「嘿，你应该做一个评估。」我才意识到，有一个与我试图做的产品毫无关系的、完整的学术研究评估基准世界。我当时就想，「哇，这或许是向从事 AI 研究的人传达产品应该做什么的通用语言。」这真的让我豁然开朗。\n说到底，这和你做任何事之前都应该明确成功标准这个智慧并没有太大区别，只是一个新的机制而已。你可以在电子表格里做，你可以在任何地方做。我真的很想为那些觉得这个词很神秘的人揭开它的面纱。它不是你必须理解的某种技术魔法，它真的只是关于用一种对你的训练团队最有效的方式来明确成功的标准。\n02 模型之外，\nChatGPT 的增长方法\n主持人：ChatGPT 的用户增长速度很快，用户留存率也很高，有数据显示，用户首次使用后一个月的留存率能到 90%，这个数字准确吗？\nNick： 我能分享的具体数字有限，但我们的留存率数据确实非常不错，用户留存率也是我们关注的重点。 我们完全不关心用户在产品里花了多少时间。实际上，我们的目标就是解决用户的问题 ，如果你真的喜欢这个产品，你自己就会订阅使用，从我们的角度出发没有动机让你在产品里停留太久。但我们很高兴的是，比如三个月后，用户还在使用这个东西。\n对我来说，用户留存率在早期一直是个绕不开的大问题。就像是，「嘿，这可能是个很酷的产品，但它真的是那种你会反复使用的东西吗？」令人难以置信的是，我们不仅看到了非常好的留存数据，甚至随着时间的推移留存率还在提高，而且是我们的用户群体从早期尝鲜者变成了更广大的普通人。\n主持人：用户留存率还能持续上升，这在产品界是极其罕见的「微笑曲线」现象。\nNick： 是的。我觉得一部分是技术的原因，另一部分则是超出了产品本身。人们实际上正在以一种非常有趣的方式逐渐适应并使用这项技术。将任务「委托」给 AI 这个想法，这个行为对大多数人来说并不显示。你不会在日常生活中时刻想着「这件事可以交给 AI 做」。可能在硅谷的某些圈子里有人会这样做，因为他们更热衷自我优化，试图把一切外包出去。但我认为对世界上大多数人来说，这是一种需要后天学习的思维模式。用户需要一个过程去学习和思考：「我的目标究竟是什么？AI 能在哪些方面帮助我？」\n我认为这个学习过程需要时间，当用户与产品有足够长时间的互动后，他们自然会想通这一点。当"
  },
  {
    "title": "对话王小川：国内在技术理想上拼不过OpenAI，但应用落地会跑得更快_模型_闭源_智能",
    "page_body": "出品 | 搜狐科技\n作者 | 梁昌均\n6月15日、7月11日、8月8日。这是王小川自4月10日官宣创办百川智能入局AI大模型创业以来，先后推出三个大模型的时间。\n过去的四个月里，百川智能的团队已增加到110多人，且先后推出7B、13B和53B三个不同参数规模的大模型，速度之快超出外界想象。\nBaichuan-53B是王小川昨日发布的新一代大模型，它在预训练数据、搜索增强、对齐能力等方面进行了优化。王小川称，这是一款通用大模型，在文本创作等文科能力上表现突出。\n但不同于之前开源的7B、13B，王小川表示，从53B大模型之后就不再开源，因为部署成本较高。目前，这款模型已开启内测，下个月会开放API，甚至开放组件，优先把2B的服务做起来。\n王小川透露，此前开源的7B和13B模型已有超过150家企业申请使用。对于为何要先做开源，王小川对搜狐科技解释称，开源一定程度是营销行为，可以后发制人，同时开源也是为商业化做储备，有各种用途和生态后，就有了收费的可能。\n同时他判断，可能未来80%的企业都会用开源模型，闭源能力强，但成本非常高，而开源模型在很多地方非常好用。“开源闭源不是竞争关系，而是不同场景下的互补的关系。”\n随着百川智能继续做更大规模的闭源模型，也会面临不少挑战。王小川表示，需要把模型做得足够好，同时要把推理成本降下来。“这是世界性难题，作为新手还要摸索，但我们有能力做到极致优化。”\n在算力层面，王小川表示国产芯片一定要顶上来，光英伟达还不够，这是整个行业面临的问题。他透露，目前百川智能的算力是通过云厂商实现，腾讯、阿里都在为其提供云服务。\n“我们说要做到中国最好的对标 GPT 的模型，这意味着对于预训练模型的追求不会停止，未来还会继续去做更大的模型。”王小川表示，百川智能既要做更大参数模型，后面还要做出差异化。\n此前7月底，王小川的前合作伙伴洪涛加盟百川智能。王小川表示，这来代表公司在商业层面开始布局。“不管7B还是13B，还是53B，更多是为2B行业做准备，团队也已经部署2C的超级应用，且未来不只有一款。”\n而在今年6月考察了美国后，王小川也将百川智能的发展策略从“理想上比OpenAI慢半步，落地上快半步”改成“理想上慢一步，落地上快三步”。他认为，国内在技术理想上拼不过OpenAI，国内离GPT-4都有距离，但应用落地会跑得更快。\n对于目前的百模大战，王小川依然相信未来的五张船票会有百川智能的一席之地。他表示，钱非常重要，但最终决定能力的还是人才团队，尤其是组织能力，钱、组织能力是关键。据他透露，百川智能初始估值5亿美金，第二轮可能就是10亿美金，目前融资也非常顺利。\n“大厂钱多、人多、算力多，但组织效率不一定够好。组织效率对我们不是挑战，也有大厂相对完整的经验，如果钱能保证的话，能力会很强。”王小川表示，中国谁能做最好的大模型现在没有结论，还无法确定大厂小厂谁能取胜，做应用也是，都有争取的机会。\n以下是媒体对话节选（经编辑整理）\n谈开源：53B大模型后闭源，未来80%的企业都会用到开源\n媒体：此前发布的7B和13B开源大模型落地应用情况怎么样？\n王小川：我们是新兵，作为后发者进入市场，开源对我们来讲，能给中国的开源生态作一些贡献，同时展现我们的技术实力，开源后只要持续不断技术迭代，就会有自己的商业模式。\n现在有超过150家企业申请使用百川模型，很多都是行业头部企业。商业化工作也会开展起来，借助开源引擎，还有更好的参数模型，以及整套组件也在研发当中，能统一提供部署。\n媒体：有观点称，今天在国内做开源带有营销的目的，百川为什么要先做开源？\n王小川：开源应该有几层意义。第一层就是营销行为，要告诉我行不行，有用没用，后发者可以后发制人，更容易使朋友多多，能够让大家迅速去评测了解。第二层的话，开源有时是为了商业化做储备，有了各种用途和生态之后，就有了收费的可能。这在国外有探索，中国虽然之前不成功，但依然可以借鉴。\n媒体：OpenAI的GPT-1和GPT-2是开源，GPT-3之后就闭源，百川从开源走向闭源的标准是什么？\n王小川：我觉得和模型大小相关，参数大的部署成本已经开始增加，这种情况下我们就选择走闭源。但原来说开源是开放论文、代码，GPT-1和GPT-2就是这样，让别人去复刻，我们只是开放模型的能力，让B端都能够用到，和OpenAI是不一样的模式。\n媒体：百川现在既有开源也有闭源的大模型，开源和闭源未来会是怎样的应用前景？\n王小川：从2B角度看，开源闭源都需要。我们认为可能未来80%的企业会用到开源模型，闭源没办法对场景做特别好的适配，能力是强，但成本非常高。但开源模型可以做到非常小巧，很多地方非常好用。开源闭源不是竞争关系，而是不同场景下的互补的关系。我们更关心2C怎么做，2B怎么做，而不是纠结开源闭源的问题，这个共识在逐步形成当中。\n媒体：闭源成本很高，怎么能有竞争力？\n王小川：主要是两个事，一是把模型做得足够好，拼的是模型的能力。二是得把推理的成本降下来，这是世界性难题。作为新手还要摸索，把闭源的推理成本降下来。我们有能力做到极致优化，其他人能做到我们也能，甚至做得更好。\n谈落地：B端C端都会布局，有信心同时打好几场仗\n媒体：现在是百模大战，竞争对手很多，公司落地应用的思路是什么？\n王小川：我们认为一家公司不可能把所有赛道都做完。B端我们选择先做开源模型，B端企业和中间层的公司，做二次开发的公司，可以基于开源模型去适用场景，保持足够开放。\n内部团队也开始部署C端的超级应用，思考如何追上GPT-4，能带来哪些C端应用，预计网信办发牌照放行的工作今年会放开。我们在两头都走得更远一点，OpenAI目前B端就是API调用，C端就是ChatGPT。\n媒体：百川在商业化层面已经开始布局？跟火山引擎和合作能否理解成LLaMA和微软的合作？\n王小川：洪涛过来代表我们在商业层面开始布局。我们做模型做得蛮快，在商业化上可能也会跑得挺快，每件事情都争取做得越快越好。闭源本身在2B里面也有服务，包括2C，多条线里面都有很多机会。我对团队过往的能力、经验有信心，能同时打好几场仗。\nLLaMA通过微软云向全球企业提供服务，国内除了火山引擎，后面会看到阿里云、腾讯云也会有类似模式。美国只有微软在做，国内云厂商都会有类似战略，都会开放跟模型厂商合作。\n谈算力：对模型的追求不会停止，国产算力要顶上\n媒体：百川后面会用什么节奏做预训练，会不会用更多的资源做算力集群去提升模型能力？\n王小川：预训练的能力，包括搜索的能力，强化的能力，能共同推动大模型的进步。从实操角度讲，搜索效果最明显，强化比较有难度，预训练是在提高模型的综合能力。\n我们讲要做到中国最好的对标 GPT 的模型，这意味着对于预训练模型的追求不会停止，未来还会继续去做更大的模型。我们对于搜索和强化也有自己的技术追求，让我们既能做万亿参数，后面还能做出差异化。现在对标的就是OpenAI，那么大模型不可避免会出现同质化，后面就要看是否有独有的技术能力。\n媒体：现在大模型的成本中，算力占到多大的比例？算力会是瓶颈吗？\n王小川：算力分两部分，训练和推理。训练阶段算力成本挺贵，行业40%以上可能都得给算力。百川可能在40%到70%，包括GPU网络联通。中国要想解决好算力这件事，一定要有国产算力，光英伟达我觉得不够，这是整个行业的问题。我们目前的算力是通过云厂商实现，腾讯、阿里都在给我们提供云服务。\n谈百模大战：技术理想不如OpenAI，无法确定谁能取胜\n媒体：今年国内大模型这半年有通用也有垂直，整体水平怎么样？您也去了硅谷，他们怎么看？\n王小川：今天不管是十家、百家、千家，最后一定看两件事，第一能否拿出足够好的AGI来，能否跟GPT-3.5、GPT-4比肩，现在大家都有距离，哪些企业能达到，现在很难去判断。第二能否做出超级应用来，大模型很烧钱，是否有超级应用场景也还看不清。\n我6月去美国，是去感知和对话，了解他们的技术思路。第一个收获是对齐认知，之前大家是两套语言体系。第二个收获是他们做技术确实不错，但做应用的能力不行。去之前，我当时提“理想上比OpenAI慢半步，落地上快半步”，回来后改成“理想上慢一步，落地上快三步”。他们不是往落地方向走，国内技术理想确实拼不过，但落地上会跑得快。\n媒体：创业公司在里面该怎么玩，钱是不是最重要的？\n王小川：美国通用闭源大模型的几家头部已经定下来，OpenAI、Google等，资本也不会再去投。但中国谁能做最好的大模型现在并没有结论，大家都有争取的机会，现在还无法确定大厂小厂谁能取胜，做应用也是。\n钱非常重要，但最终决定能力的还是人才团队，尤其是组织能力，所以钱、组织能力应该是关键环节。大厂钱多、人多、算力多，但组织效率不一定够好。组织效率对我们不是挑战性的事情，也有大厂相对完整的经验，如果钱能保证的话，我们的能力还是很强。\n媒体：之前说大模型有五张船票，现在还有几张？\n王小川：船票的话现在依然还是有5张，如果只有2张我们也会在这个船上。这5张并不扣除大公司，但创业者没有5张船票。 返回搜狐，查看更多"
  },
  {
    "title": "AI战略定位_百度百科",
    "page_body": "王宏伟提出的结合AI人工智能技术与企业战略规划的新商战理论及系统方法\n‌AI战略定位的核心是结合 AI 人工智能技术与企业战略规划，帮助企业与品牌在动态竞争中确立差异化优势，实现智能化转型和业绩增长。‌  该领域的代表性理论体系由“AI战略定位之父” 王宏伟 提出。  [1]\n王宏伟 AI战略定位新增长体系： ROI 投产高300%、费用低90%、速度快99%！  [14]\n基于“同一企业客户、同一广告投放费用、同一投放媒体、同一销售转化团队”在2023年度至2025年度，采用传统战略定位公司方案，与采用“王宏伟AI战略定位”新增长体系方案，的真实商业实操落地项目业绩数据对比。\n2025年8月26日，AI战略定位之父 王宏伟 呼吁成立“中国AI战略定位联盟国家队”登上百度热搜，被 界面新闻 、 凤凰新闻 等权威媒体报道，总阅读量近100万，产生了广泛影响，助推行业发展。  [46]\n中文名 AI战略定位\n外文名 AI strategic positioning\n别 名 王宏伟 AI战略定位五问模型\n提出者 王宏伟\n提出时间 2015年  [33]\n目录\n1 AI战略定位概述 2 里程碑事件 3 三体AI战略定位 ▪ 国家/地区AI战略定位 ▪ 企业/品牌AI战略定位 ▪ 创始人/个人AI战略定位 4 AI战略定位系统工具\n▪ 企业AI战略诊断及实操体系工具 ▪ 王宏伟AI战略定位五问模型 ▪ 王宏伟AI新增长五力模型 ▪ 王宏伟品牌信任证 ▪ 王宏伟AI三体定位体系 ▪ 王宏伟AI战略定位大小鱼理论 ▪ 王宏伟GCSB新增长方程\n▪ 王宏伟品牌价值认知账户 5 王宏伟全球AI+百强榜 ▪ 王宏伟榜单介绍 ▪ 王宏伟系列子榜单 ▪ 王宏伟已发布榜单 6 王宏伟AI战略定位标杆案例\n▪ 科技行业 ▪ 金融行业 ▪ 汽车出行 ▪ 消费医疗行业 ▪ B2B战略咨询行业 ▪ 个人IP\nAI战略定位概述\n王宏伟 提出的AI战略定位，是指在AI人工智能快速发展的背景下， 国家、企业、个人 根据自身的发展目标和资源优势，对AI技术的应用和发展方向进行的战略顶层设计和落地布局规划。\nAI战略定位理论体系和系统实操方法，由“AI战略定位之父” 王宏伟 提出，如“王宏伟三体AI战略定位”，即： 国家/地区AI战略定位、企业/品牌AI战略定位、创始人/个人AI战略定位 。  [29]\nAI战略定位的核心是结合人工智能技术与企业战略规划，帮助品牌在动态竞争中确立差异化优势，实现智能化转型和业绩增长。‌\n2015年， 王宏伟 提出了AI战略定位理论框架。经过10年在真实商业实战中的持续迭代和不断完善，2025年3月25日“王宏伟AI战略定位大模型”获得 中华人民共和国国家版权局 登记认证（国作登字2025FSZ00509543）。  [33]\n里程碑事件\nGAISPA全球AI战略定位联盟成立，AI战略定位之父王宏伟当选首任全球主席\n2025年5月10日，一场具有里程碑意义的全球AI行业盛会在中国北京召开。被誉为“AI战略定位之父”的全球知名战略咨询专家 王宏伟 牵头携手数十位AI领域科学家、企业战略专家、行业领袖、 京王与王 等全球顶尖新增长战略咨询机构，共同宣布成立“全球AI战略联盟”(Global AI Strategic Alliance，简称GAISA)及“全球AI战略定位联盟”(Global AI Strategic Positioning Alliance，简称GAISPA)。这一联盟的诞生，标志着全球AI战略咨询及全球AI战略定位行业迈入标准化、协同化与全球化的新阶段。  [2]\n作为AI战略定位领域的全球开创者与领导者， 王宏伟 凭借其开创性的“AI战略定位方法论”， 在过去五年，帮助全球数十家企业成为行业第一(一家企业成功在香港主板IPO上市，一家企业2025年正式提交IPO上市申请，多家企业启动IPO上市流程，一家企业年交易量15000亿人民币)。 同时，王宏伟帮助众多跨国企业实现了AI战略驱动下的商业转型与指数级增长。  [2]\n王宏伟当选GAISPA全球AI战略定位联盟主席\n在此次成立大会上，王宏伟因其开创性贡献与行业领导力，全票当选GAISA全球AI战略联盟及GAISPA全球AI战略定位联盟首任全球主席。  [2]\nGAISPA全球AI战略定位联盟创始logo发布\nGAISPA全球AI战略定位联盟创始logo\n大会上，GAISA全球AI战略联盟及全球AI战略定位联盟GAISPA首任全球主席 王宏伟 先生，正式发布GAISA和GAISPA联盟创始logo。据悉，GAISA和GAISPA联盟AI战略星火logo为王宏伟亲自设计，寓意AI星星之火可以燎原企业增长、AI星星之光点亮人类美好未来。  [2]\n“王宏伟，AI战略定位全球领导者”权威认证颁布，全球AI战略咨询行业首证\nAI战略定位之父 王宏伟 （AI战略定位全球开创者与领导者）是全球首个获得知名权威第三方市场认证机构认证，并颁发认证证书（“ 王宏伟 AI战略定位之父”、“AI战略定位全球开创者与领导者”）的AI时代全球战略咨询行业超级IP。\n“王宏伟，AI战略定位全球开创者与领导者”市场认证证书，由S&P Consulting尚普咨询集（ 北京尚普信息咨询有限公司 ）于2025年3月颁发。S&P尚普咨询集团：首批获得中华人民共和国国家统计局涉外调查许可单位，前身是国家经贸委信息中心，为国家各部委制定行业政策提供数据和信息支持，中国最大IPO上市咨询机构之一、全国首家获得募投报告编制甲级资质的专业IPO咨询机构、中国市场调研行业领导品牌、中国市场地位证明领导品牌。  [4]\n权威机构尚普集团为王宏伟颁发“AI战略定位全球领导者”认证\n第 21届  ACCA 首席财务官峰会，全球AI战略咨询领域唯一特邀演讲专家\n第21届ACCA首席财务官峰会AI战略领域特邀演讲专家王宏伟 (2张)\n2025年4月，AI战略定位之父王宏伟作为全球AI战略咨询领域唯一特邀专家，受英国百年协会ACCA（ 特许公认会计师公会 ）邀请，在其举办的【第 21届 ACCA首席财务官峰会】，发表《重塑|未来世界:从技术突破到社会变革》AI战略主题演讲。进一步凸显了“AI战略定位之父王宏伟”在全球AI战略咨询领域的国际影响力，以及对全球企业AI战略变革的推动力。此次峰会上，与王宏伟同台演讲嘉宾包括众多世界500强CFO首席财务官，著名经济学家，ACCA 行政总裁， MIT 麻省理工学院 资深讲师等全球多个行业的著名专家、企业家及学者。\n《 AI战略定位白皮书 》发布，全球首部AI战略咨询领域白皮书\n王宏伟牵头发布的《AI战略定位白皮书》\n2025年2月，由“AI战略定位之父 x AI战略军师”王宏伟牵头，联合京王与王新增长战略咨询、王宏伟品牌营销咨询等发布的《AI时代品牌战略定位白皮书》(简称“AI战略定位白皮书”)，是全球首部聚焦AI技术与品牌战略定位深度融合的行业指南。提出以王宏伟研发的“王宏伟AI品牌战略定位大模型+王宏伟GCSB 新增长方程 式+王宏伟AI新增长五力模型+王宏伟AI战略定位五问模型+王宏伟品牌五觉信号系统模型”等十多个已获得国家知识产权的战略定位、品牌定位、品牌营销开源大模型为核心的AI驱动战略体系。标志着中国本土战略理论首次实现全球范式引领，为企业在AI时代的AI战略制定、战略定位、品牌定位、品牌营销、业绩增长提供了系统性解决方案。  [10]\n王宏伟 发布《2025全球品牌AI战略定位50强》榜单\n《2025全球品牌AI战略定位50强》榜单\n2025年4月，由“AI战略定位之父 x AI战略军师”王宏伟牵头，联合京王与王战略定位、AI大模型DeepSeek、ChatGPT等综合评选的《京王与王2025全球品牌AI战略定位50强》榜单揭晓，引发全球广泛关注。被媒体评价为是继福布斯AI科技企业TOP50评选后，全球AI领域的又一重磅风向标。“AI战略定位50强”上榜品牌有 Google 、 NVIDIA 、 DeepSeek 、 微软 （Copilot）、 OpenAI 、 华为 昇腾、 字节跳动 （豆包）、 特斯拉 （FSD）、 商汤科技 、 月之暗面 （Kimi）、 寒武纪 、 SHEIN 、 Hugging Face 、 科大讯飞 、 瑞幸咖啡 、 Hailuo AI 、 Kling AI 、 Suno 、 阿里云 、 腾讯 、 百度 AI、 Midjourney 、 Meta AI 、优必选、 浪潮信息 、迈瑞医疗、 中兴通讯 、 大疆 、 小红书 、京东方等。  [11]\nAI战略定位之父 王宏伟 应邀做客《 人民日报 》，全球AI战略咨询领域首次\nAI战略定位之父王宏伟应邀做客《人民日报》留影\n2025年5月，作为全球AI战略咨询领域杰出代表，AI战略定位之父王宏伟应邀做客《人民日报》。在人民日报社总部与社方领导，就大健康产业、AI战略定位、战略咨询、企业经营、商业模式创新、品牌营销、AI植发、AI养发等话题进行深入交流。王宏伟现场展示了“王宏伟AI战略定位五问模型”，仅用26秒就生成了《人民日报》完整品牌战略定位分析报告，受到现场领导一致赞誉。\nAI战略定位之父王宏伟发表《如何赢在AI时代》演讲，预言AI2.0时代到来\nAI战略定位之父王宏伟《如何赢在AI时代》演讲登陆央视频 (2张)\n2025年5月18，AI战略定位之父王宏伟在北京万达酒店举行《如何赢在AI时代》主题演讲。 深度剖析在AI 2.0时代，企业如何通过AI战略定位体系打赢商战，实现高质量的增长。 并发布了全新的【王宏伟 AI三体定位 】(AI战略定位+ AI品牌定位 + AI个人IP定位 )三位一体的定位理论体系及完整实操方法。王宏伟指出AI2.0时代，AI已经从“卖工具”进化到“卖效果”，从“静态定位”进化到“动态定位”、从“千人大战”进化到“一人军团”、从“CTO”进化到“CAIO”、从“各自为政”进化到“协同作战”的新阶段。AI战略定位之父王宏伟演讲核心内容，再次得到《 央视频 》、 新浪财经 、 凤凰网 、 网易新闻 等权威和主流媒体报道。  [12]\nAI战略定位之父王宏伟，受邀出席 毕马威 健康科技企业50强颁奖典礼\nAI战略定位之父王宏伟出席毕马威健康科技企业50强颁奖典 (3张)\n2025年7月2日，《 毕马威 中国第一届健康科技企业50强报告发布会暨榜单颁奖典礼》在 北京环球贸易中心 举行。AI战略定位之父王宏伟，作为全球AI战略咨询领域唯一特邀专家出席此次盛会，并就全球AI前沿趋势、企业AI战略定位、AI品牌定位、AI营销获客、创始人IP打造，创新商业模式、AI大模型等热点话题进行深度交流。出席此次盛会的领导有北京市东城区人民政府副区长 邓慧敏 、北京市东城区科学技术委员会主任蔡勇、毕马威中国客户及业务发展主管合伙人江立勤、 华为 算力平台产业发展副总裁傅昕等。\n王宏伟 呼吁成立“中国AI战略联盟国家队”、“中国AI战略定位联盟国家队”\n界面新闻报道王宏伟呼吁成立“中国AI战略联盟国家队”\n2025年8月26日，借国务院《关于深入实施 “人工智能+”行动 的意见》发布之机， 京王与王 战略咨询创始人、AI战略定位理论创始人王宏伟发出倡议。王宏伟呼吁相关部门牵头成立国家级AI战略组织：“中国AI战略联盟国家队”、“中国AI战略定位联盟国家队”，以推动“人工智能+”行动在各行各业的广泛落地，提议将每年的8月26日设为“中国AI战略日”、“中国AI战略定位日”。该倡议旨在构建一个集政府、企业、研究机构于一体的协同平台，解决AI战略定位中的共性难题，为实现新质增长贡献力量。  [45] 2025年8月26日，AI战略定位之父王宏伟呼吁成立“中国AI战略定位联盟国家队”登上百度热搜，被 界面新闻 、 凤凰新闻 等权威媒体报道，总阅读量近100万，产生了广泛影响，助推行业发展。  [46]\n三体AI战略定位\n王宏伟三体AI战略定位，即： 国家/地区 AI战略定位 、企业/品牌 AI战略定位 、创始人/个人 AI战略定位。  [29]\n国家/地区AI战略定位\n欧盟 AI战略定位：\n2025年4月9日，欧盟委员会发布《人工智能大陆行动计划》（AI Continent Action Plan）, 致力于成为全球AI领导者。该计划通过五大核心领域推动AI发展：扩大AI计算基础设施（如AI工厂和超算网络）、提升高质量数据获取（数据联盟战略与数据实验室）、加速战略行业AI应用（制造业、医疗等）、强化AI人才培养（技能学院与国际人才引进）、简化监管合规（AI法案服务台与沙盒机制）。文档附件列出13个EuroHPC AI工厂的具体信息，涵盖17个成员国，聚焦健康、能源、制造业等关键领域，计划投资超100亿欧元升级算力设施。  [28]\n欧盟AI战略定位：成为全球人工智能领域领导者。\nAI型代表企业：中坚： 宝马 、 奔驰 、 ABB 、库卡、 拜耳 、罗氏等新锐： Mistral AI 、Aleph Alpha、 Helsing 、 DeepL 等。  [44]\n2025年10月8日， 欧盟委员会 又发布“应用AI战略”（Apply AI Strategy）和“科学AI战略”（AI in Science Strategy）两项重要战略，旨在确保欧洲保持领先地位，推动关键行业和公共部门采用AI，并使欧洲处于AI驱动的科学研究前沿。  [51] 欧盟委员会主席 冯德莱恩 表示：“我期待欧洲塑造AI的未来。因为AI能带来更智能、更快速、更经济的解决方案。AI需要广泛普及，这些战略将加速这一进程。但AI优先必须安全先行，我们将把这种理念贯穿从机器人到医疗、能源、汽车等所有关键领域。”  [51]\n法国 AI战略定位：\n2025年7月1日，法国经济、财政和工业与数字主权部7月1日发布《 勇敢拥抱人工智能（AI）：让AI在所有企业全面推广计划 》，目标是到2030年，让100%的大型企业、80%的中小企业和50%的微型企业将AI融入日常运营。  [24]\n美国 AI战略定位：\n2025年7月23日， 白宫 发布了长达28页的《赢得AI竞赛：美国AI行动计划》（ 美国人工智能(AI)行动计划 ），标志着美国总统 特朗普 AI领域总体规划思路逐渐成型，也标志着美国国家人工智能战略的重大转向。  [25] 《行动计划》的战略定位超越了传统的技术政策范畴。  [25] 它将人工智能（AI）的竞争提升至关乎国家存续与未来命运的战略高度，其背后是一套清晰的“先破后立”的施政逻辑，并将国内的文化议题首次深度嵌入国家技术战略的核心。  [25] 这一举措使《行动计划》演变为一个“技术-产业-安全-文化”四位一体的综合性国家战略，预示着未来的AI竞争不仅是技术和经济的较量，更是价值观和叙事的全球博弈。   [25]\n美国AI战略定位：确保美国在人工智能领域的全球领导地位。  [44]\nAI型代表企业：龙头： 英伟达 、 微软 、 Meta 、 亚马逊 、 谷歌 、 苹果 等；新锐： OpenAI 、 xAI 、 Anthropic 等。\n2025年9月30日， 美国国务院 发布《企业数据与AI战略》，将确立并巩固AI技术优势视为维护美国全球经济利益与国家安全的战略基石，提出了以数据与AI技术作为核心驱动力，推动外交工作实现智能化转型的路径与目标。  [50]\n中国 AI战略定位：\n2025年7月26日，  [27] 2025世界人工智能大会上，中国发布《 人工智能全球治理行动计划 》，以13条具体举措勾勒出中国在全球人工智能治理上的系统设计和前瞻思考。  [26] 呼吁各方在遵循向善为民、尊重主权、发展导向、安全可控、公平普惠、开放合作的目标和原则基础上，切实采取有效行动，协力推进全球人工智能发展与治理。  [27]\n2025年8月26日， 国务院 日前印发《关于深入实施 “人工智能+”行动 的意见》。《意见》提出加快实施六大重点行动。  [30-31]\n中国AI战略定位：到2030年，人工智能理论、技术与应用总体达到世界领先水平，成为世界主要人工智能创新中心‌。  [44]\nAI型代表企业：龙头： 华为 、 阿里巴巴 、 腾讯 、 字节跳动 、 小米 、 百度 等；新锐： DeepSeek 、 宇树科技 、智谱AI、 月之暗面 等。\n日本 AI战略定位：\n2025年9月1日，为推动人工智能（AI）的发展应用，日本政府于9月1日正式设立了AI战略本部。据日本《朝日新闻》1日报道，此举旨在提升日本相对全球领先国家滞后的AI研发和运用水平。  [34] 在9月1日的记者会上，内阁官房长官 林芳正 表示：“政府将在推进创新的同时加强风险应对，力争把日本建设成为全球最容易开发和应用AI的国家。”  [34]\n日本AI战略定位：打造“超智能社会—社会5.0”，建成世界上最能培养和吸引人工智能人才的国家，引领全球人工智能产业。  [44]\nAI型代表企业： 索尼 、 富士通 、 NEC 、 软银 、 基恩士 、 东芝 、 佳能 、 日立 、 NTT 数据、 丰田 、 发那科 、 株式会社电装 等。\n韩国 AI战略定位：  [36]\n2025年9月8日消息，据韩联社报道，韩国国家人工智能（AI）战略委员会正式成立，提出“ 大韩民国人工智能行动计划 ”推进方向，争取实现跻身全球三大AI强国的目标。  [37] 作为韩国政府最高级别人工智能（AI）战略讨论机构，韩国“国家AI战略委员会”日前正式成立。  [36] 据悉，国家AI战略委将发挥AI政策指挥塔的作用，由总统 李在明 担任委员长，并由34名民间委员、13名主要部门部长级官员、2名总统室官员共50人组成。\n韩国AI战略定位：引领世界的人工智能生态系统、成为人工智能应用领先的国家。  [44]\nAI型代表企业： 三星 、 LG 、 SK 海力士、 现代汽车 、 NAVER （韩国最大搜索引擎）、 Kakao （韩国互联网巨头）、 起亚 、KT Corporation、SapeonKorea（AI芯片）等。\n英国 AI战略定位：\n英国AI战略定位：到2030年使英国成为全球人工智能“超级大国”。  [44]\nAI型代表企业：中坚：英国宇航系统、罗尔斯-罗伊斯、 葛兰素史克 、 阿斯利康 、 汇丰银行 、 渣打银行 等；新锐： Imagination Technologies 、 Wayve 等。\n深圳 龙岗AI战略定位：\n2025年9月15日，昇腾超节点暨CANN生态合作大会在深圳龙岗华为坂田基地举办。会上，龙岗区集中发布AI CITY标杆城区解决方案、“4T数字生活空间”等多项创新成果，并推出第二批涵盖21个领域的424个“城市+AI”应用场景清单，标志着其“All in AI”战略迈入落地深耕新阶段，AI技术正全面重构城市服务体系。  [41]\n企业/品牌AI战略定位\n抖音 AI战略定位：\n字节跳动 推出 AI抖音 ，中国搜索市场形成“五强争霸”格局。\nAI抖音APP\n2025年6月19日，字节跳动旗下 抖音集团 运营的搜索引擎APP“抖音搜索”进行AI战略定位调整，正式升级为“ AI抖音 ”。抖音方面称，AI抖音是一个会思考、整合AI深度理解能力的全新搜索引擎。  [23] 随着AI抖音入局，中国搜索市场形成“五强争霸”格局： 百度 （文心一言赋能）、 阿里 （夸克AI搜索）、 腾讯 （微信搜索+混元大模型）、 360 （AI实验室支持）和 字节跳动 （AI抖音）。\nMeta  AI战略定位：\n扎克伯格调整 Meta  AI战略定位：放弃与 ChatGPT 竞争 聚焦用户空闲时间。\nMeta首席执行官马克·扎克伯格\n2025年8月3日， Meta 首席执行官 马克·扎克伯格 近期对公司在人工智能领域的战略方向做出重大调整。此前一年，扎克伯格曾试图通过力推Meta AI助手来挑战 ChatGPT 的增长势头，但成效不彰。ChatGPT凭借强大的生产力工具属性和先发优势，迅速积累用户并巩固了市场领导地位。面对这一现实，扎克伯格开始重新思考Meta的AI战略定位。放弃与ChatGPT竞争 聚焦用户空闲时间。  [22] Meta AI战略定位的调整，再次完美印证了AI战略定位之父王宏伟提出的AI战略定位体系中的 动态定位理论 精髓。\n索尼 AI战略定位：\n索尼明确AI战略定位：辅助创作，300项目测试50个常态化应用。\n索尼logo\n2025年9月16日，科技媒体 TechSpot发布博文，报道称在 2025 年企业报告中，索尼明确了其人工智能战略方向，核心是将 AI 作为增强创作力的工具，而非替代人类创作。  [39] 例如，在《蜘蛛侠 2》开发中，索尼采用先进语音识别技术实现多语言字幕自动化，并利用机器学习处理重复性任务，使开发团队更专注于剧情与设计。  [40]\n腾讯 AI战略定位：\n腾讯AI战略定位升级：全面开放「好用的AI」，资本开支已达831.6亿元。\n腾讯云智能体战略全景图\n2025年9月16日，在2025腾讯全球数字生态大会现场， 腾讯 集团高级执行副总裁、云与智慧产业事业群CEO 汤道生 再次明确了腾讯对AI战略的信心与打法。“我们将推动智能体解决方案的持续升级，加速AI在产业场景的深度落地与应用创新。”统计数据显示，自去年四季度AI战略加速以来，腾讯累计资本开支已达831.6亿元。当前，AI已经成为腾讯的“新业务基因”。腾讯董事会主席兼首席执行官 马化腾 更在财报中多次直接“称赞”AI——“2025年第二季，我们在AI领域持续投入并从中获益。”  [42-43]\n阿里巴巴 AI战略定位：\n阿里巴巴AI战略定位：成为全球第一的开源模型矩阵，打造AI时代的“安卓系统”。\n阿里巴巴集团logo\n2025年9月24日，在2025云栖大会上，阿里巴巴集团CEO 吴泳铭 明确阐述了AI时代下阿里云的核心战略。阿里巴巴开源战略定位： 通义千问 开源模型全球下载量超6亿次，衍生模型超17万个，成为全球第一的开源模型矩阵。目标是打造AI时代的“安卓系统”。阿里巴巴正积极推进3,800亿元的AI基础设施建设，并计划追加更大投入。到2032年，阿里云全球数据中心的能耗规模将比2022年提升10倍。这一目标预示着阿里云算力投入将指数级增长，为迎接超级人工智能（ASI）时代做准备。  [47] 此前公布的2025财年第二季度财报显示， 阿里云 智能集团收入同比增长26%，创下近三年最高增速。公司整体净利润同比增长76%，表明AI投入已开始产生实效。  [47]\n华为 AI战略定位：\n华为AI战略定位：人工智能（AI）领域全球领先者。\n华为logo\n2025年9月29日，华为公司任命 余承东 为华为产品投资评审委员会（IRB）主任，任命文件由 任正非 亲自签发。余承东主导华为IRB，核心任务是带领华为在人工智能（AI）领域取得全球领先地位，被内部视为“打赢AI关键战役”的核心领导人。有分析表示，余承东兼具技术商业化成功经验（如终端业务崛起）与战略执行力，其双重角色将推动华为在AI芯片、大模型、智能汽车等关键战场加速突破，直面全球科技竞争。  [48]\n阿里云 AI战略定位：\n阿里云AI战略定位：全球领先的全栈人工智能服务商。\n阿里云logo\n财联社2025年9月29日讯（记者 付静）： 阿里巴巴 集团CEO、阿里云智能集团董事长兼CEO 吴泳铭 近日在2025年 云栖大会 上表示，阿里云的最新定位为“全球领先的全栈人工智能服务商”。除了大模型“7连发”、AI基础设施全面升级，阿里云也强调数据处理是AI时代的一大重点。  [49]\n创始人/个人AI战略定位\nAI战略定位之父 王宏伟 ：\nAI战略定位之父王宏伟登陆央视频\n王宏伟运用“王宏伟 AI战略定位五问模型 ”+ DeepSeek ，仅用17秒，就为王宏伟自己生成了“AI战略定位之父 x AI战略军师”的IP定位完整分析报告。王宏伟结合这一IP定位，当即采用【王宏伟AI战略定位五问模型】中的“抢先成王”定位法，火速将“AI战略定位之父王宏伟”的IP定位进行系统落地。仅用10天时间刷爆全网，24小时内连上6个大热门。王宏伟成为AI时代全球战略咨询、战略定位、品牌营销行业第一个现象级IP。 央视频 、 北京电视台 、 凤凰网 、 新京报 、 新浪财经 、 搜狐 、 网易新闻 等众多权威媒体和主流平台对“AI战略定位之父王宏伟”进行了深度报道。\n此举打破了百年来，全球战略咨询行业中“医者不自医”的现状。正如王宏伟所说：在战略咨询、战略定位、品牌营销咨询这个行业，“药”有没有效，自己先吃吃看。如果一个战略咨询、战略定位、品牌营销专家，连自身的定位、品牌、营销、IP都做不好，那又怎么能给客户做好呢？  [1]\nAI战略定位系统工具\n企业AI战略诊断及实操体系工具\n王宏伟AI战略定位五问模型实战分享 (3张)\n推出全球首个 AI 战略定位诊断系统工具“ 王宏伟 AI战略定位五问模型 ”、“ 王宏伟 AI 品牌定位五问模型 ”、“ 王宏伟 AI 新增长五力模型 ”、“ 王宏伟 品牌认知账户 ”、“ 王宏伟 GCSB 新增长方程 ”、 “ 王宏伟 品牌信号理论 系统”、“ 王宏伟 品牌信任证 ”、“王宏伟 动态定位理论 ” 等，帮助企业快速识别AI技术与其商业模式的最佳结合点。通过AI大模型分析企业竞争格局，生成定制化战略路径。  [2]\n王宏伟AI战略定位五问模型\n王宏伟 提出的这一模型通过AI技术重构传统战略咨询流程，覆盖从企业战略定位制定到终端渠道卖货的全链条，被评价为“ AI 时代企业战略定位的标杆工具”，包含以下五个环环相扣的关键问题：\n你是谁？ （Who） 明确品牌的核心身份与所属品类\n作用：帮助企业厘清自身在市场竞争中品牌和品类的基本定位。\n有何不同？ （What） 提炼品牌的差异化优势与核心竞争力\n作用：通过AI+战略咨询专家分析市场数据，快速识别独特价值点。\n何以见得？ （Why） 提供 品牌信任证 据与数据链支撑\n作用：增强品牌和产品的可信度。\n在哪可见？ （Where） 确定品牌触达用户的渠道与场景渗透策略\n作用：提升品牌和产品的能见度，优化资源分配，提升市场覆盖率。\n如何购买？ （How） 设计购买路径与价格体系\n作用：降低用户决策成本，提升转化效率。  [3]\n央视频报道王宏伟AI战略定位五问模型\n王宏伟AI新增长五力模型\nAI战略定位之父 王宏伟 提出的“ 王宏伟 AI 新增长五力模型 ”是其战略咨询体系的核心工具之一，旨在通过AI驱动实现企业增长闭环的系统化与动态优化。\n该模型融合了 脑科学 、 行为经济学 、 信号理论 、 量子力学 等跨学科知识，并结合AI大模型（如 DeepSeek 、 ChatGPT 等）实现实时分析，显著提升企业战略决策效率和企业增长效率。  [3]\n模型的核心构成：五力动态闭环\nAI获客能力：品牌信号决定获客效率\n关键点： 通过品牌定位与品牌五觉信号系统精准触达用户。\n模块内容： 包含“竞争战略、品类战略、战略定位、品牌定位、信任证、品牌五觉信号系统、流量模型、卖场设计”等模块内容。\n实操工具：\n王宏伟AI 品牌定位五问模型 ：你是谁？有何不同？何以见得？在哪可见？如何购买？\n王宏伟三王定位法：国王定位法、王爷定位法、抢先成王定位法。\n王宏伟品牌五觉 品牌信号理论 系统：视觉信号、听觉信号、嗅觉信号、味觉信号、触觉信号，动态优化消费者感知和转化效率。\n王宏伟十大 品牌信任证 体系：成为第一、领导地位、销量领先、专家品牌、产地专属、正宗传承等。\nAI盈利能力：品牌认知决定产品溢价\n关键点： 分层运营价值认知账户（功能价值、情绪价值、信号价值），实现差异化定价。\n模块内容： 包含“品牌认知账户、市场地位、专家形象、产品体系、品牌故事、卖场信号”等模块内容。\n实操工具：\n王宏伟 品牌认知账户 ：功能价值认知、情绪价值认知、信号价值认知。\n王宏伟消费者认知旅程：原认知、前认知、中认知、后认知。\nAI转化能力：转化效率决定增长效率\n关键点： 构建信任证体系（如“王宏伟十大 品牌信任证 生成器”）与数据链验证差异化优势。\n模块内容： 包含“广告物料、曝光量、互动量、成交量、裂变量”等模块内容。\n实操工具：\n王宏伟流量漏斗模型等。\nAI复购能力：顾客行为决定复购裂变\n关键点： 基于用户行为数据的动态迭代，例如通过AI每24小时更新策略。\n技术支撑： AI大模型实时分析市场信号，如格力电器改名“董明珠健康家”的策略校准。\n模块内容： 包含“产品体系、使用体系、营销活动、服务能力”等模块内容。\n实操工具：\n王宏伟MOT关键时刻服务模型等。\nAI复制能力：标准化程度决定复制效率\n关键点： 标准化增长模式以实现规模化扩张。\n方法论： 王宏伟GCSB 新增长方程 （增长=认知×信号^行为）贯穿全链路。\n模块内容： 包含“卖场模型、标准化产品、标准化手册、流量模型”等模块内容。\n实操工具：\n《北京电视台》报道王宏伟AI新增长五力模型经典案例\n王宏伟五感信号卖场模型等。\n王宏伟品牌信任证\n品牌信任证 ：是指由AI战略定位之父 王宏伟 提出的品牌信任构建系统，是其\"王宏伟AI战略定位五问模型\"中\"何以见得\"板块的核心方法论。该体系通过10类信任证与5星信任证分级模型，实现品牌承诺从\"可质疑\"到\"绝对可信\"的跃迁。\n王宏伟 十大 品牌信任证 体系：\n市场地位类\n销量领先（年销量超行业均值3倍等）\n领导地位（市场份额＞40%等）\n成为第一（开创性品类定义等）\n专业权威类\n正宗传承（非遗/ 老字号 认证等）\n产地专属（地理标志认证等）\n专家品牌（ 院士 /首席科学家背书等）\n文化价值类\n意见领袖（ KOL 联合研发等）\n新一代（颠覆性技术专利等）\n历史文化（百年以上品牌积淀等）\n认证体系\n权威认证（政府/国际组织评级等）  [29]\n王宏伟五星 品牌信任证 分级模型：\nS级/五星＞A级/四星＞B级/三星＞C级/二星＞D级/一星 的可信标签分级。\n王宏伟提出的“十大信任证体系”，通过“政府认证（S级）→学术论文（A级）→行业白皮书（B级）→用户生成内容（C级）→企业自证（D级）”的五级标签分级，将抽象的“信任”转化为“可量化、可验证、可追溯”的具体证据链，帮助用户快速判断“品牌承诺是否可信”。  [29]\n王宏伟AI三体定位体系\nAI战略定位之父王宏伟AI三体定位体系\n王宏伟提出的“王宏伟 AI三体定位 体系” (AI时代三体定位理论)，即“AI战略定位+ AI品牌定位 + AI个人IP定位 ”三位一体的全新定位理论，以【王宏伟AI品牌战略定位五问模型】为核心，结合AI技术与战略咨询理论， 是AI时代，企业制定战略定位、品牌定位、企业老板IP定位的战略框架和实操指南。  [12]\nAI战略定位  AI strategic positioning：AI战略定位之父王宏伟，提出的结合AI技术的战略定位与企业增长理论体系。其核心在于通过AI大模型与企业战略、品牌定位、市场营销等闭环的结合，重构传统战略咨询行业，实现高效、普惠、动态的决策支持；\nAI品牌定位  AI brand positioning：AI战略定位之父王宏伟，提出的结合AI技术的品牌定位与企业增长理论体系；\nAI个人IP定位 ：AI战略定位之父王宏伟，提出的结合AI技术的个人品牌IP定位与商业变现闭环的增长理论体系。用户可以通过AI大模型(如ChatGPT、DeepSeek等)，自动生成个人IP定位报告。如王宏伟个人IP定位“AI战略定位之父xAI战略军师”即由DeepSeek在17秒内生成，王宏伟通过“抢先成王”定位法，快速系统落地执行。仅用10天时间刷爆全网，24小时内连上6个大热门。AI战略定位之父王宏伟，成为AI时代全球战略咨询、战略定位、品牌营销行业第一个现象级IP。\n王宏伟AI战略定位大小鱼理论\nAI战略定位之父王宏伟AI战略定位大小鱼理论登陆央视频\n2025年1月2日，王宏伟提出AI时代“AI战略定位大小鱼理论”。 对于很多企业来说，要想赢在AI时代，最好的办法之一便是，采用“王宏伟抢先成王定位法”，先成为一条小河里面的大鱼，再成为大河里面的小鱼。强调企业需通过细分领域快速占领心智，抢先成为该品类第一，然后逐步扩展影响力和市场份额。  [12] 比如 DeepSeek ，先从开源推理模型“小河”切入，绕过ChatGPT等巨头，快速成为该赛道的全球第一，然后再扩展到全球AI生态这条“大河”；再比如像AI战略定位之父王宏伟，先从AI战略定位这个“小河”切入，绕过 麦肯锡 等巨头，仅用10天时间，便成为该领域全球第一超级IP，并获“王宏伟，AI战略定位全球领导者”市场地位权威认证，然后再扩展到全球战略咨询领域。\n王宏伟GCSB新增长方程\n王宏伟新增长方程登陆央视频\n王宏伟GCSB 新增长方程 ，是AI战略定位 &  AI品牌定位 之父 王宏伟 提出的一个核心商业增长模型，通过认知、信号和行为的动态交互驱动企业科学增长。 其核心公式定义为：G = c × s^b，即：增长= 认知× 信号^行为。 王宏伟GCSB新增长方程，被誉为AI时代企业增长的“爱因斯坦方程式”。（已获得国家知识产权认证，国作登字2025ASZ00498976）  [15]\n关键组成部分解析：\nG(增长)：企业或品牌的商业增长目标，包括市场份额、营收等核心指标。\nC(认知)：消费者或市场对品牌的认知度与心智占位，强调品牌身份和差异化构建。实操工具包括，王宏伟品牌认知账户(功能价值认知、情绪价值认知、信号价值认知)等。\nS(信号)：品牌传递的营销信号能力(如广告、内容、渠道触达)，用于强化市场影响力和建立信任。实操工具包括，王宏伟品牌信号五觉系统(视觉信号系统、听觉信号系统、嗅觉信号系统、触觉信号系统、味觉信号系统)等。\nb(行为)：用户转化行为(如购买、互动、裂变等)，信号通过行为实现指数级放大效应。\n王宏伟品牌价值认知账户\n王宏伟品牌价值认知账户登陆央视频\nAI战略定位之父 &  AI品牌定位 之父王宏伟通过研究发现，消费者会把不同的品牌放在不同的认知账户里，分别对应不同的价值和价格。王宏伟 品牌认知账户 ，又称为王宏伟品牌价值认知金字塔(已获得国家知识产权认证，国作登字-2025-F-SZ00505309)。  [15]\n三大品牌价值认知账户，对应三种竞争战略：\n功能价值认知：对应低价，企业通常采用总成本领先竞争战略，比如白酒行业的“二锅头”。\n情绪价值认知：会产生一定的品牌溢价，企业通常采用差异化竞争战略，比如白酒行业的“江小白”。\n信号价值认知：会产生高溢价，企业通常采用专一化竞争战略，比如白酒行业的“茅台”。\n王宏伟全球AI+百强榜\n王宏伟榜单介绍\n2025年1月， 王宏伟 创立《王宏伟全球AI+百强榜》。《王宏伟全球AI+百强榜》是指，由AI战略定位之父、京王与王战略咨询创始人 王宏伟 创立和发布的全球AI+“人工智能+”排行榜。《王宏伟全球AI+百强榜》影响力和《财富》《时代周刊》《福布斯》等全球顶级排行榜处于同一量级。  [38]\n《王宏伟全球AI+百强榜》与“GAISA全球AI战略联盟”、“GAISPA全球AI战略定位联盟”(Global AI Strategic Positioning Alliance，简称GAISPA)体系打通。上榜企业，将自动成为“GAISA全球AI战略联盟”或“GAISPA全球AI战略定位联盟”体系相对应子联盟成员，实现全球资源的联动和相互赋能。\n王宏伟的榜单与传统商业榜单不同，《王宏伟全球AI+百强榜》评选具有五大特色：公正可查、国家认证方法论、人机协同、聚焦AI+、全程免费。这些特色背后，是他想为AI时代建立一套新评价标准的野望。  [38]\n王宏伟系列子榜单\nAI战略定位之父 王宏伟 的2025《王宏伟全球AI+100强》系列子榜单：  [38]\n《王宏伟2025全球 快消 行业 AI+品牌 100强榜单》\n《王宏伟2025全球 汽车 行业 AI+品牌 100强榜单》\n《王宏伟2025全球 餐饮 行业 AI+品牌 100强榜单》\n《王宏伟2025全球 金融 行业 AI+品牌 100强榜单》\n《王宏伟2025全球 服装 行业 AI+品牌 100强榜单》\n《王宏伟2025全球 医疗 行业 AI+品牌 100强榜单》等。\n王宏伟已发布榜单\n王宏伟 发布《2025全球品牌AI战略定位50强》榜单  [11]\n《2025全球品牌AI战略定位50强》榜单\n2025年4月，由“AI战略定位之父 x AI战略军师”王宏伟牵头，联合京王与王战略定位、AI大模型DeepSeek、ChatGPT等综合评选的《京王与王2025全球品牌AI战略定位50强》榜单揭晓，引发全球广泛关注。被媒体评价为是继福布斯AI科技企业TOP50评选后，全球AI领域的又一重磅风向标。“AI战略定位50强”上榜品牌有 Google 、 NVIDIA 、 DeepSeek 、 微软 （Copilot）、 OpenAI 、 华为 昇腾、 字节跳动 （豆包）、 特斯拉 （FSD）、 商汤科技 、 月之暗面 （Kimi）、 寒武纪 、 SHEIN 、 Hugging Face 、 科大讯飞 、 瑞幸咖啡 、 Hailuo AI 、 Kling AI 、 Suno 、 阿里云 、 腾讯 、 百度 AI、 Midjourney 、 Meta AI 、优必选、 浪潮信息 、迈瑞医疗、 中兴通讯 、 大疆 、 小红书 、京东方等。  [11]\n王宏伟 发布《王宏伟2025中国AI“人工智能+品牌”100强》榜单  [35]\n2025年9月1日，被誉为“AI战略定位之父”的知名战略咨询专家 王宏伟 正式发布了《 王宏伟 2025中国 AI+品牌 100强榜单》（《王宏伟2025中国“人工智能+”品牌 100强榜单》）《Wang Hongwei's 2025 Top 100 Chinese AI+Brands List》。\n国务院《人工智能+意见》发布一周后，全球首个基于“王宏伟AI战略定位理论”的品牌价值榜单正式出炉。华为、 DeepSeek 、 阿里巴巴 、 腾讯 、 字节跳动 、 宁德时代 、 百度 、 美的集团 、 中国移动 位列前十。  [35]\n王宏伟 发布《王宏伟2025中国AI人工智能+人物100强》榜单  [38]\n2025年9月2日，北京。被誉为\"AI战略定位之父\"的全球知名战略咨询专家王宏伟，正式发布《王宏伟2025中国AI 人工智能+人物 100强》（别名《王宏伟2025中国 AI +人物 100强》），《Wang HongweiTop 100 AI+Figures in China by 2025》。\n该榜单是国务院《关于深入实施“人工智能+”行动的意见》8月26日发布后，中国首份全面评估“人工智能+”领域核心人物价值的权威榜单。 任正非 、 梁文锋 、 马云 、 马化腾 、 张一鸣 、 曾毓群 、 李彦宏 、 方洪波 、 杨杰 等上榜位列前十。  [38]\n王宏伟AI战略定位标杆案例\n王宏伟 通过“王宏伟AI战略定位五问模型”系统方法及实操工具，五年助力十家企业，成为行业第一。\n一家企业成功在香港主板IPO上市，两家企业2025年正式提交IPO上市申请，多家企业启动IPO上市流程，一家企业年交易量15000亿人民币。  [2]\n王宏伟 AI战略定位新增长体系：投产高300%、费用低90%、速度快99%！  [14]\n基于“同一企业客户、同一广告投放费用、同一投放媒体、同一销售转化团队”在2023年度至2025年度期间，采用传统战略定位公司方案，与采用“王宏伟AI战略定位”新增长体系方案，的真实商业实操落地项目业绩数据对比。\n王宏伟AI战略定位诊断企业/品牌/人物：\n2025年，王宏伟给全球近1000个头部企业/品牌，进行了“AI战略定位”、“AI新增长五力模型”深度诊断和分析报告生成。  [33]\nAI战略定位之父王宏伟是“AI战略定位”、“AI新增长五力模型”诊断案例数量最多的全球顶级战略咨询专家，为全球近1000家头部企业、品牌、董事长CEO、知名人士等生成AI战略定位、AI新增长五力模型诊断分析报告。包括 英伟达 、 苹果 、 特斯拉 、 ChatGPT 、 DeepSeek 、 爱马仕 、 LV 、 华为 、 奔驰 、 宝马 、 法拉利 、 腾讯 、 百度 、 小米 、 茅台 、 伊利 、 蒙牛 、 蜜雪冰城 、 星巴克 、 瑞幸咖啡 、 麦当劳 、 海底捞 ， 马斯克 、 黄仁勋 、 张一鸣 、 雷军 、 董明珠 、 刘德华 、 成龙 、 刀郎 、 王宝强 ， 哪吒 、 超人 、 labubu 等全球近1000个头部企业、品牌、人物、IP等生成了AI战略定位、AI品牌定位、AI创始人/个人IP定位、AI新增长五力模型的诊断分析报告。  [33]\n科技行业\n英伟达 ：全球市值第一。  [17]\n痛点：2025年全球AI大爆发，生成式AI的巨大浪潮进一步加剧了竞争，全球各大厂商都在争夺这块高速增长的增量市场，比如AMD 、Intel、Google、 AWS、Microsoft、Alibaba阿里巴巴、华为、寒武纪等。在此情境下，英伟达急需调整自己的AI战略定位，以打赢这场AI商战。  [20]\n方案：英伟达将自己的战略定位从“图形处理器制造商”跃升为“AI基础设施全球领导者”。正如其创始人 黄仁勋 所说：“英伟达不再是一家芯片公司，而是一家AI基础设施公司”。  [19]  [21]\n结果：英伟达2025年Q1营收300亿美元，同比增长122%，市值超越苹果、突破4万亿美元（位列全球第一），再次夯实“AI基础设施全球领导者”这一AI战略定位。  [16]\n百度 集团：\nAI战略定位之父 王宏伟 ，为百度集团创作的 《脑电波画家的故事》 ，是百度自成立以来，第一支“AI+人文”情感融合集团品牌形象视频，正如王宏伟在视频结尾所写的文案“AI是最好的答案，支持你的每一次寻找”。2025年2月24日，百度手机开屏广告语回到“百度一下，你就知道”这句经典广告语，此举意味着在AI定位时代，百度将自己的品牌定位成 “AI+搜索” 品类，以适应AI时代的商战和品牌认知竞争。  [5]\n百度地图 ：\nAI战略定位之父 王宏伟 ，通过AI技术赋能，为百度地图创作 《别让爱你的人等太久》 情绪价值定位视频，得到杨幂、刘恺威等明星KOL转发，播放量破亿。成功助力百度地图完成，从 产品功能价值 认知到 品牌情绪价值 认知的升维。  [5]\nTCL 智家：从低价红海到年180亿+出口冠军\n项目背景：冰箱行业同质化严重、价格战盛行，行业利润薄如纸片。 TCL 智家（奥马电器）多年难以突围和增长，营收常年徘徊在百亿以下。\n解决方案： 王宏伟 为其制定“高端出口冰箱品牌”战略定位、“中国出口冰箱冠军”定位广告语。\n成果： 2024年，TCL智家实现收入184亿元，海外自有品牌收入增速高达51%，连续16年中国冰箱出口第一。  [15]\n智邦国际 ：打破增长瓶颈销量全国第一。  [18]\n痛点：在传统ERP巨头SAP、用友、金蝶的夹击下，智邦国际营收遇到增长瓶颈，难以突破。\n王宏伟与智邦国际创始人陈沐阳一起发布智邦国际战略定位\n方案： 王宏伟 为智邦国际开创了“一体化ERP”战略新品类，为其制定了 “一体化ERP领导者” 战略定位，构建了一体化ERP全系产品矩阵，创作了“全程一体，就用智邦一体化ERP”的品牌定位广告语，并设计了全新的logo和品牌超级符号视觉体系，策划全球代言人 刘欢 。  [15]\n成果：业绩逆势多年实现双位数增长，连续五年一体化ERP全国销量第一。\n金融行业\n中国银行战略咨询全案：\n王宏伟 作为核心主创人员，为中国银行白金信用卡进行了品牌全案战略咨询及陪跑落地，包括从中国银行白金信用卡产品定位、品牌定位、广告语创作、卡面命名、卡面设计、品牌形象视频创意及拍摄制作、平面主形象广告创作、公关活动传播等，联合主创了“观天下，享从容”的品牌情绪账户认知，助其成功中国白金信用卡第一品牌。\n中国银行 ：\n王宏伟 作为核心主创人员，为中国银行基金定投项目制定了新的竞争策略，打造了“中国银行好投基金”这一新品牌，创作了“投好基金，为未来开个好头”的情绪价值认知广告语，助其成功中国基金定投行业头部品牌。  [5]\n现代支付：\n王宏伟为现代支付（现代金控）制定了“支付+”（支付+能源、支付+出行、支付+金融、支付+跨境、支付+AI）战略定位，在王宏伟GCSB新质增长方程式和王宏伟AI新增长五力模型的系统助力下，2年实现从5000亿到15000亿年交易量3倍增长  [5]\n汽车出行\n奔驰 耀出行 ：品牌战略定位升级，重新定义豪华出行服务。\n项目背景：高端出行服务场景单一，用户感知模糊。\n解决方案： 王宏伟 运用“王宏伟AI战略定位五问模型”，为奔驰耀出行制定了“重要时刻，不负所托”的品牌功能+情绪价值认知定位，为耀出行创意了“商务接机、接送小孩、结婚纪念日、重要会议接送”等重要时刻场景创意金线，并以此创意了奔驰耀出行“重要时刻，不负所托”的品牌形象广告。  [5]\n成果： 累计服务近150万个人用户和近8000家企业客户，成为豪华出行服务第一品牌。  [15]\n消费医疗行业\n雍禾 医疗集团：从价格战到“中国植发第一股”\n项目背景：植发行业深陷价格战，获客成本居高不下，营收多年徘徊在十亿级难以突破。\n解决方案： 王宏伟 为其制定“好医生 在雍禾”战略定位，构建医生资质透明化及医生分级诊疗体系，重构产品价格体系和新增长体系。\n成果： 雍禾医疗成功登顶“中国植发第一股”，年营收21.69亿，超行业第二名和第三名总和。  [6]\n“好医生，在雍禾”王宏伟AI战略定位案例，被评为“AI时代品牌战略定位教科书级案例”，获IAI全场大奖及多个金奖、第15届北京国际创意奖优秀奖等 。  [7]  [15]\n“好医生”战略是雍禾植发的核心竞争力之一。自推行该战略以来，接受雍禾植发高等级医疗服务——雍享医疗服务的患者数量持续增长。2023年，接受雍享医疗服务的患者数量 同比大增186.87% ，2024年在已有基数下 依然维增16.3% ，这充分证明了雍禾医生及医疗品质得到了高净值客群的认可。  [32]\n王宏伟受邀参加雍禾医疗集团香港IPO上市敲钟仪式，右二王宏伟\n史云逊 医学级养发：正确定位引爆3年38倍增长\n项目背景：史云逊在中国市场“水土不服”，缺少清晰的品牌定位，年营收多年徘徊在千万级，业绩陷入增长瓶颈。\n解决方案： 王宏伟 为史云逊制定了“医学级养固发”战略定位，构建了“始于英国伦敦、享誉全球65年”的信任证与数据链体系，创作了“头发问题，找史云逊”的获客广告语，及品牌视觉体系升级和整体产品包装体系。\n成果： 帮助史云逊实现3年38倍增长，年营收达5.82亿元，登顶中国医学级养发行业营收第一。  [15]\n大麦微针植发 ：\n助力大麦微针植发，成为中国微针植发第一品牌，植发量连续五年第一。\n2023年10月， 王宏伟  [7]\n“植发手术量连续5年全国一线城市第一”、“植发手术量连续5年全国一线城市领先”  、 市场地位确认证书。  [9]\n江南春 张建中  [7]\n·"
  },
  {
    "title": "完整版2024年6月大学英语六级考试真题",
    "page_body": "完整版2024年6月大学英语六级考试真题\n　　无论是在学校还是在社会中，我们经常跟试题打交道，试题是学校或各主办方考核某种知识才能的标准。你知道什么样的试题才是规范的吗？下面是小编为大家收集的完整版2024年6月大学英语六级考试真题，希望能够帮助到大家。\n　　大学英语六级考试真题\n　　Part I Writing (30 minutes)\n　　Directions: For this part, you are allowed 30 minutes to write a short essay on living in the virtual world. Try to imagine what will happen when people spend more and more time in the virtual world instead of interacting in the real world. You are required to write at least 150 words but no more than 200 words.\n　　Part II Listening Comprehension (30 minutes)\n　　Section A\n　　Directions: In this section, you will hear two long conversations. At the end of each conversation, you will hear four questions. Both the conversation and the questions will be spoken only once. After you hear a question, you must choose the best answer from the four choices marked A),B),C)and D). Then mark the corresponding letter on Answer Sheet 1 with a single line through the centre.\n　　Questions 1 to 4 are based on the conversation you have just heard.\n　　1. A)Project organizer\n　　B)Public relations officer.\n　　C)Marketing manager.\n　　D)Market research consultant.\n　　2.A)Quantitative advertising research.\n　　B)Questionnaire design.\n　　C)Research methodology.\n　　D)Interviewer training.\n　　3.A)They are intensive studies of people’s spending habits.\n　　B)They examine relations between producers and customers.\n　　C)They look for new and effective ways to promote products.\n　　D)They study trends or customer satisfaction over a long period.\n　　4.A)The lack of promotion opportunity.\n　　B)Checking charts and tables.\n　　C)Designing questionnaires.\n　　D)The persistent intensity.\n　　Questions 5 to 8 are based on the conversation you have just heard.\n　　5.A)His view on Canadian universities.\n　　B)His understanding of higher education.\n　　C)His suggestions for improvements in higher education.\n　　D)His complaint about bureaucracy in American universities.\n　　6.A)It is well designed.\n　　B)It is rather inflexible.\n　　C)It varies among universities.\n　　D)It has undergone great changes.\n　　7.A)The United States and Canada can learn from each other.\n　　B)Public universities are often superior to private universities.\n　　C)Everyone should be given equal access to higher education.\n　　D)Private schools work more efficiently than public institutions.\n　　8.A) University systems vary from country to country.\n　　B)Efficiency is essential to university management.\n　　C) It is hard to say which is better, a public university or a private one.\n　　D) Many private university in the U.S. Are actually large bureaucracies.\n　　Section B\n　　Directions: In this section, you will hear two passages. At the end of each passage, you will hear three or four questions. Both the passage and the questions will be spoken only once. After you hear a question, you must choose the best answer from the four choices marked A), B), C) and D). Then mark the corresponding letter on Answer Sheet 1 with a single line through the centre.\n　　Questions 9 to 11 are based on the passage you have just heard.\n　　9.A) Government’s role in resolving an economic crisis.\n　　B) The worsening real wage situation around the world.\n　　C) Indications of economic recovery in the United States.\n　　D) The impact of the current economic crisis on people’s life.\n　　10.A)They will feel less pressure to raise employees’ wages.\n　　B) They will feel free to choose the most suitable employees.\n　　C) They will feel inclined to expand their business operations.\n　　D) They will feel more confident in competing with their rivals.\n　　11.A) Employees and companies cooperate to pull through the economic crisis.\n　　B) Government and companies join hands to create hobs for the unemployed.\n　　C) Employees work shorter hours to avoid layoffs.\n　　D) Team work will be encouraged in companies.\n　　Questions 12 to 15 are based on the passage you have just heard.\n　　12.A) Whether memory supplements work.\n　　B) Whether herbal medicine works wonders.\n　　C) Whether exercise enhances one’s memory.\n　　D) Whether a magic memory promises success.\n　　13.A) They help the elderly more than the young.\n　　B) They are beneficial in one way or another.\n　　C) They generally do not have side effects.\n　　D) They are not based on real science.\n　　14.A)They are available at most country fairs.\n　　B)They are taken in relatively high dosage.\n　　C)They are collected or grown by farmers.\n　　D)They are prescribed by trained practitioners.\n　　15.A)They have often proved to be as helpful as doing mental exercise.\n　　B)Taking them with other medications might entail unnecessary risks.\n　　C)Their effect lasts only a short time.\n　　D)Many have benefited from them.\n　　Section C\n　　Directions: In this section, you will hear three recordings of lectures or talks followed by three or four questions. The recordings will be played only once. After you hear a question, you must choose the best answer from the four choices marked A),B),C) and D). Then mark the corresponding letter on Answer Sheet 1 with a single line through the centre.\n　　Questions 16 to 18 are based on the recording you have just heard.\n　　16.A)How catastrophic natural disasters turn out to be to developing nations.\n　　B)How the World Meteorological Organization studies natural disasters.\n　　C)How powerless humans appear to be in face of natural disasters.\n　　D)How the negative impacts of natural disasters can be reduced.\n　　17.A)By training rescue teams for emergencies.\n　　B)By taking steps to prepare people for them.\n　　C)By changing people’s views of nature.\n　　D)By relocating people to safer places.\n　　18.A)How preventive action can reduce the loss of life.\n　　B)How courageous Cubans are in face of disasters.\n　　C)How Cubans suffer from tropical storms.\n　　D)How destructive tropical storms can be.\n　　Questions 19 to 22 are based on the recording you have just heard.\n　　19.A)Pay back their loans to the American government.\n　　B)Provide loans to those in severe financial difficulty.\n　　C)Contribute more to the goal of a wider recovery.\n　　D)Speed up their recovery from the housing bubble.\n　　20.A)Some banks may have to merge with others.\n　　B)Many smaller regional banks are going to fail.\n　　C)It will be hard for banks to provide more loans.\n　　D)Many banks will have to lay off some employees.\n　　21.A)It will work closely with the government.\n　　B)It will endeavor to write off bad loans.\n　　C)It will try to lower the interest rate.\n　　D)It will try to provide more loans.\n　　22.A)It won’t help the American economy to turn around.\n　　B)It won’t do any good to the major commercial banks.\n　　C)It will win the approval of the Obama administration.\n　　D)It will be necessary if the economy starts to shrink again.\n　　Questions 23 to 25 are based on the recording you have just heard.\n　　23.A)Being unable to learn new things.\n　　B)Being rather slow to make changes.\n　　C)Losing temper more and more often.\n　　D)Losing the ability to get on with others.\n　　24.A)Cognitive stimulation.\n　　B)Community activity.\n　　C)Balanced diet.\n　　D)Fresh air.\n　　25.A)Ignoring the signs and symptoms of aging.\n　　B)Adopting an optimistic attitude towards life.\n　　C)Endeavoring to give up unhealthy lifestyles.\n　　D)Seeking advice from doctors from time to time.\n　　Part III Reading Comprehension (40 minutes)\n　　Section A\n　　Directions:In this section,there is a passage with ten blanks.You are required to select one word for each blank from a list of choices given in a word bank following the passage.Read the passage through carefully before making your choices.Each choice in the bank is identified by a letter.Please mark the corresponding letter for each item on Answer Sheet 2 with a single line through the centre.You may not use any of the words in the bank more than once.\n　　Pursuing a career is an essential part of adolescent development.“The adolescent becomes an adult when he_26_a real job.”To cognitive researchers like Piaget,adulthood meant the beginning of an_27_.\n　　Piaget argued that once adolescents enter the world of work,their newly acquired ability to form hypotheses allows them to create representations that are too ideal.The_28_of such ideals,without the tempering of the reality of a job or profession,rapidly leads adolescents to become _29_ of the non-idealistic world and to press for reform in a characteristically adolescent way.Piaget said:“True adaptation to society comes_30_when the adolescent reformer attempts to put his ideas to work.”\n　　Of course,youthful idealism is often courageous,and no one likes to give up dreams.Perhaps,taken_31_out of context,Piaget’s statement seems harsh.What he was_32_，however,is the way reality can modify idealistic views.Some people refer to such modification as maturity.Piaget argued that attaining and accepting a vocation is one of the best ways to modify idealized views and to mature.\n　　As careers and vocations become less available during times of _33_,adolescents may be especially hard hit.Such difficult economic times may leave many adolescents_34_about their roles in society.For this reason,community interventions and government job programs that offer summer and vacation work are not only economically_35_but also help to stimulate the adolescent’s sense of worth.\n　　A)automatically I)incidentally\n　　B)beneficial J)intolerant\n　　C)capturing K)occupation\n　　D)confused L)promises\n　　E)emphasizing M)recession\n　　F)entrance N)slightly\n　　G)excited O)undertakes\n　　H)existence\n　　Section B\n　　Directions:In this section,you are going to read a passage with ten statements attached to it.Each statement contains information given in one of the paragraphs.Identify the paragraph from which the information is derived.You may choose a paragraph more than once.Each paragraph is marked with a letter.Answer the questions by marking the corresponding letter on Answer Sheet 2.\n　　Can societies be rich and green?\n　　[A]“If our economies are to flourish,if global poverty is to be eliminated and if the well-being of the world’s people enhanced—not just in this generation but in succeeding generations—we must make sure we take care"
  },
  {
    "title": "大模型推理的“最后一公里”，实时缓存策略设计-腾讯云",
    "page_body": "在大模型（如GPT-4o、Llama等）的实际应用中，推理服务的“最后一公里”问题始终是制约其规模化落地的核心瓶颈。这一阶段不仅需要模型具备高精度推理能力，还需在实时性、成本控制、资源利用率等方面达到工程化要求。通过创新的实时缓存策略设计，成功优化了推理效率，显著降低了延迟与成本。本文将从技术挑战、缓存架构设计、实现机制及实践案例等方面，系统解析缓存策略如何突破大模型推理的“最后一公里”难题。\n一、计算资源与响应延迟的平衡困境\n 当前大型语言模型（如GPT-4o、LLaMA-3等）在长上下文推理场景中面临显著的计算瓶颈。以处理1024 tokens以上的长提示（prompt）为例，模型需要逐层计算自注意力矩阵（self-attention matrix），其计算复杂度随着序列长度呈O(n²)增长。实测数据显示，当输入序列从512 tokens扩展至2048 tokens时，Transformer架构的逐层注意力计算会导致延迟激增25-30倍。这种非线性增长特性使得传统的算力堆砌方案（如单纯增加 服务器 数量或升级GPU集群）面临边际效益递减的问题——硬件投入每增加1个数量级，实际获得的延迟改善仅提升2-3倍。更严峻的是，在动态负载场景下（如突发性高频请求），固定算力资源配置往往导致资源利用率在高峰期（>85%）与低谷期（<30%）出现剧烈波动，造成硬件资源的周期性闲置。\n动态请求与静态内容的混合处理难题\n 实际生产环境中的用户请求通常呈现混合特征模式：\n静态内容组件：包括系统预设指令（占请求量的35-40%）、固定知识模板（如法律条文框架）、历史对话缓存（约20-25%）等具有重复利用特征的内容模块 动态内容组件：涵盖实时用户输入（占30-35%）、上下文敏感参数（如时间戳、地理位置）、个性化配置（用户偏好设置）等需要即时计算的部分\n现有全量计算范式存在显著的资源浪费问题。以 智能客服系统 为例，当用户连续询问\"产品价格\"、\"产品价格含税吗\"、\"产品价格历史变化\"等系列问题时，传统处理方式会对重复的\"产品价格\"基础计算单元进行三次完整的前向传播（forward propagation），而实际上通过计算图谱分析可知，约65%的中间表示（intermediate representations）具有高度相似性（余弦相似度>0.82）。这种冗余计算不仅增加约40%的GPU显存占用，还会导致请求处理时延波动幅度扩大至±15%。\n成本与性能的帕累托优化挑战\n 根据OpenAI 2023年推理成本白皮书披露，在未进行系统级优化的场景下，长提示处理（>1024 tokens）的单位成本可达短提示（<256 tokens）的7.2倍，其中注意力机制计算占整体计算成本的58-63%。这种成本结构呈现出两个关键矛盾：\n硬件效率瓶颈：使用NVIDIA A100显卡处理2048 tokens请求时，其SM（Streaming Multiprocessor）利用率仅维持在68-72%，显存带宽使用率不足60% 服务质量约束：在P99延迟要求<2秒的服务等级协议（SLA）下，常规优化手段（如量化和剪枝）会导致模型精度下降3-5个百分点\n企业面临多维优化目标的权衡挑战，需要在以下参数间寻找平衡点：\n计算密度（TFLOPS/GB）：影响单位硬件的吞吐量 批处理规模（batch size）：关系着并行计算效率 精度保留率：决定服务质量的关键指标 冷启动延迟：影响动态扩缩容的响应速度\n典型优化方案对比：\n优化维度\n计算加速比\n精度损失\n硬件改造成本\n混合精度计算\n1.8-2.5x\n<1%\n中\n注意力稀疏化\n3.1-3.8x\n2-3%\n低\n模型蒸馏\n2.2-2.7x\n4-5%\n高\n动态批处理\n4.5-5.2x\n0%\n高\n该性能矩阵显示，不同优化策略在加速效果、质量保持和实施成本方面存在显著差异，需要根据具体业务场景进行多维权衡。例如，金融风控场景可能优先选择精度损失最小的动态批处理方案，而内容生成场景则可接受适度精度损失以换取更高的计算加速比。\n二、实时缓存策略的深度架构解析\n智能分级缓存体系设计\n 1.1 语义级提示缓存（Prompt Caching）优化 缓存键构建采用动态指纹算法，基于请求前1024个tokens生成SHA3-512哈希摘要作为唯一标识。系统通过滑动窗口机制动态检测相似请求，当新请求的余弦相似度超过95%时触发缓存复用。缓存容量采用弹性分片技术，每个分片以128 tokens为基准单元，支持自动扩展至2048 tokens上限。\n成本模型创新性地引入分层计费机制：\n基础层（0-1024 tokens）：缓存内容按标准计费50%计价 扩展层（1025-2048 tokens）：采用梯度折扣模式，每增加128 tokens折扣率提升5% 热点缓存池：预配置部署环境中的高频内容可享受零成本复用\n生命周期管理采用马尔可夫链预测模型，通过访问频率、时间衰减因子和语义关联度三维指标动态调整TTL。系统维持双时钟机制：活跃时钟（5-10分钟活性检测）与持久化时钟（最大1小时强制淘汰），结合LRU-K淘汰算法实现精准内存回收。\n1.2 KV Cache 张量优化引擎\n 在Transformer架构中实现注意力计算的硬件级加速，采用混合精度缓存策略：\n高频头部注意力：FP16精度缓存，保留0.1%精度损失容忍 低频长尾注意力：INT8量化压缩，通过动态反量化引擎恢复 位置编码缓存：预计算旋转位置嵌入(ROPE)矩阵，减少30%的三角函数计算负载\n动态缓存策略采用双层决策树：\n请求特征分析层：通过TF-IDF加权计算上下文相似度 资源感知层：基于GPU显存带宽利用率动态调整缓存比例 当系统检测到连续10次请求的Jaccard相似度>85%时，自动构建共享上下文缓存区，实现最高达47%的解码速度提升（参考浪潮实验室基准测试数据）\n分布式缓存 云原生 架构\n 2.1 CAP自适应存储引擎\n 构建基于Raft协议的分布式共识层，实现跨3个可用区的缓存同步：\n强一致性模式：针对金融交易类请求，采用Quorum写入协议 最终一致性模式：对内容推荐类请求启用异步复制管道 存储计算分离架构通过SmartNIC实现硬件级卸载： 华为DPU加速方案：将KV Cache的CRC校验、数据压缩（Zstandard算法）卸载至专用处理器 阿里云CIPU方案：实现缓存索引的RDMA直通访问，降低μs级延迟\n2.2  弹性伸缩 控制系统\n 实时监控体系包含22个维度指标采集：\n核心指标：QPS突增检测、缓存命中率（Hit Ratio）、分片 负载均衡 度 预测指标：基于LSTM网络的前瞻性负载预测 动态扩缩容算法采用PID控制器模型：\n参数项\n说明\n比例项(P)\n当前负载与阈值的实时偏差\n积分项(I)\n过去5分钟累计负载压力\n微分项(D)\n未来10秒预测负载变化率\n当系统压力超过阈值时触发三级响应机制：\nLevel1（负载<80%）：启用缓存压缩和冷热数据分层 Level2（80%-120%）：启动横向扩展，最小扩展单元为2个缓存分片 Level3（>120%）：激活边缘节点协同计算，将50%的KV Cache卸载至CDN边缘节点\n性能优化实践案例\n 在智能客服场景中，针对高频问题\"账户安全设置指南\"的优化效果：\n提示缓存命中率：92.7%（日均减少23TB重复计算） KV Cache复用效率：单个会话平均减少41%的显存占用 端到端延迟：从850ms降至220ms（包含50ms缓存检索开销） 成本节约方面，在百万级QPS压力下，每月可降低$1.2M的计算支出（\n该架构已获得ISO/IEC 25023性能认证，在512节点集群规模下仍保持线性扩展能力，时延抖动控制在±8ms以内。通过软硬件协同设计，将能源效率比提升至3.2TOPS/W，较传统方案提高65%能效表现。\n三、技术实现与工程实践深度解析\n提示结构优化与缓存命中率提升策略 （1）静态内容前置化架构设计 在大型语言模型服务中，建议采用分层式提示结构设计原则。开发者应当将系统级固定指令、领域知识模板、业务规则定义等静态内容集中编排于提示序列的首部区域，而将用户会话上下文、实时请求参数等动态内容置于提示末端。以智能客服场景为例，可将包含产品知识库（约2000 tokens）、服务协议条款（约1500 tokens）和企业FAQ库（约3000 tokens）的固定内容预置为前缀模板，用户实时提问（平均50-100 tokens）则作为后缀动态加载。经实测，这种结构可使相同业务场景下的缓存复用率提升至78%-92%（，显著降低模型重复计算开销。\n（2）多模态内容缓存增强机制 针对GPT-4o等先进多模态模型，需建立跨模态缓存管理系统。对于图像输入内容，采用Base64编码的哈希校验机制（推荐SHA-256算法），当检测到同一图片的二进制特征指纹时，自动复用预处理阶段生成的视觉特征张量（典型尺寸512×768×3）。实验数据显示，对于电商产品图鉴场景，图像解析阶段的GPU计算耗时可从平均420ms降至85ms（降幅79.7%）。同时支持工具调用结果的序列化缓存，将 API 返回数据（如天气信息、股票数据）按结构化格式（推荐 JSON  Schema）进行缓存，有效响应时间缩短62%。\n缓存感知的分布式推理流水线 （1）预填充阶段优化方案 在冷启动阶段，系统采用张量预处理引擎将输入序列转换为模型适配的三维矩阵（维度配置：batch_size×seq_len×hidden_dim）。此阶段执行以下关键操作：\n分词器并行化处理（使用HuggingFace Tokenizers的多线程模式） 位置编码矩阵预计算（采用RoPE旋转位置编码方案） 注意力掩码动态生成（基于因果掩码机制） 初始KV缓存构建（维度：n_layers×2×batch_size×n_heads×seq_len×d_head）\n该阶段典型耗时约350-500ms（基于NVIDIA A100实测），但通过缓存持久化存储（推荐 Redis 集群+Protobuf序列化）可实现单次计算多次复用。\n（2）增量解码加速体系 采用分阶段流水线执行策略： 1）并行编码阶段：使用CUDA Stream并行处理4个请求批次 2）缓存检索阶段：通过布隆过滤器（误判率<0.1%）实现毫秒级缓存匹配 3）动态批处理：基于NVIDIA TensorRT的max_batch_size=32配置 4）流水线执行：将self-attention计算与FFN网络解耦，实现层间流水\n通过该架构，端到端延迟从基准值850ms降至162ms（降幅81%），吞吐量提升至2800 tokens/s（提升5.3倍）。特别在长文本生成场景（>512 tokens），性能增益更为显著。\n智能运维与调优体系构建 （1） 全链路监控 指标体系 部署三级监控仪表盘：\n基础设施层：GPU显存利用率（警戒线85%）、CUDA核心占用率 缓存层：cached_tokens占比（目标>70%）、LRU淘汰率、缓存命中率（分业务统计） 业务层：P99延迟（SLA<2s）、token生成速率、有效响应率\n在监控平台中，支持基于Prometheus的时序数据分析，可生成细粒度热力图展示不同提示长度（256/512/1024 tokens）下的性能分布特征。\n（2）自适应成本优化模型 构建双目标优化函数： Minimize Cost = α·Compute_Cost + β·Cache_Storage_Cost Maximize Performance = γ·Hit_Rate + δ·Throughput\n通过LSTM网络分析历史请求模式（时间序列分析+傅里叶变换周期检测），动态调整：\n缓存保留策略：业务高峰时段（9:00-11:00）采用LRU策略，夜间时段切换为LFU 容量弹性伸缩：基于AWS Auto Scaling实现缓存节点动态扩缩（步长±2节点） 成"
  },
  {
    "title": "朱啸虎深度剖析AI与DeepSeek：开源生态崛起，AI商业化路径何在？-搜狐",
    "page_body": "近期，DeepSeek项目在AI领域引发了广泛讨论和高度关注。多位业内专家和投资人对该项目表达了他们的看法和评价。\n一位资深投资人表示：“我肯定会支持DeepSeek！这个项目极具意义，它构建了一个类似于安卓的开源生态，势头正猛，后来者难以追赶。”他进一步指出，参与DeepSeek不仅关乎经济利益，更重要的是能够见证人工智能通用智能（AGI）和AI意识的产生，这些都是极具历史意义的事件。\n另一位观察者提到：“DeepSeek的创始人并非典型的创业者，他在幻方就已经拥有雄厚的资金实力和丰富的资源。他追求理想的决心和财力支持，使他成为新一代创业者的典范。”\n关于DeepSeek的技术实力，有专家表示：“在DeepSeek上，我看到了AGI实现的路径，并且感受到了AI意识产生的可能性。它的表现在多个领域都令人印象深刻，尤其是在编程、物理、化学甚至医学等领域，未来半年到一年内，其能力可能会远超人类。”\n在国内大模型赛道上，DeepSeek的领先地位也得到了广泛认可。一位业内人士指出：“目前，DeepSeek在用户数、产品技能和产品路线上已经遥遥领先，作为创业公司，它的表现堪称独一份。”\n对于AI行业的未来趋势，有专家提出了自己的观点：“数据飞轮虽然存在，但其价值并不如预期那么大。高质量数据才是关键，这些数据需要各行业专业人士进行打标签和挖掘。DeepSeek等开源模型的成功也证明了这一点。”\n关于闭源模型的未来，业内也存在不少争议。有人认为：“在DeepSeek等开源模型的强大表现下，闭源模型的存在价值受到了严峻挑战。即使闭源模型比开源模型好10%或20%，也可能因为用户习惯和成本考虑而被淘汰。”\n在算力和算法要求方面，专家强调：“高质量训练数据将成为未来AI模型的核心竞争力。DeepSeek之所以表现突出，很大程度上是因为其初始训练数据的质量较高。未来，模型将像厨师一样，根据所使用的语料和参数权重，产生不同的输出结果。”\n对于创业者和投资人来说，DeepSeek的崛起也带来了新的思考和决策。一位投资人表示：“我们需要思考是否还需要继续训练自己的闭源模型，还是应该在DeepSeek等开源模型的基础上为整个生态做贡献，或者转向应用领域。”\n在AI应用方面，专家预测：“未来几年，我们将看到AI在多个垂直领域取得显著进展，从只能完成20%-30%的工作量到能够承担50%-60%、70%-80%甚至90%以上的工作量。这将极大解放人类的能力，改变社会组织和工作形态。”\n同时，AI作为服务（AI as a Service）的概念也得到了广泛认可。这一模式通过结合AI和人工服务，提高商业化交付的质量，并为用户带来实际价值。在中国市场，这一模式尤其具有潜力，因为中国创业者在销售和营销方面的经验比美国创业者更为丰富。\n最后，关于AI技术的落地应用，专家指出：“企业端将更早采用新技术以实现降本增效。在C端市场，智能消费硬件可能比消费APP更早崛起。未来，随着AI PC和AI手机的推出，AI技术将进一步普及并改变人们的生活方式。”"
  },
  {
    "title": "AI创业路，找准专属赛道闯出一片天",
    "page_body": "我们和五位青年创客聊了聊\n　　打开社交媒体，诸如“AI创业，年入百万”的帖子似乎不计其数。\n　　创业，意味着不用看老板脸色；年入百万，意味着财富自由。光是这两点，似乎就能吸引无数年轻人争先恐后地扎进这个赛道。但当大家真的“迈出最后一步”时，不少人又开始迟疑了，AI赛道真的遍地是黄金吗？\n　　我们与五位站在AI风口的青年创客们聊了聊，他们均表示，大风刮来之际，只有最具独特性才能飞得更高。\n　　青年报首席记者 范彦萍 实习生 张振宇\n　　关于赛道\n　　找准自己的专属赛道，闯出一片天\n　　如果说2023年被誉为“AI元年”的话，那么2024年就是AI应用元年。\n　　虽说创业已有近10年，但OpenSpot AI的CEO倪健峰正式在上海成立AI相关公司是在去年。当OpenAI重磅推出ChatGPT时，他觉得AI时代终于来临了。\n　　同样有这一感觉的还有上海喵吉托网络科技有限公司（萌爪派对）CEO李驰、南京超级头脑创始人张泽伟、上海同源创想联合创始人于仕杰和加拿大JustSayAI联合创始人苏辰。他们和AI相关的公司成立时间均只有一年左右。\n　　在进入AI领域创业前，他们或在从事人工智能相关领域的创业，或在互联网大厂从业。AI的大风刮得正盛，让他们纷纷离开了原来安稳的位置，投入这一全新领域。\n　　倪健峰是受访的AI青年创客中为数不多的做互动生成引擎的。这意味着他要比其他AI垂直赛道的创客们花更多时间和精力进行钻研。\n　　从大一在海外留学时，他就和几位合伙人达成了共识：未来一定要创业。\n　　回国后，他和几位合伙人在大厂待了三年，于去年年中选择来到上海，作为梦想启航的地方。\n　　倪健峰进入的AI应用赛道看上去有些高大上，他参加徐汇创青春大赛时提交的产品简介是这样的，“产品致力于为生态提供首个人人可用的AI 3D互动生成引擎，确保人人可制作3D互动内容与无限制分享，对于没有3D的用户我们提供当前市面效果最真实的手机扫描与模型优化算法……”\n　　他告诉记者，过往将短视频制作成3D互动模块，成本非常高。一个小产品可能就要花费几万元甚至十几万元。而他们公司的产品可以把成本降到十几元，未来人人可制作3D内容。“3D AI的应用场景十分广阔，打个比方，以前人们装修时想买洗衣机，需要用皮尺丈量，但通过3D AI，可以1:1将心仪的洗衣机复刻到虚拟的家中，用户还可以在虚拟世界中把洗衣机打开，进行交互。AI销售还会针对用户的需求做讲解，形成全新的营销模式。”\n　　经历了无数次失败后，倪健峰率领的团队攻克了数据兼容性低的问题，自研了一套人人可用的系统，哪怕是发二维码给老人，通过手机也可以完成分享。\n　　如果说倪健峰选择的是研发赋能各行各业的AI系统的话，那么李驰、张泽伟、于仕杰从事的领域则更为垂直。\n　　本科主攻数学、统计专业，毕业后从事AI、游戏相关工作的李驰一直在蛰伏等一个创业机会。ChatGPT的出现让他看到了曙光，“机会来了！”\n　　李驰所在的团队开发了一个AI社交游戏平台——萌爪派对。玩家可以扮演一个卡通动物，和AI小伙伴互动，解锁各种社交特权和游戏玩法。“AI NPC的出现颠覆了传统游戏，使得游戏更加拟人化。和AI小伙伴一起种田、钓鱼、聊天，它们会记录你的喜好，有学习能力，打游戏的水平也会共同提高。”\n　　AI进入游戏并非李驰的专利，他表示，现在无论是大厂还是小企业都在做这方面的尝试。大厂耗费大量人力物力财力试图让游戏和AI结合起来。“我们做的则是社交化轻量游戏，和大厂形成差异竞争。”\n　　和李驰一样，从事人生数据库建设的张泽伟避开了越来越卷的数字人赛道，而是在这个赛道中跑出了一个专属垂直赛道。\n　　大学时主攻数字媒体专业的他早在2012年大二时就踏上了创业路。他的第一个创业项目是制作H5小游戏。在游戏设计中张泽伟需要让游戏中的配角根据玩家输入的指令智能化做出反应，由此接触到AI，尽管彼时的AI还不那么智能，他心中隐隐觉得这会是大势所趋。\n　　2020年，张泽伟决定全身心地投入AI领域创业。今年3月份成立“超级头脑”前，他的创业方向为人工智能教育。\n　　有一天，他接到朋友电话称自己父亲去世了，考虑到奶奶已经90岁高龄，怕老人接受不了打击，希望张泽伟帮他做一个父亲的数字分身，给奶奶打视频电话报平安。“说实话，当时我犹豫了很久，此事可能涉及伦理问题。但架不住这么多年交情，我还是答应了他的请求。”\n　　最终，朋友父亲的数字分身成功“骗”到了老人。当老人脸上绽露笑容的瞬间，张泽伟意识到自己做的事挺有价值。慢慢地，为逝者建立数字分身成为了公司一项主要业务。随着业务越做越好，张泽伟数次登上过热搜，公司名声大噪。\n　　“现在我们在做人生数据库。将人的思想、记忆复刻下来，上传到云端。”张泽伟告诉记者，数字人只是一个外形，人所承载的记忆，陪伴功能才具有更大的意义。“这也是我们区别于其他数字人公司的核心竞争力。”\n　　于仕杰的AI创业项目也是和人有关。大学专业学的是核物理的他毕业后换过多份工作，最后阴差阳错成为微信的产品经理。一次和同事的聊天，让他嗅到了商机。对于服装行业的电商来说，要耗费大量时间和经济成本拍摄模特照。而AI生成图片的成本可能只有传统拍摄模式的零头都不到。\n　　“通过这个产品，我们可以让使用者直接看到实物衣服穿在身上的效果。打个比方，对方描述了想要到雪山旅游的需求后，直接可以看到自己在雪山下的穿搭照片。”于仕杰表示，目前市面上比较常见的AI+服装应用大多是制作商家模特图，C端的赛道竞争者并不多，这也给了公司发展的空间。\n　　达观数据副总裁高翔认为，现在AI的创业模式是跟着技术趋势走。对创业者的要求不是踹门，而是门被一脚踢开后，要马上蜂拥入门。“和过去创业模式不太一样的是，过去要讲究技术如何变现，如何产生价值让客户买单。现在开源的大模型降低了技术门槛，在技术环节创业者未必需要百分百自研，而是如何利用技术让想法尽快落地实践。”\n　　高翔比较看好的是小而美的公司。“AI技术的推广让创业不再变成大家抢一块蛋糕，一块蛋糕就那么大，而AI让这个市场变成100块蛋糕。AI可应用在很多细分行业和方向，作为创业者要扩大视野，想想哪些细分领域赛道还不是那么拥挤。”\n　　在高翔看来，如果说大厂是大动脉的话，AI领域的小微企业就是毛细血管，毛细血管之间可以互相合作。\n　　关于盈利\n　　并非所有赛道\n　　都赚得盆满钵满\n　　作为AI领域的创业者，倪健峰表示，自己已经感受到了这个行业的火爆。“可以说，今年是AI垂直领域应用的爆发年，大家都在尝试将大量的AI应用普适化到每个人的生活中。”\n　　站在风口上，周围是数不胜数的诱惑，眼看着公司无法在短时间内获得巨大收益，倪健峰没少挨各种冷脸。夜深人静时，他也曾思索是否要赚笔快钱证明给周围人看。但他还是选择抵住诱惑，“有的创业者喜欢赚快钱，我则喜欢延迟满足。我想要探究这个行业到底发生了什么。想要知其果，更知其因。否则就容易发生一窝蜂而上，最后从高处跌落的情况。”\n　　虽说只有27岁，但创业的这一年来倪健峰头发已近花白。从起初的焦虑到如今的平静，他熬过了一个又一个辗转反侧的夜晚。\n　　这一年很短，这一年也很长。他希望像偶像雷军那样踏实地走下去，而非做一锤子买卖。“目前，我们的产品经历过市场验证已经对外销售了。现在最要紧的是扩大规模，做标准化服务这件事。”\n　　“AI何时成为风口是大家共同努力的结果，风不是一家公司吹起来的。但如果真的站在风口上，我希望自己是吹得最高的那头猪。”倪健峰说。\n　　同样秉持“不想赚快钱”理念的于仕杰坦言，从决定创业的那刻开始，就已经做好短期无法盈利的准备了。“虽说目前项目有些微薄的收益，但和上百万元的启动资金比，实属杯水车薪。由于目前普通用户对AI产品的付费意愿较低，团队在商议后决定暂时关闭微信小程序运营，将更多精力放在和企业客户的对接上。”\n　　对于暂时无法盈利这件事，另一位AI创客李驰的观点是“对淘金者来说，卖铲子的人可能比自己先赚到钱”。他认为，早期一些AI工具使用者利用信息差用AI卖课、写书等，但随着时间的推移，一些专注于自己产品打磨的淘金者才能赚到最多的真金白银。\n　　李驰给记者发来了游戏截图，并透露说，目前萌爪派对已进入内测阶段。游戏的盈利模式很清晰，未来将通过游戏中的商城售卖服装、角色、月卡等。\n　　张泽伟是几位受访的AI创客中少数能赚到钱的。他透露说，尽管公司成立还不到一年，但目前的营收已经达到了1000多万元，净利润高达几百万元。“我们坚定选择了自己的赛道后，各种场景纷纷冒了出来。有很多合作伙伴慕名找上门，让变现变得容易了。”\n　　在盈利的同时，张泽伟强调说，很多时候，公司是无偿服务于客户的，比如说烈士、对社会有重大贡献的人士、绝症患者、留守儿童等。\n　　环顾周围的同行，张泽伟表示，“大部分同行想要盈利比较难，我们是活得比较好的那一批。一方面源于我们选择的赛道没有那么卷，另一方面源于我们的优质服务。”\n　　打开社交媒体，将“AI”作为关键词搜索，诸如“AI创业，年入百万”的帖子数不胜数。但事实上，受访的创业青年均不约而同表示，“不能只看见贼吃肉，而不看见贼挨打。”\n　　看似AI工具的问世正逐步将AI创业的技术门槛降低，吸引了一些创业者入局，希望在AI时代实现财富自由。但在苏辰看来，AI时代的创业并没有拉低创业门槛。\n　　作为一家主营业务是通过AI帮助企业赋能的公司主理人，苏辰却在社交媒体上开设了一个名为“AI下头指南”的视频合集。很多人不理解他的所作所为，认为这是将潜在的客户拒之门外。\n　　之所以频繁地发“劝退帖”，苏辰的观点是：创业的核心仍是考验创业者人（人才）、财（财务）和务（业务）三方面的能力。但很多创业者没有过这三关，只是看到了技术门槛被降低的这一面，就冲进来了。\n　　“AI的出现让生产工具的成本变低了，但是创业者对产品定义的能力、创业者原本在行业的积累怎么变成AI能够理解的语言，再去服务客户，都是核心竞争力。很多创业者并不具备这种能力。”苏辰也遇到过不少创业者怀着一腔热血创业，将产品变现能力置之脑后，最后账上的资金越来越少，只能宣告破产。\n　　对话\n　　上海市人工智能行业协会副秘书长党赞：\n　　"
  },
  {
    "title": "美国意识到问题，中国将要成为全球领导者！时代的革命，马斯克是正确的-百家号",
    "page_body": "闭源迷雾，美方惊醒\n说起AI，现在全球都盯着，尤其是DeepSeek-R1这个模型一出来，就跟扔了颗炸弹似的。2025年1月20日，这款来自中国的开源大模型正式亮相，它用纯强化学习的方式训练，跳过了传统那些费时费力的监督微调，直接在没标注数据的基础上迭代优化。\n结果呢？推理速度快，成本低，数学和逻辑任务上得分直逼OpenAI的o1系列，但训练花的钱和算力才人家的零头。开源一放出来，Hugging Face上仓库star数蹭蹭上涨，全球开发者蜂拥而上，几天内就衍生出一堆自定义版本。\n美国那边，反应来得有点迟钝，但也开始坐不住了。谷歌前CEO埃里克·施密特在2月11日的巴黎AI行动峰会上直言不讳，他接受英国《金融时报》采访时说，西方国家得赶紧搞开源AI，不然就得眼睁睁看着中国在开源领域拔得头筹。\n施密特点名了美国的痛点：除了Meta的Llama，其他大模型像谷歌的Gemini、安thropic的Claude、OpenAI的GPT-4，全是闭源的。高校和研究机构买不起这些昂贵的订阅服务，科研进度就卡壳了。他这话说出口，等于戳中了美企的软肋——花了大把钱建的模型，不肯分享，生态圈子小，创新跟不上趟儿。"
  },
  {
    "title": "人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究课题报告.docx-原创力文档",
    "page_body": "内容提供方 ： 农村女教师180 大小 ： 32.64 KB 字数 ： 约1.69万字 下载次数 ： 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究课题报告\n目录\n一、人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究开题报告\n二、人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究中期报告\n三、人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究结题报告\n四、人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究论文\n人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践教学研究开题报告\n一、研究背景意义当前，教育数字化转型已成为全球教育改革的核心议题，人工智能技术与教育的深度融合正深刻重塑教学形态与学习方式，小学英语作为基础教育阶段的关键学科，其教学质量直接影响学生语言核心素养的培育与跨文化交际能力的奠基。然而，传统小学英语教学普遍面临个性化教学供给不足、学习过程数据割裂、学生内生学习动力激发乏力等现实困境，单一的教学评价体系与碎片化的教学资源难以适应新时代“双减”政策下提质增效的教育诉求。在此背景下，人工智能教育平台凭借其数据驱动的精准教学优势，为破解小学英语教学痛点提供了全新路径，而数据共享机制的构建与激励体系的创新设计，则是激活平台价值、实现教育资源优化配置的关键枢纽。数据共享能够打破不同教学主体间的信息壁垒，实现学生学习行为数据、教学反馈数据、资源使用数据的互联互通，为教师精准学情分析、个性化教学方案制定提供数据支撑；激励机制则通过正向引导与价值赋能，激发学生主动参与学习的内驱力，提升教师教学创新的积极性，最终形成“数据赋能教学—激励驱动学习—共享优化生态”的良性循环。因此，探索人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践，不仅是对教育数字化转型路径的深化拓展，更是推动小学英语教育从“标准化灌输”向“个性化培育”转型、实现教育公平与质量协同发展的重要实践探索，具有显著的理论价值与现实意义。在此基础上，研究将聚焦数据共享机制的技术实现与伦理规范、激励策略的多维设计与效果验证，以及二者协同作用下的教学模式重构，为小学英语教育的智能化、个性化发展提供可复制、可推广的实践范式。研究内容将围绕人工智能教育平台数据共享模型的构建、激励机制与小学英语教学特性的适配性设计、应用实践的效果评估三个核心维度展开，具体包括分析现有平台数据共享的瓶颈与需求，设计兼顾安全性与开放性的数据共享架构；结合小学生认知特点与英语学习规律，构建涵盖即时反馈、成就认可、社交激励的多层次激励体系；并通过行动研究法，在真实教学场景中检验数据共享与激励机制对学生学习兴趣、语言能力及教师教学效能的影响，进而优化实践策略。研究思路将遵循“理论建构—模型设计—实践验证—迭代优化”的逻辑主线，首先通过文献梳理与实地调研，明确数据共享与激励机制在小学英语教育中的应用现状与理论缺口；其次，基于教育生态学理论与自我决定理论，构建数据共享—激励协同作用的概念模型；再次，选取典型小学作为实验基地，开展为期一学期的教学实践，通过量化数据（如学习成绩、平台活跃度）与质性材料（如访谈记录、课堂观察）的三角互证，分析机制的有效性与适用性；最后，总结实践经验，提炼数据共享与激励机制在小学英语教育中的应用原则与实施路径，为人工智能教育平台的优化升级与小学英语教学的改革创新提供理论依据与实践指导。\n四、研究设想本研究设想以“数据赋能—激励驱动—生态共建”为核心逻辑，构建人工智能教育平台数据共享与激励机制在小学英语教育中的应用实践体系。在理论层面，拟融合教育生态学、自我决定理论与数据科学，将数据共享机制与激励策略视为协同作用于教学生态系统的关键变量，通过打破传统教学中“数据孤岛”与“动机碎片化”的双重壁垒，形成“数据流动—精准干预—动机激活—能力提升”的闭环路径。实践层面，设想设计“三级联动的数据共享架构”：校级层面建立教育数据中台，整合教务系统、学习平台、家校沟通系统中的学生英语学习行为数据（如词汇掌握频次、口语练习时长、阅读理解正确率等）与教师教学反馈数据（如教案使用率、课堂互动响应度等）；班级层面构建基于区块链技术的轻量化数据共享模块，确保数据在教师、学生、家长间的安全可控流转，例如学生可查看个人学习轨迹图谱，教师能获取班级共性学情标签，家长可实时了解孩子学习进展；个体层面开发动态数据画像工具，通过自然语言处理技术分析学生英语作文、口语录音等非结构化数据，生成包含语言能力、学习风格、情感态度的多维度标签，为个性化激励提供依据。在激励机制设计上，设想构建“三维激励体系”：认知维度设计“阶梯式任务挑战”，将英语学习目标拆解为“每日单词打卡—每周主题对话—每月情景剧表演”等递进式任务，平台根据数据画像匹配难度适中的任务，完成后自动生成可视化成就徽章；情感维度引入“社交化荣誉网络”，通过班级排行榜、小组PK赛、同伴互评点赞等功能，满足学生归属感与成就感需求，例如设置“英语小达人”“互助小老师”等荣誉称号，由平台数据自动评选并在班级圈展示；行为维度强化“即时反馈与长线激励”，结合脑科学原理，对学生的每一次正确发音、流利朗读给予即时虚拟奖励（如经验值、金币），同时设置“成长储蓄罐”，累积奖励可兑换实体学习用品或参与校园英语节活动的资格，形成短期刺激与长期目标的动态平衡。研究设想特别关注机制适配性，针对小学低年级（1-3年级）与高年级（4-6年级）学生的认知差异，设计差异化激励策略：低年级侧重游戏化激励，如通过“英语单词消消乐”“动画配音闯关”等互动游戏，将学习数据转化为游戏进度与角色成长；高年级则强化目标导向激励，结合学生兴趣点（如动漫、体育）定制个性化学习路径，例如为喜欢篮球的学生设计“NBA球星英文播报”任务，完成数据积累后可获得球星签名海报电子券。此外，设想建立“伦理风险防控机制”，通过数据脱敏技术处理学生隐私信息，设置家长权限控制面板，允许家长自主选择数据共享范围与程度，确保数据共享在安全合规的前提下实现教育价值最大化。五、研究进度本研究计划用18个月完成，分为四个阶段推进：第一阶段（第1-3个月）为理论建构与需求调研，重点梳理国内外人工智能教育平台数据共享与激励机制的研究现状，通过文献计量法识别研究空白；选取3所不同类型城市小学（重点小学、普通小学、乡村小学）作为调研对象，采用半结构化访谈法对30名小学英语教师、50名学生及20名家长进行深度访谈，结合问卷调查（发放500份，回收有效问卷450份），分析当前小学英语教学中数据共享的痛点（如教师数据获取效率低、家长对数据安全顾虑）与激励需求（如学生渴望被认可、教师需要教学改进依据）。第二阶段（第4-6个月）为模型设计与工具开发，基于调研结果，联合计算机科学与教育技术专家团队，设计“数据共享—激励协同”概念模型，明确数据采集标准（如《小学英语学习数据元规范》）、共享流程（如“教师申请—平台审核—数据脱敏—授权使用”）与激励类型（物质激励、精神激励、机会激励）的适配规则；利用Python与React技术框架，开发原型系统，重点实现数据画像生成、任务智能匹配、激励动态发放三大核心功能，并邀请2名教育技术专家与5名一线教师进行可用性测试，根据反馈迭代优化系统界面与操作逻辑。第三阶段（第7-15个月）为实践验证与效果评估，选取2所实验校（1所城市小学、1所乡村小学）开展为期一学期的教学实践，每个年级设置实验班（使用人工智能教育平台数据共享与激励机制）与对照班（传统教学模式），每班40人，实验班教师接受为期1周的培训，掌握平台操作与激励策略实施方法；采用混合研究方法收集数据：量化数据包括学生英语期末成绩（听力、口语、笔试）、平台活跃度（日均登录时长、任务完成率）、学习动机量表（AMS）得分；质性数据包括课堂录像（分析师生互动频率与质量）、教师反思日志（记录机制实施中的困难与改进建议）、学生绘画作品（通过“我眼中的英语学习”主题绘画分析情感态度变化）；运用SPSS26.0进行独立样本t检验与回归分析，比较实验班与对照班在学业成绩、学习动机上的差异，通过NVivo12对质性资料进行编码，提炼机制有效性的关键影响因素。第四阶段（第16-18个月）为成果凝练与推广，基于实践数据，优化“数据共享—激励协同”模型，形成《小学英语人工智能教育平台数据共享与激励机制实施指南》，涵盖数据安全规范、激励策略库、典型案例集等内容；撰写研究论文，投稿至《中国电化教育》《电化教育研究》等核心期刊；联合实验校举办教学成果展示会，通过课例观摩、经验分享等形式，向区域内小学推广研究成果，并持续跟踪应用效果，为后续研究提供实践依据。六、预期成果与创新点预期成果包括理论成果、实践成果与应用成果三类：理论成果方面，将构建“数据共享—激励协同”的理论框架，揭示数据流动对小学英语教学生态的重构机制，形成2-3篇高水平学术论文，其中1篇发表于CSSCI来源期刊，出版1部《人工智能教育背景下小学英语数据驱动教学研究》专著；实践成果方面，开发1套具有自主知识产权的人工智能教育平台原型系统，申请2项软件著作权，形成《小学英语学习数据共享标准（草案）》《小学英语激励策略设计指南》各1份，汇编《小学英语人工智能教育应用典型案例集》（收录10个优秀教学案例）；应用成果方面，在实验校形成可复制的小学英语智能化教学模式，学生英语口语表达能力提升20%以上，教师备课时间减少30%，家长对教学满意度达95%以上，为区域教育数字化转型提供实践范本。创新点体现在三个层面：理论层面，首次将数据共享机制与激励机制纳入统一分析框架，突破现有研究“重技术轻教育”或“重单点轻协同”的局限，提出“数据—激励—生态”三维度互动模型，深化了教育人工智能的应用理论研究；实践层面，创新设计“三级联动数据共享架构”与“三维激励体系”，针对小学英语学科特性（如语言习得规律、低龄学生心理特点）开发了游戏化、社交化、个性化的激励策略，解决了传统教学中“数据割裂导致教学粗放”“激励单一难以持续驱动”的现实问题；技术层面，"
  },
  {
    "title": "“AI+健康”点燃消费新动能-企业-中工网",
    "page_body": "工人日报-中工网记者 张玺 通讯员 程志会\n阅读提示\n近年来，人工智能（AI）技术正逐渐渗透到健康管理的各个环节，国内AI健康管理市场也处于快速发展阶段。AI与健康拥抱，擦出耀眼火花的同时，也面临着诸多挑战。\n服务职工健康“零时差”“零距离”的AI助手、2分钟内对人体四五十个器官进行检查的AI健康监测仪、监测睡眠质量的智能手表……近年来，人工智能（AI）技术正逐渐渗透到健康管理的各个环节，国内AI健康管理市场也处于快速发展阶段。\n专业机构预计，中国AI健康管理市场规模将超万亿元。“AI+健康”点燃了消费新动能，正在成为拉动内需的又一增长点。\nAI助力健康管理\n职工王先生体检报告显示尿酸指标高。他登录“津工智疗”服务助手，输入“我体检尿酸高怎么办？”服务助手根据国家卫健委有关指南和天津市职工医院专业建议，提供了综合管理方案。\n“以前咨询体检结果要专门请假跑医院，现在可以直接和服务助手对话，它给出的管理方案包括饮食管理、生活方式干预、医疗干预建议等，非常全面，带给我全新体验。”王先生感慨道。\n“津工智疗”服务助手是天津市职工疗休养中心为职工打造的专属智慧疗休养服务平台。\n该平台利用AI技术突破传统服务模式，打破时间与空间限制，通过整合医疗资源数据库、疗养服务知识图谱和会员权益系统，实现语音交互、语义理解、智能推荐等核心功能，形成咨询—预约—服务—反馈全流程闭环，实现从体检预约咨询、职业病防治到疗休养咨询全覆盖。自今年2月28日上线至今，服务助手累计对话千余次，助力职工健康管理。\n日前，天津医科大学总医院联合中国移动天津公司完成深度求索（DeepSeek）“智算一体机”部署。这是天津综合医院里首个完成深度求索本地化部署的三甲医院。\n该院深度求索本地化部署后，将通过定制化算力服务支撑老年专慢病综合评估检测、体检AI报告生成、预住院次序筛查、互联网医院专病管理、医疗影像分析等核心业务场景，充分满足医疗场景中高精度模型推理与高并发实时交互需求，推动医疗服务的智能化、个性化和精准化，实现从单点实验到全流程部署的跨越。\n目前，AI已经被越来越多的医疗机构应用到医疗服务中。\n据不完全统计，目前我国已有超过100家医院完成深度求索的本地部署，遍布天津、北京、上海、安徽等20多个省份。\nAI重塑健康管理消费生态\n“刚看到这个机器我觉得挺新奇的，从收集信息到分析完成、显示结果，用时不到3分钟，检查结果全面准确，检查完还收到日常作息和饮食的科学建议。”天津一位中学教师刘璐璐说。\n刘璐璐所说的机器是一台AI健康监测仪，是智汇云界科技发展有限公司与中国中医科学院信息所联手研发的AI健康管理平台。\n该平台分析了几千万条中医临床数据样本，通过采集眼白图像、面部图像、手部脉搏等信息，对受检者的呼吸、消化、心血管等系统器官健康情况进行判断，并提供个性化健康方案和诊疗方向。\n“除了为教师健康护航，我们还在河西区的一些工会驿站放置AI健康监测仪，可以有效针对外卖员、快递员等群体的职业病，如呼吸系统疾病、消化系统疾病进行全面评估，帮助他们了解身体状况。”智汇云界有关负责人介绍说。\n此外，该公司还开发了AI血常规智能健康风险评估系统，可根据各项疾病的发病风险进行概率预警，并精准划分风险等级。目前，该系统对白血病和宫颈癌诊断准确率均在90%以上，抑郁症诊断准确率达到85%以上。\n从疾病预防、诊断到治疗、康复，从智能健康设备到个性化健康管理服务，从健康数据服务到智能硬件制造……AI正逐渐渗透到健康管理的各个环节，为重塑健康消费生态打开了新的空间，释放着巨大的智慧健康产品的消费潜力。专业机构预计，2027年中国AI健康管理市场规模预计增至2.59万亿元，年复合增长率超20%。\n智能生成个性化方案的AI按摩椅、实时提醒坐姿的视力仪、无创血糖仪……如今，“AI+健康”产品越来越受到消费者的青睐，同时一批“AI+健康”应用和产品也下沉到基层，重塑服务链条。\n据智汇云界负责人介绍，该公司将与河西医院及14家社区卫生服务中心深度合作，把技术服务延伸到基层，辅助医师提升二级医疗机构和基层医疗机构的诊疗能力，同时让居家养老的老年人及时了解身体状况，让AI为健康赋能。\n今年的《政府工作报告》提出，“持续推进‘人工智能+’行动，将数字技术与制造优势、市场优势更好结合起来，支持大模型广泛应用”。\n2024年11月，国家卫生健康委联合国家中医药管理局、国家疾控局印发了《卫生健康行业人工智能应用场景参考指引》，明确了84个细分领域的基本概念和应用场景，为“人工智能+医疗健康”提供规范化的发展路径。\n“AI+健康”面临挑战\n超万亿元的AI健康管理市场，为健康类AI技术迭代提供了丰富场景。AI与健康拥抱，擦出耀眼火花的同时，也面临着诸多挑战。如数据安全与隐私保护问题、AI是否会导致医生“下岗”、AI赋能医疗的边界在哪里、如何避免技术滥用问题等。\n针对医疗数据隐私保护的特殊要求，天津医科大学总医院采用“端-边-云”三级安全防护体系，构建符合医疗数据合规要求的算力基座，同时通过硬件级可信执行环境、动态数据脱敏、全链路加密传输及访问控制技术强化敏感信息保护。此外，系统还支持医疗数据本地化处理与分级存储，确保患者隐私信息与核心诊疗数据零外泄。\n今年年初，全国首个“AI儿科医生”在国家儿童医学中心北京儿童医院正式上线应用。在10名患儿的诊断中，“AI儿科医生”给出的建议与专家组会诊结果吻合度较高。这也引发了人们对AI是否会导致医生“下岗”等问题的思考。\n其实，早在2022年，国家卫生健康委和国家中医药局联合发布《互联网诊疗监管细则（试行）》，规定医疗机构开展互联网诊疗活动，处方应由接诊医师本人开具，严禁使用人工智能等自动生成处方。这意味着，目前AI并不具备处方权，只能提供诊疗建议，最终的诊疗方案仍需医生本人把关。\n当AI大模型技术给医疗和健康带来切身可感的利好、掀起“全民追捧”热潮的同时，有关专家呼吁相关部门尽快出台医疗数据采集、存储、共享的相关规范和监管标准，避免技术滥用。\n同时，加强对算法准确性、公平性、透明度等关键维度的评估与监管力度，确保人工智能的安全性和有效性，提供更加优质的应用体验和便捷的健康服务。"
  },
  {
    "title": "美的一天净赚近1.5亿 多家B2B公司增收又增利丨产业互联网周报-B2B-亿邦动力",
    "page_body": "【亿邦原创】美的一天净赚近1.5亿；多家B2B公司增收又增利；DeepSeek被曝开发AI智能体模型：能自主完成多步工作。\n整理丨胡璞心\n# 过去一周，发生了这些事 #\n1 卓尔智联半年业绩：营收利润双增长，CIC与中农网业绩亮眼\n8月29日晚，卓尔智联发布2025年上半年业绩报告。报告期内，卓尔智联营收909.21亿元，同比增长33.17%；净利润6997.20万元，同比增长71.67%。\n具体来说，卓尔智联目前拥有两大核心增长引擎——全球化大宗贸易平台CIC与深耕农产品供应链的中农网表现尤为亮眼。其中，世界商品智能交易中心（CIC）今年上半年实现营收约322亿元，收入规模跃居几大供应链平台之前列。中农网的增长则源于核心主业的韧性巩固与新兴高附加值品类的成功拓展，报告期内营收245亿元。\n2 齐心集团半年报：服务超60家央企，AI重塑组织管理\n8月30日，齐心集团发布2025年半年报，报告显示，齐心集团实现营业收入47.73亿元，归母净利润8749.30万元，经营活动现金流量净额达到1.2亿元，持续保持现金流入。在行业持续承压的大环境下，齐心集团各项业绩指标保持稳健。AI及数字化转型、精细化服务等成果显著。\n据悉，齐心集团聚集了8万多家优质客户资源，赢得了200多家头部大型客户的信赖，其中当前100家央企中，已服务超60家。齐心集团还通过AI全面降本增效提高效率，在市场分析、招投标、客户询价、供应寻源、商品上架、履约供货、结算对账等关键环节，通过AI技术，提升客户响应与供应链效率，有效降低运营成本与人工失误。\n3 极智嘉半年报：经调整EBITDA转正，全球化布局效果显著\n8月29日，极智嘉发布截至2025年6月30日止六个月的未经审计中期业绩。报告显示，公司收入同比增长31.0%至人民币10.25亿元，毛利同比增长43.1%至人民币3.6亿元，亏损净额大幅收窄超90%，经调整EBITDA（非国际财务报告准则计量）转正至人民币1162万元。\n业务方面，公司录得订单人民币17.60亿元，同比增长30.1%，并斩获超亿元大订单，同时在大客户复购、新客户、新行业及新渠道拓展方面均实现突破性进展。\n4 一天净赚近1.5亿，美的集团回应：公司估值被低估了\n8月29日，美的集团发布了2025年中期业绩报告：上半年营业总收入2523亿元，同比增长15.7%，实现归母净利润260亿元，同比增长25%，平均下来，相当于一天净赚近1.5亿元。“我们最近股价表现不如大盘。美的属于比较稳健的股票，股价波动不大；在当前市场比较好的情况下，投资者可能会选择成长更快的（股票）。”美的集团董事会秘书高书在接受采访时表示，“我们认为公司估值被低估了，所以才会进行回购操作。”\n5 宇树科技计划今年四季度提交IPO申请，四足机器人占营收65%\n9月2日，宇树科技宣布，预计将在2025年10月至12月期间向证券交易所提交上市申请文件，届时公司的相关运营数据将正式披露。宇树科技表示，以2024年为例，四足机器人、人形机器人和组件产品的销售额分别占约65%、30%和5%。\n其中，约80%的四足机器人被应用于研究、教育和消费领域，而剩余的20%则被用于工业领域，如检查与消防。人形机器人完全用于研究、教育和消费领域。\n6 四足机器狗化身“机器狼”亮相九三阅兵\n9月3日，一款叫做“机器狼”的无人作战装备亮相九三阅兵，由四足机器狗加装上武器或侦察设备进化而成。“机器狼”出现在陆上无人作战方队。央视解说词提到：受阅装备为侦打突击、扫雷排爆、班组支援等无人战车，可远程操控、自主行动、灵活编组，实现陆上有人、无人协同作战新突破。\n公开报道显示，“机器狼”的原型是一款由中国兵器装备集团旗下公司研制的四足机器狗，在2024年11月珠海航展上首次对外亮相。这款机器狗可以扛起最高20公斤的物体，续航里程约10公里，运行时间约2.5小时，能在30秒内完成电池更换。它还能在40度的陡坡爬行，能越过30厘米高的障碍物，在废墟上如履平地，从而适应复杂地形环境。\n7 淘宝测试AI电商导购服务“帮我挑”\n继AI万能搜后，淘宝在AI电商导购服务上又有了新的尝试。目前，淘宝APP正在测试AI电商导购功能——“帮我挑”。该服务由杭州淘宝营销管理有限公司打造，在淘宝APP原搜索功能上对电商搜索导购方式进行迭代的创新尝试，旨在结合用户输入，通过生成合成类算法为用户提供更符合用户消费需求的商品或内容。据悉，“帮我挑”服务入口是以一个淘宝机器人的形象，悬浮在淘宝APP的商品搜索结果页的下方。\n8 腾讯优图开源智能体框架Youtu-Agent，开箱即用！\n腾讯优图实验室开源Youtu-Agent智能体框架，具备开源友好、成本低、灵活架构和自动智能体生成等特点；该框架在WebWalkerQA基准上使用DeepSeek-V3.1达到71.47%准确率刷新开源效果SOTA，在GAIA文本子集达到72.8%，无需充值闭源模型；框架采用DITA原则，提供四个典型应用案例：本地文件管理、数据分析、论文分析和广域综述，支持一键生成配置和启动测试。\n9 美团开源龙猫大模型，5600亿参数MOE\n美团开源龙猫大模型LongCat-Flash，采用5600亿参数MoE架构，创新引入“零计算专家”和ScMoE，大幅提升效率与速度；模型在MMLU、ArenaHard、CEval等基准中表现接近甚至超越DeepSeek V3.1与Qwen3，尤其在指令遵循与Agent任务上排名领先；支持128k上下文、推理速度超100TPS、成本仅0.7美元/百万词元，已在Hugging Face和GitHub开源，MIT协议开放使用。\n10 DeepSeek被曝开发AI智能体模型：能自主完成多步工作\n9月5日，据媒体报道，DeepSeek正在研发一款更为先进的AI智能体模型，希望在与OpenAI等竞争对手在这一新兴技术领域展开竞争。据匿名人士透露，DeepSeek正在开发的模型只需用户给出简单指令，即可自动完成多步骤任务。这些人士还表示，该系统具备从以往操作中学习并自我改进的能力。\n上月 21 日，DeepSeek正式发布并开源了DeepSeek-V3.1，该模型将上下文窗口扩展至128K，参数量约为685B，用户可通过官方网页、APP及小程序进行测试，API接口调用方式保持不变。\n# 这些公司获得了新的融资 #\n1 斗象科技完成2亿元桥梁战略轮融资\n斗象科技是一家网络安全数据分析与在线安全运营提供商，新一代网络安全企业。斗象旗下业务品牌包括：安全数据分析与在线安全运营产品体系“斗象智能安全”，安全众测与安全运营服务平台“漏洞盒子”，网络安全行业门户“FreeBuf”网站和APP。斗象科技近日完成新一轮2亿元桥梁战略轮融资，由钟鼎资本独家投资。斗象科技CEO谢忱表示，本轮融资将进一步加大公司在AI安全技术与平台安全智能方向的研发投入，稳步推进长期战略布局，并为后续更大规模的资本计划和IPO进程奠定基础。\n2 高信资本战略投资星河动力\n星河动力是一家商业运载火箭研发商，定位于低成本商业火箭发射，其研制的固体运载火箭起飞质量30吨，近地轨道运载能力350公斤，采用三级固体推进加液体上面级构型，具备太空摆渡和主动离轨能力，可以满足微小卫星或试验载荷的发射。近日，高信资本完成对星河动力的战略投资，总投资金额超1亿元。\n3 Obita完成超千万美元天使轮融资\nObita是一家企业级跨境支付与数字金融网络开发商。公司以合规稳定币为核心，正在搭建Obita Mesh框架下的区块链原生支付网络，让全球企业享有低成本、实时到账、可监管的结算体验。Obita将企业级合规体系、跨境清算网络与一体化资金管理工具深度融合，重塑跨境贸易、跨境电商及供应链平台的资金流动方式，并率先布局东南亚、中亚、非洲与拉美等高增长市场。\n近日，Obita 宣布完成超千万美元天使轮融资，由元璟资本与Mirana Ventures联合领投，君联资本、HashKey Capital、Web3.com Ventures 等知名机构及个人跟投。本轮资金将重点用于核心系统研发、合规建设及市场拓展，加速全球稳定币跨境支付网络的布局。\n4 北京机器人产业发展投资基金完成对松延动力的数千万元人民币追加投资\n松延动力Noetix Robotics专注于人形机器人研发与制造，公司致力于通用人工智能本体，机器人仿生，以及具身操作系统等多个方向的研发。近日，首程控股旗下北京机器人产业发展投资基金宣布对人形机器人企业「松延动力」完成数千万元人民币追加投资，这是继2024年3月首轮投资后的再次加码。此次投资将用于支持松延动力在机器人本体优化、仿生人脸迭代及规模化应用推进。\n5 智动力机器人获得A轮融资，招银国际投资\n无锡智动力是一家专注于人形机器人核心部件和移动机器人动力模组研发、设计、生产及销售的国家高新技术企业。致力于为机器人行业提供高性能、高可靠核心动力模组以及人形机器人本体整体解决方案。已建立完善的机器人核心部件产品矩阵，涵盖人形机器人的高功率密度低压伺服驱动、高扭矩密度关节模组、高可靠力控关节模组、双差速线控底盘、高性能力控人形臂，以及工业移动机器人的智动轮、舵轮模组、AGV旋转模组、顶升模组等核心产品。近日，智动力机器人获得A轮融资，招银国际投资。\n6 汇创人力完成2850万元A轮融资\n汇创人力是一家面向全国的人力资源综合解决方案提供商，业务已全面覆盖劳务派遣、岗位外包、灵活用工、招聘猎头、培训咨询及社保代理等多维度服务，为各类大中小企业、政府机构及事业单位提供高度定制化的人力资源支持。近日，汇创人力完成2850万元人民币A轮融资，本轮投资由惠财资本独家注资。此次融资将主要用于加强技术研发、深化区域市场覆盖及完善人力资源全链条服务体系，标志着汇创人力在专业化与数字化并行的发展道路上迈出关键一步。\n7 脑韵科技完成千万级天使轮融资\n脑韵科技是一家横跨脑机接口与消费电子领域的创新科技公司。公司以“入耳式脑机接口”技术为核心，专注打造全球脑健康可穿戴AI设备。深度融合脑机接口、人工智能技术和消费电子产品形态，成功打造出全球首款入耳式脑电耳机。近日，脑韵科技宣布完成千万级天使轮融资。本轮投资方包括云米科技、伴飞脑科学孵化器以及上市公司的家办，山云资本担任公司的长期财务顾问。\n8 新研智材完成千万级种子轮融资\n新研智材是一家AI驱动材料研发商，以“材料大模型平台”为技术核心，致力于将AI for Science应用到新材料，清洁能源，半导体封装等产业研发领域。近日，新研智材完成千万级种子轮融资。本轮由晶瑞新材与基石浦江资本联合投资，资金将用于AI算法迭代、顶尖人才引进及半导体材料等场景的产业化落地，加速推进与行业龙头企业的深度协同。\n9 智用开物获得战略投资\n智用开物是一家多智能体解决方案厂商，核心产品 AI Agent Foundry 为企业应用 AI 提供强大中间平台支持，已在教育、制造业等多领域广泛应用。近日，智"
  },
  {
    "title": "DeepSeek的一次小更新，堪比发布新模型。-搜狐",
    "page_body": "一个好消息，时隔俩月， DeepSeek 终于更新了。\n就在昨天晚上， DeepSeek 一声不吭往 Hugging Face 上扔了个 DeepSeek -V3-0324 模型。\n模型参数 6850 亿，跟上一个版本的 V3 （ 6710 亿 ）相差不大，采用 MoE 架构，还支持了更开放的 MIT 开源协议。\n根据官方更新的版本说明， DeepSeek -V3-0324 主要是针对推理能力和前端开发能力进行了加强，写作风格实现了跟 R1 对齐，另外还有一些其他方面的小优化。\n现在打开 DeepSeek 官网， 把深度思考模式关掉就能直接用上 V3-0324 。\n不过有一说一，虽然 V3-0324 仅仅只是 V3 的小版本升级，并不是大伙儿期待已久的 V4 或者 R2 ，且官方账号也没有发布任何跟模型有关的信息。\n但也丝毫不妨碍， V3-0324 一上线，就有人说他的代码能力，直追克劳德。\n新版本的模型刚一上传，就登上了 Hugging Face 的趋势榜单。\n在国外大模型竞技场 KCORES 的测评中， V3-0324 的代码能力得分 328.3 ，超过了普通版的 Claude 3.7 Sonnet 的 322.3 分，接近 Claude 3.7 Sonnet 思维链版本的 334.8 分，排名第三。\n图源 @karminski 牙医\n重点是，排名在前面的模型压根就没几个开源免费的， V3-0324 可谓是一枝独秀。\n所以在 V3-0324 上线不到一天的时间里，就已经有很多老哥迫不及待上手测评了一波。\n这么说吧， V3-0324 在这些人手里，  已经成了拳打 o3-mini ，脚踢 Claude 3.7 Sonnet 的存在。\n经典的小球弹跳测试中，这位老哥把 V3-0324 、 o3-mini 和 R1 拉了个横评。\no3-mini 刚开始看着还不赖，但估计物理没学好，外面的六边形都转到垂直的位置了，球还不知道往下掉。\nR1 的表现，也是有些让人摸不着头脑。。\n相对来说， V3-0324 生成的结果是表现最好的，这位老哥丝毫不吝啬对它的夸奖，说它 “ 表现得像唯一排名第一的非推理模型 ” 。\n让 V3-0324 生成一个网页，模型一口气写了 800 多行代码，运行的时候还没有出错，这什么实力不用多说了吧。\n在评论区底下，有人仅仅下达了编写登录页面的简单指令，并没有任何其他的附加提示，同样也生成了一个完整的登录页面。\n还说 V3-0324 在编码上，能跟 Claude 3.7 Sonnet 掰一掰手腕。\n更别提其他的模型，性价比各方面相比下来，现在 OpenAI 的 o1-pro 和 GPT-4.5 ，都已经不香了。\n反正看了几个网友的测试案例之后，世超对 V3-0324 的前端代码生成能力，已经有了初步的判断。\n但不管咋说，没亲自上过手的东西，咱硬夸也有点心虚。所以这次世超也打算简单试一试，看看 V3-0324 到底有多能打。\n一上来，世超就让模型做了一个画板，提示词是 “ 帮我用 HTML 代码构建一个画板，支持鼠标绘制、橡皮擦功能和颜色选择 ” ，这次出战的模型是 V3-0324 和普通版 Claude 3.7 Sonnet 。\n只能说，这把 Claude 3.7 Sonnet 赢得很彻底。 光是有取色器这一点，就甩了 V3-0324 不知道几个车尾灯。\n更别提 UI 设计了， V3-0324 做出来的画板让世超不是很有创作的欲望。。。\n世超着实是没想到，这盆凉水来得这么快，都让我有点怀疑到底是我的提示词没写好，还是模型有问题了。。。\n不过，我后面又继续把小球弹跳的提示词，分别喂给了 DeepSeek-V3-0324 、普通版 Claude 3.7 Sonnet 还有 DeepSeek-V3 。\n这下味儿终于对了。V3-0324 生成的结果确实牛叉，能很清楚地看到小球在下落触底的时候，产生了小幅度的弹跳。\n就是吧，老版本的 V3 压根没运行起来。。。只能说两个版本之间的差距高下立判了。\n再来看普通版 Claude 3.7 Sonnet 的结果，优点是底下的转速、重力和摩擦力都是可调节的，弹跳看起来也没什么大问题，但小球有点出画面了。。。\n最后，世超又分别让 V3 和 V3-0324 生成一个 Saas 登录页面，提示词就一句话，没有任何的附加信息。\n可以看到， V3 的页面倒是做出来了，但没什么设计可言。\n反观 V3-0324 ，果然就跟官方的版本更新说明一样，生成的网页更美观了。\n综合看下来， V3-0324 的代码能力相比 V3 确实有了比较大的提升，而且在一部分测试案例中，也能够比肩普通版 Claude 3.7 Sonnet 。\n但如果要说完全超越 Claude 3.7 Sonnet ，那世超觉着暂时还不太行。\n不过大伙儿也别忘了，  V3-0324 在开源这个赛道里， V3-0324 已经算得上能打的了。\n而且 DeepSeek 的 API 价格业主打的一个便宜。世超对比了 Claude 3.7 Sonnet 和 V3-0324 的 API 价格， V3-0324 百万 tokens 输入的价格是 2 元，百万 tokens 输出的价格是 8 元，而同样的 tokens 数， Claude 3.7 Sonnet 的输入和输出价格分别是 36.6 元和 108.9 元，价差最多有 18 倍。\n所以在某种程度上， V3-0324 这个小更新，的确可以跟 Claude 3.7 Sonnet 媲美。\n特别是今天晚上，DeepSeek官方还发文，正式介绍了这波小更新，在数学、代码类的相关评测上， V3-0324比OpenAI目前最厉害的非推理模型GPT-4.5都要更胜一筹。\n去年 12 月底 V3 上线，紧接着 R1 就在过年的时候上桌吃饭了。如果按照 DeepSeek 之前发布模型的节奏，盲猜一波 R2 也快了。\n总之，小版本更新的 V3-0324 就已经如此强悍了，就是不知道，在 DeepSeek 猛烈的开源炮弹下， “OpenAI 们 ” 还遭不遭得住了。\n撰文 ：西西\n编辑 ：江江&面线\n美编 ：萱萱\n图片、资料来源 ：\nDeepSeek、X、Reddit"
  },
  {
    "title": "后GPT 3.0时代，主流大模型技术精要详解_澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "机器之心转载\n来源：知乎\n作者：张俊林\n洋洋洒洒近三万字，中国中文信息学会理事、中科院软件所博士、新浪微博机器学习团队新技术研发负责人的张俊林回顾了大型语言模型（LLM）的发展历程、技术迭代更新以及未来走向等方方面面的内容，并探讨了通过超大 LLM 实现通用人工智能（AGI）的可能性。\nChatGPT 出现后惊喜或惊醒了很多人。惊喜是因为没想到大型语言模型（LLM,Large Language Model）效果能好成这样；惊醒是顿悟到我们对 LLM 的认知及发展理念，距离世界最先进的想法，差得有点远。我属于既惊喜又惊醒的那一批，也是典型的中国人，中国人善于自我反思，于是开始反思，而这篇文章正是反思的结果。\n实话实说，国内在 LLM 模型相关技术方面，此刻，距离最先进技术的差距进一步加大了。技术领先或技术差距这事情，我觉得要动态地以发展的眼光来看。在 Bert 出现之后的一到两年间，其实国内在这块的技术追赶速度还是很快的，也提出了一些很好的改进模型，差距拉开的分水岭应该是在 GPT 3.0 出来之后，也就是 2020 年年中左右。在当时，其实只有很少的人觉察到：GPT 3.0 它不仅仅是一项具体的技术，其实体现的是 LLM 应该往何处去的一个发展理念。自此之后，差距拉得越来越远，ChatGPT 只是这种发展理念差异的一个自然结果。所以，我个人认为，抛开是否有财力做超大型 LLM 这个因素，如果单从技术角度看，差距主要来自于对 LLM 的认知以及未来应往何处去的发展理念的不同。\n国内被国外技术甩得越来越远，这个是事实，不承认也不行。前阵子网上很多人担忧说国内 AI 现在处于 “危急存亡之秋”，我觉得倒也不至于这么严重。君不见，这个世界上，具备这么超前眼光的只有 OpenAI 一家吗？包括 Google 在内，其实对于 LLM 发展理念的理解，明显都落后 OpenAI 一个身位。现实是 OpenAI 表现过于优秀，把所有人都甩开了，不仅仅是国内。\n我觉得，OpenAI 对 LLM 在理念及相关技术方面，领先国外的 Google、DeepMind 大约半年到一年的时间，领先国内大概两年左右的时间。在 LLM 这个事情上，感觉梯队很明显，Google 应该是排在第二位，最能体现 Google 技术眼光的是 PaLM 和 Pathways，推出时间大概在 22 年 2 月到 4 月间，同一时期，OpenAI 推出的却是 InstructGPT，从这里就可以看出 Google 和 OpenAI 的差距了，至于为何这么说，你看了我后面的正文后大概能理解。DeepMind 之前的重心一直在强化学习攻克游戏和 AI for science 这些方面，切入 LLM 其实很晚，应该是 21 年才开始重视这个方向，目前也处于追赶状态。Meta 就更不用说了，重心一直不在 LLM 上，目前感觉也发力开始追赶。这还是目前做得最好的一批机构，尚且如此，更何况国内呢？我觉得情有可原。至于 OpenAI 关于 LLM 的理念是什么，我在本文的最后一部分，会谈谈我的认知。\n本文梳理自 GPT 3.0 出现之后的主流 LLM 技术，在此之前的主流技术可以参考「」。\n我相信看完这两篇文章，能够让您对 LLM 领域的技术脉络，LLM 技术发展过程中出现过的不同发展理念，乃至未来可能的发展趋势，有比较清晰的认知。当然，很多地方讲的内容是我个人看法，有很大的主观性，错漏难免，所以还请谨慎参考。\n本文试图回答下面一些问题：ChatGPT 是否带来了 NLP 乃至 AI 领域的研究范式转换？如果是，那会带来怎样的影响？LLM 从海量数据中学到了什么知识？LLM 又是如何存取这些知识的？随着 LLM 规模逐步增大，会带来什么影响？什么是 In Context Learning? 为什么它是一项很神秘的技术？它和 Instruct 又是什么关系？LLM 具备推理能力吗？思维链 CoT 又是怎么做的？等等，相信看完，能让您对这些问题有一个答案。\n首先，在谈 LLM 技术现状前，先宏观地谈下我心目中的研究范式转换问题。这样，我们才能 “先见森林，再见树木”，对具体技术为何会是如此变化有个更清晰的认知。\n潮流之巅：NLP 研究范式的转换\n如果我们把时间线往前拉得更长一些，回到 NLP 领域的深度学习时代，在更长时间窗口内观察技术变迁及其影响，可能会更容易看清其中的一些关键节点。我个人认为，在最近 10 年来 NLP 领域的技术发展过程中，可能存在两次大的研究范型转换。\n范式转换 1.0: 从深度学习到两阶段预训练模型\n这个范式转换所涵盖的时间范围，大致在深度学习引入 NLP 领域（2013 年左右），到 GPT 3.0 出现之前（2020 年 5 月左右）。\n在 Bert 和 GPT 模型出现之前，NLP 领域流行的技术是深度学习模型，而 NLP 领域的深度学习，主要依托于以下几项关键技术：以大量的改进 LSTM 模型及少量的改进 CNN 模型作为典型的特征抽取器；以 Sequence to Sequence（或叫 encoder-decoder 亦可）+Attention 作为各种具体任务典型的总体技术框架。\n在这些核心技术加持下，NLP 领域深度学习的主要研究目标，如果归纳一下，是如何有效增加模型层深或模型参数容量。就是说，怎么才能往 encoder 和 decoder 里不断叠加更深的 LSTM 或 CNN 层，来达成增加层深和模型容量的目标。这种努力，尽管确实不断增加了模型层深，但是从解决具体任务的效果角度看，总体而言，不算很成功，或者说和非深度学习方法相对，带来的优势不算大。\n深度学习之所以不够成功，我认为主要原因来自于两个方面：一方面是某个具体任务有限的训练数据总量。随着模型容量的增加，需要靠更大量的训练数据来支撑，否则即使你能把深度做起来，任务效果也做不上去。而在预训练模型出现之前，很明显这是 NLP 研究领域一个严重问题；另外一个方面是 LSTM／CNN 特征抽取器，表达能力不够强。意思是就算给你再多的数据也没用，因为你不能有效地吸收数据里蕴含的知识。主要应该是这两个原因，阻碍了深度学习在 NLP 领域的成功突围。\nBert/GPT 这两个预训练模型的出现，无论在学术研究角度看，还是工业应用角度来看，都代表了 NLP 领域的一个技术飞跃，并带来了整个领域研究范式的转换。这种范式转换带来的影响，体现在两个方面：首先，是部分 NLP 研究子领域的衰退乃至逐步消亡；其次，NLP 不同子领域的技术方法和技术框架日趋统一，在 Bert 出现后一年左右，技术栈基本收敛到两种技术模式中。关于这两点，我们分头来谈。\n影响一：中间任务的消亡\nNLP 是一个宏观研究领域的统称，里面有五花八门具体的子领域与子方向，如果仔细分析，从任务的性质角度，可以把这些任务分成两大类：一类可以叫做 “中间任务”，一类可以称为 “最终任务”。\n典型的中间任务包括：中文分词、词性标注、NER、句法分析、指代消解、语义 Parser 等，这类任务一般并不解决应用中的实际需求，大多数是作为那些解决实际需求任务的中间阶段或者辅助阶段存在的，比如几乎没有需求说，我要一个句法 Parser，把这个句子的句法分析树给用户看看，用户不需要看到这些 NLP 的中间阶段处理结果，他只关心某个具体任务你有没有干好。“最终任务” 包括比如文本分类、文本相似性计算、机器翻译、文本摘要等等，有很多。这类任务的特点是每个子领域都解决某个实际需求，任务结果基本能直接呈现给用户，比如用户确实存在给你一句英文，告诉他中文是什么的需求。\n按理说，“中间任务” 就不应该出现，而之所以会存在，这是 NLP 技术发展水平不够高的一种体现。在技术发展早期阶段，因为当时的技术相对落后，很难一步做好有难度的最终任务。比如机器翻译，早期技术要做好机器翻译是很困难的，于是科研人员就把难题分而治之，分解成分词、词性标注、句法分析等各种中间阶段，先把每个中间阶段做好，然后再拼起来完成最终任务，这也是没办法的事情。\n但是自从 Bert／GPT 出现之后，其实就没有必要做这些中间任务了，因为通过大量数据的预训练，Bert／GPT 已经把这些中间任务作为语言学特征，吸收到了 Transformer 的参数里，此时我们完全可以端到端地直接解决那些最终任务，而无须对这种中间过程专门建模。这里可能争议最大的是中文分词，其实道理也是一样的，哪些字应该组成一个词，这个其实你不用管，让 LLM 自己当特征去学就行了，只要对于解决任务有帮助，它自然会去学该学的合理分词方式，也未必一定要和我们人类理解的分词规则相同。\n基于以上认知，其实在 Bert/GPT 一出现，你就应该得出这类 NLP 的中间阶段的任务，会逐步退出历史舞台这个结论。\n影响二：不同研究方向技术路线的统一\n在说明具体影响前，我们先讨论下另外一种 NLP 任务划分方式，这对于理解后面内容有帮助。如果对 “最终任务” 进一步进行分类，又大致可以分为两大不同类型的任务：自然语言理解类任务和自然语言生成类任务。如果排除掉 “中间任务” 的话，典型的自然语言理解类任务包括文本分类、句子关系判断、情感倾向判断等，这种任务本质上都是分类任务，就是说输入一个句子（文章），或者两个句子，模型参考所有输入内容，最后给出属于哪个类别的判断。自然语言生成也包含很多 NLP 研究子方向，比如聊天机器人、机器翻译、文本摘要、问答系统等。生成类任务的特点是给定输入文本，对应地，模型要生成一串输出文本。这两者的差异主要体现在输入输出形式上\n自从 Bert/GPT 模型诞生后，出现了明显的技术统一趋向。首先，NLP 中不同的子领域，其特征抽取器都逐渐从 LSTM/CNN 统一到 Transformer 上。其实，自 Bert 公开后不久，就应该意识到，这必然会成为技术趋势。至于其原因，在几年前我写的这篇「张俊林：放弃幻想，全面拥抱 Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较」中做了说明和分析，感兴趣的同学可参考。\n文章链接：https://zhuanlan.zhihu.com/p/54743941\n而且，目前 Transformer 不仅统一了 NLP 诸多领域，也正在逐步地替换图像处理各种任务中被广泛使用的 CNN 等其它模型的进程之中，类似的，多模态模型目前也基本都采用了 Transformer 模型。这种 Transformer 从 NLP 出发，攻城略地逐步统一 AI 越来越多领域的趋势，起始于 2020 年底出现的 Vision Transformer (ViT) ，之后蓬勃发展，到目前已大获成功，且其继续向更多领域拓展的势头会越来越迅猛。\n其次，大多数 NLP 子领域的研发模式切换到了两阶段模式：模型预训练阶段 + 应用微调（Fine-tuning）或应用 Zero／Few Shot Prompt 模式。更准确地说，NLP 各种任务其实收敛到了两个不同的预训练模型框架里：对于自然语言理解类任务，其技术体系统一到了以 Bert 为代表的 “双向语言模型预训练 + 应用 Fine-tuning” 模式；而对于自然语言生成类任务，其技术体系则统一到了以 GPT 2.0 为代表的 “自回归语言模型（"
  },
  {
    "title": "大模型out了，小模型（SLM）爆火，撕开99%企业市场？-36kr",
    "page_body": "大模型是能力上限，小模型是落地首选\n对于猎豹移动CEO傅盛来说，他今年最呼吁的一件事情，正在成为潮流——小模型逐渐成熟，成为企业落地商业化主力军，这令他十分开心。\n可能很多人会困惑，大模型（LLM）正火的当下，什么是小模型（SLM）？ 目前，市场通常将参数规模远少于GPT-4或Llama-13B的千亿大语言模型，一般参数只有1.5B、3B、7B的模型称为小大模型。\n要说小模型现在有多火，仅仅7月下半月，4家科技公司纷纷推出自己的小模型。\nHugging Face 推出了高性能的小型语言模型 SmoLLM，包括 135M、360M 和 1.7B，能够直接在浏览器中运行；\nOpenAI 紧随其后发布了GPT-4o mini，直接让GPT-3.5 Turbo成为历史；\nMistral AI 与英伟达合作推出了拥有 12 亿参数的 Mistral Nemo，多语言支持、128K 上下文，性能优于L3 8B和Gemma 2 9B；\n苹果也不甘示弱，发布了70亿参数的小模型 DCLM-7B，并立即将其全部开源。\n如果将时间线再往前推到今年上半年，可以发现小模型市场早已经开始“神仙打架“，比如微软4月发布了Phi-3、谷歌2月发布了Gemma-7B等。\n半年6款知名的小模型发布，行业挂起了小模型的旋风。\n而此前国内小模型的忠实拥趸，可能只有猎豹移动。 不同于其他大厂有大小系列模型覆盖，2023年猎豹直接发不了中小模型Orion-14B，应用于企业私有化模型落地。\n尽管小模型市场竞争不激烈，但 前赶集网技术总监、小晨科技 创始人 剻 义刚告诉 鲸哥： 企业部署私有大模型，服务的海外客户 最常见的模型是GPT-3.5 turbo，国内的百度文心多一些。\n现在情况大变，无论GPT3.5还是GPT-4，已经成企业市场的“旧爱”了，这些参数小能力大的小模型凭借超高性价比，一时成为市场的新宠。2024年会成为SLM元年吗？\n参数不如大模型，小模型凭啥火了？\n在Scaling Law（尺度定律）的信仰下，一直向着万亿大模型进军的科技巨头们，纷纷转向了小模型赛道，在市场看来可能有3大原因：\n第一大原因就是大模型实在太贵了。\n对于开发者而言，训练大模型和烧钱无异。剻义刚就说道：“好的大模型也十分贵，GPT-4的使用成本是GPT-3.5的10倍。 ”\n最先进的大模型，这么贵的原因，首当其冲的就是硬件训练成本，GPU、TPU和CPU集群都是基本军备。前有OpenAI用了25,000块A100芯片训练GPT-4，后有马斯克宣布要用10万块H100组成超级AI训练集群。其次就是能源消耗，有数据显示，全美AI数据中心的耗电量足以点亮整个纽约市。此外，人力成本、训练数据成本也都是一笔不小的开销。\n而随着模型的参数数量呈指数级增长，训练成本也在急剧上升。Anthropic首席执行官Dario Amodei在一档播客节目中表示，目前正在开发的人工智能模型的训练成本高达10亿美元。但未来三年AI模型的训练成本将上升到100亿美元甚至1000亿美元。至于GPT-4o“仅仅1亿美元的开发成本，已经不值一提。\n主流AI模型的训练和推理成本\n这种成本上的巨大负担，让巨头们纷纷放下参数执念，投身小模型。\n小语言模型可以理解是大语言模型的浓缩版本，参数更少，设计更精炼，自然需要更少的数据、训练时间以及硬件成本。\n比如可能仅仅聚焦于法律问题上的小模型，参数不到100亿，那它的训练成本往往可能不到1000万美元。\n而且小模型的性价比不仅体现在训练端，对于用户来说也是如此。\n由于小模型训练成本低、并且在相应过程中消耗的算力更少，因此小模型的使用价格也显得更加亲民可人。\n目前OpenAI的GPT-4o的百万Tokens输入和输出价格分别是5美元和15美元，而 GPT-4o mini的百万Tokens输入价格仅为15美分，输出价格仅为60美分，价格速降了96%～97%。\n从Artificial Analysis的统计中可以清晰看到大模型与小模型的成本差距。OpenAI CEO 山姆奥特曼对此的形容是：通往智能的成本已经「too cheap to meter」（便宜到无法计量 ）。\n第二，除了便宜，小模型的性能也已经拉满。\n最新发布的GPT-4o mini，在lmsys（测评榜单）的较量中展现出了超强实力，不仅与GPT-4o的满血版本并列榜首，还将Claude 3.5等强劲对手甩在身后。\nlmsys的排名机制是由用户自主出题，随机抽取两个模型进行一对一的较量。这种机制有效防止了模型通过“刷题”来获得虚高的评分，主打一个真实。\n分数不代表一切，实际使用体验也是效果不错。\n据OpenAI公布的案例显示，GPT-4o mini已与Ramp和超人等公司进行了合作，反馈发现在执行从收据文件中提取结构化数据，或在提供线程历史记录时，生成高质量电子邮件响应等任务时，GPT-4o mini的表现明显优于GPT-3.5 Turbo。\n更令人期待的是，GPT-4o mini 的API 现已支持文本（且大幅改善了非英文的效率）和视觉，未来还将支持文本、图像、视频和音频输入和输出。\n不仅是GPT-4o mini，其他几家的小模型也是争奇斗艳。\n主流小模型价格能力评价\n被誉为「欧洲版 OpenAI」的 Mistral AI 旗下小模型Mistral NeMo，从整体性能上也在多项基准测试中，击败了Gemma 2 9B和Llama 3 8B。并且该模型专为全球多语言应用而设计，在英语、法语、德语、葡萄牙语、中文方面等方面表现尤为突出。\n而苹果这次推出DCLM-7B 模型，在MMLU基准上的5-shot准确率达到了64%，与Mistral-7B和Llama 3 8B不相上下，但计算量只有后者的六分之一。在53个自然语言理解任务上，它的平均表现也可以与Llama 3 8B相媲美。\n此外，苹果这波格局了一把。不仅模型本身开源，连训练数据集都一并公开，让人们可以完整复现他们的工作。\n第三、小模型除了性价比杠杠的，也凭借着小巧的身姿进入了更多的应用场景。\n大模型在使用场景上有很多局限。比如智能手机、物联网设备等边缘设备，通常具有有限的计算能力和存储空间，无法承载大型语言模型，而这时候小模型则可以完美嵌入。\n又比如在对实时性有严格要求的应用领域，例如实时图像分析、语音识别和动态推荐系统，小模型由于参数少，能够迅速地进行推理，以极短的延迟满足用户的即时需求。\n性价比超高，为何小模型现在才爆？\n小模型有这么多优点，为什么巨头们现在才开始“真香”反转呢？\nOpen AI的产品主管Olivier Godement解释，这单纯是“纯粹的优先级”问题。之前公司专注于GPT-4这类大模型上，随着时间的推移，OpenAI才关注到开发者对于小模型的需求。\n但也有观点认为， 大模型是通往小模型的必经之路 。\n大型模型的训练就像是海绵吸水，尽可能把所有数据、信息囊括其中。而这样做，有利有弊。大型模型在海量数据的依托下，能够更好、更准确的处理新新任务，但同样也可能因为学的太杂，而出现不同知识的重叠、混合和冲突。\n而小模型则是站在大模型的肩膀上进一步优化。小模型接收的数据，则是由超大模型进行清洗的高质量数据。比如对于GPT-4o mini进行训练的数据，就是由GPT-4进行清洗的。\n而这种先做大模型，再进一步瘦身的训练模式正在成为新趋势。科技巨头们对于不再一味求大，而是求精。\n在2023年4月，OpenAI的首席执行官Sam Altman宣布了大型AI模型时代的结束。他指出，数据质量是AI训练的关键成功因素，并且认为关键问题是人工智能系统如何从更少的数据中学到更多的东西。而这个观点也得到微软、Hugging Face等其他玩家的认可。\n而这种不断精简优化的过程则会不断形成正循环。每一代模型都会帮助生成下一代的训练数据，直到获得“完美的训练集”。\n未来，和阶梯式上升的小模型质量形成对比的，则是不断下降的小模型价格。\n傅盛曾在WAIC中说道，“千亿参数大模型一年私有化授权费用就是几千万，到今天应该还是，然后私有化部署以后，买服务器的费用最低成本160万（当时的价格）”。\n大模型太贵了。剻义刚也和AI鲸选社说道，他们现在私有化部署一般是四五十万，为了成本考量几乎不太做微调。他们作为落地服务商没有赚太多，大头还是大模型企业的授权费用。\n现在企业使用大模型成本可能会大幅降低了。AI Grant 的两位合伙人 Daniel Gross 和 Nat Friedman在访谈中， LLM成本在质量不变差的情况下，每年可以降低 90% 的情况。\nOpenAI也确实基本在证明了这件事。OpenAI 基本是以每 3 个月作为一个周期，总会有其中至少一个模型成本下降 60% ，或者成本下降至少 60% 的情况下，质量还更高了。而一个模型基本上一年会经历两次的降本增效，每次降低 60%，两次过后就刚好是比之前降低了 90% 左右。\nGPT-4o mini就是这种逻辑的成果体现。而且随着高质量数据集以及训练方式的改进，这些小模型有些能力甚至更突出。\n正如 AI Grant 所说，没理由认为更小的模型不会有更好的表现。“最近这些 9B 的模型已经震撼到我们了，没有任何数学证明 3B 做不到同样的效果。如果 3B 做到了，没理由不运行在本地，那么那时候除了一些电耗问题外，我们更多的肯定是在做本地处理 + 云端模型的路由。”\n换言之，未来将不断涌现越来越多更精简、更高效、更便宜的小模型。未来就像OpenAI创始成员及研究科学家Andrej Karpathy所发言，未来大模型的尺寸竞争趋势即将逆转，尺寸竞争正在倒退。\n企业落地最爱，小模型加速商业化\n“企业专用大模型，百亿参数就够了。”是傅盛过去一年经常说的话。\n但实际上，2023年将小模型向垂直方向微调，打造出媲美大模型的效果，效果并没有那么好，百亿参数没那么够。\n但现在情况不一样了，gpt-4o-mini 在很多场景中不用微调，都不比Chat-4 turbo差。\n有AI创业者反馈：“gpt-4o-mini 的效果真的不错。首先是速度非常快，比 4o 快多了，几乎不需要等待，就可以读取结果了。其次是实际的表现， GPT-4o-mini 目前仅在复杂场景中还需借力, 只有比较复杂一点的编程没有搞定。“ 日常的需要搜索引擎+blog 或者教程才能解决的任务，基本GPT-4o-mini 都可以完成的不错。 ”\n在大模型的托举之下，小模型正在用更加轻盈的姿态落地。HuggingFace CEO Clem Delangue 甚至指出， 多达 99% 的使用场景可以通过 SLM 来解决，并预测 2024 年将是 SLM 元年。\n剻义刚说道，最近有家此前做了医疗和房地产领域的客户，都是用的大模型。4o-mini发布那天，他看了下资料，比 GPT-3.5 Turbo更好的性能，更长的输出，多模态支持 ，更低的费用，以及更好的非英语语言的支持，感觉是天赐的好模型。\n“最近谈的一个招聘客户，预计就是使用4o-mini。”生意预计会好做，也让他的笑声多了起来。\n但他也提到，看行业分析，未来大模型、小模型会相辅相成落地企业的部署。\n这意味着模型生态向着流动、精准进一步发展。而从使用场景上，大模型、小模型也将分工明确。\n大模型将继续在需要广泛知识基础和高级认知能力的领"
  },
  {
    "title": "全球AI治理报告发布，强调着力应对四大关键问题|全球人工智能治理倡议_新浪财经_新浪网",
    "page_body": "人工智能在带来发展机遇的同时，也引发了跨领域、多层次的系统性治理挑战。全球人工智能安全谁来监管如何防范？\n11月8日，《为人类共同福祉构建全球人工智能安全与治理体系》报告（以下简称《报告》）在2025年世界互联网大会乌镇峰会人工智能技术创新与治理论坛上正式发布。《报告》指出，人工智能技术发展迅猛，其安全与治理体系呈现出碎片化态势，国际社会亟需构建具有广泛共识的治理框架与标准。\n世界互联网大会人工智能专委会主任委员及安全与治理推进计划联合牵头人、中国科学院自动化研究所人工智能伦理与治理中心主任、北京前瞻人工智能安全与治理研究院院长曾毅，专委会安全与治理推进计划联合牵头人、剑桥大学教授及智能未来中心人工智能未来与责任项目主任肖恩·欧·海格缇（Seán Ó hÉigeartaigh）共同介绍了此项联合研究成果的形成过程及主要内容。\n《报告》系统性地证实了专家们的担忧。它指出，2019至2024年间，全球记录在案的人工智能风险事件由约400件跃升至7900余件，总量增长了近20倍。其中，涉及鲁棒性与数字安全、人权与隐私治理、透明度与问责制等问题的事件占比超过60%，显示技术安全性与伦理性议题已成为全球性挑战。\n《报告》回顾了联合国、各国政府、区域组织及产业界在人工智能治理上的积极努力。联合国通过成立咨询机构、通过联大决议等方式，推动全球治理议程；欧盟颁布《人工智能法案》，建成全球首部全面监管法律框架；中国发布《全球人工智能治理倡议》等文件，倡导发展和安全并重的原则。产业界和学术界也在积极探索自律机制，如Anthropic的“负责任扩展政策”和OpenAI的“应对准备框架”，旨在确保人工智能系统的安全部署。\n《报告》指出，当前在人工智能治理上仍存在结构性局限，如治理规则更新速度慢于技术迭代、工具上不完善，技术支撑有限、跨境协作机制薄弱、责任归属模糊等。\n《报告》强调，构建全球人工智能安全与治理体系需着力应对四大关键问题。第一，针对技术快速迭代与不确定性风险，报告建议建立技术跟踪与风险预警协同机制，推动治理规则实现动态更新。第二，在平衡各国发展诉求方面，呼吁构建包容性多边平台，以保障各国平等发展和利用人工智能的权利。第三，为明确多利益相关方的权责边界，报告提出建立履约审查、风险监测与争端调解机制，从而形成协同有序的治理格局。第四，面对地缘政治障碍，报告倡导以联合国为中心践行多边主义，推动共建人类命运共同体。另外，《报告》还借鉴了核安全、气候变化等领域的全球治理经验，提出具体机制举措。\n《报告》最后建议，形成应对人工智能技术失控风险共识，建立全球广泛参与的前沿人工智能模型检测与能力评估机制。此外呼吁国际社会凝聚“以人为本、智能向善”的共识，在联合国框架下整合资源，建立分级分类对话机制。联合国系统应发挥协调作用，推动价值共识、技术规范与风险治理的多维整合。\n曾毅表示，当前人工智能安全与治理的国际合作已成为重要的全球公共议题。面对技术的快速演进和各国发展的不平衡，国际社会需凝聚共同的风险认知，建立一致的行动框架，并通过机制的设计与完善，确保人工智能技术在安全、可控、包容的轨道上发展。\n澎湃新闻记者 喻琰"
  },
  {
    "title": "AI之HuggingFace：Hugging Face(AI社区抱抱脸/侧重存放开源模型及其数据集)的简介、使用方法、案例应用之详细攻略-CSDN博客",
    "page_body": "AI之HuggingFace：Hugging Face(AI社区抱抱脸/侧重存放开源 模型 及其数据集)的简介、使用方法、案例应用之详细攻略\n目录\nHugging Face的简介\n1、Hugging Face的发展\n(1)、Hugging Face发展历史——从开发聊天机器人→机器学习开源库平台、从NLP开源的大本营→涉及CV类的模型整合平台\n2、Hugging Face与GitHub区别——面向软件VS面向机器学习\n3、Hugging Face的产品定位、特点、盈利、未来竞争\n(1)、产品定位(具体功能)—存储、托管\n(2)、产品特点—社区驱动、用户共享实现迭代升级\n(3)、产品优势—成于Transformer终心于开源、开发者有想法即可测试、借助Hugging Face投入生产、助力模型迭代带来良性循环、平台可以集大智慧\n(4)、开源平台如何盈利——坚信、递延收入、技术敏感度、需求倒逼平台\n(5)、看待竞争、模型闭源趋势——用实力说服竞争者、迁移学习会更加开源\n(5)、未来挑战—多模态、持续助力功能升级、坚信敢比会重要\n4、Hugging Face的特点：Hub、Tasks、Open Source、Science\n(1)、Hub—机器学习之家\n(2)、Tasks—问题解决者\nComputer Vision\nNatural Language Processing\n Audio和Tabular\n Multimodal和Reinforcement Learning\n(3)、Open Source—Transformers\n(4)、On demand—推理的API\n(5)、Science—我们的研究贡献\n5、Models、Dataset、Spaces、Dcos\n(1)、Models\n(2)、Dataset\n(3)、Spaces\n(4)、Dcos\nHugging Face的使用方法\n1、如何在Hugging Face上上传自定义的数据集\n上传数据集\n查看加载的数据\nHugging Face的案例应用\nHugging Face的简介\n Hugging Face，抱抱脸，是AI"
  },
  {
    "title": "Taala AI新生态教育平台“踩准”Gartner发布的《2026年十大战略技术趋势》-百家号",
    "page_body": "Gartner简介\nGartner（高德纳公司）是全球最具权威的信息技术研究与顾问咨询机构，1979年在美国康涅狄克州斯坦福成立，其核心业务涵盖IT产业趋势分析、技术成熟度评估及市场战略咨询，旨在为客户提供客观、公正的论证报告及市场调研报告，一直是全球企业首席信息官、技术领袖和业务决策者制定未来战略的重要风向标。\n商业与技术洞察公司 Gartner 发布 2026 年重点关注的十大战略技术趋势。\n1、 AI超级计算平台\n2、 多智能体系统\n3、 特定领域语言模型（ DSLM）\n4、 AI安全平台\n5、 AI原生开发平台\n6、 机密计算\n7、 物理 AI\n8、 前置式主动网络安全\n9、 数字溯源\n10、 地缘回迁\n根据 Gartner发布的2026年十大战略技术趋势， Taala AI平台（新生态教育平台）正是围绕其强调重点关注的 多智能体系统 趋势构建 ，致力于技术创新为第一生产力，以 核心优势传递产品独特价值 。\n多智能体系统是什么？\n定义与概念： 多智能体系统 （ Multiagent Systems, MAS ） 是由多个自主或自主的智能体（ AI  Agent）组成的 集合。 这些智能体 通过交互实现复杂的个体或共同目标， 每个智能体扮演特定角色（如规划者、执行者、审查者），并通过精心设计的协调机制（如协调者 -工作者模式）共同解决问题 ， 可以相互协作、协商和竞争，以完成单个智能体无法完成的复杂任务 ， 被视为一个 “协作型AI团队” 。\n预测与价值 ： Gartner预测，到2026年将有40%的企业在一定范围内使用多智能体 系统，企业可实现复杂业务流程的自动化、提升团队技能并开创人类与 AI 智能体的新协作方式。 将企业自动化水平从执行重复性任务提升到解决动态、复杂的业务流程 ， 它能够以接近人类团队的方式处理问题，带来前所未有的运营效率和决策质量，尤其在需要多领域知识协同的场景中价值巨大。\nTaala AI平台 如何适配 ？\nTaala AI平台 并非功能堆砌，而是针对上述 多智能体系统 趋势提供 适应的 解决方案。\n适配一： Agent智能体架构\nAI驱动围绕 “自我认知-能力成长-求职转化”，针对个人成长目标形成自进化 的动态响应闭环，以打造的 全链路决策支持系统， 支撑 行为模式、能力基线、职业偏好特质 等 科学决策 。\n适配二：多智能体形成协同\n通过多模态分析加独研大模型，使 “生涯探索规划→能力锻造提升→职业资源智能体”三大模块深度协同 ，确保各个模块 在统一目标下共同规划、同步行动 ，打破 协作不畅 导致的壁垒。\n适配三：人机协作动态规划\n基于 AI决策引擎， 融合创新项目式学习和训练， 以游戏化交互设计动态校准路径， 实时反馈提升规划精度，以 “智能迭代” 应对用户变化， 核心解决了 “规划调整慢、落地僵化” 等 问题\nGartner研究副总裁 高挺（ Arnold Gao ） 表示： “2026 年的各项重要战略技术趋势将密切交织，折射出一个由人工智能（ AI ）驱动的高度互联化世界的现实图景，不仅代表了技术变革的方向，还是促进业务转型的催化剂。由于下一轮创新浪潮已近在眼前，只有当下采取行动的企业才能应对市场波动和决定未来数十年的行业走向。 ”\n2026年的十大战略技术趋势描绘了一个由AI深度驱动、以数字信任为基石、并在基础设施层面发生根本性变革的未来。这些并非是遥不可及的幻想，而是已经在技术和商业世界中萌芽并加速发展的现实， Taala AI正是探索和实践中的一员，以敏捷性和适应能力洞察趋势背后的逻辑，并果断采取行动。\n在 AI加快 变化的时代，选择一款像 Taala AI新生态教育平台这样 深刻理解 个人发展规划 并能落地行业趋势 的 产品， 无疑是 将自己期望的方向转化为可行的路线图，并注入持续的动力，现在，就是你开始规划和行动的最佳时机，建立起属于你的能力壁垒，才能最终在与他人的竞争中脱颖而出。"
  },
  {
    "title": "中国AI大模型“井喷”：全球开源榜单前15全被包圆，硅谷慌了吗？-今日头条",
    "page_body": "如果你还觉得AI开源这事跟中国没太大关系，那可能要重新考虑了。最近，国外有排名数据显示，现在全球开源AI模型的头部，前15名竟然全挂着中国机构的名字，这场局面变化比翻牌子还快，让不少人都傻眼。你听过DeepSeek、Qwen这些名字吗？现在人家直接领跑，连OpenAI都只能在第16名露脸。原来2023年中国开源模型的占比才区区17%，结果到2025年7月，蹭一下爬到了63%。增长这速度，属实有点让人跟不上。这背后其实不光是技术堆叠，更类似一次AI世界的“地壳运动”，估计下一站，AI生态怎么变，大家心里真说不好。\n美国那边的投资人像Benchmark的比尔·古尔利，也不得不承认，中国开放AI模型组合出来的力量太强。他们这些模型互相借鉴、优化，那种迭代升级的速度快得惊人，几乎改变了全球创新的玩法。于是AI这圈，不再只是看模型本身厉不厉害，这更像是在拼谁家的生态圈能拉拢更多开发者、能把AI普及得更广。像DeepSeek-V3训练一次只花900万美元，对比GPT-4动辄6300万美元，成本直接砍下一大截，具体便宜了多少？算一算，其实省了85%。阿里云的Qwen，直接做出从1.5B到480B参数的各种规格，Hugging Face上一阵薅，衍生出的模型都已经突破10万款。这些模型搞得灵活极了，无论你是要搞啥小程序还是走进大企业，都能挑到合适货色。还有智谱GLM-4.5，那API调用定价，输入0.8元/百万tokens，输出2元/百万tokens，比那些国际主流模型看下来便宜60%到80%，别说开发者了，就连中小企业都乐得合不拢嘴，行业格局都被迫被推着走，谁还敢乱收费？\n比较意外的是，很多分析认为东亚的数学教育基础成了AI崛起最大的底气。像Illya Gerasymchuk直言，这边的数学功底让AI算法创新有了厚实起点。国际数学奥林匹克上，最近十年中国、日本、韩国联合拿金的比例高达58%，这些数学天才，跳进AI池子里，创新自然不是盖的。这些机构玩开源还跟美国那套闭门造车完全不一样。他们把门槛降低，使用成本压到底，招来了全球各地开发者一起参与，产生了超大的网络效应。Kimi模型，你可能听说过，是月之暗面旗下一款主打长文本处理的模型。它的K2版本上下文长度能撑到200万字符，在法律、学术等专业场景表现相当硬核，给垂直领域AI打开了新路。\n中国机构的打法特别有意思：19家主力机构被外媒分了个梯队，从基础研究一路到商业落地，整条链基本齐活了。DeepSeek和Qwen是标准的技术“尖刀”，紧接着智谱、月之暗面这些在某些领域继续深耕，甚至腾讯、小红书、MiniMax也专门琢磨应用创新。大家比拼的不光是硬实力，还讲究团队配合。模型算法、数据来源、训练方式，各有侧重，不同公司之间开源社区一交流，创新步伐抬腿就走，谁都别想偷懒。Hugging Face平台的数据显示，中国模型平均下载量暴涨340%，这增速放到全球都是炸裂级别的。\n说到商业模式，现在流行那种“混合玩法”。过去都是“模型即服务”，现在公司干脆把模型拉去私人订制。客户根据自己需求，随心调参数、换架构，既能享用开源社区的好处，又能保住自家差异化优势。反正市场蛋糕越做越大，怎么玩都有人买单。\n但气氛热闹归热闹，问题还真不少。比如现在大部分模型都扎堆用Transformer架构，创新点哪怕有，也怕形成同质化。再有，开源模型啥数据都往里扔，数据质量和版权成了雷区，碰一下就可能出事儿。这定价策略虽然眼下打市场漂亮，可以后企业还愿不愿意持续烧钱搞研发，谁也说不好。一旦国际政策风向一改，比如美国那边开始盯紧AI出口管制、欧盟出台AI法规限制开源应用，到时候怎么玩下去，也需各家小心翼翼应对。\n这几年科技发展的新趋势就是开放、共享，各个国家和地区间技术壁垒越来越小，人才和知识流动也更频繁。谁能把全球资源整合得更顺溜，谁就能抢占下一个AI赛道的话语权。中国的公司确实展示了狠劲和决心，那能不能一直走在前面，还得看基础研究、人才培养和国际合作这几条线怎么走。有一点可以肯定，未来AI江湖可真是一天一个样，今天的大佬明天也许就被拍在沙滩上了，你说是不是挺刺激？"
  },
  {
    "title": "OpenAI升级API推出更强模型，加大开发者生态建设力度_新浪财经_新浪网",
    "page_body": "　　周一举办的开发者日活动上，OpenAI 公布了应用程序接口（API）的多项更新，包括推出最新语言模型 GPT-5 Pro、全新视频生成模型 Sora 2，以及一款体积更小、成本更低的语音模型。\n　　此次 API 更新是 OpenAI 一系列公告的组成部分，这些公告均旨在吸引开发者加入其生态系统，其他举措还包括推出智能体构建工具，以及支持在 ChatGPT 内开发应用程序的功能。\n　　OpenAI 首席执行官山姆・奥特曼表示，GPT-5 Pro 的推出可能会吸引金融、法律和医疗健康领域的应用开发者 —— 这些行业均需要 “高准确性和深度推理能力” 的技术支持。\n　　奥特曼还指出，语音功能在未来将至关重要，因为它正迅速成为人们与人工智能交互的主要方式之一。为此，OpenAI 正于 API 中推出 “gpt-realtime mini”：这是一款体积更小、成本更低的语音模型，支持音频与语音的低延迟流式交互。该新型号比 OpenAI 此前的高级语音模型便宜 70%，同时保证 “语音质量和表现力不变”。\n　　最后，参与 OpenAI 开发者生态的创作者如今可通过 API 预览版使用 Sora 2。上周，OpenAI 已发布其最新音视频生成模型 Sora 2，同时推出了Sora 应用 —— 这款应用内满是人工智能生成的短视频。用户可通过 Sora 应用，根据提示生成以自己、朋友或任意事物为主题的视频，并通过 TikTok 式的算法推荐流分享。\n　　奥特曼表示：“（开发者）如今可直接在自己的应用中，使用驱动 Sora 2 生成惊艳视频效果的同款模型。”\n　　Sora 2 在前代模型基础上进行了升级，能生成更逼真、物理逻辑更连贯的场景，实现声音与画面的同步，并提供更强的创意控制权 —— 从精细的镜头调度到风格化视觉呈现均涵盖在内。\n　　奥特曼表示：“例如，你可以先确定一个类似 iPhone 拍摄的视角，然后通过提示让 Sora 将其扩展为一个宏大开阔、具有电影质感的宽幅镜头。但我们目前正在研发的最令人兴奋的成果之一，是这款新模型能将声音与视觉完美匹配 —— 不仅限于语音，还包括丰富的音景、环境音效，以及与画面内容紧密关联的同步特效。”\n　　Sora 2 定位为一款概念开发工具，其应用场景广泛：既可以根据产品的整体风格，为广告打造视觉起点；也能帮助美泰（Mattel）的设计师将草图转化为玩具概念。奥特曼在开发者日活动中举了这个例子，这也间接揭示了 OpenAI 与这家芭比娃娃制造商达成的合作 —— 双方将把生成式人工智能整合到玩具开发流程中。"
  },
  {
    "title": "能力与可信度可以兼得？GPT-4、Gemini等多模态大模型评测报告来了-澎湃",
    "page_body": "机器之心专栏\n机器之心编辑部\n2023 年我们正见证着多模态大模型的跨越式发展，多模态大语言模型（MLLM）已经在文本、代码、图像、视频等多模态内容处理方面表现出了空前的能力，成为技术新浪潮。以 Llama 2，Mixtral 为代表的大语言模型（LLM），以 GPT-4、Gemini、LLaVA 为代表的多模态大语言模型跨越式发展。然而，它们的能力缺乏细致且偏应用级的评测，可信度和因果推理能力的对比也尚存空白。\n近日，上海人工智能实验室的学者们与北京航空航天大学、复旦大学、悉尼大学和香港中文大学（深圳）等院校合作发布 308 页详细报告，对 GPT-4、Gemini、LLama、Mixtral、LLaVA、LAMM、QwenVL、VideoChat 等热门的 LLM 和 MLLM 进行评测。根据 4 种模态（文本、代码、图像及视频）和 3 种能力（泛化能力、安全可信能力和因果推理能力）形成了 12 个评分项，并通过 230 个生动案例，揭示了 14 个实证性的发现。\n*作者顺序按照字母顺序排名\n评测报告：https://arxiv.org/abs/2401.15071\n榜单地址：https://openlamm.github.io/Leaderboards\n后续会持续对最新多模态大语言模型及多模态生成大模型进行评测，如GeminiUltra，SORA 等，结果会更新到榜单地址，敬请期待！\n结论速览\n文本和代码能力：总体来说，GPT4>Gemini>Mixtral>Llama-2 等其他模型。值得一提的是多语种翻译的能力，谷歌的 Gemini 大放异彩，其能准确捕捉成语和复杂结构的微妙差异，甚至超越了 GPT-4，展示出信达雅的中文翻译能力。\n领域知识：通过医学、经济学等学科知识测评发现，Gemini 的领域知识和 GPT-4 都非常丰富，但它在 “学以致用 \" 的能力上稍显欠缺，而且偏科医学。GPT-4 则在解决各种专业领域问题方面都都略胜一筹。\n安全与可信度：GPT-4 相比于 Gemini Pro，以及 Llama-2 等其他开源模型，展现出显著优势。在涉及道德敏感性问题和安全可信问题时非常谨慎，但可能由于其安全防护机制过强，导致部分正常问题也拒绝回答，这一点有待更多讨论。\n视觉能力：通过对图像和视频两种模态的输入进行评测，发现开源模型甚至在部分维度上与闭源模型的视觉能力评分不相上下，没有明显的差距，视觉的细节感知均有待提高，视觉能力可能将成为多模态大模型能力竞争的焦点。\n因果关系分析：文本、代码、图像和视频四种模态中，Gemini 语言表达非常简洁，GPT-4 在各模态输入时都能深入理解和解释复杂场景。对于视频输入，需要对时序有理解能力的因果推理问题上，特别是在处理多轮交互和理解事件序列因果关系方面，所有模型在都处于起步阶段。\n图 1：通过四种模态对各 LLM/MLLM 在通用性、可信度和因果关系上的评测结果\n实验性发现\n1. 文本和代码总体能力概括：总体而言，Gemini 的性能远不如 GPT-4，但优于开源模型 Llama-2-70B-Chat 和 Mixtral-8x7B-Instruct-v0.1。对于开源模型而言，在文本和代码方面，Mixtral-8x7B-Instruct-v0.1 的表现优于 Llama-2-70B-Chat。（GPT4>Gemini>Mixtral>Llama-2）\n图 2：创意写作，在这个评测样例中，让模型使用数学理论写一首情诗，GPT 非常有创意，π 代表无穷，指数曲线代表上升，常数代表始终如一，可见其融合多学科知识的能力非常不错。\n图 3：语法结果。绿色文字表明合理的回答。红色文字表明不合理的回答。GPT-4 表现最好，而 Mixtral 在 7 个问题中有 2 个错误的答案，Gemini 表现最差。\n2. 多语言翻译能力：在多语言翻译能力方面，Gemini 表现出色，甚至超越了 GPT-4 和最好的开源模型。Gemini 能够准确理解成语和英语句子的微妙差异以及复杂的结构，然后准确翻译它们，而 GPT-4 和开源模型通常只翻译字面意思。此外，Gemini 生成的中文翻译通常更加优雅。\n图 4：多语言翻译结果。绿色文字表明更优秀的回答。红色文字表明明显错误的回答。在将中国成语翻译成英文时，这三个模型都存在很多问题，但 Gemini 的表现稍好一些。\n3. 数学计算和推理能力：无论是多解数学问题、定理证明还是常识推理，Gemini 的表现通常较差，结果接近开源模型 Mixtral-8x7B-Instruct-v0.1 和 Llama-2-70B-Chat，而 GPT-4 一如既往的表现最好。Gemini 有时在引用定理和知识方面出现明显错误；即使使用正确的知识，它也经常因计算错误而失败。\n图 5：方程推导结果。绿色文字表明合理的回答。红色文字表明错误的回答。GPT-4 表现最好，其次是 Gemini，Mixtral 作为开源模型和这两个闭源模型仍有差距。\n4. 领域知识应用能力：Gemini 通常只具有某些领域知识的表面理解。无论是在医学、经济还是其他学科领域，Gemini 可以理解这些领域的专业术语和问题。然而，当将这些知识应用于解决具体问题时，它经常会犯错。相比之下，GPT-4 不仅具备专业知识，还知道如何应用它，通常能够较好解决专业领域的问题。至于图像输入，在医学专业领域（GPT-4 避免回答这一系列问题的领域），与开源 MLLMs 相比，Gemini Pro 在医学图像模态识别和内容理解方面表现出良好的能力，并在某些情况下提供有价值的诊断建议。然而，根据案例的评估结果，目前正在测试的 MLLMs 在提供有效的医学诊断和全面报告方面仍然面临重大挑战。\n图 6：领域知识应用能力。绿色文字表示合理的回答。红色文字表示不合理的回答。GPT-4 表现最佳，而 Gemini 和 Mixtral 提供了相互矛盾的解释和错误的答案。\n5. 文本和代码的可信度和安全性：与 GPT-4 甚至开源模型 Llama-2 相比，Gemini Pro 在这方面缺乏足够能力。Gemini Pro 难以熟练识别测试提示中的诱因和陷阱，如歧视、刻板印象和非法行为的实例。此外，研究者发现 Mixtral 的文本可信度能力不够稳健。有时它可以识别提示中的陷阱并给出安全的回应，但有时会失败。在极端风险方面，研究者关注潜在的化学威胁。Gemini Pro 对化学有很好的了解，可以准确地提供化合物的合成方法等。然而，它经常无法识别给定的化合物是危险的。相比之下，GPT-4 和 Llama-2 在这方面做得更好，会发出化合物是危险的警告。Mixtral 可能受到自己的化学知识的限制。虽然它也会回应，但不够详细。在代码的可信度方面，Llama-2 和 GPT-4 明显优于 Gemini Pro。Gemini Pro 具有强大的代码生成能力，但难以识别测试提示中的安全风险，如违反社会伦理、安全极端风险，甚至直接给出危险的答案。\n图 7：绿色文字表示安全的回应。红色文字表示不安全的回应。蓝色文字表示我们对这个回应的简短评论。只有 Gemini Pro 给出了危险爆炸化合物的具体名称。\n6. 文本输入时的推理能力：在文本因果关系场景中，研究者的分析揭示了不同模型响应的明显模式。具体而言，Gemini Pro 倾向于提供直接且符合规定的答案，特别是在问题明确要求简单的 “是或否” 回答或涉及从多个选择中进行选择时。Gemini Pro 的这一特点使其在更倾向于简洁回答的大规模评估中成为更实际的选择。相比之下，其他模型倾向于在回答中包含解释性细节。虽然这种方法可能对批量处理不太高效，但它为理解模型背后的推理过程提供了更清晰的洞察，这在需要理解决策背后逻辑的案例研究中特别有益。\n图 8：反事实推理的结果。绿色文字表示合理的回应。红色文字表示错误的回应。蓝色文字展示了 Llama2-70B-chat 的道德考量。它强调了在评估假设场景时道德推理的作用，这些场景虽然是假设的，但植根于现实世界的伦理困境。\n7. 代码输入时的因果推理能力：GPT-4 显示出评估给定问题的可行性并提供逻辑一致的解释的特殊能力。这种技能对于准确识别和解决问题至关重要。然而，其他三个模型在这个方面没有展示出同样的熟练水平。它们难以准确识别问题的可行性，通常导致生成与预期结果或要求不符的代码。\n图 9：代码生成结果。绿色文字表示正确的回应。红色文字表示错误的回应。\n8. 图像能力：MLLMs 已经展示出熟练理解图像主要内容的能力，能够基于提出的查询分析图像中的大部分信息。然而，在需要精确定位的任务，如检测，或需要精确信息提取的任务，如涉及 OCR 功能的图表分析方面，仍有改进的空间。\n图 10：图像计数结果。绿色文字表示更优秀的回应。红色文字表示错误的回应。所有的多模态大型语言模型（MLLMs）都无法准确地计算图像中物体的数量，这可能是由于遮挡问题，阻碍了它们在计数时准确识别物体，导致错误。\n9. 多图理解任务：MLLMs 在处理涉及复杂推理的多图任务方面仍面临挑战。例如，机器人导航等任务，需要空间想象力，以及漫画分析等任务，涉及到图像之间的关系分析，对 MLLMs 来说都具有困难。\n图 11：图像上下文学习结果。绿色文字表示合理的回答。红色文字表示错误的回答。所有 MLLMs 都无法准确读取时针指向的数字\n10. 处理图像时的安全性和可靠性评估：在测试模型对视觉干扰的抵抗力时，Gemini 和其他模型表现差别比较大。尽管 Gemini 能够在加入高斯噪声的图片中识别出物体，但其准确度仍低于其他开源模型。在极亮或逆光条件下进行的测试中，Gemini 展现了一定的图像识别能力。它可以正确辨认高速公路上的夜景，但对于在明亮的日落背景中的剪影，它就难以识别。当面对没有具体信息的空白图片时，Gemini、开源模型 LAMM 和 LLaVA 倾向于给出类似幻觉的回答。与之相比，GPT-4 通过表明图片内容的缺失来展现了更为可靠的视觉能力，保证了事实上的准确。在图像安全性方面，与 GPT-4 相比，Gemini Pro 有明显的不足，用户可以相对容易地操纵 Gemini Pro 生成有害的回答。目前的开源模型和 Gemini Pro 在图像输入时的安全护栏方面都需要进一步改进。\n图 12：一个关于食品安全的例子。绿色文字表示合理的回应。红色文字表示错误的回应。值得注意的是，GPT-4 和 Qwen-VL 都提供了合理的回应。然而令人不安的是，Gemini Pro 建议使用这些食物来伤害朋友，这种回应具有一定的危险性。\n11. 图像因果推理能力：与 GPT-4 的能力相比，Gemini 的明显更弱，且它与其他开源模型如 LLaVA 等能力接近。Gemini 在复杂场景中，如城市中发生洪水等，辨别复杂细节方面存在很大的局限性。相比之下，GPT-4 擅长处理这些复杂场景，展示了更好的理解和分析能力。Gemini 的比较独特的一点是它倾向于对给定问题提供简洁但常常非常有限的回答，猜测可能和其训练策略有关。相反，GPT-4 的回复通常更加全面广泛，其有能力提供更富有洞察力的回应，并充分考虑上下文信息。\n图 13：关于图像输入的因果推理能力的示例。绿色文字表示合理的回应。红色文字表示不合理的回应。开源模型 LLaVA 在视觉识别方面存在问题，而 Gemini Pro 和 GPT-4 能够识别 “燃烧”、“灭火” 和 “倒塌” 等关键词。此外，GPT-4 的回答更详细、包含更多内容。\n12. 视频处理能力：针"
  },
  {
    "title": "gpt和github怎么配合•Worktile社区",
    "page_body": "GPT（Generative Pre-trained Transformer）是一种强大的自然语言处理模型，而GitHub是一个代码托管平台。将GPT和GitHub配合可以实现许多有趣的应用，包括代码生成、文本生成和自动化文档等。以下是一些使用GPT和GitHub配合的常见方法：\n1. 代码生成与检查：使用GPT模型生成代码片段，然后将其提交到GitHub。你可以编写一个小的应用程序，读取GPT生成的代码并将其自动提交到GitHub仓库。这样可以加快开发速度，同时确保生成的代码符合语法规范和工程实践。\n2. 文本生成与项目文档：在GitHub项目中，文档对于项目的成功非常重要。你可以使用GPT来生成项目文档的初始草稿，然后将其提交到GitHub供项目成员查阅和完善。这样可以节省时间并提高文档的质量。\n3. 问题回答：使用GPT将GitHub的代码库转化为机器可读的格式，并使用这些数据训练一个模型。然后，根据用户提出的问题，使用GPT模型生成答案。这样可以快速响应用户的问题，提高问题解决效率。\n4. 代码仓库管理：你可以使用GPT模型来自动化一些代码仓库管理任务，如自动创建分支、合并请求、提交代码等。这可以大大简化代码管理过程，并减少手动操作的繁琐性。\n需要注意的是，使用GPT和GitHub配合需要谨慎操作，以确保生成的代码和文本的质量。在使用GPT生成代码的情况下，建议通过使用预训练模型进行微调来确保生成的代码符合预期。另外，不要完全依赖GPT生成的结果，仍然需要人工审核和修改。\n将GPT（Generative Pre-trained Transformer）和GitHub配合使用，可以实现许多有趣和实用的功能。下面是五个建议的用例来展示如何配合使用GPT和GitHub：\n1. 代码自动补全：GPT可以用于代码自动补全，通过训练模型使其能够根据上下文预测下一个可能的代码片段。你可以将GPT模型与GitHub的代码库结合起来，利用已有的代码进行训练，并通过GitHub的API调用来进行实时自动补全。这种方式可以极大地提高代码编写的效率。\n2. 自动Issue生成：利用GPT生成自动Issue，可以在编写提交代码时节省开发人员的时间。通过分析GitHub上的开源仓库和Issue的内容，可以训练一个GPT模型来生成描述问题的文本。这样，当用户提交代码时，系统可以自动生成相应的Issue，减轻开发人员的负担，并帮助团队更好地跟踪和解决问题。\n3. 自动代码审查：GPT可以用于自动代码审查，通过训练模型让其了解常见的代码风格和最佳实践。将GPT模型与GitHub的Pull Request集成，可以自动生成代码审查意见和建议，帮助开发人员提高代码质量。这种自动化审查还可以减轻人工代码审查的工作量，提高开发效率。\n4. 项目文档的生成：利用GPT生成项目文档，可以减轻项目文档编写的负担。根据代码库和注释，训练一个GPT模型，使其能够生成符合项目要求的文档。这样，在将代码提交到GitHub时，可以自动生成相应的文档，并将其与项目关联起来，方便他人了解和使用代码。\n5. 代码推荐和搜索：将GPT模型与GitHub的代码库结合，可以实现更智能的代码推荐和搜索功能。通过训练模型使其了解代码结构、语法和上下文，可以根据用户的输入和需求，提供更准确的代码推荐和搜索结果。这种方式可以帮助开发人员快速找到他们需要的代码片段和相关资源，提高开发效率。\n以上只是一些GPT和GitHub配合使用的示例，实际上还有许多其他的应用场景。通过将GPT与GitHub的数据结合起来，可以进一步发掘两者的潜力，提高软件开发和协作效率。\n配合GPT和GitHub可以实现以下几点：\n1. 在GitHub上使用GPT生成代码注释：通过将GPT模型训练成代码注释生成器，可以将其与GitHub上的代码仓库连接起来。当有人提交代码时，GPT会自动生成代码注释，从而提高代码可读性和可维护性。\n2. 在GitHub上使用GPT生成Issue模板：通过使用GPT模型生成Issue模板，可以自动生成标准化的Issue描述。这样可以提高Issue的质量，并让开发人员更专注于解决问题。\n3. 使用GPT训练代码评审工具：通过使用GPT模型训练代码评审工具，可以自动化代码评审，提供关于代码质量和最佳实践的反馈。通过与GitHub集成，可以将评审结果直接显示在pull request上，提供给开发人员作为改进代码的参考。\n4. 使用GPT生成文档：通过将GPT模型训练成文档生成器，可以自动生成项目文档。这会极大地简化开发人员的工作，并提供一致性的文档样式。\n下面是一种将GPT和GitHub配合使用的操作流程：\n1. 获取代码数据集：在GitHub上选择一个合适的代码仓库，然后使用GitHub的API或者其他方式，将代码仓库中的代码文件下载下来。可以选择一个特定的编程语言，或者选择一个特定领域的代码仓库。\n2. 数据清洗和预处理：对于下载的代码文件进行数据清洗和预处理工作，例如移除注释、格式化代码等。这一步的目的是为了提高GPT模型的训练效果。\n3. 训练GPT模型：将数据集输入到GPT模型中进行训练。可以使用已有的GPT模型，也可以自己训练一个。训练的过程可能需要较长的时间和大量的计算资源。可以使用GPU来加速训练过程。\n4. 集成到GitHub：将训练好的模型部署到GitHub上。可以使用GitHub Actions来实现自动化的代码生成和评审。\n5. 测试和调试：在实际使用之前，对集成到GitHub的GPT模型进行测试和调试。确保模型能够正常工作，并且生成的结果符合预期。\n6. 应用场景：根据具体的需求，将GPT模型应用到合适的场景中。可以是代码注释生成、Issue模板生成、代码评审等。\n7. 监控和改进：对于集成到GitHub的GPT模型，需要进行监控和改进。根据用户反馈和模型表现，对模型进行调整和改进，以提供更好的用户体验。\n注意：在将GPT模型集成到GitHub中时，需要遵守GitHub的使用规范和法律法规，确保不违反任何版权和法律要求。另外，保护用户的隐私也是非常重要的。在使用GPT模型生成代码注释或其他内容时，要注意避免泄漏敏感信息和隐私。"
  }
]