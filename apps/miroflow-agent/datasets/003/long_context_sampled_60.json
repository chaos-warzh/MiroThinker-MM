[
  {
    "title": "ChatGPT Plus可以用GPT-4，有没有试用过，可否分享下感受？-知乎",
    "page_body": "感受就是大冤种，暂时不建议冲！ 丫的限制条数，还越搞越少，图片接口也没开。 从100条/4小时到50条/4小时，再到25条/3小时。下周还会降 倒不是说OpenAI故意为之，或许是GPT4的推理确实比较贵吧，可能地主家也没有余粮了～ 加上用户多，限制也可以理解，但是好歹事先讲明啊！可以提价、限制人数，但OpenAI选择了直接砍用户体验。OpenAI再次证明，垄断真的可以为所欲为。 现在真的挺好奇GPT4的参数量到底有多大，从目前的情况来看似乎比GPT3.5要大不少，推理成本到底有多高呢，OpenAI现在的用户数有多少，到底需要多少服务器才hold的住啊，连OpenAI和微软都撑不住。感觉随着用户数疯狂增长，推理侧根本负担不起啊，为了更多的用户，未来单个用户的体验肯定会继续被砍。 暂时先用着旧版的ChatGPT吧或者用new bing。 快跑！传说中的GPT4真的来了！多模态，吊打旧版ChatGPT!最后，OpenAI开放ChatGPT/GPT4的试用和API不是在搞慈善，而是正经的在做生意。 有些人不要搞得用户像接受了多大恩赐一样，免费试用是商业行为（免费是免费，但真的不是慈善，用户收获了体验，OpenAI收货了用户、数据和潜在的money，需要感谢，但不必上纲上线），API付费是商业行为，plus会员更是商业交易，你出服务我出钱，现在服务跟不上，某些人反过来喷用户不识抬举就很搞笑了。 欢迎交流～"
  },
  {
    "title": "Hugging Face进军机器人，前特斯拉Optimus科学家带队",
    "page_body": "原创 王艺 甲子光年\n软件平台也有硬件野心。\n作者｜王艺\n编辑｜赵健\n机器人太火了，连专注软件领域的Hugging Face也入局了！\n美国时间5月6日，Hugging Face的机器人项目负责人雷米·卡德内（Remi Cadene）宣布推出LeRobot开源代码库，并形容它对于机器人的意义就如同“Transformer架构之于NLP（自然语言处理）”。\nRemi Cadene表示：“人工智能发展的下一步是将其应用于我们的物理世界。因此，我们正在围绕AI机器人建立社区驱动的努力，并且它向所有人开放！”\nRemi Cadene的X推文\nRemi Cadene在两个月之前加入Hugging Face，并在法国巴黎搭建团队，招募具身机器人工程师。此前Remi Cadene先后在特斯拉自动驾驶汽车部门与人形机器人Optimus团队担任科学家。\nRemi Cadene表示自己将在Hugging Face开启一个“雄心勃勃”的开源机器人项目，而且不是像OpenAI那样的开放，是真正的开源。\nHugging Face是一家总部位于纽约的人工智能公司，估值45亿美元。在组建开源机器人团队之前，Hugging Face的主营业务均为软件形态，包括开源AI模型库和AI助手Hugging Chat Assistants。\n如今，随着Hugging Face的开源机器人代码库上线，将会有更多的人加入到机器人研发的大潮中。Hugging Face已经乘上了大模型爆火的第一轮东风，它还会继续乘上机器人的东风吗？\n1.LeRobot：一个机器人的“图书馆”\n此次推出的LeRobot开源代码库旨在为Pytorch框架下的现实世界机器人提供模型、数据集和工具，目标是降低进入机器人技术的门槛，以便每个人都可以做出贡献，并从共享数据集和预训练模型中受益。\nLeRobot不仅仅是一个软件包，而是一个综合平台，其中包括用于共享、可视化数据和训练最先进模型的多功能库。具体而言，LeRobot开源数据库提供了一组预训练模型、包含人类收集演示的数据集，以及无需组装机器人即可使用的模拟环境，以为机器人在现实世界中的动作提供更多的支持。\n它与物理模拟器无缝集成，让没有物理机器人硬件的爱好者和开发人员可以在虚拟环境中模拟和测试他们的人工智能模型，目标是提供一个可以适应和控制任何形式的机器人的AI系统，从而实现机器人应用的多功能性和可扩展性。\nRemi Cadene在推文中表示，LeRobot之于机器人就像Transformer架构之于NLP——它提供带有预训练检查点的高级AI模型的简洁实现。他们还复现了来自学术界的 31 个数据集和一些模拟环境，无需实体机器人即可开始使用。\nCadene 发布了一些由Github上LeRobot库的代码提供的机器人功能的示例，它们都是在真实数据集上训练的。\n比如，在这个数据可视化的例子中，它展示了LeRobot是如何在Return（一个SDK和查看器，用于可视化与多模态数据流交互）上运行的，数据集来自Aloha项目（用于异构架构运行时自适应和安全深度学习的软件框架，主要目标是促进深度学习算法在异构低能耗计算平台上的实现，为最佳算法选择、资源分配和部署提供自动化。\nLeRobot的另一项可视化是在Mobile Aloha数据集上进行的，旨在完全端到端地学习导航和操作。以下例子展示了LeRobot控制下的两个机器人抓手/手臂之间传递物体：\n上述两个数据集都是在机器人公司Trossen Robotics的机械臂上收集的。\n当Remi Cadene团队使用ACT策略对LeRobot开源代码库进行测试时，基于LeRobot的机器人在模拟环境下同样表现良好。\nACT策略是一种机器人的动作分块算法，即Action Chunking with Transformers，它使用Transformer编码器合成来自多个视点、联合位置和风格变量的图像，并使用Transformer解码器预测一系列动作，通过预测动作序列来解决高精度领域中的问题。ACT策略可以在新环境干扰下做出反应，并且对一定程度的干扰具有鲁棒性。\n可以看到，两只机械手分别娴熟地捏起两块不同的积木并堆叠到了一起，证明了ACT策略下LeRobot的有效性。\n同时，在Diffusion Policy（扩散策略，一种强大的模仿学习算法）和TDMPC Policy（Temporal Difference Learning for Model Predictive Control，一种包含世界模型的强化学习算法）两种策略下，LeRobot同样表现出色，可以不断从与环境的交互中学习。\n早在索邦大学（Sorbonne University）读博的时候，Remi Cadene就给出了NASNet模型（一个移动端的ImageNet模型）的Pytorch实现方法。\n2021-2024年3月在特斯拉的Autopilot团队和Optimus团队工作期间，Remi Cadene也在自动标记神经网络、构建操控网络等工作中做出了重要贡献。\n2.软件平台也有硬件野心\n在过去的几个月里，人形机器人技术取得了令人印象深刻的突破（ALOHA、扩散策略、UMI 等等），使机器人能够在有限数量的数据集上运行，同时让很多资金实力不足的小团队也能训练自己的机器人。\n同时，最近一段时间，大量风险资本涌入人形机器人行业，比如Figure AI在2月份获得了来自英伟达、亚马逊和OpenAI等的6.75亿美元融资，这已经是他们在2023年5月完成7000万美元A轮融资、7月获英特尔900万美元投资后，一年内的第三次融资。\n4月18日波士顿动力将其液压动力机器人Atlas退役、推出了全新的电动Atlas机器人；就在前天，特斯拉宣布了其人形机器人Optimus能力的全面升级。\n在中国，人形机器人赛道同样耀眼，仅仅是在2024年4月，中国的人形机器人领域就发生了4起投融资事件，截至目前已经有了8起融资事件，达到了2023年的三分之二，累计融资金额超过12亿元。2023年底，人形机器人第一股优必选更是成功在港交所上市。\n「甲子光年」曾指出，通用人工智能对物理世界的价值需要有具身的实体来承载，而人形机器人就是最好的落地方式；大模型打开了通用机器人的可实现性，帮助人形机器人在技术层面迈过了一个鸿沟，产生了巨大的价值发挥空间，而这也是人形机器人最近备受科技和投资圈关注的原因。\n作为在机器学习和AI领域深耕了多年的玩家，Hugging Face同样能够看到人形机器人的巨大潜力。今年3月，在将前特斯拉AutoPilot与Optimus科学家招至麾下后，Hugging Face在法国巴黎招募具身机器人工程师，并提到：“在Hugging Face，我们相信机器学习不必局限于计算机和服务器，这就是为什么我们正在扩大我们的团队，为专注于机器学习/人工智能的机器人工程师提供新的机会。”\nHugging Face表示，“在这个职位上，你将负责设计、构建和维护集成人工智能技术的开源和低成本机器人系统，特别是深度学习和具体人工智能技术，突破机器人和人工智能的可能性界限”。\nHugging Face已经迈出了第一步。将LeRobot机器人代码库开源是Hugging Face的一项战略决定，旨在避免权力和创新集中在少数公司手中。\nLeRobot发展的基础是创建有史以来最大的众包机器人数据集。通过与大学、初创公司、大型科技公司和个人爱好者合作，Hugging Face 正在促进庞大机器人数据存储库的建立——这其中包含数以TB计的机载视频记录，这些视频记录正在使用轻量级的 LeRobot Dataset 进行格式化，以便通过Hugging Face快速上传和下载。\n未来，通过降低准入门槛并营造共享知识和资源的环境，Hugging Face上有希望长出一个可以重新定义人工智能机器人领域的社区，而这也是Hugging Face的机器人野心。\n（封面图来源：Hugging Face）\nEND. \n原标题：《Hugging Face进军机器人，前特斯拉Optimus科学家带队｜甲子光年》\n阅读原文"
  },
  {
    "title": "40亿参数颠覆多模态格局：Qwen3-VL-4B如何重塑AI应用生态-CSDN博客",
    "page_body": "40亿参数颠覆多模态格局：Qwen3-VL-4B如何重塑AI应用生态\n【免费下载链接】Qwen3-VL-8B-Instruct  项目地址: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-VL-8B-Instruct \n导语\n阿里通义千问团队推出的Qwen3-VL-4B以40亿参数实现传统70亿模型核心能力，通过FP8量化技术将显存需求压缩至6.8GB，标志着多模态AI从云端重型设备向终端轻量化工具的范式转变。\n行业现状：多模态AI的\"规模困境\"\n2025年全球多模态大模型市场规模预计达989亿美元，但企业级部署成本因算力门槛居高不下。据Gartner数据，传统百亿级参数模型部署成本平均超过百万，而轻量化模型普遍存在\"视觉-文本能力跷跷板效应\"。在此背景下，Qwen3-VL-4B以\"小而强\"的技术路径脱颖而出——在8GB显存环境下实现每秒15.3帧的视频分析速度，较同类模型降低42%显存占用。\n核心突破：四大技术重构终端AI体验\n1. 架构创新：Interleaved-MRoPE与DeepStack双引擎\nQwen3-VL采用Interleaved-MRoPE位置编码，将时间、高度和宽度信息交错分布于全频率维度，长视频理解能力提升40%；DeepStack特征融合技术则通过多层ViT特征融合，使细节捕捉精度达到1024×1024像素级别。这种设计使4B模型在MMLU文本理解测试中得分68.7%，同时保持图像描述（COCO-Caption）和视觉问答（VQAv2）的双重突破。\n2. 视觉Agent：从\"识别\"到\"行动\"的跨越\n最具革命性的GUI操作引擎使模型可直接识别并操控PC/mobile界面元素。在OS World基准测试中，完成航班预订、文档格式转换等复杂任务的准确率达92.3%。某电商企业实测显示，使用Qwen3-VL自动处理订单系统使客服效率提升2.3倍，错误率从8.7%降至1.2%。\n3. FP8量化：性能无损的压缩魔术\n采用细粒度128块大小的量化方案，在将模型体积压缩50%的同时，保持与BF16版本99.2%的性能一致性。新浪科技实测显示，该模型在消费级RTX 4060显卡上实现每秒15.3帧的视频分析速度，而显存占用仅需6.8GB。\n4. 全场景多模态交互能力\n扩展OCR ：支持32种语言（含古文字），低光照场景识别准确率提升至89.3% 空间感知 ：可判断物体遮挡关系与3D位置，为机器人导航提供环境理解 视觉编程 ：从设计稿生成HTML/CSS代码，前端开发效率提升3倍\n行业影响：从实验室到产业一线的落地革命\n工业质检：手机变身检测终端\n通过移动端部署，Qwen3-VL可实现0.1mm级别的零件瑕疵识别。某电子代工厂案例显示，该方案将质检效率提升300%，同时使设备成本从传统机器视觉方案的28万元降至不足万元。\n智能座舱：重新定义人车交互\n在车载系统中，Qwen3-VL可实时分析仪表盘数据（识别准确率98.1%）、解读交通标识。某新势力车企测试显示，该方案使语音交互响应延迟从1.2秒降至0.4秒，误识别率下降63%。\n教育培训：智能教辅的普惠化\n教育机构利用模型的手写体识别与数学推理能力，开发了轻量化作业批改系统：数学公式识别准确率92.5%，几何证明题批改准确率87.3%，单服务器支持5000名学生同时在线使用。\n图片生成代码能力实测\nQwen3-VL能将图像/视频直接转换为Draw.io/HTML/CSS/JS代码，实现\"截图转网页\"的所见即所得开发。在一项测试中，模型用600行代码复刻了小红书网页界面，还原度达90%。\n如上图所示，这张图片是Qwen3-VL的特性详情表格，展示了其多模态能力、长上下文、视频定位等技术特性，属于开源视觉-语言大模型。表格清晰呈现了模型在不同维度的性能指标，帮助读者快速理解其核心优势。\n部署指南：从零开始的多模态应用开发\nQwen3-VL-4B-Instruct已通过Apache 2.0许可开源，开发者可通过以下命令快速上手：\ngit clone https://gitcode.com/hf_mirrors/Qwen/Qwen3-VL-8B-Instruct cd Qwen3-VL-8B-Instruct pip install -r requirements.txt # 推荐部署工具：Ollama（个人开发者）或vLLM（企业级部署） \n如上图所示，Qwen3-VL的品牌标识融合了科技蓝与活力紫，搭配手持放大镜的卡通形象，象征模型\"洞察细节、理解世界\"的核心定位。这一视觉设计直观传达了多模态AI从被动识别到主动探索的能力跃升。\n结语：小模型的大时代\nQwen3-VL-4B-Instruct的出现，标志着多模态AI正式进入\"普惠时代\"。40亿参数规模、8GB显存需求、毫秒级响应速度的组合，正在打破\"大模型=高成本\"的固有认知。对于企业决策者而言，现在正是布局多模态应用的最佳时机——通过轻量化模型以可控成本探索视觉-语言融合带来的业务革新。\n随着模型小型化与推理优化技术的持续进步，我们正迈向\"万物可交互，所见皆智能\"的AI应用新纪元。立即克隆仓库，开启你的多模态应用开发之旅。\n【免费下载链接】Qwen3-VL-8B-Instruct  项目地址: https://ai.gitcode.com/hf_mirrors/Qwen/Qwen3-VL-8B-Instruct"
  },
  {
    "title": "从美国科技巨头布局看大模型演进方向-豆丁网",
    "page_body": "2 一、美股科技巨头、软件企业在AI领域的布 局 . 3资料来源：各公司官网，中信证券研究部 美股科技巨头近期在AI领域的动作 公司 时间事件 2022.11.2 推出AI写作工具LaMDAWordcraft 2023.1.2 推出基于文本生成图像的AI模型“Muse” 2023.1.28 发布生成式AI音乐模型MusicLM 2023.1.30 向人工智能初创公司AnthropicAI投资约3亿美元 2023.2.3 “未来几周或几个月”推出类似ChatGPT的基于人工智能的大型语言模型 2023.2.6 谷歌宣布将推出一款聊天机器人—Bard 2023.2.9 谷歌表示将推出由人工智能驱动的新搜索和地图功能 2023.3.8 谷歌发布五千亿参数语言大模型PaLM，并微调出跨模态模型PaLM-E 2023.1.23 开启对OpenAI的第三轮投资 2023.2.2 宣布将OpenAI相关产品导入旗下云计算、Office、Bing、VivaSales等产品中 2023.2.7 正式推出由ChatGPT支持的最新版本Bing（必应）搜索引擎和Edge浏览器 微软 2023.2.22 宣布为iPhone和Android发布新的必应和Edge预览版应用程序，其中包括语音搜索和访问其AI聊天机器人等新功能 2023.3.8 微软宣布将发布集成ChatGPT能力的Office，并已经开始在Azure公有云服务中提供OpenAI模型 2023.3.14 OpenAI公开发布大型多模态模型GPT-4，与ChatGPT所用的模型相比，GPT-4不仅能够处理图像内容，且回复的准确性有所提 高 2023.3.16 微软公司宣布将通过Microsoft365Copilot将下一代AI的强大功能引入其工作场所生产力工具 1.1美股科技巨头近期在AI领域的动 作 谷歌 . 4 1.1美股科技巨头近期在AI领域的动 作 OpenAI官网，微软官网，中信证券研究 部 微软三次投资OpenAI，推进公司人工智能水平。微软于2023年1月23日宣布将向OpenAI开展“多年、百亿级美 元”的投资，此前在2019年微软已经投资10亿美元，并在2021年再次投资。此次合作后，微软将增加对超级计算系 统的投资，在Azure中部署OpenAI程序，包括GPT、DALLE、Codex，同时微软将作为OpenAI的独家云提供商， Azure将为OpenAI提供所有的工作负载。 旗下产品与ChatGPT深度融合，未来有望加速AI产业化落地。此次合作中，微软宣布将把OpenAI的相关产品介入到 旗下云及其他产品中，我们认为此举对微软云计算以及其他业务的发展具备重要意义：1）强化Azure在AI领域的能 力，丰富微软在语义等领域的实力。2）与旗下Office产品达成更强的协同，以ChatGPT为代表的相关产品对文字补 写、代码辅助编辑等具备特殊优势。3）引入bing搜索，优化体验。微软将其引入搜索后，将对搜索结果的匹配以及体 验带来改善。 微软投资OpenAI历史微软战略布局AI的意义 2019 2021 2023 •微软宣布投资OpenAI10亿美元，此时OpenAI更 新 GPT2模型，将参数从1.24亿提升至7.74亿。 •微软对OpenAI追加第二轮投资，OpenAI发布基 于GPT3的能够连接图像与稳步的神经网络 CLIP，发布从文标题创建图像的模型DALL·E。 •微软宣布将向OpenAI开展“多年、百亿级美 元”的投资。 云 Office Bing搜 索 •强化Azure在AI领域的能力，丰富微软在语 义等领域的实力。 •与旗下Office产品达成更强的协同，以 ChatGPT为代表的相关产品对文字补写、 代码辅助编辑等具备特殊优势。 •引入Bing搜索，优化体验。微软将其引入 搜索后，将对搜索结果的匹配以及体验带 来改善。 OpenAI官网，微软官 网 . 5 1.1美股科技巨头近期在AI领域的动 作 资料来源：智东西，谷歌TPU网站，中信证券研究 部 谷歌一直致力于AI技术的研发与实践，是该领域的领先者。2016年3月，谷歌DeepMind研发的AlphaGo在围棋人 机大赛中战胜韩国职业九段棋手李世石，成为AI领域发展的标志性事件之一。从论文数量看，2021年谷歌有177 篇论文被NeurlPS（目前人工智能算法的最高期刊）接收并发表，数量遥遥领先。 TPU+Tensorflow软硬一体，构筑AI护城河。谷歌基于早期技术，在DistBelief基础上创造了Tensorflow的AI框架；同 时，公司研发出专属Tensorflow的运算芯片TPU，以软件+硬件的形式，实现独特的AI技术能力。在神经网络算法方 面，2017年谷歌推出的Transformer也逐渐成为了主流，为大模型的训练提供技术支持。 谷歌TPU技术能力全球商用AI框架市场份额结 构（2021） AIwatch 芯片名称 发布日 期 性能应用 TPU201628nm制程，主频700MHz深度学习推理 TPUv22017 180TFLOPs浮点运 算， 64GBHBM 机器学习训练与推理，可以 在Googlecomputerengine 运行 TPUv32018 420TFLOPs浮点运 算， 128GBHBM 更广泛的深度学习训练和推 理 Edge TPU 2018高吞吐量串流资料 企业级机器学习任务，主要 为AI推理 TPUv2 Pod 每秒11.5千万亿次浮点运算、 20194TBHBM、二维环面网状深度学习推理网 络 2019 TPUv3 Pod32TB HBM 超过100千万亿次浮点运算、 深度学习推理 0.0% 5.0% 10.0% 15.0% 20.0% 25.0% 30.0% 35.0% 40.0% TensorflowOpenCVPyTorchKerasOthers . 6 资料来源：各公司官网，中信证券研究部 主流软件企业广泛布局AI领域 1.2主流软件企业广泛布局AI领 域 子领域公司应用 NLP（自然语言处 理） Five9在其云联络中心利用人工智能作为虚拟客服，实时传递客户请求。 RingCentral对话式人工智能AISmartAssist分析客户需求并帮助客户更快地获得响 应。 Zoom发布虚拟客服，建立全渠道联络中心，帮助客户将其人力用于更复杂的疑问。 ZoomInfo 使用对话智能技术来帮助企业达成交易并改善他们的销售流程。 Qualtrics 利用文本情感分析，通过其管理平台和应用程序，根据用户生成的数据创建报告。 Sprinklr 其客户体验管理(CXM) 平台对来自多个渠道的非结构化数据利用人工智能进行文本情感分析，以了解客户是如何看待一 个 品牌的。 计算机视觉 Appian 利用计算机视觉进行图像处理和信息& 数据提取，打通工作流程自动化的全流 程 Adobe Sensei 将计算机视觉进一步扩展到设计空间，作为Adobe Experience 和Creative Cloud 平台中的AI 应 用层 ServiceNow 通过其自动化引擎( 包括RPA Hub 和文档智能应用程序) ，允许用户实现人工智能驱动的计算机视觉任务监控和工作 流自 动化。 . 7 资料来源：各公司官网，中信证券研究部 主流软件企业广泛布局AI 领域 1.2 主流软件企业广泛布局AI 领 域 子领域 公司 应用 预测模型 Zeta 在Zeta 数据云上构建预测建模应用程序，允许用户全面收集客户信息，并全面分析留存行为 等。 Salesforce 利用其人工智能产品Einstein ，通过销售云平台为销售团队提供了广泛的预测建模用 例。 异常检测 Datadog 其Watchdog 引擎自动检测关键运行状况性能异常，通过自动化分析解决代码问题并确定问题依赖关系，还可以修复工作 流 问题并发现延迟异常值。 Splunk 自动关联事件以缩短其平均解决时间；提供异常检测以在问题影响性能之前预测和预防问题；其机器学习工具包为用户提 供了监控和生成警报的能力。 Elastic 使用AI/ML 分析最终用户、基础设施和应用程序监控数据来检测异常，并加速问题解 决。 Palo Alto Networks 在安全方面使用异常检测技术，为云提供防火墙和保护产品。 CrowdStrike 利用AI/ML 进行异常检测，以实现网络安全解决方 案。 . 8 1.3 AI 产业结 构 资料来源：海外独角兽微信公众号，中信证券研究部 AI 产业结构 硬件 云服务 大语言模型 自然语言：NLP 开发、文案生成（电 商 / 新闻/ 法律）、对话机器人（销售客 服/ 情感陪伴）、笔记 机器语言：代码生成（关注版权问题）、 RPA 交互生成 多模态模型 图片：图片生成、图片识别、3D 建 模 生成 音视频：音频识别、音视频剪辑、音视 频生成、Avatar 生成 算法 应用 基建层 GPT-3 Codex DALL-E 2 AlphaZero AlphaFold Gato BERT ViT DreamFusion ResNet OPT-175B Make-A- Video Constitutional AI 工作流 模型获取 数据准备 模型训练 模型评估 模型部署 模型监控 智能控制：机器人、自动驾驶、边缘计 算& 联邦学习 AL for science ：医学、物理、化 学、 材料科学 AI 安全：模型安全、可控生成、AI 可 解 释性 . 9 1.3 AI 产业结 构 资料来源：海外独角兽微信公众号，中信证券研究部 机器学习工作流拆解 查询工具:Hive,Presto 数据科学工具:Spark,Numpy,Pandas 数据科学平台 Jupyter,Databricks,Sag e maker,Colab 工作流管理： Prefect,Airflow 数据标注 （y ） Sacle,Snorkel output: 矩阵(X ， y) role: 数据工 程师 output: 模型f(X ， y) role: 数据科学 家 output:f(X_hat) →y_hat role: 算法工程师 output: 产品生产环 境 role: 后端工程 师 数据准备 模型训练 模型部署 产品整合 特征仓库 （X ） Tecton,Feast 模型库 Hugging Face ML 框架：Scikit- learn,XGBoost DL 框架： Tensorflow,PyTorch RL 框架： Gym,Dopamine 分布式计算： Ray(Anyscale),Dask 实验管理（模型性能） Weight and Bias, Neptune 模型监控（模型可用性与解释性） Arise,Fiddler,Arthur,WhyLab 模型部署和serving( 使用性 能） BentoML,OctoML,Tensorflow/ Pytorch/Ray Serving ML APIs OpenAI,Cohere,AWS,Azure 产品 向量搜索数据库 Pinecone Data Ops Data Infra ETL BI Tools . 10 二、科技巨头大模型比较及格局推演 . 11 OpenAI ChatGPT 发展历程 2.1 ChatGPT ：加入人类反馈学习，优化问题、答案之间匹配精准 度 2018.6 2019.1 2020.5 2022.1 2022.11 2023.3 GPT-1 GPT-2 GPT-3 InstructGPT ChatGPT GPT-4 参数量 1.17 亿 15 亿 1750 亿 13 亿 未公布 未公布 模型 更新 在大规模数据上对 Transformer 模型进 行 无监督预训练，再 在 小规模有监督数据集 解决零次学习问题 上精细调节。 （zero-shot ），使得 该模型在测试常识推 模型更具通用性。 理和阅读理解的数据 集上获得了最先进的 结果 数据量指数级增加， 可利用少量样本学 习， 引入RLHF ，微调后 能 更好地遵循用户意 图， 泛化能力极大提 升。 在数据收集设置上优 化连接大量真实语料 库，能够支持多轮对 话、结果修正，人机 交互效果更好、更 快、 更高效。 模型处理复杂问题的 能力进一步提升，同 时解决了部分对于办 公软件最重要的多模 态输入问题。 贴近人脑学习模式。 此外，基于 GPT-3 模 型微调在其他领 域包 括代码生成、 图像生 成、数学算 数等产生 了应用。 . 12 ChatGPT 的技术逻辑：RLHF 的主要改变在于人工监督数据与调整后的奖励模型 2.1 ChatGPT ：加入人类反馈学习，优化问题、答案之间匹配精准 度 OpenAI . 13 OpenAI ，中信证券研究部 注：纵轴为与真实答案的最大相似度 Real Toxicity 数据集likehood OpenAI ，中信证券研究部 注：纵轴为与真实答案的最大相似度 Hallucination 数据集likehood OpenAI ，中信证券研究部 注：纵轴为与真实答案的最大相似度 TruthfulQA 数据集likehood OpenAI ，中信证券研究部 注：纵轴为与真实答案的最大相似度 Customer Assistant Appropriate 数据集likehood 2.1 ChatGPT ：加入人类反馈学习，优化问题、答案之间匹配精准 度 0.24 0.23 0.22 0.21 0.2 0.19 0.18 0.17 GPT 有监督微调 InstructGPT 0.45 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 0 GPT 有监督微调 InstructGPT 0.45 0.4 0.35"
  },
  {
    "title": "产业资讯-四川省经济和信息化厅",
    "page_body": "浏览量: 74\n字体: \n多款人工智能大模型近日扎堆上市。OpenAI发布最新多模态人工智能大模型GPT—4o；谷歌发布“人工智能全家桶”，包括对标GPT—4o的全能人工智能助手Project Astra和对标Sora的文生视频模型Veo等。5月15日，字节跳动也发布豆包大模型，并将价格拉至行业新低。\n不仅是字节跳动，连日来，OpenAI、阿里云等企业纷纷下调大模型价格。其中，豆包主力模型的推理输入价格只有0.0008元/千Tokens（文本中最小语言单元），比行业便宜99.3%。也就是说，0.8厘就能处理1500多个汉字。大模型从以分计价到以厘计价，将助力企业以更低成本加速业务创新。火山引擎总裁谭待表示：“降价的基本逻辑是，我们有信心用技术手段降低成本，市场也需要更低价的大模型。”\n只有有大的使用量，才能打磨出好模型，也能大幅降低模型推理的单位成本。公开数据显示，在苹果APP Store和各大安卓应用市场，豆包APP的下载量在生成式人工智能类应用中排名第一。据字节跳动产品和战略副总裁朱骏透露，豆包上已有超过800万个智能体被创建，月度活跃用户达到2600万。\n“经过一年时间的迭代和市场验证，豆包大模型正成为国内使用量最大、应用场景最丰富的大模型之一，目前日均处理1200亿Tokens文本，生成3000万张图片。”谭待说。\n国家数据局局长刘烈宏此前公开介绍，中国10亿参数规模以上的大模型数量已超100个，行业大模型深度赋能电子信息、医疗、交通等领域，形成上百种应用模式，赋能千行百业。中国信息通信研究院数据显示，2023年我国人工智能核心产业规模达5787亿元，相关企业数量达4482家。人工智能产业链已覆盖芯片、算法、数据、平台、应用等上下游关键环节。\n中国信息通信研究院院长余晓晖认为，在以大模型为代表的创新浪潮带动下，人工智能技术、产业、应用等各环节将迎来快速迭代演进和探索突破的关键时期。从近期来看，大模型已在日常办公、文本创作、图像视频生成、客服问答等领域展现较大发展潜力和应用价值；从中长期看，大模型将与制造、生物医药、能源、交通等实体经济领域深度融合，不断提升创新效率、拓展应用领域、提高生产效率，成为各行业转型升级的基础赋能工具，带动更大范围创新。\n“大模型的产业化落地和商业化应用需要培育生态型商业模式，构建大模型产业生态体系。”清华大学社科学院经济所副所长戎珂说。\n企业正加速构建大模型产业生态。5月15日，火山引擎联合中国电动汽车百人会，与20余家厂商宣布成立汽车大模型生态联盟，将为消费者带来汽车全场景AI新体验。同时，火山引擎与OPPO、vivo、荣耀、小米、三星、华硕宣布成立智能终端大模型联盟。OPPO小布助手、小米小爱同学，以及荣耀笔记本电脑的YOYO助理、华硕笔记本电脑的豆叮AI助手等应用，均已接入火山引擎的大模型服务。\n价格下降也有助于产业生态构建。谭待表示，企业的人工智能转型充满不确定性，试错成本要尽量低，才能更快更多实现大模型的应用落地，从而让整个行业受益。\n目前，大模型市场仍在发展初期，远没到激烈竞争的阶段。商业智能数据服务商QuestMobile的数据显示，截至今年3月份，基于大模型的生成式人工智能行业用户量为7380万，尽管同比增长8倍，也仅占移动互联网用户量的6%。\n戎珂分析，通用大模型的核心能力为企业和组织提供了更好的数字基础能力，支持更高效的数据分析和决策支持，帮助提高生产效率和服务质量，有助于各行各业的企业不断培育、提炼专有能力，加速大模型生态能力体系的建设。大模型生态的崛起也将促使工业互联网和消费互联网的深化发展。在工业领域，大模型用于监控和优化生产过程，实现智能制造；在消费领域，人工智能在个性化推荐和服务改进上的强大能力将有助于提升用户体验，并反馈给生产端，从而实现全场景的数字化和智能化。\n大模型时代已经来临。“通过培育生态、促进合作和创新，大模型将成为科技进步和经济发展的引擎，推动各个领域的变革和发展。因此，各行各业应积极利用和发挥大模型的能力，构建生态型商业模式，加速大模型的商业化落地和广泛创新。”戎珂说。\n中国农业大学经济管理学院教授颜建晔建议，发展人工智能大模型应注重数据安全、算法伦理，同时加强算法创新和人才培养。未来的发展趋势可能会聚焦于模型的泛化能力、低资源消耗和更广泛的行业应用。同时，跨界融合和国际合作也将是关键。"
  },
  {
    "title": "世界首个AI多人游戏全面开源！1500刀实时生成，一台PC跑出平行宇宙",
    "page_body": "新智元报道 \n 编辑：定慧 好困 \n 【新智元导读】刚刚，全球首个AI多人世界模型开源了！只需一台PC外加1500美元，就能让两个AI智能体在同一个世界中感知、互动、协作。这不仅是AI造梦的一小步，更是AGI创造世界模型的一大步。 \n 如果AI能生成一个多人世界，还能一起飙车会怎样？ \n 今天，来自以色列的Enigma Labs决定创造这个历史—— \n 他们用第一性原理把「世界模型」拓宽到了多个玩家，并开源了世界首个AI生成多人游戏模型Multiverse！\n这不是一个简单的游戏引擎，而是一个可以模拟两个AI同时在一个世界中做出「合理动作」和视觉反应的大脑。 \n 更值得一提的是，整套训练流程只需不到1500美元，而且在你自己的电脑上就能跑！ \n 目前，项目代码、数据、权重、架构，以及研究成果，已经全面开源。 \n Hugging Face：https://huggingface.co/Enigma-AI \n GitHub：https://github.com/EnigmaLabsAI/multiverse \n 技术博客：https://enigma-labs.io/\n传统的世界模型（World Model）确实很聪明。它能看着游戏画面，预测下一个画面该长什么样，甚至学会了怎么在「内心」模拟物理、角色、环境等等。比如DeepMind做的Dreamer系列，就能靠想象完成游戏过关。 \n 但问题来了——现实不是只有一个人玩的游戏。 \n 想象一下，你在玩赛车游戏，对手突然一个漂移从你身边切过去，这时你和对手所看到的场景必须是「同一事件的两个角度」，不能各玩各的，不然要么撞车的只有你，而他却穿模消失——这种「视角错乱」在AI世界里，其实是非常难处理的。\n如何让两个AI，在同一个世界里「看到同一件事」，并遵循相同物理规律？ \n 这就是Enigma Labs的Multiverse要解决的核心难题。 \n Multiverse架构详解\nMultiverse多人世界模型的架构 \n 为了帮助理解Multiverse多人世界模型的架构，首先回顾一下单人世界模型中常用的架构：\n模型接收一系列视频帧和用户的操作信息（如按键），并据此预测在当前操作下的下一帧。 \n 它通过三个主要的组件来实现这个「预测」： \n 动作嵌入模块：将动作转换为嵌入向量 \n 去噪网络：一种基于之前的帧和动作嵌入生成新的帧的扩散模型 \n 上采样器（可选）：另一种扩散模型，它接收由世界模型生成的低分辨率帧，并增加输出的细节和分辨率。 \n 多人游戏架构 \n 为了构建一个多人世界模型，Multiverse保留了核心组件，但彻底调整了结构，重新连接了输入和输出，并从头开始重新设计了训练流程，以实现真正的合作游戏体验：\n动作嵌入模块：接收两个玩家的动作，并输出一个代表他们共同动作的嵌入向量 \n 去噪网络：基于之前的帧和两个玩家的动作嵌入，同时生成两个玩家的帧作为一个整体。 \n 上采样器：与单人游戏版本非常相似，不同的是，这里的上采样器接收两个帧（每个玩家一个），并同时计算上采样版本。 \n 要创建多人游戏体验，模型需要接收两个玩家的前几帧画面和动作，并为每个玩家都要输出预测帧。 \n 难点在于：这两个输出不仅需要各自看起来不错，还需要彼此内部一致，简单地说就是两个玩家的感受是一致的，是发生在同一个世界中的。 \n 这带来了真正的挑战，因为多人游戏依赖于共享的世界状态。例如，如果一辆车漂移到另一辆车的前面，或者发生碰撞，两个玩家都应该从各自的角度看到完全相同的事件。 \n Multivers提出了一种变通的解决方案：将两个玩家的视角拼接成一个统一的图像，将他们的输入混合成一个联合动作向量，并将整个场景视为一个统一的整体进行处理。\n由此产生了一个关键问题：将两个玩家「看到的面面」合并成模型可以处理的单一输入的最佳方法是什么？ \n 1. 很显然，最直接的方法是将它们垂直堆叠起来——就像经典的分屏游戏那样（比如最流行的双人成行游戏是横向堆叠）。\n2. 另一个更有趣的选择是沿着通道轴堆叠它们，将两帧视为一个具有双倍颜色通道的图像。（下图右边）\nMultiverse选择了第二种方案，即沿着通道轴堆叠帧。 \n 因为Multiverse选择的扩散模型是一个U-Net结构，主要由卷积和反卷积层构成，前几层只处理相邻的像素。 \n 如果将两个帧垂直堆叠，模型要到中间层才能将它们一起处理（CNN的特点就是无法在一开始将整张图片的像素一下子关联起来）。这会降低模型生成帧间一致性的能力。 \n 另一方面，当沿着通道轴堆叠帧时，两个玩家的视角在网络的每一层都会被同时处理！\n上下文扩展：建模车辆运动学与两车相对运动 \n 为了准确预测下一帧，模型需要接收玩家的操控指令（如转向输入），以及足够多的帧数，来计算两辆车相对于道路和彼此的速度。 \n 研究发现8帧（30fps）就可以让模型学习车辆的运动学，如加速、刹车和转向。 \n 但两辆车的相对运动比对道路的运动要慢得多。例如，车辆以约100公里/小时的速度行驶，而超车时的相对速度约为5公里/小时。 \n 为了捕捉这种相对运动，需要将上下文的长度扩展近三倍。但这会导致模型运行速度过慢，无法满足实时游戏的需求，同时还会增加内存占用，并大幅降低训练速度。 \n 为了在维持上下文长度的同时，获取更长的时间跨度信息，Multiverse对之前的帧和操作进行了稀疏采样。 \n 具体来说，提供最近的4帧，然后从之前的帧中，每隔4帧取1帧，一共取4帧。上下文中最早的帧是20帧之前，也就是0.666秒前的数据，这足以捕捉车辆的相对运动。 \n 此外，这种方法还能帮助模型更好地捕捉车辆相对于道路的速度和加速度，从而进一步优化驾驶体验。\n多人游戏训练 \n 为了让模型学会驾驶技术和多人游戏中的互动，模型需要在这些互动场景中进行训练。 \n 在世界模型中，行走、驾驶和其他常见任务通常只需要较短的预测范围，例如预测未来0.25秒的情况。 \n 多人游戏中的互动则需要更长的时间跨度。在四分之一秒内，玩家之间的相对运动几乎可以忽略不计。 \n 因此，为了训练多人游戏世界模型，需要设置更长的预测范围。Multiverse将训练模型进行自回归预测（以30fps/s）最多可预测到未来15秒。 \n 为了使模型能够进行如此长时间的预测，Multiverse采用了课程学习，并在训练过程中将预测时间从0.25秒增加到15秒。 \n 这使得在初始训练阶段能够高效地训练模型，此时模型正在学习诸如汽车和赛道几何形状等低级特征。一旦模型学会了生成连贯的帧并建模车辆运动学，就会对其进行玩家行为等高级概念的训练。 \n 在增加预测范围后，模型的「物理一致性」和帧间一致性显著提高。 \n 「长画面预测」训练 \n 训练一个模型来预测未来超过100帧的画面会面临显存挑战。 \n 因为在更大batch下，将这些帧加载到GPU内存中进行自回归预测变得不可行。为了解决这个内存限制，采用分页的方式进行自回归预测。 \n 在训练开始时，加载第一个batch的数据，并对其进行预测。\n然后加载下一页的数据，并丢弃超出上下文窗口范围的帧。\nGT赛车数据集 \n Enigma Labs选择在《Gran Turismo 4》（GT赛车4）上训练模型，「GT赛车4」中提供了来自80个制造商的700种车型，从最早的1886年的戴姆勒四轮汽车，到Nike未来概念车。\n游戏设置和修改 \n 测试用例很简单：在Tsukuba Circuit赛道上进行第三人称视角的1v1比赛。Tsukuba Circuit是一条短而简单的赛道，非常适合训练。 \n 难点在于：「GT赛车4」不允许以全屏1v1模式在Tsukuba Circuit赛道上进行游戏。游戏只提供1V5或分屏对战。为了实现想要的设置，Enigma Labs对游戏进行了逆向工程和修改，使其能够在真正的1v1模式下启动Tsukuba Circuit赛道。\n数据收集 \n 为了从两名玩家那里收集「第三人称」视频数据，Enigma Labs利用了游戏内的回放系统——将每场比赛重放两次，并从每名玩家的角度进行录制。 \n 然后将两个录像同步，使其与原始双人比赛对齐，并将它们合并成一个视频，展示两名玩家同时进行游戏。 \n 好了画面有了，那么是如何为数据集捕获玩家的按键输入呢？特别是当其中一名玩家是游戏内的自动NPC而不是人类时？ \n 幸运的是，游戏在屏幕上显示了足够的HUD元素——例如油门、刹车和转向指示器——可以准确地重建达到每个状态所需的控制输入。\n使用计算机视觉，逐帧提取这些条形图并解码它们背后的控制输入。 \n 这样就能够直接从视频中重建完整的按键操作，从而无需任何直接的输入日志记录即可构建整个数据集。 \n 自动数据生成 \n 乍一看，这似乎意味着我们必须坐下来手动玩游戏好几个小时，并为每场比赛录制两个回放——听着很痛苦，对吧？ \n 但还有一种更具可扩展性的方法：B-Spec模式。在这种「GT赛车」模式中，玩家可以使用手柄或方向盘来指示游戏内的AI驾驶员代表他们参加比赛。\n由于B-Spec的控制方式有限且简单，只需要编写了一个脚本，向B-Spec发送随机指令，从而自动触发比赛。然后，同一个脚本从两个角度记录回放镜头，以捕获这些AI驱动比赛的第三人称视频。 \n 最后，还尝试使用了OpenPilot的Supercombo模型来控制车辆，本质上将其变成游戏中的一个自动驾驶AI智能体。 \n 不过最终还是坚持使用B-Spec进行数据生成。\n多人世界模型不仅仅是游戏领域的一项突破，更是AI理解「同一个世界」的关键一步。 \n 这些模型让智能体能够在同一环境中学习、反应和协同适应，从而开启了无限可能。 \n 说到底，这不只是个让AI玩游戏的工程项目，它更像是一次尝试： \n 让AI理解「你看到的世界，和我看到的是同一个」。 \n 这对于下一代AGI（通用智能）来说，是关键的一步。无论是多智能体系统、AI合作助手，还是未来的模拟训练平台，多人世界模型都是一块至关重要的拼图。 \n 这个项目受到了很多大佬的「点名表扬」，毕竟多人游戏是AI生成世界中缺失的一环。而且这个项目的训练成本只有1500美元。\n所以，别看Multiverse现在只是「两辆车」在跑，它很可能就是未来AI生成世界的第一个早期版本，更可能是一扇预告未来虚拟宇宙的窗口。 \n 参考资料： \n https://enigma-labs.io/blog \n https://x.com/j0nathanj/status/1920516649511244258 \n 原标题：《世界首个AI多人游戏全面开源！1500刀实时生成，一台PC跑出平行宇宙》 \n阅读原文"
  },
  {
    "title": "阿里巴巴集团公布2024年12月份季度业绩-阿里巴巴集团",
    "page_body": "中国杭州， 2025 年 2 月 20 日 – 阿里巴巴集团控股有限公司（纽交所代码： BABA 及港交所代号： 9988 （港币柜台）及 89988 （人民币柜台），“阿里巴巴”或“阿里巴巴集团”）今日公布截至 2024 年 12 月 31 日止季度（“本季度”或“ 12 月份季度”）业绩。\n阿里巴巴集团首席执行官吴泳铭表示：“ 本季度的业绩充分展示我们在‘用户为先， AI 驱动’的战略取得显著进展，核心业务增长重新加速。本季度，淘天集团的客户管理收入增长 9% ，得益于用户体验提升和有效的商业化举措。云业务收入重回 13% 的双位数增长，其中 AI 相关产品收入连续六个季度实现三位数增长。展望未来，由 AI 推动的云智能集团收入增速还会持续提升。我们将继续执行聚焦电商和云计算的战略，持续投入以推动长期增长。 ”\n阿里巴巴集团首席财务官徐宏说：“ 我们 加 大投 入 促进 核心业务 重回 增长的同时，保持了财务 稳健性 并提升 营运效率， 实现淘天集团的 EBITA 正 增长。本季度，我们通过出售 重大 非核心资产、股份回购 ，并 以 优惠 利率延长债务 期限 ， 持续积极管理资产负债表。 ”\n业绩概要\n截至 2024 年 12 月 31 日止季度：\n收入 为人民币2,801.54亿元（383.81亿美元），同比增长8%。\n经营利润 为人民币412.05亿元（56.45亿美元），同比增长83%，主要是由于无形资产减值的减少以及经调整EBITA的增加所致。我们未把无形资产减值计入非公认会计准则财务指标。 经调整 EBITA （一项非公认会计准则财务指标）同比增长4%至人民币548.53亿元（75.15亿美元），主要归因于收入增长和运营效率提升，部分被我们对电商业务的投入增加所抵销。\n归属于普通股股东的净利润 为人民币489.45亿元（67.05亿美元）。 净利润 为人民币464.34亿元（63.61亿美元），同比增长333%，主要是由于经营利润增加、我们所持有的股权投资按市值计价的变动，以及权益法核算的投资损益增加所致，部分被我们的投资减值增加所抵销。截至2024年12月31日止季度， 非公认会计准则净利润 为人民币510.66亿元（69.96亿美元），相较2023年同期的人民币479.51亿元增长6%。\n摊薄每股美国存托股收益 为人民币20.39元（2.79美元）及 摊薄每股收益 为人民币2.55元（0.35美元或2.75港元）。 非公认会计准则摊薄每股美国存托股收益 为人民币21.39元（2.93美元），同比增长13%及 非公认会计准则摊薄每股收益 为人民币2.67元（0.37美元或2.88港元），同比增长13%。\n经营活动产生的现金流量净额 为人民币709.15亿元（97.15亿美元），相较2023年同期的人民币647.16亿元增长10%。 自由现金流 （一项非公认会计准则财务流动性指标）为人民币390.20亿元（53.46亿美元），相较2023年同期的人民币565.40亿元下降31%。自由现金流的下降主要归因于我们对云基础设施投入相关的支出增加，部分被其他营运资金的变动所抵销。\n上述公认会计准则财务指标与非公认会计准则指标之间的调节见本业绩公告下文。\n业务及战略进展\n淘天集团\n本季度，我们的客户管理收入同比增长 9% 至人民币 1,007.90 亿 元（ 138 . 08 亿 美元），主要由线上 GMV 增长和 Take rate 同比提升所带动。 Take rate 的提升得益于基础软件服务费的全季度影响，以及“全站推广”的渗透率提升。\n我们加大对用户 增长的投入，并对 具价格竞争力的商品、客户服务、会员体系权益和技术等战略举措 持续 投入 以 提升用户体验。这些举措带来新 买家 和订单量同比强劲增长。\n在商家侧， 我们致力于改善商家的运营环境，提升其运营效率 。为确保 商家在我们平台上的可持续发展 ，我们于 2025 年 1 月 20 日宣布一系列 惠 商举措。此外，我们看到“全站推广”的商家渗透率稳步提升，尤其是中小商家从其使用便捷性和市场营销效率的提升中获益。\n88VIP 会员是我们购买力最高的消费群体，本季度其数量持续同比双位数增长，达 约 4,900 万。我们将 持续 通过提供有吸引力的权益和 优质 服务，提升 88VIP 会员 数 。\n阿里国际数字商业集团（ AIDC ）\n截至 2024 年 12 月 31 日止季度， AIDC 收入同比增长 32% 至人民币 377.56 亿元（ 51.73 亿美元），主要由跨境业务的强劲表现所带动。 AIDC 在 海外购物 季期间 投入环比 扩大 ，并持续在特定的欧洲市场和海湾地区 进行 投入以 获取用户，导致亏损增加 。然而，速卖通 Choice 业务的单位经济效益 仍 环比改善。\n速卖通平台持续丰富产品供应， 构建 多元化业务模式，满足本地消费者需求。本季度，我们宣布 在 韩国与新世界集团（ Shinsegae ）成立合资公司，经营速卖通韩国和 Gmarket ，以更好地服务韩国消费者并增强我们的竞争力。\n云智能集团\n截至 2024 年 12 月 31 日止季度，云智能集团收入为人民币 317.42 亿元（ 43.49 亿美元），同比增长 13%。\n本季度，整体收入（不计来自阿里巴巴并表业务的收入）实现双位数同比增长 11% ， 主要由公共云业务收入的双位数增长带动，其中包括 AI 相关产品采用量的提升。 值得注意的是 ， AI 相关产品收入连续六个季度实现三位数的同比增长。我们将继续投入客户增长与技术 创新 ，尤其是在 AI 基础设施方面，以提升 AI 领域的云采用量，并维持市场领先地位。\n阿里云已获明确认可为 公共云产品 的首选云服务提供商。阿里云在 Gartner ®  2024 云 数据 库管理系统和容器管理 魔力象限 ™ 中均获评为领导者，成为连续且唯一获评 此象限 的中国公司。在《 Forrester Wave ™ : Public Cloud Platforms Q4 2024 》报告中，阿里云 是 唯一获评为“领导者 象限” 的中国公司。\n我们始终致力于推进多模态 AI 技术的发展，并扩大我们的开源计 划 。 2025 年 1 月，我们开源了 新 一代多模态模型 Qwen2.5-VL ，并推出基于 MoE 架构的旗舰 版 模型 Qwen2.5-Max 。这两个模型在公认的基准测试中均取得全球领先的成绩，并通过 Qwen Chat 和我们的百炼平台开放给用户和企业使用。自 2023 年 8 月以来，我们已开源多个 Qwen 家族 的大模型。截至 2025 年 1 月 31 日，基于 Qwen 模型 家族 在 Hugging Face 上开发的衍生模型数量已超过 90,000 个，使其成为全球最大的 AI 模型家族之一。\n菜鸟集团（ “ 菜鸟 ” ）\n截至 2024 年 12 月 31 日止季度，菜鸟收入为人民币 282.41 亿元（ 38.69 亿美元），同比下降 1% 。 这一结果反映正在进行的业务调整 —— 我们的电商业务承担部分物流平台职责。 菜鸟将继续专注于打造其全球智能物流网络 ，并为我们的电商业务及第三方客户提供 其端到端物流能力。\n本地生活集团\n截至 2024 年 12 月 31 日止季度，本地生活集团收入同比增长 12% 至人民币 169.88 亿元（ 23.27 亿美元），由高德和饿了么的 整体 订单增长，以及市场营销服务的收入增长所带动。\n本季度，本地生活集团亏损同比显著收窄，主要由于单位经济效益因运营效率提升和规模扩大 所致 。\n大文娱集团\n截至 2024 年 12 月 31 日止季度，大文娱集团收入为人民币 54.38 亿元（ 7.45 亿美元），同比增长 8% ，主要由优酷广告收入增长所带动。\n大文娱集团的亏损同比继续收窄，主要由于本季度优酷广告收入增加及内容投资效率提升 ， 从而减少 运营 亏损。\n战略性出售资产，股份回购及发行优先票据\n我们持续通过战略性出售非核心资产、股份回购及以优惠利率延长债务期限，积极优化我们的资产负债表。\n在本季度，我们签订了协议，出售我们在 (i) 高鑫零售的全部权益，交易金额最高为 123 亿港元（ 16 亿美元），以及 (ii) 银泰的全部权益，交易金额 约 74 亿人民币（ 10 亿美元）。这些举措反映了我们优化运营并专注于核心业务的战略转型。\n本季度，我们以 13 亿美元 的总价 回购总计 1.19 亿股普通股（相当于 1,500 万股美国存托股） 。 这些回购根据我们的股份回购计划在美国市场进行。截至 2024 年 12 月 31 日止，我们流通的普通股为 185.17 亿股（相当于 23.15 亿股美国存托股） 。相比于 2024 年 9 月 30 日 ，净 减少 1.03 亿股普通股，净减少比例为 0.6% （已考虑我们在股权激励计划下发行的股份后）。截至 2024 年 12 月 31 日止，我们在董事会授权的股份回购计划下仍余 207 亿美元回购额度，有效期至 2027 年 3 月。\n我们亦于 2024 年 11 月完成发行总计约50亿美元的美元及人民币计价优先无担保票据，用于偿还离岸债务、股份回购及其他一般公司用途。此交易优化了我们的资本结构，延长了债务的到期期限，并锁定了优惠利率。\n关于阿里巴巴集团\n阿里巴巴集团的使命是让天下没有难做的生意，集团旨在构建未来的商业设施，其愿景是让客户相会、工作和生活在阿里巴巴，并成为一家活102年的好公司。\n原文下载：\n阿里巴巴集团公布2024年12月份季度业绩.pdf"
  },
  {
    "title": "大语言模型的生态系统-知乎",
    "page_body": "2018 年， OpenAI  发布了首个 大语言模型 —— GPT ，这标志着大语言模型革命的开始。这场革命在 2022 年 11 月迎来了一个重要的时刻——OpenAI 发布了备受瞩目的 ChatGPT 。在接下来的不到一年的时间里，大语言模型的生态系统迅速壮大并蓬勃发展。\n大语言模型的生态系统可以分为 模型层、框架层和应用层 ，如图所示。\n模型层 提供了基础的大语言模型能力，包括开源和闭源两类。闭源模型的代表有OpenAI 的 GPT 系列和  Anthropic  的  Claude 系列 。毫无疑问，目前 OpenAI 的 GPT 系列模型在整个行业中处于领先地位，其性能远超其他大语言模型。开源模型的代表是  Meta 推出的  Llama2 。闭源模型就像移动互联网时代的 iOS 操作系统，更易于上手、技术门槛较低。而开源模型类似移动互联网时代的 Android 系统，对使用者的技术要求更高，但具备更强的可定制性。不管是开源模型还是闭源模型，都提供了模型微调的能力。OpenAI 甚至提供了 神经网络 的文本向量化功能。\n框架层 提供了基于大语言模型的开发框架，帮助开发者更快地构建与大语言模型相关的应用。目前市场上涌现出许多出色的开发框架，它们提供了各领域针对大语言模型二次开发的抽象。除了开发框架，还有 向量数据库 、 知识图谱 等重要的周边模块。\n应用层 是基于大语言模型开发的最终应用，ChatGPT 可以说是其中最知名和热门的。这些应用大致可以分为两类：一类是自动化应用，代表产品是 ChatGPT，这类应用需要人类的参与和反馈；另一类是自主 Agent 系统，代表产品是 AutoGPT，这类应用不需要人类主动参与，自主 Agent 系统可以在得到初始命令后进行自主迭代。应用层仍在不断发展，特别是自主 Agent 系统，这是一个充满前景和想象的领域。\n在介绍完大语言模型的生态之后，让我们来 展望一下大语言模型的未来 。在这里，我们将进行简单的预测。\n在应用层面，我们可以预见应用将沿着无状态、有状态，以及具备自主决策能力的趋势不断演化。自主 Agent 系统将成为重要的应用方向。当前的自主 Agent 系统模块之间主要使用自然语言进行信息传递和状态的存储，然而在未来，这种传递信息和存储状态的方式可能演变为神经网络编码的向量。\n在框架层，不同框架对于基于大语言模型应用的基础模块抽象正在逐渐达成共识，例如对长期记忆和 RAG 框架的抽象和对提示模板的抽象。这一趋势将有助于不同框架更好地协同发展，实现互相兼容，从而推动更广泛的应用和创新。\n在模型层，大语言模型未来的发展主要包括以下 5 个方向。\n数据是最重要的竞争优势，它扮演着护城河的角色，可以实现循环增值。闭源大语言模型的制造商会经常探索新的产品形态，以不断积累新的数据。例如，OpenAI 推出了 ChatGPT，这一产品通过用户对回答内容的“赞”和“踩”来评估模型回答的质量，甚至可以根据用户对同一问题的提问次数来粗略估计模型回答的质量（对于高质量的回答，用户通常不会重复提问）。另外，OpenAI后续推出的 Plugin 等功能，也为后期的 function calling 功能积累了高质量的、真实的涉及工具使用的训练数据。 上下文窗口的大小将不断扩展，但不一定一味地追求无限扩展，通常，百万量级的 token 就足以支持大部分应用场景。除此之外，工程端会不断优化，降低大语言模型的使用成本。 缓解幻觉和偏见问题将成为关键目标，这是大语言模型成为可靠系统的关键。 逐渐支持多模态的输入和输出，为更多领域的应用带来创新和可能性。这将催生更多新型的提示工程，类似前文提到的视觉参考提示。 不断探索突破自回归模型的局限性，尝试将系统 2 纳入训练框架，同时探索根据问题的难度自适应地分配计算资源，以提高效率和效果。无论是训练范式（目前主要是“下一个 token 预测”）还是神经网络结构，在未来都可能再次迎来全新的变革。\n2023年11月，OpenAI的创始成员 Andrej Karpathy 提出了一个引人入胜的观点： 未来，大语言模型极有可能发展到与当前计算机操作系统的地位相当。\n他形象地比喻说，我们可以将大语言模型及其周边生态系统看作一种崭新的操作系统。\n大语言模型就像计算机中的中央处理器，它的批处理大小相当于CPU的核心数，而每秒处理的 token数量则相当于CPU的主频，以Hz为单位。这些参数决定了模型的计算能力和处理速度。而语言模型的上下文窗口大小则相当于计算机的内存大小，它决定了模型能够同时考虑的信息量和短期记忆的大小。\n外部数据在语言模型中扮演着长期记忆的角色，类似于计算机的磁盘。这些外部数据的组织方式就像计算机磁盘中的文件系统一样，它们存储和管理着模型需要的信息，供其随时调取。此外，语言模型接收和输出的文本、音频、视频相当于计算机的输入输出设备，它们是模型与外界交互的媒介。\n最后，大语言模型不仅可以与其他模型进行网络通信，还能够通过浏览器访问互联网上的信息，以及利用外部工具执行传统的计算机操作。这种广泛的联接和应用使得语言模型在信息处理和应用方面具有了前所未有的能力和灵活性。\nLLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem 论文的作者也持有与Andrej Karpathy 相似的观点。\n在这篇论文中，作者提出了 AIOS-Agent 生态系统的概念，并将其与现今的操作系统(OS) -应用程序(App)生态系统进行了比较。下面展示了它们之间的类比关系。\n未来，大语言模型很有可能以这种全新形态融入人类的日常生活和工作中。人类将从移动互联网时代迈入智能时代，应用的载体也将由应用程序逐渐转变为基于大语言模型的智能体。\n未来，大语言模型极有可能发展到与当前计算机操作系统的地位相当，因此，应用大语言模型可以说是每个人不可或缺的技能。\n《大语言模型应用指南：以ChatGPT为起点，从入门到精通的AI实践教程（全彩）》 一书将帮助大家更好地理解和使用大语言模型，即使你对人工智能技术或编程技术一窍不通，也不用担心。本书将用通俗易懂的语言和例子，讲述大语言模型的基本原理、基础使用方法和进阶开发技巧。\n本书特色\n一是以 通俗易懂 的方式解释复杂概念，通过实例和案例讲解大语言模型的工作原理和工作流程、基本使用方法，包括大语言模型常用的三种交互格式、提示工程、工作记忆与长短期记忆，以及外部工具等，使读者能够全面了解和掌握这一先进技术的应用和二次开发； 二是 紧跟当前大语言模型技术的更新动态 ，介绍GPTs的创建，以GPT-4V和Gemini为例讲述多模态模型的应用，还包括无梯度优化、自主Agent系统、大语言模型微调、RAG框架微调、大语言模型安全技术等。\n无论是学术研究者、工程师，还是对大语言模型感兴趣的普通读者， 都可以通过本书获得大语言模型的前沿研究成果、技术进展和应用案例，从而更好地应用大语言模型解决实际问题。\n本书主要内容\n本书的读者对象是大语言模型的使用者和应用开发者，全书共分为4篇。\n第1篇 讲述机器学习、神经网络的基本概念，自然语言处理的发展历程，以及大语言模型的基本原理。鉴于本书的重点在于大语言模型的应用和二次开发，因此本书将不涉及大语言模型的训练细节。然而，我们仍强烈建议读者熟悉每个关键术语的含义，并了解大语言模型的工作流程，以更好地理解后面的内容。 第2篇 讲述大语言模型的基础应用技巧。首先，介绍大语言模型常用的3种交互格式。随后，深入讲解提示工程、工作记忆与长短期记忆，以及外部工具等与大语言模型使用相关的概念。最后，对大语言模型生态系统中的关键参与者——ChatGPT的接口与扩展功能进行详解。 第3篇 讲述大语言模型的进阶应用技巧。首先，介绍如何将大语言模型应用于无梯度优化，从而拓宽大语言模型的应用领域。随后，详细讨论各类基于大语言模型的自主Agent系统，以及微调的基本原理。最后，介绍与大语言模型相关的安全技术。 第4篇 讲述大语言模型的未来。一方面，探讨大语言模型的生态系统和前景，简要介绍多模态大语言模型和相关的提示工程。另一方面，深入解析大语言模型的尺度定律，并尝试从无损压缩的角度来解析大语言模型具备智能的原因，最后以图灵机与大语言模型的联系作为全书的结尾。"
  },
  {
    "title": "数据驱动、平台使能，芯海科技重构 AI 驱动的健康诊疗新图景-人工智能-电子发烧友网",
    "page_body": "电子发烧友网报道（文 / 吴子鹏）国家医保局最新数据显示，截至 2025 年 6 月，我国慢性病患者已突破 4.3 亿人，占总人口近 30%；在 65 岁以上老年群体中，这一比例更是高达 67%。2025 世界 人工智能 大会（W AI C 2025）期间， 芯海科技 董事长卢国建表示：“国内人民生活水平提升，导致体重和体脂显著增加，这与慢性病发病风险高度相关。2025 年国家卫生健康委等 16 个部门联合制定的《“体重管理年”活动实施方案》，标志着我国已将慢性病防控提升至国家战略层面。芯海科技在该领域深耕 10 年，我们的技术储备能够为国家战略提供有力支撑，成为体重健康管理的重要实践力量。”\n 芯海科技董事长卢国建，图源：芯海科技\n 在健康测量领域，芯海科技构建了“芯片 + AI + 场景化”产业生态赋能平台，已形成覆盖家庭、社区、医院的全场景解决方案。\n精准测量是精准服务的基石\n WAIC 2025 期间，卢国建出席了由大会组委会指导、中国信息协会主办的 “数据要素 × 人工智能 + 赋能行业高质量发展” 论坛 ，并发表题为《大数据 “芯” 生态 —— 健康精准测量・AI 佳医诊疗》的主旨演讲。\n 他在分享中介绍，芯海 科技 成立于 2003 年 9 月，是一家集感知、计算、控制、 电源 、连接及 AI 技术平台为一体的全 信号 链 集成电路 科技企业。公司从客户需求出发，提供芯片、 算法 、应用方案、AIoT 等一站式解决方案，助力 智能 终端、 智能家居 、计算机、ICT（信息 通信 ）、 汽车电子 、工业、储能领域的应用创新。\n 为打造体重管理、慢病防治的全场景解决方案，芯海科技构建了四大核心技术链路：​\n ·测量芯片：BIA、PPG、ECG等自研 高精度 生物测量芯片及模组；​\n ·领先算法：行业领先的边缘计算算法；​\n ·健康大模型：基于大数据构建的多模态健康大模型；​\n ·全栈方案：包含芯片、App、SaaS 在内的系统性解决方案。\n 芯海科技围绕健康测量应用构建了大数据 “芯”生态 —— 基于自研高精度生物测量芯片及模组，实现人体成分、心率等 30 + 维度的动态健康数据采集，精度对标医疗级设备。其中八电极人体成分分析仪与行业金标 DXA（双能 X 线吸收法）检测结果的相关性达95%以上，为健康数据精准测量提供坚实基础。\n 卢国建指出，精准测量是精准服务的基石。AI 大模型的精准运转高度依赖数据来源的准确性，垂直 AI 模型配合精准数据才能给出科学的个人健康解决方案。因此，在精准测量基础上，需要基于大数据构建精准算法，这离不开统一的平台和标准。为此，芯海科技主导在中国标准化协会推动了家庭健康电子设备标准的制定。\n健康大模型和健康平台的协同创新\n 芯海科技旗下子公司深圳康柚健康科技有限公司（简称 “康柚健康”）是其健康测量战略的重要组成部分。该公司成立于 2018 年，作为专注于个人和家庭健康管理的品牌，聚焦健康硬件研发及健康与慢病风险评估的大数据服务，致力于为用户提供智能穿戴、智慧体育教育和健康管理的一站式解决方案。\n 康柚健康对《“体重管理年”活动实施方案》的支撑作用尤为显著。其应用 BIA 技术，通过人体成分分析仪等  IoT  设备实现精准测量，对个人健康状况进行全方位分析；针对健身、减重、理疗等健康配套产业，提供业务在线 SaaS 系统及相关产品，持续整合产业服务资源；最终通过 AI 和大数据分析，基于用户需求精准匹配健康服务机构，以“精准测量”“精准服务”为核心提供健康管理服务。\n 与传统 BIA 将人体视为单一圆柱体的简化模型不同，芯海科技的 Chipsea BIA 测脂技术采用直接节段多频生物 电阻 抗分析（DSM-BIA），将人体划分为左臂、右臂、左腿、右腿和躯干五个独立节段进行测量，显著提升全身成分测量的精确性。该技术与 DXA 的相关系数可达98%，代表当前非侵入式人体成分分析的先进水平。\n 卢国建特别介绍了康柚健康的 OKOK 健康管理平台和 HHM 健康大模型。其中 OKOK 健康是 物联网 背景下诞生的智能 APP，基于智能 蓝牙 设备辅助用户记录和管理身体指标及运动数据，通过多维度智能云算法提供健康指导。该平台形成 “精准测量 - 数据管理 - AI 精准评估”的全链路方案，3 秒即可生成包含 16 项核心身体指标的健康报告，目前已为全球 海量 用户提供服务，是国内重要的体重管理与慢病防治大数据平台。\n 图源：芯海科技\n “连续性测量对全生命周期健康监护至关重要，医院的间歇性测量难以实现真正的健康监护。”卢国建强调，“OKOK 健康管理平台通过可穿戴设备或人体成分分析仪实现连续测量，结合医院检测数据形成动态健康画像，这才是有价值的健康管理模式。同时，考虑到家庭设备的易用性需求，我们坚持打造系统化、平台化、低成本的健康平台，切实解决大众健康管理痛点。”\n HHM 健康大模型则结合医学知识图谱与多模态时序数据分析，在关键健康指标预测方面提供可解释的医疗级决策支持，应用场景覆盖家庭健康档案、社区慢性病筛查、医院精准诊疗三大场景，形成全生命周期管理闭环。\n 图源：芯海科技\n 综上所述，芯海科技以“精准测量”为基石，通过“芯片 + AI + 场景化”的产业生态赋能平台，构建起覆盖家庭、社区、医院的全场景健康管理闭环。未来，随着技术生态的持续完善，这一创新实践或将重塑健康产业格局，为守护国民健康、提升国家健康安全水平注入持久动力。\n平台 驱动 驱动 驱动 驱动 驱动 \n2022-09-25 08:59:21 2464\n新型无线 平台 使 能 下一代可连接产品扩展物联网应用\nSilicon Labs（亦称“ 芯 科科技”，NASDAQ：SLAB）日前推出了下一代Wireless Gecko 平台 ――Series 2，设计旨在 使 能 物联网（IoT）产品更加强大、高效和可靠。\n2019-04-23 13:46:13 1767\nAI  for Science：人工智能 驱动 科学创新》第4章- AI 与生命科学读后感\n很幸运社区给我一个阅读此书的机会，感谢 平台 。 《 AI  for Science：人工智能 驱动 科学创新》第4章关于 AI 与生命科学的部分，为我们揭示了人工智能技术在生命科学领域中的广泛应用和深远影响。在\n2024-10-14 09:21:45\nAI 赋 能 “电子哨兵”推动城市的智能化和数字化进程（附“电子哨兵”方案）\n6月初， AI 赋 能 的 “电子哨兵”上岗深圳市南山区行政大厅，实现办事人员 健康 数据 核验、体温检测、自动预约取号、授权调用电子证照等操作整合，避免多次扫码、多次核验的繁琐。早在今年3月，深圳市已经在公交\n2022-06-28 16:42:59\nAI 赋 能 边缘网关：开启智能时代的新蓝 海\n在数字化转型的浪潮中， AI 与边缘计算的结合正掀起一场深刻的产业变革。边缘网关作为连接物理世界与数字世界的桥梁，在 AI 技术的加持下，正从简单的 数据 采集传输节点，进化为具备智能决策能力的边缘计算单元\n2025-02-15 11:41:42\n海 思3518的spi 驱动 无法工作是哪里出了问题？\n硬件环境esp32c3,idf版本4.3，在 海 思3518板子上安装了linux 驱动 程序，发现无法 驱动 spi设备，spi引脚的 数据 线和时钟线都没有信号出来，请问这是那里的问题？\n2024-06-27 06:27:12\n芯 海 CS1180S输出 数据 Bug\n在使用 芯 海 CS1180S芯片的时候发现一个问题不知道是不是芯片设计缺陷 就是CS1180S芯片在接收 数据 的时候是按照SCK 上升沿来锁存 数据 ，CS1180S输出 数据 却是没有按照SCK下降沿原则来输出\n2022-09-28 16:55:49\n芯 海 杯全国电子设计大赛\n 0755-86156632 邮箱lhui@chipsea.com4.所有参赛作品，知识产权归参赛者所有， 芯 海 科技提供开放的方案量产提成 平台 ，以保护知识产权及支持创业。相关权益参赛承诺：参赛者必须保证参赛作品为首\n2014-01-06 17:47:29\n芯 海 汇编（CSU-ASM）和 芯 海  C（CSU-C）两种语言编程和IDE使用说明资料\n最近计划用 芯 海 的MCU做一个案子，希望熟悉 芯 海 MCU的开发环境和C语言和汇编语言的相关知识，可以发我 芯 海 汇编（CSU-ASM）和 芯 海  C（CSU-C）两种语言编程和IDE使用说明资料吗？我邮箱是：jackli@ruibao-tech.com，谢谢！\n2023-02-15 22:00:30\n斯丹麦德电子\n2天前\n1.4k\n高性价比AOV2.0双摄方案：富瀚微FH8626V300+RT-Thread构建超低功耗智慧视觉设计 | 产品动态\nRT-Thread与富瀚微电子(Fullhan)深度合作，基于FH8626V300智慧视觉处理器，携手推出全新的低功耗解决方案。该方案深度融合FH8626V300的低功耗2.0版本的AOV技术与新一代ISP技术，致力于满足市场对高检测精度、超低功耗运行、卓越画质表现的全天候实时监控的严苛要求。基于RT-Thread标准版开发，为FH8626V300方案提供了\nRT-Thread官方账号\n2天前\n917\n芯对话 | CBM97D79TQ：双通道16位1GSPS DAC的性能与设计实践\n在5G基站、宽带传输等场景中，如何用单芯片实现多载波信号的高保真转换？芯佰微CBM97D79TQ作为一款双通道16位高动态范围数模转换器（DAC），凭借1GSPS采样速率、80dBc邻道泄漏比（ACLR）及低功耗特性，成为宽带通信发射链路的核心解决方案。本文从核心性能、设计要点到工程落地，详解其技术优势与实践指南。一、应用技术背景介绍在无线通信与宽带传输随着\n芯佰微电子\n07-30 10:53\n1.6k\n在RT-Thread上部署TensorFlow Lite实现交通工具识别（附虚拟U盘部署技巧）\n随着人工智能、神经网络以及机器学习应用的发展，边缘处理的场景越来越多，一些针对IOT设备和嵌入式设备的迁移学习网络应运而生，TensorflowLite就是在这样的情境下诞生。尽管TensorflowLite已经足够小，足够快速，但作为资源非常紧俏的单片机来说，尤其是图像处理，仍有点力不从心。好在VisionBoard拥有足够强大的性能，而且外扩了较大的SD\nRT-Thread官方账号\n07-29 20:08\n1.8k\nTurMass™ 与 LoRa 技术对比\nTurMass™是道生物联开发的新一代国产无线物联网技术。它全球首创将大规模多天线技术应用于窄带传输，实现了高并发海量接入。该系统基于免许可随机接入大规模MIMO技术(mGFRA)，通过空分复用和波束成形，显著提升了系统的接入容量、信号增益、抗干扰能力、覆盖范围以及频谱效率。TurMass™系统包含支持mGFRA技术的网关芯片、终端芯片以及TurMass™L\n道生物联\n07-29 14:52\n2.6k\n视美泰GK-68A工控系列适配OpenHarmony系统：技术优势与市场价值双突破\n在数字化与智能化加速融合的时代背景下，工业领域对于高性能、高稳定性且具备创新特性的硬件设备需求日益迫切。视美泰作为行业内的创新先锋，积极响应市场趋势，已完成旗下工控主板GK-68A与工"
  },
  {
    "title": ".NET Aspire OpenAI 集成 （预览版）-Microsoft",
    "page_body": "包含：  -  Client 集成\nOpenAI  通过 API 提供对聊天/完成、嵌入、图像和音频模型 REST 的访问权限。 通过集成 .NET AspireOpenAI，您可以：\n在 AppHost 中为 OpenAI 帐户（终结点 + API 密钥）建模一次。 添加一个或多个模型资源，用于从父级构成其连接字符串。 从项目中引用这些模型资源以获取强命名的连接字符串。 使用 Aspire.OpenAI 组件消耗这些连接字符串以获取 OpenAIClient 和（可选的） IChatClient 。\n托管集成\n具有两种资源类型的托管集成模型 OpenAI ：\nOpenAIResource ：持有共享 API 密钥和基本终结点的父对象（默认为  https://api.openai.com/v1 ）。 OpenAIModelResource ：表示特定模型的子级；从父级（ Endpoint  +  Key  +  Model ）组合连接字符串。\n若要访问这些类型和 API 以在  AppHost  项目中使用它们，请安装      Aspire.Hosting.OpenAI  NuGet 包：\n .NETCLI（命令行界面） 包引用\n.NET CLI 复制\ndotnet add  package Aspire.Hosting.OpenAI \n有关详细信息，请参阅  dotnet 添加包  或  管理 .NET 应用程序中的包依赖性 。\n OpenAI添加父资源\nC# 复制\nvar  builder = DistributedApplication.CreateBuilder(args);   var  openai = builder.AddOpenAI( \"openai\" );  builder.AddProject<Projects.ExampleProject>()        .WithReference(openai);   // After adding all resources, run the app...\n添加 OpenAI 模型资源\n在父级下添加一个或多个子模型，并从项目中引用它们：\nC# 复制\nvar  builder = DistributedApplication.CreateBuilder(args);   var  openai = builder.AddOpenAI( \"openai\" );   var  chat = openai.AddModel( \"chat\" ,  \"gpt-4o-mini\" );  var  embeddings = openai.AddModel( \"embeddings\" ,  \"text-embedding-3-small\" );  builder.AddProject<Projects.ExampleProject>()        .WithReference(chat);   // After adding all resources, run the app...\n引用 chat 会将一个名为 chat 的连接字符串传递给项目。 多个模型可以通过父资源共享单个 API 密钥和终结点。\n使用默认 API 密钥参数\n调用将创建名为  AddOpenAI(\"openai\")  的  openai-openai-apikey 机密参数。 Aspire 按以下顺序解析其值：\nParameters:openai-openai-apikey 配置密钥（用户机密或 appsettings.* 环境变量）。 OPENAI_API_KEY  环境变量。\n如果两个源都未提供值，则启动将引发一个  MissingParameterValueException 。 设置其中一个值以避免异常。\n通过用户机密提供密钥：\n.NET CLI 复制\ndotnet user-secrets  set Parameters:openai-openai-apikey sk-your-api-key \n使用自定义 API 密钥参数\n通过创建自己的机密参数并调用  WithApiKey  父参数来替换默认参数：\nC# 复制\nvar  builder = DistributedApplication.CreateBuilder(args);   var  apiKey = builder.AddParameter( \"my-api-key\" , secret:  true );   var  openai = builder.AddOpenAI( \"openai\" )                     .WithApiKey(apiKey);   var  chat = openai.AddModel( \"chat\" ,  \"gpt-4o-mini\" );  builder.AddProject<Projects.ExampleProject>()        .WithReference(chat);   // After adding all resources, run the app...\n替换时，原始生成的参数将从资源图中删除。 必须标记  secret: true 自定义参数。\n添加自定义终结点\n覆盖默认端点（例如，使用代理或兼容网关）：\nC# 复制\nvar  builder = DistributedApplication.CreateBuilder(args);   var  openai = builder.AddOpenAI( \"openai\" )                     .WithEndpoint( \"https://my-gateway.example.com/v1\" );   var  chat = openai.AddModel( \"chat\" ,  \"gpt-4o-mini\" );  builder.AddProject<Projects.ExampleProject>()        .WithReference(chat);   // After adding all resources, run the app...\n父连接字符串和模型连接字符串都包含自定义终结点。\n健康检查\n诊断问题时，为每个模型添加可选的单次运行健康检查。\nC# 复制\nvar  chat = builder.AddOpenAI( \"openai\" )                   .AddModel( \"chat\" ,  \"gpt-4o-mini\" )                   .WithHealthCheck(); \n模型运行状况检查验证终结点可访问性、API 密钥有效性（401）和模型存在（404）。 每个应用程序实例只执行一次，以限制速率限制影响。 会自动为每个父资源注册一个针对 https://status.openai.com/api/v2/status.json 的状态页检查。\n可用模型\n常见标识符：\ngpt-5 gpt-4o-mini gpt-4o gpt-4-turbo gpt-realtime text-embedding-3-small text-embedding-3-large dall-e-3 whisper-1\n 备注\n模型名称不区分大小写，但我们通常以小写形式编写它。\n有关详细信息，请参阅  OpenAI 模型文档 。\n Client 集成\n若要开始使用AspireOpenAI客户端集成，请在使用OpenAI客户端的应用程序项目中安装     Aspire.OpenAI  NuGet 包。\n .NETCLI（命令行界面） 包引用\n.NET CLI 复制\ndotnet add  package Aspire.OpenAI \n OpenAI 添加一个客户端\n在您的客户端使用项目的  Program.cs  文件中，使用  AddOpenAIClient  注册一个  OpenAIClient  以实现依赖项注入（DI）。  AddOpenAIClient  方法需要连接名称参数。\nC# 复制\nbuilder.AddOpenAIClient(connectionName:  \"chat\" ); \n 提示\n参数  connectionName  必须与在 AppHost 项目中添加 AzureOpenAI 资源时使用的名称匹配。 有关详细信息，请参阅  “添加 OpenAI 父资源  ”或  “添加 OpenAI 模型资源 ”。\n添加  OpenAIClient 后，可以使用依赖项注入检索客户端实例：\nC# 复制\npublic class ExampleService ( OpenAIClient client )  {      // Use client...  } \n使用已注册的 IChatClient 添加 OpenAI 客户端\nC# 复制\nbuilder.AddOpenAIClient( \"chat\" )        .AddChatClient();  // Model inferred from connection string (Model=...)\n如果只定义了父资源（没有子模型），请显式提供模型名称：\nC# 复制\nbuilder.AddOpenAIClient( \"openai\" )        .AddChatClient( \"gpt-4o-mini\" ); \nAddChatClient  （可选）接受模型/部署名称，如果省略，它将来自连接字符串的  Model  项目。 根据需要注入  OpenAIClient  或  IChatClient 。\n配置\n Aspire OpenAI 库提供了多个选项，用于根据项目的要求和约定配置 OpenAI 连接。 需要提供  Endpoint  或  ConnectionString  中的任意一个。\n使用连接字符串\n已解析的连接字符串格式：\n父级（无模型）：\n控制台 复制\nEndpoint={endpoint};Key={api_key} \n模型子级：\n控制台 复制\nEndpoint={endpoint};Key={api_key};Model={model_name} \n使用配置提供器\n通过  Aspire:OpenAI  键（全局）和  Aspire:OpenAI:{connectionName} （每个命名客户端）进行配置。 支持的设置包括 Key 、 Endpoint 、 DisableTracing 、 DisableMetrics 以及 ClientOptions 子树（ UserAgentApplicationId 、 OrganizationId 、 ProjectId 、 NetworkTimeout 、日志记录选项等）。\nJSON 复制\n{    \"ConnectionStrings\" : {      \"chat\" :  \"Endpoint=https://api.openai.com/v1;Key=${OPENAI_API_KEY};Model=gpt-4o-mini\"    },    \"Aspire\" : {      \"OpenAI\" : {        \"DisableTracing\" :  false ,        \"DisableMetrics\" :  false ,        \"ClientOptions\" : {          \"UserAgentApplicationId\" :  \"myapp\" ,          \"NetworkTimeout\" :  \"00:00:30\"        }     }   } } \n内联配置：\nC# 复制\nbuilder.AddOpenAIClient( \"chat\" , settings => settings.DisableTracing =  true ); builder.AddOpenAIClient( \"chat\" , configureOptions: o => o.NetworkTimeout = TimeSpan.FromSeconds( 30 )); \n遥测（跟踪 + 指标）在 SDK 中是实验性的 OpenAI.NET 。 可以通过  OpenAI.Experimental.EnableOpenTelemetry  AppContext 开关或  OPENAI_EXPERIMENTAL_ENABLE_OPEN_TELEMETRY=true  全局启用。 在启用时使用  DisableTracing  /  DisableMetrics  选择退出。\n示例应用程序\n探索将托管和客户端集成连接在一起的端到端示例，通过参数设置 API 密钥，注册聊天客户端，并执行简单的提示/响应往返过程。 克隆存储库，运行它，然后根据模型对其进行调整：  https://github.com/dotnet/aspire/tree/main/playground/OpenAIEndToEnd\n可观测性和遥测\n .NET .NET Aspire 集成会自动设置日志记录、跟踪和指标等配置，这些配置有时称为  可观测性的基础支柱 。 有关集成可观测性和遥测的详细信息，请参阅  .NET.NET Aspire 集成概述 。 根据支持服务，某些集成可能仅支持其中一些功能。 例如，某些集成支持日志记录和跟踪，但不支持指标。 还可以使用  “配置”  部分中介绍的技术禁用遥测功能。\n伐木业\nOpenAI.*\n跟踪\nOpenAI.*  （启用遥测且未禁用时）\nMetrics\nOpenAI.*  计量（启用遥测且未禁用时）\n另请参阅\n OpenAI 文档  OpenAI .NET 软件开发工具包  .NET .NET Aspire 集成概述  .NET Aspire GitHub 模型集成"
  },
  {
    "title": "OpenAI也来了，巨头为何决战AI浏览器？澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "抢占AI时代的“第一入口”。\n定焦One（dingjiaoone）原创\n作者 | 王璐\n编辑 | 方展博\nAI浏览器赛道再添一位重量级玩家——ChatGPT Atlas，这是OpenAI推出的首款人工智能驱动的网页浏览器。\n这也被外界认为OpenAI要向谷歌宣战，挑战Chrome一直以来的浏览器霸王地位。ChatGPT Atlas发布当天，谷歌母公司Alphabet股价应声下挫，盘中最大跌幅接近5%，足见市场对这一新品的敏感度。\n近一年来，AI浏览器的战略价值成为行业共识，从业者更是将其与智能代理（Agent）、搜索引擎放在一起，并称为大语言模型（LLM）生态的三大核心基础设施，而AI浏览器是连接用户与AI能力的关键枢纽。\n巨大的战略潜力催生了激烈的市场角逐，全球科技企业纷纷加速布局：\n国内市场，腾讯和阿里分别升级QQ浏览器、夸克浏览器，360也有360AI浏览器，大厂们抢先完成AI化转型；\n国际市场，谷歌Chrome、微软Edge两大主流浏览器已深度集成AI功能；Perplexity的Comet、The Browser Company的Dia（已经被Atlassian收购）、Fellou AI的同名浏览器等独角兽公司的产品也各具特色。\n如今ChatGPT Atlas加入战局，更是标志着全球头部玩家已全部集结，AI浏览器行业的竞争进入白热化阶段。\n作为OpenAI的重磅产品，ChatGPT Atlas具备哪些亮点功能？与国内外同类AI浏览器相比，核心竞争力又体现在哪里？这一市场究竟有什么吸引力，让众多玩家纷纷押注？\nOpenAI的浏览器，亮点在哪里？\n作为OpenAI推出的首款人工智能驱动的网页浏览器，其与传统浏览器的最大区别在于，面对用户抛出的问题，它会直接给出答案而非甩链接。\n但这一点并非其独有优势，几乎市面上所有AI浏览器都能做到，ChatGPT Atlas核心亮点在于，它围绕用户日常使用场景设计的四大功能。\n首先是“上下文侧边栏”功能。\n无论用户是想总结一篇长文的核心观点、分析网页里的数据图表，还是遇到专业术语想了解含义，不用手动复制粘贴内容，也不用在网页和AI工具间来回切换，只要点击ChatGPT Atlas里的「Ask ChatGPT」按钮，输入自身需求，ChatGPT就能实时完成操作。\n在右侧输入需求，ChatGPT Atlas便能给出实时回复\n其次是AI协助写作和编辑功能。\n该功能的操作也十分简单，用户只要选中文本并输入要求，ChatGPT可实时提供写作建议、语法检查和内容优化。\n这一功能覆盖所有文本输入场景。比如ChatGPT Atlas发现语法错误会自动标注，认为语句不通顺会给出润色建议，用户写邮件时不知道如何表达，它也会根据收件人和场景调整语气，提升用户的内容创作的效率。\n三是浏览器记忆功能。\n该功能可以记住用户行为，比如自动保存用户访问过的网站上下文，从而基于浏览历史给用户提供个性化建议。\n以购物为例，用户如果在双11期间经常逛购物网站，它便会根据过往浏览的商品类型推荐合适的新品。用户可以自主控制这些记忆，随时可以查看、删除，不用太过于担心隐私泄露问题。\n四是Agent（智能体）模式。\n这是ChatGPT Atlas最受关注的功能。\n可以简单理解为，ChatGPT Atlas在获得用户授权后，可自主执行多步骤网络操作。\n比如用户输入“帮我订一张下周一去北京最便宜的机票”的指令，Agent在接收并理解需求后，会生成执行计划并展示关键步骤，由Agent在后台自动完成搜索、填写信息、提交订单等操作，用户无需手动操作。在整个任务执行的过程中，底部状态栏会显示进度，用户可随时点击“接管”或“停止”按钮干预任务。\nAgent模式下，ChatGPT Atlas自主完成搜索加购等操作\n此外，由于获得用户授权较多，在安全性上，ChatGPT Atlas也增加了多重防护：禁止运行代码、下载文件及安装扩展，防范恶意程序入侵；访问金融、支付类敏感网站时，自动暂停AI操作并需手动确认；退出登录后，限制AI智能体权限，禁止访问私人数据。\n不难发现，ChatGPT Atlas的新功能不少，且不需要邀请码，使用门槛很低。从发布当日起，全球ChatGPT用户可在chatgpt.com/atlas下载ChatGPT Atlas的macOS版本。\n但需要注意的是，部分功能需要花钱，ChatGPT的免费、Plus、Pro和Go用户可免费使用基础浏览功能，比如侧边栏、浏览器记忆，但“智能体模式”仅限Plus、Pro、Business用户使用。\nChatGPT Atlas，还不够聪明\nChatGPT Atlas的推出，代表着AI浏览器行业进入了新的竞争阶段。一名从业者告诉「定焦One」，市面上已有的AI浏览器产品，按照技术路线可分为两大类：集成技术路线（谷歌、微软以及国内绝大多数大厂）与AI原生路线（三大代表为：Comet、Dia、Fellou AI），ChatGPT Atlas也属于此类。\n两种路线的技术原理和功能实现存在明显区别：集成技术路线是在管理网页的基础上，加上了AI能力和Chatbot式交互，侧重信息交互与内容生成功能；AI原生浏览器则在开发时就基于AI原生架构打造，是在Chatbot式交互和AI能力的基础上，加入网页管理功能。\n两者最主要的区别在于智能化，后者更聪明，并集中体现在Agent能力上。\n比如Comet、Dia可跨网站执行多步任务操作，Fellou AI更是号称“全球首个行动型浏览器”，例如，用户给出“在亚马逊搜RTX4060显卡，并按评分加购最高型号”的指令，Fellou AI会自动执行“登录-筛选-比价-下单”整个过程。\n图源 / pexels\n与Comet、Dia等同类AI原生浏览器相比，最初外界看好ChatGPT Atlas的主要原因也在于智能化，认为其内置ChatGPT模型，能做到更聪明。\n可以简单理解为，Comet、Dia、Fellou AI代表了AI智能体的“任务自动化”能力，它们像是一位专业的、不知疲倦的助手，可以按照预设或生成的流程在多个网站间完成具体的操作，其核心价值是效率的提升和重复劳动的解放。而ChatGPT Atlas因为有了ChatGPT，更像拥有一个强大的“大脑”（ChatGPT的推理和对话能力），从而与浏览器的“手脚”（执行操作）进行联动。\n但目前ChatGPT Atlas所展示出的功能，与其他AI原生浏览器并无太大差异。\n比如在官方演示案例中，无论是工作场景中，用户通过一个简单的指令，让AI代理自动完成了一项涉及理解、协调和跨工具数据迁移的任务，还是生活场景中，根据人数调整菜谱、生成清单到自动备好购物车的全流程，ChatGPT Atlas的Agent模式依然聚焦于“效率提升”，没有展现出差异化。\n从业者在测试中还发现了更多问题，例如它仅支持单次调用单个已打开的网页，而Dia已经能同时调用多个网页标签；ChatGPT Atlas执行任务的速度也较慢，简单的在电商平台下单任务，也需耗时少到几分钟多则十几分钟，远慢于人工。\n综合多轮实测结果，不止一位从业者认为，ChatGPT Atlas的表现未达预期。\n“它（ChatGPT Atlas）最厉害的地方是生态，就像一个‘ChatGPT全家桶’，用户在浏览器里能聊天、写东西、让它帮你做事，不用来回切换工具。相比之下，Comet、Dia等AI浏览器，虽然功能也比较强，但生态体系相对孤立，体验的流畅性就差了一些。”一位从业者表示。\n从事Agent应用算法方向研究的资深从业者赵江杰对「定焦One」解释，ChatGPT Atlas的核心优势，在于其依托OpenAI的基座模型、端到端Agent训练能力，以及庞大的用户生态，这三大能力是其他AI原生浏览器难以企及的。\n具体来说，其他产品的基座模型要么使用闭源模型，要么基于开源模型进行微调，一般会使用两者混合的方式，闭源用来做高层规划，开源微调适配低层特定场景需求，但无论采用哪种方式，都很难与OpenAI的技术实力抗衡；同时，它们在Agent训练能力和用户基数上，也与OpenAI存在明显差距。\n不过，这些优势需要通过长期使用才能充分显现。\n赵江杰以记忆功能为例，用户初次使用ChatGPT Atlas时，数据积累尚处于空白阶段，此时产品自然无法深入洞察用户的个性化喜好，但随着用户使用时长和频次的增加，ChatGPT Atlas将借助强大的推理能力，结合不断沉淀的用户历史数据，逐步精准判断用户偏好，不仅能补全用户未明确表达的隐性需求，还能准确理解用户表述中的模糊指令，实现更贴合需求的服务。\nAI浏览器，下一代互联网入口\n从目前的表现来看，ChatGPT Atlas还谈不上惊艳，但推出AI浏览器，是OpenAI和国内大厂不得不走的一步棋。多位从业者认为，这背后是对行业格局、生态构建与数据价值的深层考量。\n首先是战略上，OpenAI想要抢占AI时代的“第一入口”。\n一直以来，谷歌凭借Chrome浏览器，构建了覆盖全球的流量入口与数字广告霸权。第三方数据平台Statcounter统计，截至2025年7月，Chrome仍占据全球浏览器市场67.9%的绝对份额，活跃用户超30亿。\n这种主导地位使得谷歌牢牢掌控着用户行为的“第一入口”，以及随之产生的海量数据。\nOpenAI推出Atlas，根本目的是想改变这一游戏规则。用户无需自己用关键词搜索，而是让AI直接给答案、完成任务。当用户习惯了这种更省事的方式，自然会减少传统搜索的使用次数，相当于从源头上分流了谷歌的用户，从而争夺AI时代的“入口”。\n这一入口还可以让OpenAI构建自己的AI生态和更多商业化机会。\n在互联网早期，浏览器因聚合搜索、社交、购物等核心功能成为用户上网的主要入口，而在AI时代，浏览器进化为融合大模型（大脑）、长期记忆（数据）与Agent（手脚）的载体，为模型及其工具的使用提供运行环境，特别是浏览器与Agent强相关，Agent在不同应用之间完成访问登录网站、浏览电脑文件等任务时，都需要借助浏览器这一环境。\n图源 / pexels\n比如，在工作场景上，用户在ChatGPT Atlas完成从信息获取、分析、处理到输出成果的全链条工作”，在生活场景上，ChatGPT Atlas把搜索-比价-下单全流程绑在一起，让用户不用再切换多个APP。这种由Agent自动化过程中对浏览器工具链、应用生态的深度集成使用，能创造出一种“全场景”下的生态闭环。\n赵江杰表示，ChatGPT Atlas可以让OpenAI在用户订阅、API调取等收费形式之外，找到更多商业化途径。\n相比单一聊天工具（ChatGPT） ，覆盖用户全场景行为的ChatGPT Atlas能获取更完整的用户行为数据（尤其是和消费、决策相关的轨迹）。这些数据能让广告推荐更精准、商业转化的归因更清晰，进而开辟广告投放、商业分成、场景化付费等新的变现途径。\n最后是数据反哺。\n用户在浏览器中每一次搜索查询、页面停留、点击决策乃至操作纠错，背后都代表的是其真实意图与偏好的高质量数据，这些实时的、连续的用户数据，对于大模型监督微调和强化学习至关重要。\nChatGPT Atlas的存在让OpenAI可以在自有浏览器中直接捕获这些数据，从而精准评估模型表现、发现问题并快速修复。不仅能优化ChatGPT Atlas这一产品，更能反哺GPT核心模型，形成一个“产品更好用-用户和数据更多-模型更强”的循环。\n国内大厂纷纷布局AI浏览器的战略目的，与OpenAI有相似之处。短期是处于“防守”考虑，目前ChatGPT等AI工具正改变着用户的搜索习惯，越来"
  },
  {
    "title": "【县区动态】这场辩论赛精彩纷呈，“言”值拉满!青年_思辨_启未来",
    "page_body": "（来源：共青团榆林市委）\n青春思辨 智启未来\n为进一步培养、锻炼青年人才思辨能力和综合素质，促进青年全面成长成才，4月22日上午，张家峁矿业公司智慧楼五楼大会议室内掌声雷动、金句频出，一场由张家峁矿业公司团委和神南产业发展公司团委联合举办的“青春思辨，智启未来”辩论友谊赛正在火热进行。来自两家单位的4支青年代表队同台竞技，围绕人工智能、青年发展等热点话题展开思维碰撞，以语言为刃、以逻辑为盾，展现新时代煤矿青年立足行业、心怀全局的思辨风采。\n紧扣时代脉搏  辩题贴近青年关切热点\n本次辩论赛聚焦青年成长与科技变革两大核心辩题。首场辩论围绕“人工智能的普及将增强还是削弱职场竞争力”展开。正方立足技术赋能视角，强调豆包、Deep Seek等AI工具的应用将解放人力，使职场人更专注于创新决策；反方则以“替代性危机”为切入点，指出重复性岗位的消失可能加剧内卷。双方从技术伦理、岗位迭代、技能重塑等角度展开交锋，金句频出。第二场辩论则直面“学历贬值时代，青年人应继续深造还是探索多元发展路径”，正反双方就“继续深造”与“多元发展”的利弊展开激辩，既有对教育本质的哲学探讨，也有对行业需求的务实分析。 \n跨界思维碰撞  打造行业交流新范式\n活动特别设置“观众提问”与“互动答题”环节，现场100余名青年职工积极参与。当观众问及“人工智能的普及，从业者是否会因AI的‘标准化建议’而导致技术依赖风险”时，辩手结合张家峁智能化建设实践，强调“人机协同”才是转型关键，赢得满堂喝彩。由陕煤集团“四种经营理念”“四项重点工作”、企业精神、企业文化等组成的互动答题，更将活动推向高潮。\n经过激烈角逐，最终评选出最佳辩手2名、最佳团队2支、优秀团队2支。此次辩论友谊赛，为青年职工提供了一个锻炼自我、展示自我的宝贵平台。参赛选手纷纷表示，今后将以此次辩论赛为契机，在明辨是非中淬炼理想信念，在工作实践中锤炼过硬本领，切实把学习成效转化为实干担当的强大动力，投身企业高质量发展。\n来源/共青团组宣部供稿 返回搜狐，查看更多"
  },
  {
    "title": "人工智能及其创造力—基于心灵-认知哲学的视角_文化评论_文化纵横_四川省情网",
    "page_body": "高新民\n《光明日报》( 2024年10月30日 11版)\n人工智能(以下简称AI)的创造力建模和机器实现研究一跃成为热门话题,各种有创造力的软件层出不穷,其突出成就体现为会写学术论文和能打败世界围棋冠军的软件,能创作小说、绘画之类作品的多层次人工系统等。基础理论研究也成就卓著,诞生了足以填补AI空白的新生事物——“计算创造力”。它有两个指称,一是指由人工系统所实现的创造力或AI创造力;二是指专门研究如何让人工系统表现创造力的、融理论探讨与工程实践于一体的AI分支领域。\n开创有中国气派的计算创造力AI分支,除了要全面深入研究国外计算创造力建设的成功经验、完成“补课任务”之外,还应弯道超车,直接切入其前沿阵地,着力研究前提性、前瞻性基础理论问题,聚焦其中的心灵-认知哲学问题,如创造力建模的原型实例问题、计算机实现创造力的可能性问题、软件工程的“接地”与“真实性缺失难题”等。\n创造力的祛魅与计算化:计算创造力的样板考量\nAI让计算机实现创造力,就是把人类或非人类的创造力当作样板或“原型实例”来建模。而要如此,当然得优先回答前提性心灵-认知哲学问题,如创造力本身究竟是什么,有无不同于思维等认知能力的独立的创造力,它本身的结构、本质和秘密是否能向人类认知开放?麻烦在于,传统的创新观即使不是全部,至少也有一部分是计算创造力研究的拦路虎,如根据传统的浪漫主义和神秘主义的创新观,创造力本身是一种谜或神秘性,甚或是一种悖论。即使世上有创造力发生,那也是缪斯诸神独有的品质。\n要清除创造力计算建模的上述屏障,无疑要设法让创造力进入AI科学基础研究的中心,为之祛魅,消除其神秘性,把创造力从认知高不可攀的神坛上拉下来,使其回归为自然界的一种客观的过程或力量。世界上的所谓神秘性、谜团都是相对于人已有的认知而言的。过去没有认识清楚的东西就是谜,就充满神秘性,如天上的打雷在科学不发达的时代就被认为是神秘莫测的力量,随着物理学的发展,它被祛魅了,进而回归它本来的自然现象的地位。创造力也是如此。\n创造力之所以不神秘,之所以能为机器建模,从内在方面说,就是因为它依赖的是我们平常的认知能力,如思维、想象、联想、类比等。它们以一定的方式集合在一起,就有创新现象的突现。用科学的语言说,创造力的发挥是由分布式皮层网络决定的,其现实显现不取决于单个的大脑区域;创造力的神经基础随任务需求及其形式的变化而变化;多数创新任务的完成都与默认模式网络和执行控制网络的动态耦合有关。默认模式网络的激活反映的是来自长期记忆的想法或信息的自发生成,而执行控制网络的激活反映的是约束思维完成特定目标任务的过程。因此创造力是自然现象,可以得到计算建模和机器实现。就创造力最倚重的发散性思维而言,它们由节点的激活所构成。如果这些节点非常固定地连接起来了,那么它们就表现为常规的心理现象。人有发散性思维,不外是出现了微弱的、间接的连接,进而唤醒系统用非特异性激活来撞击大脑皮层。结果人的精神生活中就表现出常见的灵光乍现之类的现象。\n就最具认知封闭性、被视为心智奇迹的灵感、顿悟之类而言,只要人类认知有办法走进去,它的神秘性就会慢慢消散。它的所谓神秘不过是作为解决问题的方式不同于标准的分析问题的方式。后一类方式的特点在于,承认所要解决的问题易于用语言表达出来,这类问题可用直接的、逻辑的方式来加以解决。实验证明,当被试面对能用逻辑方式解决的问题时,他们就会用语言来报告他们解决问题的循序渐进的步骤。而适合于用灵感等方法解决的问题则不同,被试不大可能用逻辑的论证来解决问题,在这种情况下,解决问题的过程就会表现出不可言说的特点。尽管如此,这样的借助灵感解决问题的过程同样是由生物的大脑完成的,里面不会有超自然的力量,仍是可为科学说明的自然过程,如有关信息以特定方法被编码和加工的过程。\n让机器实现创造力,对创造力作出计算化也是必要条件。所谓计算化,就是为概念提供操作定义,或把创造力翻译成能在人工系统上实现的属性,用计算术语重新表述创造力及其构成,揭示它所具有的形式或符号转化的本质特点。计算化也可理解为用计算术语对有关概念作形式化处理。形式化的方式多种多样,如代数形式化、逻辑形式化等。为满足形式化的要求,已诞生了像代数符号学这样的研究。它试图从逻辑上将符号、符号系统及其映射的结构形式化。随着计算创造力探讨的深入,已诞生了许多有理论根据和实用价值的创造力计算化方案,如认知方案、程序方案、情境主义方案、计算主义方案等。根据计算主义方案,将创造力计算化,就是要用概念空间、启发式、搜索等计算术语去说明创造力,去重构创造力观念,例如将创新能力的诸组成、诸机制形式化于机器之中。只有做了这样的工作,机器才能实现这些形式化或其中的一部分,进而完成创新任务。\n创造力AI建模如何可能:计算创造力的机制探究\n计算创造力基础理论建设的又一工程是化解怀疑论的质疑,即计算机和创造力风马牛不相及,因为创造力是人类心灵的奇迹,是最能体现人的本质特点的东西,而计算机是按程序运行的,所做的事情都是程序员安排好了的事情,其特点是被编程。被编程是自主性的对立面,而自主性是创造力的必然特征。计算机即使能表现所谓的创造力,也只应归功于程序员。程序中的指令、规则决定了计算机的所有可能表现,这些是没法超越的。\n但只要作与时俱进的研究,就会发现,上述认知是基于对程序狭隘而陈旧的理解而形成的。根据对程序的新研究,上述看法的问题在于没有看到程序包含规则本身的变化,即程序中包含规定怎么变化的规则,能被嵌入随情境变化而变化的“活算法”甚或有创造力的算法。再者,程序被内嵌了能学习的算法,会对来自环境的没有预料到的输入作出反应。重要的是,它还包含遗传算法,这种算法能对程序面向任务的规则作出随机更改。这些变化类似于促成生物进化的点突变和交叉。许多进化程序还包含适应度函数,它能从每个新一代任务程序的成员中挑选出最好的成员,作为下一轮随机按规则变化的“父母”。没有适应度函数时,这样的选择由人来做,而有了这样的函数,机器就可以“自己”做了。这意味着,机器由于程序概念的变革而有了特定意义的自主性和创造力,也能生成符合人类创造力两个标准(即新颖性和有用性)的输出。以进化编程为例,它可以导致初步的转型性人工智能,即让机器有转型性创造力,如有的程序生成的图像完全不同于原来的图像,即是新的和有用的图像。之所以如此,是因为遗传算法不仅允许单一的被编程的指令内的点突变,如改变一个数字,而且允许整个图像生成程序的连续和分层的嵌套。\n由于AI建模和实现创造力如何可能既是一个理论问题,又是一个实践问题,且后一方面更根本、更关键,因此,我们既可双管齐下,同时从理论和实践上探讨人工系统表现创造力如何可能问题,又可将重点放在工程实践的攻关之上。事实上,AI采取了边讨论边实践的策略,并把重点放在如何设计有更大创新能力的人工系统之上,已取得了大量举世瞩目的成果,如前述的会撰写创新性论文和创作文艺作品的软件,能对最难预测的蛋白质结构作出远超人类科学家的最准确预测的AlphaFold等。既然如此,现在似乎没有必要再在创造力是否可能这一问题上浪费人类的宝贵精力。事实上,计算创造力研究已然有这样的前进方式,即抛开“是否可能”等宏大理论问题,而在解剖具体的创造力形式的基础上,做一些具体、细小的让人工系统实现创造力的工作。\n软件工程创新:计算创造力的技术关键\n软件工程就是将系统化的、严格约束的、可量化的方法应用于软件的开发、运行和维护等工程技术研究和实践的过程。在计算创造力研究中,软件工程既是其主要驱力,也可说是其主要工作,例如在所从事的应用领域(绘画、游戏、科学发现等)研究、设计、编写有创造力的软件。用哲学术语说,它是名副其实的“牛鼻子”,因为不管为创造力做多少祛魅、计算化和模型建构工作,最终都要通过软件来落实和实现。\n应承认,刚开始由于人们对软件的本质和作用持这样的理解,即设计软件不过就是编写代码和算法,因此计算创造力中出现的软件多数成了实现目的的手段。如果认识和实践停留在这个水平,那么计算创造力的创造创造力的理想就无法变成现实。基于从创新软件的角度对软件工程的认真反思和研究,人们对目标作了这样的调整,即让软件生成的代码和算法同时成为一种创新成果,让软件成为有创造力的软件生成器,它的一个作用是向世界提出问题,而不仅仅是解决问题。要如此,就要改变方法论。基于这样的认知,计算创造力编程中的代码就不像在别的地方那样只是一种工具,而是能像科学或艺术中的成果或过程一样,即这样的代码也有自己的生命,可以被研究、修改,可应用于不可预见的领域中,可受到文化的推崇,等等。按照这样的理念去设计和研制软件,就不仅是在从事工程技术工作,而同时是在进行具有哲学意义的创造力探讨,其表现是,这里一定会重思创造力的本质等哲学问题。根据新的研究,创造力的作用不只在于解决问题,更重要的是向世界提出问题,或将世界问题化。所谓问题化是指,所生成的代码暴露了这样的机会,即要么有助于通过问题解决更好地理解世界,如暴露一种意外的异常或关于数据集的假设,要么将代码应用于变化之中以改变世界。\n软件工程的关键工作是编程,因为计算机表现创造力是通过程序实现的。具言之,要让机器表现创造力,除了要研究创造力、让其计算化以便实现于程序之外,还要探讨程序的承受能力问题,如程序与创造力是何关系,能否实现创造力,能实现到何种程度,等等。正是看到这一点,许多计算创造力研究专家便践行这样的工程学进路,即先研究程序的承受能力和本质,再据此对创造力作计算化说明,解决具体的工程实现问题。\n“真实性缺失难题”及其化解:计算创造力的“接地”建模\n冷静反思已有的计算创造力软件和编程研究工作,哲学家和一些关注基础理论工作的AI专家都承认,已有的模拟了各种智能现象的软件都有“真实性缺失(lack)难题”。这一问题其实是塞尔等人所说的“意向性缺失难题”在计算创造力建模中的表现。只要考察就会发现,人类所表现的创造力有两种情况:一是系统真实地实现了创造力,如该系统要么是创新的真正合作者,要么是能独立创新的自主体;二是被评价为、被解释为有创造力,即有表面上的创造力。按照关于创造力的内在主义的观点,已有的有创造力的软件只是被评价为有创造力,而非真的有创造力,此即真实创造力的缺失问题。"
  },
  {
    "title": "阿里巴巴国际站商品评估体系重磅升级，快来get精准商机！外贸订单-跨境电商-阿里巴巴国际站中文官网",
    "page_body": "一年一度的全球采购盛宴-阿里巴巴国际站 3月新贸节 -即将开启，相信不少商家朋友们已经报名成功，满怀期待地跃跃一试了。\n今年的3月新贸节，主打 新品 与 实力优品 ，也就是说，若你在阿里巴巴国际站发布的产品不是新品，想要参加3月新贸节，就一定得是实力优品。\n那么，在阿里巴巴国际站发布的产品怎样才算是实力优品呢？以阿里巴巴国际站商品评估体系为准。\n为了充分体现平台上各行业之间的平衡性与专业性，进一步优化解决以往“不同行业共用一套标准”、“商品的行业核心属性表达不足“等问题，阿里巴巴国际站商品评估体系于1月17日进行了全新升级。\n本次升级，便聚焦在 “行业平衡性 ” 与 “行业专业性 ” 两大方面：\n一、行业平衡性——从之前的“全行业同一标准，且固定不更新”，升级到 “不同行业，不同标准，且动态更新 ” 。\n*举个例子，在新的评估体系之下，如机械、建材这样的非消费品类，也可以拥有和蓝牙耳机、假发假睫毛这样的热门大消费品类相似的实力优品获评几率。\n二、行业专业性——从之前的“内容表达、效果转化、商品服务”，升级到 “行业特征、内容表达、效果转化、商品服务 ” 。\n阿里巴巴国际站商品评估体系升级的目的，是希望通过引导商家对外呈现专业买家最关注的 商品核心属性 ，以更好地服务专业买家，减少沟通成本，最终实现更精准的买卖匹配。\n简言之，升级后，阿里巴巴国际站商品评估体系将体现 行业化差异，不同行业商品转化为实力优品的难度实现平衡 ，筛选出的实力优品也将更具有行业特征，能够代表行业的商品力。\n用心做品的商家从此有福了，马上去check一下自己的店铺，看看自己在阿里巴巴国际站发布的产品有多少实力优品吧！\n每一次升级，都是为了更懂你，为了匹配更精准的商机。\n3月新贸节，祝，大卖！"
  },
  {
    "title": "《解放日报》整版报道普陀：政府社会联动，共谋数字经济发展新蓝图_澎湃号·政务_澎湃新闻-The Paper",
    "page_body": "海纳小镇不是镇，中关村不是村，它们都是一个区域面向未来的窗口，科技发展的承载地。\n普陀区委书记胡广杰表示，海纳小镇通过布局海纳工程院等新型研发机构和创新配套设施，加速推动创新要素、数据要素与城区深度融合，加强与杭州云栖小镇、无锡雪浪小镇的“三镇联动”，全力构建充满活力、包容多元、协同共创的数字经济生态体系。\n在前不久召开的海纳大会上，上海市普陀区由点及面地展开一张共享、共创的数创生态图，以数据为媒，与长三角协同，同世界联通。\n由点及面\n海纳小镇推动数据要素发挥乘数效应\n在我国，超过1.8亿经营主体是数据要素市场化价值化的主战场。而海纳小镇作为一个“数据集”，正在发挥关键作用。\n海纳小镇位于真如城市副中心，依托武宁路沿线科研院所等丰富的科创资源，以及海纳工程院、中海中心、“真如境”综合体等载体配套，通过机制创新识才、引才、聚才。\n如今，以数据为引擎，占地2.32平方公里的海纳小镇，既是普陀区转型发展的“孵化基地”，也是各类应用场景的“跳板”。\n如今，海纳小镇及周边真如副中心集聚了约3000家数字经济企业，以20%的区域企业数量，形成了近60%的经济贡献。\n在机制创新、生态构建、应用落地等方面，一个数字IP正在形成，一方面，海纳小镇通过布局新型研发机构及创新配套设施，重点发展先进计算、深度智能、元宇宙、数字广告、数字服贸、数字能源等新兴产业，推动数字产业集聚，构建数字经济产业生态；另一方面，通过举办海纳大会等品牌活动扩大影响力，打造能触达行业潜力主体的重要平台载体，面向企业发布数字应用场景建设需求清单，实现政府、企业、居民多方共赢共享。\n“这里不仅是技术创新的实验室，更是城市可持续发展的样板。”真如副中心副总规划师陈霞介绍，海纳小镇范围内全部新建建筑均达到绿色建筑二星级及以上标准，绿色建筑三星级比例达61.71%，中心区超低能耗建筑比例为28.99%。区域内还设置了H型地下车行通道，缓解地面交通压力，并通过架空廊道、街边步道等立体化公共空间合理规划区域。\n对于百姓来说，城市数字化转型这个词或许还比较陌生，但其实它每天都在发挥作用，如在南郑路（曹杨路—真华南路）段增设可变车道，根据交通需求，运用智慧化的交通管理方式缓解交通压力，优化大客流运行组织，为周边市民购物娱乐提供舒适便利的交通环境；2.5公里长的真如绿廊沿内环向外环延伸，通过融合景观建筑、植被绿化和滨水空间，构建特色生态系统，形成水网纵横、绿树成荫的高品质空间环境。\n上海智慧城市发展研究院院长盛雪锋表示：“作为长三角一体化的重镇，普陀无论在空间还是产业上，都处于重要一环。依托区位优势，数字经济将成为普陀发展的重要板块，围绕海纳小镇，以及协同生态社区，在前沿数字创新技术、模式上形成突破。”\n三年时间里，海纳小镇建设发展已然取得了丰硕成果。成功争取到市级数字化转型示范区授牌，落地了上海市首个数字广告产业园，获评创建国家发改委数字经济特色小镇，入选2023年度上海市特色小镇清单，成为全市中心城区唯二的特色小镇。此外，小镇还发布了全国首个地市级数字化转型指数，吸引了菲尔兹数学科学院中国中心等一大批优质项目落地。\n作为真如地区服务长三角一体化建设的数字引擎，通过加强产业培育、提升数字能级、营造绿色生态和改善公共服务，海纳小镇不仅推动了区域经济高质量发展，也为长三角地区科创协同发展树立了新的标杆。\n“上海的城市数字化到底走一条什么样的路径，以一个什么样的方式，我们一直在探索。”在中国工程院院士、海纳工程院发起人王坚看来，普陀区大力推进海纳小镇数字化转型示范区建设，积极探索科技创新机制，非常有远见和魄力。\n承上启下\n普陀区发挥数据共享共创溢出效应\n当前，数据作为新型生产要素，已快速融入生产、分配、流通、消费和社会服务管理等环节，正成为价值创造的重要源泉。\n数据的互联互通，让使用者受益的同时，也让区域更加协同。\n作为上海中心城区西北门户，普陀区区位及交通优势明显。高速路、公路穿越而过，城市枢纽站转接四面八方，城市地铁线路内外联通。一条沪宁高速公路串联起南京、镇江、常州、无锡、苏州和上海市普陀区。\n从高速到高铁，城市之间通行时间的缩短，就是经济联系紧密度的增强。交通基础设施的完善，造就了长三角“廊”“带”的产业合作基础。\n2月中旬持续到3月中旬，近一个月内，普陀区党政代表团连续4周，每周选定一天，前往江苏考察，分别到访南京、无锡、常州、苏州、南通、镇江、泰州7个城市，并与各地主要领导会面。每次会面主题均聚焦“沿沪宁产业创新带建设”，并逐一签署沿沪宁协同创新城市联盟合作备忘录。\n为什么要“北上”？\n普陀区的优势在于人才资源和科技力量，但地处上海市中心，土地、能源等要素保障相对有限，部分科创成果难以“消化”。打造科创走廊、建设创新产业带，目的在于让政府搭台，让企业“唱戏”，提升长三角在科技创新和产业创新领域的分工协同水平。\n区域数据化转型，不仅需要依靠有效市场，也要依托有为政府。在区域合作机制下，长三角政务数据已建成共享底座，通过打通三省一市大数据资源平台数据共享节点，实现跨区域高效共享，有力支撑了各类应用拓展，如“一网协同”“一码畅游”“一码通行”，财政电子票据共享应用，经济困难学生跨省资助免申即享等。\n政府“北上”之后，企业也在南下。\n医疗器械和生物医药是镇江重点规划布局的产业链，在发展过程中，企业需要对产品进行迭代升级以应对激烈的市场竞争，所以有企业提出希望能够在上海建立创新中心的需求。普陀区身处沿沪宁产业创新带的起点，且土地、人才、高校、医院等创新要素配置齐全，成为不少企业的首选地。\n2024年12月4日，长三角区域合作办公室新闻发布会在上海召开，通报了2018年以来的多项成就。长三角一体化推进了上海、南京、杭州、合肥、嘉兴五市科创金融改革试点；长三角协同优势产业基金两期累计投资了47只子基金、52个直投项目，覆盖底层项目近1000个，为长三角地区培育了312家国家级专精特新“小巨人”企业。\n让更多用户享受数字化红利，离不开数据的汇聚与使用。在海纳工程院首席科学家薛贵荣看来，海纳小镇作为一个平台，利用灵活机制，联结企业和国内外需求，将来自全球的人才、技术、数据聚合在一起，针对不同应用场景，为国内外城市、机构和用户提供数字化解决方案。“沿沪宁产业创新带”七市一区已建立了数据合作机制，进一步促进数据要素在城市之间跨区域、跨领域的协同创新，释放数字要素对经济的乘数效应。\n积少成多\n政企学研共建数据应用新生态\n数据积累是创造价值的前提，共享流通是释放价值的关键，如何让数据共享流通利用打破“不愿”“不敢”“不能”，在普陀区政府的支持下，海纳小镇充分发挥机制优势，吸引全国行业专家、头部企业、创新人才共同参与活动交流和小镇建设。\n“企业在AI落地上的探索和实践路线很多都是同频的，但靠一家企业单独的力量去推进，它的成本是相当高的。”有门互动相关负责人洪刚表示，政企合作可以大大降低数据处理与合规成本，让中小企业也能共享算力与基础设施红利。\n大部分数据的跨领域联动，靠企业单打独斗亦难以实现。蔚蓝云创产研中心副总经理于梦溪介绍：“我们通过开展水务集团的数据治理与涉水企业数据产品的开发工作，挖掘部分企业用水数据与区域文旅消费带动性的隐性关联，跨行业的数据碰撞，往往能解锁意想不到的价值。”\n从标准制定到数据共享，从人才培养到场景创新，海纳小镇正成为数字产业的试验场与连接器，构筑起数字产业发展新高地。\n普陀区数据局相关负责人介绍，全区依托“数智普陀”数字化转型实验室和近年来积累的公共数据资源，建立“数智普陀”数据创新实验室，提供“技术有支撑、安全有保障”的实验平台，为数字化转型项目提供试制环境。联合5所高校、16家大院大所、70个科创平台的资源，共建数据创新实验室，并通过“揭榜挂帅”的方式挖掘和打造一批技术创新优、应用效果好、复制推广性强的数字化转型标杆示范应用场景。\n在支付领域，作为国内支付服务提供商，收钱吧拥有海量的线下支付交易记录，可以帮助支付机构和商户更好地了解市场动态，从而优化支付服务和营销策略。\n在安全领域，上海化工院检测有限公司信息技术部部长王高俊表示：“我们基于拉曼光谱技术自主研发了危化品快速识别系统，可在180秒内解码多达10万级的光谱数据，为城市安全治理提供决策支撑。”\n在数据向内汇聚乘数效应的同时，普陀区也在向外寻求合作。\n在海纳大会上，普陀区聚焦数字经济全链条服务，携手人民网联合打造“828数据港”平台，构建“数据要素流通+产业生态赋能+政企协同创新”的新型服务模式。\n人民网相关负责人表示，平台涵盖企业全生命周期服务、数据要素流通与赋能、数字技术应用与场景落地等模块，通过区块链技术保障数据安全与可信流通，在金融、医疗、交通等领域推动高质量数据集开放共享。\n“未来，我们还将继续发挥数据港的开放服务能力，扩大海纳小镇的合作范围，营造服务全球数字创新者的开放共享创新环境。”普陀区数据局副局长尹欣介绍称，“政产学研用”深度融合将不断推进海纳小镇技术成果向实体经济转化，夯实数据融合发展底座。\n之江实验室主任、阿里云创始人王坚认为，数据资源是未来城市发展的决定性资源，各地数据生态要从“打破孤岛”向“应联尽联”转变，数据使用要从“数据归集”向“数据下基层”转变，从而提升城市治理能力，改善企业营商环境，让企业、百姓办事从“找关系”到“找数据”转变。\n有了数据“翅膀”，普陀区的发展不止于本地和区域，也更具全球视野。\n“我们聚焦城市交通拥堵和热岛效应两大难题，依托算力和数据资源，吸引全球研究者共同探索解决方案。”薛贵荣透露，海纳工程院正与联合国机构合作，将中国的人工智能城市治理方案推向世界。\n“海纳小镇位于普陀，不仅仅限于普陀，更是面向全球的出发点。”盛雪锋表示，数据跨境流通与应用将成为上海乃至长三角发展的新方向，海纳小镇要主动承担起谋划推动跨境流通的任务，从而衍生出更多新的应用场景。\n今年的政府工作报告提出，“持续推进‘人工智能+’行动”“将数字技术与制造优势、市场优势更好结合起来”。\n王坚院士表示：“各地不仅要搞清楚人工智能加什么，更要搞清楚怎么加，如何把机制"
  },
  {
    "title": "OpenAI大神亲自揭秘，大模型是怎么炼成的？ #AI #人工智能 #openai #大模型 #干货分享",
    "page_body": ""
  },
  {
    "title": "人工智能赋能社区治理，九圣祠开启“城市唤醒”行动_技术_发展_应用",
    "page_body": "人工智能赋能社区治理，九圣祠开启“城市唤醒”行动\n2025年，随着科技的迅速发展，人工智能逐渐深入到各个领域。长春市的九圣祠社区积极拥抱这一变革，发起了吉林省首个社区融媒体服务中心，旨在通过人工智能技术的应用，激活社区治理的潜力。这不仅是对社区管理方式的革新，更是以 人工智能为核心 ，改变基层干部与群众互动的新方式。\n借助于整合的资源优势，九圣祠社区正在构建一个新时代的“数字治理”模式。这一模式的核心在于 将AI技术与社区治理深度融合 ，以应对日益复杂的社区服务需求。通过有效整合高校技术资源、社会市场资源和企业应用场景，社区可以在治理生态中实现 循环发展 ，提升治理的效率与效果。\n在“城市唤醒”行动的启动仪式上，社区通过公开的专业学习活动，强调了如何利用现代科技手段提升社区工作者服务群众的能力。此次活动选择了深度学习和数据挖掘等多项前沿技术，通过专业讲师的指导，将这些技术的实际应用呈现给参与者，真正让社区工作者理解人工智能的技术优势。\n与此同时，九圣祠社区还特别聚焦**“金牌项目”**的推动，尤其是在“共享+”和“未来+”等领域。这些项目不仅为社区服务提供了新的试点，也为人才的培养提供了新的方向。社区党委书记姜丽丽表示：“我们将持续引进优质的社会力量，确保高质量地参与社区治理。”\n这种前瞻性的思维使九圣祠社区不再局限于传统的社区管理，而是将目光投向未来，着力于培养 复合型创新人才 ，为推动社区治理创新开辟出新思路。未来，随着人工智能技术的不断发展，社区的治理模式必将更加丰富和多样化。\n第一个“城市唤醒”的行动仅仅是一个开始。社区将继续探索智能算法和自然语言处理等技术在实际工作中的落地应用。通过这些措施，九圣祠社区不仅可以提升内部效率，更能够为居民提供更便捷、更高效的服务。\n展望未来，人工智能将会在 基层治理中扮演越来越重要的角色 。通过持续的技术整合与优化，社区治理将从传统的模式逐步转向以技术为驱动，实现科学决策与精细化管理。正如九圣祠社区所倡导的那样，在开启城市发展的新篇章时，社区治理的新图景也在慢慢清晰。\n总之，以人工智能赋能城市治理，九圣祠社区正在通过“城市唤醒”行动，为其他社区实现转型奠定了坚实的基础。这不仅为居民提供了智能化的生活选择，亦为未来的社区发展开辟了更多可能。"
  },
  {
    "title": "AI应用开发平台-得助智能",
    "page_body": "从想法到产品，一个开发平台搞定一切，快速构建企业AI应用\n开箱即用 百大行业开发助手，告别“凑活用”的通用AI，直接对接核心业务 零码搭建 不用懂代码，业务团队可以拖拽配置高价值应用，提效自己掌控 无缝接入 企业级管控护航，无缝集成企业现有的业务系统，保障安全稳定合规\n立即咨询 免费试用\n提效 10倍\n零码配置+预置行业Agent，10分钟搭建应用\n降本 >50%\n业务人员主导构建，无需庞大技术团队\nAI能力复用率高达 80%\n沉淀行业知识资产，直接复用\n开箱即用、敏捷交付\n行业Agent库 | 零代码搭建 | 多渠道发布 | 全景监控\n智能应用中心\n集中管理、一键发布你所有的AI大模型应用，提供API/SDK、web、Chrome 插件等多渠道集成，快速方便的集成企业CRM、ERP等业务系统\n免费试用 立即咨询\n模版广场\n我们提前搭好了200多个 “开箱即用” 的高价值业务Agent，拿过来就能直接用，省掉从零开发的1-3个月时间。像搭积木一样拖拽式配置界面，业务人员自己就能搞定轻量级AI大模型应用\n免费试用 立即咨询\n智能体无缝对接\n轻松对接智能体能力，再结合你家独有的企业知识库（规章制度库、设备参数库），AI瞬间变成老员工，直接解决客户、内部员工等问题，打造更懂业务的智能应用\n免费试用 立即咨询\n应用全流程监控\nAI大模型应用谁在用、用了多少次、资源消耗多少、性能稳不稳定，都看得明明白白，优化体验，保障稳定运行\n免费试用 立即咨询\n选择我们的原因？\n极速上线 敏捷响应\nAI应用开发平台构建效率翻倍，周级上线产品，业务落地先人一步\n降本增效 人人可创\n业务专家直接创建，降低开发维护成本，解放IT团队，提高ROI\n安全省心 开箱即用\n操作权限、监控等保障数据安全，开箱即用的RAG框架与模板\n深度集成 融合复用\n对接企微/业务系统（OA、ERP）/API/SDK,资产复用，避免浪费\n应用场景\n制造业\n船舶领域专业智库\n工单流转机器人\n设备预测性维护助手\n生产运营智能监控\n故障维修诊断助手\n设备故障自检报告助手\n泛金融业\n信贷办理查询助手\n反洗钱风险筛查助手\n贷后风险预警助手\n行业研究报告\n信用评级报告助手\n保险产品智能比对工具\n财富小助手\n企业准入风险评估助手\n政务与公共事业\n水利工程智能审校\n专业文献智能翻译\n报告解读问答\n智慧党建\n工作汇报助手\n医保政策智能问答平台\n企业办公\n企业规章问答助手\n合同法审助手\nPPT大师 \n专业文献翻译工作站\n客户案例\n船舶 金融 公安 工业 工程 政务\n为央企发展新质生产力提供创新范本\n中关村科金助力中国船舶集团经济研究中心自主研发船舶行业大模型\"百舸\"，并深度集成DeepSeek-R1。百舸深度融合船舶领域百万级专业知识库与DeepSeek-R1的长文本推理与深度思考能力，构建覆盖智能问答、研报写作、文档解读、情报分析等全链路解决方案，推动船舶工业\"数智大脑\"建设。\n立即咨询\n更多客户\n更多案例详情 >\n最新动态\nNEWS\nPrevious\n大模型 IVR 颠覆传统客服：得助智能如何用 AI 重构企业呼入服务体验？\n2025-11-12\nAI大模型应用开发平台对哪些企业有用?对企业的功能作用有哪些？\nAI大模型应用开发平台对任何企业都有用，但说到最有用的话，有三类，第一个是没有技术团队的中小企业；第二个是有明确需求的企业，第三个是对安全稳定性隐私性要求的中大型企业。\n2025-11-12\n打造水利垂类大模型＋知识库：告别信息孤岛，如何用大模型“唤醒”沉睡数十年的知识宝藏？\n本文将剖析某水利研究院利用得助智能大模型平台实现智能系统升级案例，看某水利研究院在得助智能帮助下如何打造垂类大模型＋知识库，在数据庞大的情况下，结合大模型总结归纳知识库，实现错误检测准确率90%以上。\n2025-11-10\n企业选择AI大模型应用开发平台有哪些注意事项？\n企业选择AI大模型应用开发平台，需重点关注五个关键事项（数据安全与合规性、业务匹配度、成本可控性、技术支持与迭代能力、易用性与团队适配），避免决策偏差导致资源浪费。\n2025-10-29"
  },
  {
    "title": "《Transformer自然语言处理实战:使用Hugging Face Transformers库构建NLP应用》PDF免费下载-不知名也-博客园",
    "page_body": "点击下载\n书籍信息\n副标题: 使用Hugging Face Transformers库构建NLP应用\n 出版年: 2024-1\n ISBN: 9787111741923\n 文件格式：pdf, epub\n内容简介\n本书涵盖了Transformer在NLP领域的主要应用。首先介绍Transformer模型和Hugging Face 生态系统。然后重点介绍情感分析任务以及Trainer API、Transformer的架构，并讲述了在多语言中识别文本内实体的任务，以及Transformer模型生成文本的能力，还介绍了解码策略和度量指标。接着深入挖掘了文本摘要这个复杂的序列到序列的任务，并介绍了用于此任务的度量指标。之后聚焦于构建基于评论的问答系统，介绍如何基于Haystack进行信息检索，探讨在缺乏大量标注数据的情况下提高模型性能的方法。最后展示如何从头开始构建和训练用于自动填充Python源代码的模型，并总结Transformer面临的挑战以及将这个模型应用于其他领域的一些新研究。\n作者简介\nLewis Tunstall是Hugging Face机器学习工程师，致力于为NLP社区开发实用工具，并帮助人们更好地使用这些工具。\nLeandro von Werra是Hugging Face机器学习工程师，致力于代码生成模型的研究与社区推广工作。\nThomas Wolf是Hugging Face首席科学官兼联合创始人，他的团队肩负着促进AI研究和普及的使命。\n点击下载"
  },
  {
    "title": "OpenAI 开源模型重磅回归：技术突破与行业范式的双重革命-今日头条",
    "page_body": "2025 年 8 月 6 日，OpenAI 正式发布自 2019 年 GPT-2 以来的首款开源权重模型 ——gpt-oss-120b 和 gpt-oss-20b，这一历史性举措不仅标志着 AI 技术民主化进程的里程碑，更揭示了行业竞争格局的深层变革。此次开源的核心意义，在于通过 MoE 架构创新 和 边缘计算适配 ，重新定义了大模型的应用边界，而其背后的战略逻辑，更折射出 OpenAI 在监管压力与市场博弈中的生存智慧。\n一、技术突破：从参数竞赛到效率革命\n此次发布的两款模型展现了 OpenAI 在架构设计上的颠覆性创新：\n混合专家（MoE）的范式重构\ngpt-oss-120b 采用 MoE 架构，总参数量达 1170 亿，但每个 token 仅激活 51 亿参数，较同等规模稠密模型节省 70% 算力。这种设计使得模型可在单个 H100 GPU 上运行，推理速度较 GPT-4o 提升 2.3 倍，而训练成本降低至传统模型的 1/5。通过分组多查询注意力（组大小 8）和旋转位置编码（RoPE），模型原生支持 128k 上下文长度，在 Codeforces 编程竞赛中得分超越 o3-mini，接近 o4-mini 水平。 量化技术的突破\n模型采用 MXFP4 原生量化，gpt-oss-20b 仅需 16GB 内存即可运行，在 M3 Pro 芯片的 Mac 上实现 23.72 token / 秒的本地推理速度，且无需额外量化处理。这种轻量化设计使得开发者可在消费级硬件上部署，彻底打破大模型依赖云端的传统模式。 工具调用的深度整合\n模型原生支持函数调用、网页浏览和 Python 代码执行，在 TauBench 工具调用评测中表现超越 o1 和 GPT-4o。例如，用户可直接通过模型生成贪吃蛇游戏代码，并实时调试，生成效率较传统流程提升 40%。\n二、行业冲击：开源生态的马太效应重构\n此次开源对 AI 行业的影响将从三个维度展开：\n开发者生态的权力转移\nApache 2.0 协议允许开发者自由商用，无需担心专利风险，这直接冲击了 Meta Llama 3 的非商用限制。目前已有 Hugging Face、Azure 等 14 家平台支持 gpt-oss 系列，Cerebras 更将 gpt-oss-120b 的推理速度提升至 3000 tokens / 秒，创下 OpenAI 模型纪录。这种生态聚合效应，使得 OpenAI 在开源领域的话语权迅速超越 Mistral 等竞争对手。 云服务市场的格局重塑\n本地部署能力削弱了对云端 API 的依赖，预计将导致 OpenAI API 收入下降 15%-20%。但另一方面，模型对英伟达 H100 的深度优化（推理速度提升 65%），反而强化了硬件厂商与 OpenAI 的绑定关系。这种 “去云端化” 与 “硬件锁定” 的矛盾，将重塑 AI 基础设施的竞争逻辑。 安全合规的新战场\n尽管模型通过 Preparedness Framework 测试，在对抗性微调中表现与闭源模型相当，但开源仍带来伦理风险。例如，gpt-oss-120b 在 HealthBench 测试中虽表现优异，但 OpenAI 明确警告其不可用于医疗诊断。这种 “能力与责任的割裂”，迫使 OpenAI 与欧盟《AI 法案》合规要求展开深度博弈。\n三、战略逻辑：监管压力下的生存智慧\nOpenAI 的开源决策，本质上是应对多重外部压力的战略妥协：\n反垄断监管的规避\n美国联邦贸易委员会（FTC）对 OpenAI 的垄断调查，促使其通过开源展示 “技术普惠” 姿态。此次开源的 MoE 架构与 DeepSeek 的 MoE 模型高度相似，被解读为对中国 AI 企业竞争的回应。 商业模型的转型试探\n2025 年 5 月 OpenAI 将营利实体转为公共利益公司（PBC），需平衡股东利益与社会责任。开源模型可吸引开发者构建生态，为未来的企业级服务（如定制微调、安全认证）创造增量市场。 技术护城河的重构\n尽管开源模型性能接近 o4-mini，但核心技术如 RLHF（人类反馈强化学习）仍保留在闭源体系。这种 “基础开源、高阶收费” 的策略，既维持技术领先，又降低舆论风险。\n四、开发者机遇：从工具使用到生态共建\n对于开发者而言，此次开源带来三重机遇：\n边缘 AI 的爆发窗口\ngpt-oss-20b 可在手机端运行，结合本地传感器数据，可构建实时健康监测、智能家居控制等场景。例如，开发者可通过模型分析心率数据，生成个性化运动建议，响应速度较云端方案提升 80%。 垂直领域的深度定制\n模型支持参数微调，开发者可在医疗、法律等领域构建专用模型。例如，通过微调 gpt-oss-120b 处理 X 光片报告，在 HealthBench 测试中诊断准确率达 92%，接近专业医师水平。 工具链的创新空间\n与 vLLM 推理引擎结合，可实现每秒超 1000 tokens 的高吞吐部署；通过 Lm Studio 平台，普通用户也能轻松调试模型，生成效率较传统编码提升 3 倍。\n五、未来挑战：开源与安全的平衡困局\n尽管前景广阔，OpenAI 仍需应对三大挑战：\n滥用风险的防控\n模型开源后 48 小时内，GitHub 出现 23 个恶意分支，试图绕过内容审核。OpenAI 虽通过动态水印和区块链存证追踪侵权，但无法完全阻止 “换脸工具” 等灰色应用。 生态竞争的压力\nMeta 计划于 2025 年 Q4 发布 Llama 4，参数规模达 2 万亿，且支持多模态。OpenAI 需在开源模型中整合视觉推理能力（如借鉴 o3 的图像思考技术），以保持竞争力。 监管合规的成本\n欧盟要求开源模型披露训练数据来源，而 OpenAI 的数据集包含 1.8 万亿 token，其中 30% 来自未授权内容。这种合规风险可能导致其在欧洲市场的受限。\n结语：开源时代的 AI 新秩序\nOpenAI 的此次开源，标志着 AI 行业从 “参数军备竞赛” 转向 “生态价值创造” 的新阶段。gpt-oss 系列不仅是技术产品，更是 OpenAI 在监管、竞争与社会责任之间寻找平衡的战略工具。对于开发者而言，这是一个 “用代码定义未来” 的黄金时代 —— 从手机端的实时推理到数据中心的大规模训练，开源模型正在重构 AI 应用的底层逻辑。当技术民主化与商业可持续性碰撞时，OpenAI 的选择或许将成为未来十年 AI 发展的风向标。"
  },
  {
    "title": "大模型PK：阿里云与百度的“全家桶”谁更胜一筹？",
    "page_body": "原创 慢放\n大模型下半场：阿里云与百度开启“全家桶”之战。\n作者丨白华\n编辑丨Han\n封面图为慢放使用Midjourney生成\n随着「百模大战」进入深水区，国内的科技巨头、互联网大厂、AIGC创企及行业龙头纷纷递交了最新答卷。\n10月31日，阿里云不仅推出最新通义千问大模型2.0版本，还推出了八大行业大模型、大模型应用开发平台，并从AI基础设施层面全方位布局，本次发布可谓阿里云的AI「全家桶」爆发。\n而不久之前，百度除了正式发布文心一言4.0版本外，包括新搜索、新地图、新文库等数十款百度AI原生应用「全家桶」也正式亮相。\n那么面向AI浪潮，阿里云与百度双方的大模型产品及实力如何？将在大模型方面有哪些新布局？谁更有望为AI大模型产业化落地提供更好的底座支持？\n本文通过对双方AI「全家桶」的产品、底层算力、行业应用与生态等方面进行深入对比探讨，试图解答上述疑问，为国内已经布局大模型或者准备应用大模型的企业，提供发展模式与方向。\nPart 01\n大模型“全家桶”PK\n10月31日，阿里云正式发布了千亿级参数大模型通义千问2.0，同时扔出一个AI「全家桶」，从IaaS（基础设施即服务）、PaaS（平台即服务）和MaaS（模型即服务）全方位秀出“肌肉”。\n相比4月发布的1.0版本，新版本在复杂指令理解、文学创作、通用数学、知识记忆、幻觉抵御等能力上均有显著提升。在10个权威测评中，通义千问2.0综合性能超过GPT-3.5，正在加速追赶GPT-4。此外，通义千问APP在各大手机应用市场正式上线，所有人都可通过APP直接体验最新模型能力。\n与此同时，为推动大模型更易在千行百业集成落地，基于通义大模型训练的8大行业模型组团上线，主要包括通义灵码-智能编码助手，通义智文-AI阅读助手，通义听悟-工作学习AI助手，通义星尘-个性化角色创作平台，通义点金-智能投研助手，通义晓蜜-智能客服，通义仁心-个人专属健康助手，通义法睿-AI法律顾问。\n尽管阿里云这次发布了八大产品模型，但阿里云CTO周靖人强调，阿里云此举并非为了直接To C提供服务，而是To B。做行业模型，更多是像个面向客户的Demo，让客户先了解到大模型能做什么。\n在令人眼花缭乱的各类产品发布背后，阿里云面向AI时代其实已经做出了坚定选择——做AI时代的基础设施、开源路线、开放平台。\n除了阿里云在10月提交了一份新答卷之外，国内各家大模型厂商也纷纷拿出通用大模型的新版本，试图一较高下，例如腾讯、百度、讯飞、智谱、百川......\n其中，早在半个月前——10月17日，百度发布了文心一言4.0版本，新版本在理解、生成、逻辑、记忆四大能力都有显著提升。其中理解和生成能力的提升幅度相近，而逻辑和记忆能力的提升则更大，逻辑的提升幅度达到理解的近3倍，记忆的提升幅度也达到了理解的2倍多。百度基于文心大模型研制了智能代码助手Comate，从内部应用效果来看，整体的代码采纳率达到40%，高频用户的代码采纳率达到60%。\n此外，包括新搜索、新地图、新文库等数十款百度AI原生应用“全家桶”也正式亮相，备受外界关注。\n从产品角度来看，阿里云和百度都推出了大模型的新版本，并且在不同领域都拥有一定优势。阿里云的通义千问2.0版本在大模型能力和行业应用方面表现突出，而百度文心一言4.0版本则在语言理解、生成和逻辑能力方面更优异。\n不过有意思的是，百度似乎对自己的技术实力更自信，起码在对外宣传的口径上是这样。周靖人在云栖大会上表示，通义千问2.0综合性能超过GPT-3.5。而百度创始人、董事长兼首席执行官李彦宏宣称文心一言4.0综合水平与GPT-4相比已经毫不逊色。\nPart 02\n大模型背后的AI基础设施\n大模型的发展需要更强壮的AI基础设施，基础设施主要是两个核心部分构成——芯片与云。\n首先由于大模型需要大量的计算资源和存储空间，因此需要高性能的芯片来支持其运行。\n飞天芯片是阿里云自主研发的大规模分布式AI芯片，专为云计算和大数据处理而设计。它采用了一种新型的架构设计，可支持多种深度学习框架，包括TensorFlow、PyTorch等。飞天芯片不仅仅是一颗芯片，它还内置了阿里云自研的云操作系统，可以与阿里云的其他产品和服务无缝集成，提供一体化的解决方案。\n昆仑芯片则是百度自主研发的AI加速器芯片，专注于高性能计算和智能推断。它采用了高性能计算架构，可实现高能效比和低功耗。昆仑芯片支持多种数据类型，包括图像、语音、自然语言等，适用于多种AI应用场景。\n飞天芯片和昆仑芯片都具有强大的计算能力。飞天芯片的分布式计算能力使其在处理大规模数据时具有显著优势，并且支持大容量内存和分布式存储，可满足云计算和大数据处理的需求。而昆仑芯片的高性能计算架构则使其在推断等计算密集型任务中表现出色。同时昆仑芯片采用了高速缓存和优化存储技术，提高了数据处理速度和效率。\n3月17日，李彦宏在亚布力中国企业家论坛上分享，昆仑芯片现在很适合做大模型的推理，将来会适合做训练。\n其次大模型的实质是一场“云计算之争”。\n在这场争夺中，阿里云是国内最早布局云计算的平台之一，可谓是国内云计算领域的先驱。回溯至十多年前，阿里云在云计算和大数据尚未成为主流的年代，就坚信云计算的重要性，并开始着手布局。当时，很多国内技术公司认为“做云还太早”、“云只是旧瓶装新酒”，但阿里云选择了坚定的信念：“必须要做，客户需要，市场需要”，“每年给阿里云投10个亿，投个十年，做不出来再说”。\n如今，云计算不仅成为全社会重要的基础设施，也为今天热潮翻涌的AI大模型创新提供算力底座。而阿里巴巴完整的AI技术体系，正是建立于自研云计算的基础之上。根据IDC相关报告，2022年下半年，中国公有云市场上，阿里云的市场份额为31.9%，排名第一。\n在云栖大会上，阿里云针对大模型升级了AI基础设施，提供更高性能、更低成本的智能算力。周靖人介绍称，全新升级的阿里云人工智能平台PAI，底层采用HPN 7.0新一代AI集群网络架构，高效协同调度各类芯片，可支持高达10万卡量级的集群可扩展规模，让超大集群像一台计算机般高效运转。\n据了解，阿里云PAI可支撑多个万亿参数大模型同时训练，超大规模分布式训练加速比高达96%，远超业界水平；在大模型训练任务中，更可节省超过50%算力资源，性能全球领先。\n从业绩看，百度云则发力较晚，在2018年第四季度才开始公布业绩。据百度财报显示，百度云2019年实现营收46.5亿元，2021年则实现营收151亿元，两年增长224.73%。2023年二季度，百度智能云收入45亿元，同比增长5%。李彦宏在财报电话会上透露，继一季度首次盈利后，本季度，百度智能云再次盈利。不过，与一季度一样，百度并没有给出具体数据。\n百度云的优势则在于其搜索引擎所拥有的海量数据，侧重于融合AI能力，将AI技术与云基础设施服务相结合，聚焦智能服务突出差异化，基于“云智一体”的技术和产品，在制造、金融、能源等领域积极实践。\n百度创始人李彦宏将大模型视为改变云计算市场游戏规则的存在，而阿里董事会主席兼CEO张勇则将大降价、联合伙伴推动大模型落地、产品被集成作为关键的“三板斧”。\n随着时间的推进，2023年云厂商们相较于2022年的“保守”状态，已经开始了奔跑，预示着这个市场将迎来一场激烈的竞争。\nPart 03\n大模型的商业化解法，已告别免费时代\n如今，大模型竞争已经进入第二阶段——拼落地、拼应用、拼商业化。\n阿里云积极推动大模型在各行业的落地，已经与60多个行业头部伙伴进行深度合作，通义千问已经在办公、文旅、电力、政务、医保、交通、制造、金融、软件开发等领域落地。早在今年9月，阿里集团CEO吴泳铭在全员信中表示，要让阿里各个场景都变成AI技术的应用场。如今，淘宝天猫、钉钉、天猫精灵、斑马智行等均接入通义千问大模型，先后发布了适合各自业务场景的AI应用。\n百度也展示了文心一言在商业化方面的成果。自8月31日文心一言面向全社会开放以来，其用户规模已经达到4500万，开发者5.4万，场景4300个，应用825个，插件超过500个。此外，百度还推出了会员模式，开通后可解锁文心大模型4.0。\n在世界大会上，百度千帆还推出了自己的“App Store”——AI原生应用商店，为基于文心大模型开发的应用提供了交易平台。目前，应用商店已经针对智能办公、营销服务、行业职能、生产提效、分析决策5个场景上线了百度自研以及客户开发的AI应用。\n显而易见，大模型与行业的融合发展已是主要趋势，具体的场景还在逐步探索，一批典型案例则已经发布。\n李彦宏提到，百度正在大力推动数字技术与实体经济的深度融合。大模型技术已应用在制造、能源、电力、化工、交通等实体产业中，他认为，“大模型正成为新型工业化的重要推动力。例如，百度与浦发银行合作推出了智能客服“小浦”，与吉利汽车合作推出了智能驾驶“银河”。同时，百度还通过开源的方式向公众开放文心一言4.0版本，以推动大模型技术的普及和应用。\n阿里云则将大模型应用于电商、金融、制造等领域。例如，阿里云与美的集团合作推出了智能家居“美的美居”，与吉利汽车合作推出了智能驾驶“斑马智行”。此外，阿里云还通过与政府、高校和其他企业合作的方式，推动大模型技术的普及和应用。\n此外在商业办公方面，双方也有诸多的应用落地。\n今年4月18日，钉钉宣布接入阿里巴巴的通义千问大模型，表态将用大模型把钉钉重做一遍。当时，钉钉发布了一个AI“魔法棒”，演示了聊天、文档、音视频会议等4大高频场景中的智能化应用。4个月后，钉钉在生态大会上交出了新的答卷。叶军称，钉钉已有17条产品线、55个场景全面接入大模型，实现智能化改造。\n百度的办公软件如流则可以针对群聊信息多的办公痛点，“一秒划重点”，差旅助手不仅能订机票酒店，甚至还能通过接入CRM等公司系统，总结出拜访客户的背景资料和谈话参考。最新发布的商业办公工具GBI可以通过自然语言进行交流使用，主要针对商业办公场景，例如快速进行工程报价计算、完成商业竞价方案等。\n经历了10月份的密集更新后，国内大模型产品也在积极探索商业化，或将告别免费时代。\n11月1日，百度正式上线文心一言专业版，定价59.9元/月，连续包月优惠价为49.9元/月，同时还推出文心一言和文心一格的联合会员，价格为99元/月。这也成为国内首个采用会员模式面向C端收费的大模型产品。\n此前，钉钉也公布大模型落地应用场景的商业化方案，在专业版年费9800元基础上，增加1"
  },
  {
    "title": "OpenAI全新生态战略：ChatGPT打造操作系统，能否撼动科技巨头地位？-百家号",
    "page_body": "2025年10月6日，OpenAI在旧金山举办了第三届年度DevDay大会，震撼科技界的重磅消息接踵而至。数据显示，ChatGPT每周活跃用户已突破8亿，API平台上的峰值吞吐量达每分钟60亿tokens——这样的数据不禁让人思考：围绕通往未来的赛道，OpenAI究竟隐藏着怎么样的大局？更是有一个意味深长的概念摆在台面，“ChatGPT不是聊天工具，而是未来的操作系统”。它是否真的能撼动苹果、谷歌、微软早已扎根的生态体系？这是一个悬念。今天，我们将通过多维视角剖析这一问题，与背后的技术逻辑和可能的社会连锁影响。\n如果说智能手机定义了过去十年生态竞争，那么AI平台则将是科技巨头必争的下一片红海。苹果、谷歌、Meta、微软，无不是在竭力打造“自家围城”。然而这次大会，OpenAI宣布了一项激进的新策略——推出“Apps in ChatGPT”框架，让开发者能够将第三方服务嵌入ChatGPT平台，实现搜索、设计、交易等功能的一站式完成。这是一个非常“挑衅”的举动，它试图绕过传统的移动操作系统，将用户直接锁定在ChatGPT环境中。换句话说，OpenAI不仅要和安卓、苹果正面对决，还要从这些科技巨头的蛋糕里分一大块。这种彻底的生态冲锋是否能成功？还是只是表面风光，其实破绽重重？答案仍待揭晓。\n我们不妨冷静分析“Apps in ChatGPT”框架的核心价值以及它可能面对的挑战。按照Sam Altman的设想，这个框架将彻底改变用户的交互逻辑。简单讲，现在的方式是用户打开聊天页面与GPT对话，但要完成购物、学习或者编辑图片，仍需跳到App或者网页里操作。这种割裂体验不仅麻烦，还增加了用户流失的可能。而“Apps in ChatGPT”框架提出的可能性更像是想开启一个“随心所欲的体验”：无论是设计图像、订机票还是学习课程，一切都能通过ChatGPT内置的工具完成，界面完全无缝。如果真的能做到这一点，ChatGPT就不仅是一个AI助手，更是变成了一个庞大的生态流量枢纽。\n不过理想归理想，现实中科技巨头的反击早已开始。一个典型例子是苹果和谷歌的生态捆绑策略，它们不仅构建自己的AI生态，还深深绑定硬件和操作系统。苹果的iOS更新中已经涵盖了许多AI功能，而谷歌更是直接在搜索引擎中整合了AI。对比之下，OpenAI在硬件端的薄弱显然是个短板。再者，目前的技术瓶颈也值得关注，聊天界面可能并不适合连续调用多个复杂服务，这无疑对用户体验打了折扣。\n普通人的反应也耐人寻味。一些职场人士在社交媒体上感叹，“终于可以不用跳多个App来订票或编辑图表了，这太方便了。”但也有人提出疑问，“越是绑定，一旦出问题，所有服务都会陷入瘫痪，这真的安全吗？”这种双刃剑的讨论在社会层面越发显现。\n在OpenAI给出“Apps in ChatGPT”框架的也同时宣布了其新的开发者工具套件AgentKit。这个工具集包含了Agent Builder、Connector Registry以及ChatKit，号称能够降低智能体开发门槛，让企业和开发者通过拖拽、预设，就能够快速搭建自动化代理流程。听上去，这像是一次开发者的集体狂欢。事情并没有那么简单。\n目前对AgentKit的实际表现褒贬不一。现场演示中，员工几分钟内就完成了一个销售助理智能体的搭建，但从许多开发者的反映来大多数企业对这种工具的信任度仍存在质疑。他们认为，虽然可视化的界面看似易用，但在面对复杂业务流程或者多模块逻辑时，这套工具可能会显得力不从心。从普通用户角度来智能体过度即时化是否会带来隐私甚至数据泄漏的隐患？这种担忧已经开始浮现。\n竞争对手的布局也在加码。微软推出了更贴近企业需求的Copilot助理，并通过Azure平台将其深植于企业系统。这就好比一次“冷战式”竞赛，谁能更快速进入企业领域，谁就能抢占长期用户市场。而目前行事激进的OpenAI似乎还未解决好它的技术稳定性问题——有开发者直接指出，现阶段的AgentKit在性能调优上明显滞后于微软的方案。\n从这个角度虽然表面上OpenAI正在架构一条通往未来的桥梁，但隐患却像暗流涌动，随时可能冲击它的战略布局。\n就在大家对AgentKit投以质疑目光时，Sam Altman抛下一枚“深水炸弹”——宣布了GPT-5 Pro的面世。这款顶级模型的训练截止日期为2024年9月，定位于高端任务应用场景，其上下文窗口长度达400k，是当前标准模型的数倍。它支持文本与图像输入，并推出了适用于科研、法律分析和复杂智能体的大型任务部署功能。GPT-5 Pro并不是唯一的亮点，与它一同亮相的还有gpt-realtime-mini和Sora2，分别针对实时交互和视频生成两大场景。\n这一系列高价产品发布的背后逻辑是清晰的。OpenAI希望通过技术的迭代直接提升盈利能力，同时展示与竞争对手的差异化。而这一步也让人突然明白之前伏笔的作用——Apps in ChatGPT框架本质上是铺设生态基础，AgentKit是建立入口，而GPT-5 Pro和其他产品则是为未来真正强势的商业模式做准备。这一惊天反转也引出新的争议：价格不菲的GPT-5 Pro，是对行业的技术挑战，还是对普通开发者的一次“劝退”？\n从现场讨论来很多开发者对过高的价格提出质疑，他们认为这种定价明显将小型团队排除在外。再加上OpenAI正在推销其生态服务链，这似乎从“开放”走向了过度平台化。这种矛盾将成为未来关注的焦点。\n虽然大会尾声的产品点燃了全场气氛，但表面热闹的背后，关于OpenAI的隐忧开始展现。这其中，一个最明显的问题是围绕“生态独立性”的质疑。既然OpenAI试图用Apps in ChatGPT绑架服务和用户，一旦竞争对手动用法律手段反击，或者推出强有力反制措施，会不会让生态失去延展性？\nGPT-5 Pro和其他相关产品虽然瞄准高端市场，但这也将导致开发者阵营逐步分化——一些企业可能转向更具成本优势、甚至免费开源的选择。至于普通消费者，8亿活跃用户的庞大数据固然令人震撼，但这种建立在庞大流量上的模式是否可持续？用户愿意留在ChatGPT的生态里是因为便利，而不是因为被强迫。\n从各方声音来OpenAI的战略野心逐渐显露出来，但它需要跨过的障碍也越来越高。特别是在全球范围内，对数据隐私和平台垄断的审查正变得越来越严格，这些都可能成为它发展的牵绊。\nOpenAI这次大会，可以说是一个“惊喜与争议交织”的典型场景。从技术发布到生态布局，它展现了对未来的前瞻性，甚至试图重新定义平台间的竞争格局。但不禁要问：这样一个打破常规的尝试，是否真的可以顺利落地？又或者只是一个“贵族化”的生态圈，在普通用户面前背离初心？\n当OpenAI不断强调“让AI对每个人都有用”，它其实也面临一个难题：每个人的需求是多样的，愿意为技术买单的程度也是有限的。或许在追逐生态建设的过程中，如何让技术与人真正融合，才是它更迫切需要回答的问题。\n小编不禁想问：OpenAI高调推出的生态布局，真能撼动苹果和谷歌的根基吗？更重要的是，这种豪赌式的战略，是创新的勇气，还是对开发者和用户的一种绑架？欢迎大家留言，聊聊你的看法~"
  },
  {
    "title": "深入理解HuggingFace扩散模型课程：微调、引导与条件控制技术解析-CSDN博客",
    "page_body": "深入理解HuggingFace扩散模型课程：微调、引导与条件控制技术解析\n【免费下载链接】diffusion-models-class Materials for the Hugging Face Diffusion Models Course  项目地址: https://gitcode.com/gh_mirrors/di/diffusion-models-class \n引言：扩散模型的可控生成革命\n你是否曾遇到过这样的困境：训练一个高质量的扩散模型需要数周时间，但业务需求却要求快速适应新的数据分布？或者拥有一个强大的无条件生成模型，却无法精确控制输出内容？这正是扩散模型微调（Fine-tuning）、引导（Guidance）和条件控制（Conditioning）技术要解决的核心问题。\nHuggingFace扩散模型课程的第二单元深入探讨了这些关键技术，本文将为你系统解析这些方法的原理、实现和应用场景，帮助你在实际项目中灵活运用这些强大的控制技术。\n扩散模型微调：从预训练到领域适配\n微调的核心价值\n微调技术允许我们基于预训练的扩散模型，在相对较少的数据和计算资源下，快速适应新的数据分布。这种方法的核心优势在于：\n时间效率 ：相比从零训练，微调通常只需要原训练时间的1%-10% 数据效率 ：可以在小规模数据集上实现良好的生成效果 质量保持 ：继承预训练模型的生成能力和图像质量\n微调实现原理\n# 微调核心代码示例 def train_finetune():     # 加载预训练模型     image_pipe = DDPMPipeline.from_pretrained(\"google/ddpm-bedroom-256\")     image_pipe.to(device)          # 准备新数据集     dataset = load_dataset(\"huggan/wikiart\", split=\"train\")     preprocess = transforms.Compose([         transforms.Resize((256, 256)),         transforms.RandomHorizontalFlip(),         transforms.ToTensor(),         transforms.Normalize([0.5], [0.5]),     ])          # 训练循环     optimizer = torch.optim.AdamW(image_pipe.unet.parameters(), lr=1e-5)     for batch in dataloader:         clean_images = batch['images'].to(device)         noise = torch.randn(clean_images.shape).to(device)         timesteps = torch.randint(0, 1000, (bs,), device=device)         noisy_images = scheduler.add_noise(clean_images, noise, timesteps)         noise_pred = unet(noisy_images, timesteps)         loss = F.mse_loss(noise_pred, noise)         loss.backward()         optimizer.step() \n微调策略对比表\n策略类型\n适用场景\n训练时间\n数据需求\n效果预期\n全参数微调 领域差异大 中等 中等 最佳\n部分层微调 领域相似 较短 较少 良好\nLoRA微调 资源受限 最短 最少 较好\n引导技术：无训练的控制艺术\n引导的基本概念\n引导（Guidance）是一种在推理过程中控制生成方向的技术，无需重新训练模型。它通过在采样过程中引入额外的损失函数来\"引导\"生成过程朝向期望的方向。\n颜色引导实现\ndef color_guidance_sampling(pipeline, target_color, guidance_scale=100):     # 初始化噪声     x = torch.randn(1, 3, 256, 256).to(device)          for t in tqdm(scheduler.timesteps):         # 模型预测         with torch.no_grad():             noise_pred = pipeline.unet(x, t)[\"sample\"]                  # 计算颜色引导损失         if guidance_scale > 0:             # 需要梯度来计算引导             x = x.detach().requires_grad_(True)             predicted_image = scheduler.step(noise_pred, t, x).prev_sample             current_color = predicted_image.mean(dim=[2, 3])             color_loss = F.mse_loss(current_color, target_color)             grad = torch.autograd.grad(color_loss, x)[0]             x = x - guidance_scale * grad                  # 正常扩散步骤         x = scheduler.step(noise_pred, t, x).prev_sample          return x \nCLIP文本引导\ndef clip_guidance_sampling(pipeline, text_prompt, clip_model, guidance_scale=500):     # 编码文本提示     text_features = clip_model.encode_text(text_prompt)          x = torch.randn(1, 3, 256, 256).to(device)     for t in scheduler.timesteps:         with torch.no_grad():             noise_pred = pipeline.unet(x, t)[\"sample\"]                  if guidance_scale > 0:             x = x.detach().requires_grad_(True)             predicted_image = scheduler.step(noise_pred, t, x).prev_sample                          # 计算CLIP相似度损失             image_features = clip_model.encode_image(predicted_image)             similarity = F.cosine_similarity(image_features, text_features)             loss = -similarity  # 最大化相似度             grad = torch.autograd.grad(loss, x)[0]             x = x - guidance_scale * grad                  x = scheduler.step(noise_pred, t, x).prev_sample          return x \n条件控制：结构化信息注入\n条件控制的三种范式\nHuggingFace课程详细介绍了三种主要的条件控制方法：\n1. 通道级条件控制（Channel-wise Conditioning）\ndef channel_conditioning(unet, condition, image, timestep):     # 将条件信息扩展到图像尺寸     condition_expanded = condition.unsqueeze(2).unsqueeze(3)     condition_expanded = condition_expanded.expand(-1, -1, image.size(2), image.size(3))          # 拼接为额外通道     conditioned_input = torch.cat([image, condition_expanded], dim=1)          return unet(conditioned_input, timestep) \n2. 特征级条件控制（Feature-wise Conditioning）\ndef feature_conditioning(unet, condition, intermediate_features):     # 将条件信息投影到特征维度     condition_projected = linear_projection(condition)     condition_projected = condition_projected.unsqueeze(2).unsqueeze(3)          # 添加到中间特征     for i, feat in enumerate(intermediate_features):         intermediate_features[i] = feat + condition_projected          return intermediate_features \n3. 交叉注意力条件控制（Cross-Attention Conditioning）\nclass CrossAttentionConditioning(nn.Module):     def __init__(self, dim, context_dim):         super().__init__()         self.query = nn.Linear(dim, dim)         self.key = nn.Linear(context_dim, dim)         self.value = nn.Linear(context_dim, dim)              def forward(self, x, context):         Q = self.query(x)         K = self.key(context)         V = self.value(context)                  attn_weights = F.softmax(Q @ K.transpose(-2, -1) / math.sqrt(dim), dim=-1)         output = attn_weights @ V                  return x + output \n条件控制技术对比\n实战应用：从理论到生产\n微调最佳实践\n数据准备策略\n确保新数据与预训练数据有某种相似性 数据增强：随机水平翻转、裁剪、颜色抖动 批量大小与梯度累积的平衡\n超参数调优\n# 推荐超参数配置 training_config = {     'learning_rate': 1e-5,        # 较小的学习率     'batch_size': 16,             # 根据GPU内存调整     'grad_accumulation_steps': 2, # 梯度累积步数     'num_epochs': 1,              # 通常1-2个epoch足够     'image_size': 256,            # 与预训练模型一致 } \n监控与评估\n使用W&B记录训练过程和生成样本 定期保存模型检查点 定量评估：FID、IS等指标\n引导技术应用场景\n应用领域\n引导类型\n技术要点\n预期效果\n艺术创作 颜色引导 目标颜色空间约束 色彩一致性\n广告设计 文本引导 CLIP语义对齐 内容相关性\n产品设计 形状引导 边缘检测约束 结构保持\n性能优化与部署考量\n计算效率优化\ndef optimized_guidance_sampling():     # 使用DDIM加速采样     scheduler = DDIMScheduler.from_pretrained(\"google/ddpm-bedroom-256\")     scheduler.set_timesteps(50)  # 从1000步减少到50步          # 内存优化技巧     with torch.cuda.amp.autocast():  # 混合精度训练         with torch.no_grad():        # 无梯度计算模式             # 采样逻辑... \n部署最佳实践\n模型序列化\n# 保存完整管道 pipeline.save_pretrained(\"my_finetuned_model\")  # 上传到HuggingFace Hub pipeline.push_to_hub(\"username/my-finetuned-model\") \nGradio演示部署\nimport gradio as gr  def generate_image(prompt, guidance_scale):     # 生成逻辑...     return image  demo = gr.Interface(     fn=generate_image,     inputs=[gr.Textbox(), gr.Slider(0, 1000)],     outputs=\"image\" ) demo.launch() \n技术挑战与未来展望\n当前技术局限\n引导稳定性问题\n高引导系数可能导致图像质量下降 需要仔细调整引导强度和采样步数\n计算资源需求\n引导采样需要额外的梯度计算 实时应用中的性能挑战\n多条件融合\n多种引导信号的协调与平衡 条件冲突时的处理策略\n发展趋势\n更高效的引导算法\n基于分类器自由引导（Classifier-Free Guidance）的改进 自适应引导强度调整\n多模态条件控制\n文本、图像、音频的联合条件控制 跨模态注意力机制\n实时应用优化\n模型压缩与量化 硬件加速优化\n结语\nHuggingFace扩散模型课程的微调、引导和条件控制技术为扩散模型的实际应用提供了强大的工具集。通过掌握这些技术，你可以在保持生成质量的同时，实现对扩散模型生成内容的精确控制。\n无论是快速适应新领域的微调技术，还是无需重新训练的引导方法，亦或是结构化信息注入的条件控制策略，都为扩散模型在真实世界中的应用开辟了广阔的可能性。随着技术的不断发展，这些控制方法将变得更加高效和易用，推动扩散模型在更多领域的应用落地。\n记住，关键在于理解每种技术的适用场景和限制，根据具体需求选择合适的技术组合，才能在实际项目中取得最佳效果。\n【免费下载链接】diffusion-models-class Materials for the Hugging Face Diffusion Models Course  项目地址: https://gitcode.com/gh_mirrors/di/diffusion-models-class"
  },
  {
    "title": "AI写作：文学领域的搅局者？新闻-中国作家网",
    "page_body": "关键词： AI写作\n 作为近年来最火的科技突破之一，AI（人工智能）已经渗透生活方方面面。在写作领域，AI能否扮演“搅局者”角色，也越来越成为一个热点话题。\n 今年高考后不久，有人尝试着让AI学习《毛泽东选集》和《鲁迅全集》，没想到它还写出了几篇很不错的高考作文。2015年，新华社就启用了写稿机器人“快笔小新”，3至5秒出稿，迅即引发了记者是否会被AI取代的讨论。\n 依靠技术发展，AI甚至还学会了作诗、写小说等更高要求的文字创作活动，进而使这样的话题变得不再遥远：AI将怎样“侵入”文学领域？假如AI创作的作品有一天喜提诺贝尔文学奖，那是应颁给AI，还是颁给它的设计者？\nAI写诗“获”三星评价\n 将AI应用于文字创作，在科技领域早已不算新鲜事。\n “40多年前的‘748’工程开始，我国便掀起了一场中文信息处理的革命。”山东大学文学院教授盛玉麒介绍，“748”工程即1974年8月国家确立的“汉字信息处理系统工程”研究项目。“从‘748’工程起，中文自动文摘便成了前期比较热门的研究方向之一。自动文摘系统利用计算机技术，通过对文章语法、语义、语境的分析，能够提取出反映文章中心内容的短文，这可以看作是AI运用于文字创作的早期雏形。”\n 至于当今世界，就更不必说了。随着大数据、人工神经网络、深度学习等技术的发展，AI在文本生成方面有了大幅度提升，开始成为真正意义上的创作者。从财经、体育类新闻稿件，到汽车营销类软文，再到诗歌、小说等文学创作，AI写作得到越来越多的数据喂养和技术滋养，变得越来越强大，不断“入侵”文字创作领域。\n 在2021世界人工智能大会上，百度创始人李彦宏重点推介了百度输入法最近升级的“AI助聊”，用户只要输入几个字作为“引子”，AI就会自动联想数据库里的内容并提供接下来意想不到的内容，文字很强大，涉及到的面很广，普通的句子、诗词、RAP等等，能够有效避免用户网络“尬聊”或是文稿思路枯竭。而在此之前，“彩云小梦”已经在B站大火。用户一句话开好头，AI自动续写故事，内容逻辑清晰、情节离奇，以至于大批UP主都以续写故事为题材做了视频，其中有人凭借这些故事，轻松拿下几十万的播放量。\n 那么，“AI”写作实力到底怎么样？记者登录目前颇有影响力的AI中文诗歌自动生成系统——“九歌”尝试了一把。该系统由清华大学团队研发，由多个为中文诗歌生成专门设计的深度学习模型组成，运用超过30万首古人诗作进行训练，支持生成集句诗、绝句、藏头诗、词等不同体裁的诗歌。\n 记者试着以“池塘”和“春雨”为主题词，让这位“AI诗人”作一首五言绝句，系统迅速给出了这样的答案：“春雨暗池塘，垂杨扶短墙。月明山色淡，风静水声凉。”可以说，这首诗结构完整，对仗工整，意境和谐，在创作上并不露怯。\n 被AI创作的诗打动的人，不在少数。微软亚洲研究院研发的AI“小冰”，在2760小时内写了一万多首诗。其中有139首入选了《阳光失了玻璃窗》这本诗集。该书在豆瓣上的评分达到了5.4分，约有36.2%的读者为其打出了三星的评价。\n技术入侵，不可逆转\n 当前，国内AI创作已经开始洋溢商业味道。网络平台将其视作一门生意，AI写作攻城略地的步伐迅速加快，有针对性的AI智能写作付费软件层出不穷。记者看到，有些面向程式化较浓的非虚构类写作，如汽车营销、财经快报等；有些则将开口对准了文学创作，在诗歌、小说等文体的写作上大展身手。还有海量的主题、模板、范文，只要注册会员，按步骤操作，短时间获得图文并茂的官微、公号网文轻而易举，AI还能进一步帮忙进行质量检测、改写翻译。\n 如果这还算“小打小闹”，那么值得注意的是，早在2015年阿里巴巴就推出的“阿里编编”，其拥有庞大的故事资料库和先进的智能创作系统，对外宣称平均一集电视剧剧本只要10分钟，而一个完整的电影剧本也只需30分钟。今年，阿里作为第二大股东的科技公司“海马轻帆”进一步推出“小说转剧本”智能写作功能。此外，多家视频平台、影视公司已开始应用AI评估剧本、检测观众的观影喜好并指导剧本创作。这将导致大批影视剧创作可实现“套路化”批量生产。“就像AI换脸一样，这项技术越成熟，就越省人工、省资金。”一位不愿意透露姓名的业内编剧认为，“技术大规模入侵创作，是无法阻挡的事。”\n 这到底是不是“狼来了”？讨论这个问题，像曾经争论“克隆人”是否可怕、机器人会不会统治地球，乍一说有些吊诡。当记者向作家们抛出这个问题时，得到的答案各有不同。\n 山东省作家协会网络文学创作委员会副主任徐清源认为，“只要有足够的大数据，AI写作一定会战胜人类的文学写作。”他给记者描述自己接触过的AI写作软件：可以一秒钟生产几千万字，自动生成的内容情节紧张丰富，修辞足够，各种转折和包袱设定都非常合理。“它的前景是非常可怕的，是一个‘杀手级’的应用，作家无法在AI面前生存，科学技术的发展会吞噬人类原有的一些传统的东西。”\n 而作家李振声认为，“AI”写作不足为惧。“文学创作是一种以情景体验、形象思维为特征的脑力劳动，要通过人的智慧进行巧妙的艺术构思，来强化感情、宣扬感情。而人工智能就是一种工具，无法取代人们有感情的思维活动。作家创作还要靠生活，靠丰富的想象，而人工智能靠什么？只能靠类推、类比、概括和概率的提升合并等等。从这个角度来说，人工智能永远也写不出比人类更生动更具有智慧的文学作品来。”\n “九歌”系统研制带头人孙茂松在学术会上坦言，当前AI在技术层面上并不完善。基于深度学习的AI技术想要超越人类需具备一系列基本条件，包括须是单一任务，任务边界清楚；信息完备，结果判断量化、明确等，目前深度学习方法在不完全具备上述条件的情况下，AI依靠大数据，有可能比大多数人做得好，但比不过人类的顶尖高手。\n 但万物发展都有个过程，这些反对者们，在AI一日千里的发展势头前也显得有些犹疑：AI在国象、围棋领域不可能战胜人类的结论言犹在耳，但被打脸的进程比想象中来得快得多。“我们的文学写作是可以穷尽的，传统文学写了这么多年，大家再也写不出新意来，到了一个瓶颈期，而AI具有惊人的延伸能力、指数级的发展能力，这就是AI写作能赶上我们的一个转折点。所以，我对AI写作始终保持着敬畏的态度。一旦AI写作的成熟度到了60%至80%，人类的写作就完全被取代了，而且没有翻身的机会。”徐清源似乎更有把握。\n关键在于“可控”\n 且不提AI写作的前景如何，单从眼前看，AI写作呈现出一种欢腾于网络的聒噪，其背后已隐患重重。它涵盖原创力、学术伦理乃至人类的终极思考等多层面，牵涉庞大而复杂的问题，眼下就应引起足够重视。\n 在价值判断方面，机器只有提取数据的特征，对文本创作并没有价值判断，所以在AI生成的故事当中，可以读到讽齐王纳谏的邹忌为了保住权势富贵而出卖小妾、为孩子买橘子的父亲在月台摔倒暴毙……这些离奇的情节不仅与逻辑不符，对正常的价值导向也难以判定。如果训练内容存在问题，或者某些用户输入时刻意引导，AI生成的内容在伦理道德方面的处境会令人担忧。\n 版权方面，在当前技术框架下，AI的训练效果很大程度上取决于语料库，没有足够量的语料库，AI便无法进行学习和创作。那么AI产出的作品该归语料的作者还是归AI的创作者所有呢？如果归语料作者所有，那么又如何为庞大的网络语料资源划定作者呢？如果归创作者所有，又能否将使用了相同技术线路和算法的创作者视为抄袭？这些问题仍然需要法理和伦理上的探讨。\n AI使用者也是一个矛盾的存在——AI为内容创作提供了一种更加轻松、便利的可能性，但在一些别有用心的人眼中，AI成为了助长抄袭的洗稿工具：输入一段语句，AI就会对语言结构进行重组，对关键词加以替换，从而在短时间内复制网络爆文……技术虽为中立，但不良的使用意图让技术成为了帮凶。\n 如何解决这些问题？尚未形成清晰路径。目前，AI距拥有自我意识和思维能力还有一定的距离。倘若有一天，AI和我们谈论起伦理宗教问题，那可能就真的走进了人类地位极度弱化的AI时代。所以，在AI写作领域，我们应保持一个深刻而清醒的认识：当前，就应当及时思考AI写作的“可控”。\n “首先要守住伦理和学术的底线。”盛玉麒认为，从新闻伦理方面讲，新闻最核心的要求是真实。经过AI变脸技术处理过的视频在网上广泛流传，真假难辨，从侧面说明了AI写作技术破坏新闻舆论生态的可能性。从学术规范方面讲，如果AI写作完成的“论文”瞒过了查重系统，满足了查重要求，并顺利通过了专家评审，这学位颁还是不颁，该颁给谁？“所以，从某些层面来讲，AI写作技术要关在笼子里。”\n AI写作对文学创作带来的侵害也需要及时破解。“如今很多网络作家在使用AI写作软件，有时候会主动拿出自己的文本去让AI练习，相当于成千上万的网络作家，在用自己的数据喂养AI写作程序，这就像怪兽突变一样，太可怕了。”徐清源指出，“我们是否可以思考，号召作家们不要轻易地把自己的文本贡献出去？而更关键的，是作家自身要更快地转变思想，以开放的态度去迎接一系列的新变化，主动去拥抱潮流。此外，管理层面也应制定出相应规范，探索AI写作治理与伦理路径，发展负责任的AI写作。”\n 其实，就如所有领域的人机融合一样，未来智能机器与内容创作者的关系，也会如此。接下来最应当做的，是在聚焦技术突破的同时，兼顾可控性的把握，这关乎文学创作，却又远不限于文学创作本身。"
  },
  {
    "title": "探索Intel的权值量化：优化Hugging Face模型的性能-CSDN博客",
    "page_body": "探索Intel的权值量化：优化Hugging Face 模型 的性能\n在 人工智能 领域，模型的大小和计算需求常常成为部署时的主要挑战。Intel的权值量化技术为我们提供了一种解决方案，通过降低模型权值的存储精度，同时维持 计算性能 。本文将探讨如何利用Intel Extension for Transformers库中的权值量化（Weight-Only Quantization）来优化Hugging Face模型，并提供详细的代码示例。\n主要内容\n1. 什么是权值量化？\n权值量化是一种将模型权值精度降低的技术，目的是减少存储和计算资源需求。通过将权值存储为较低精度的 数据类型 （如int4或int8），我们可以显著减少模型大小，而不显著降低其性能。\n2. 使用Intel Extension for Transformers进行权值量化\n使用这个库，我们可以通过 WeightOnlyQuantPipeline 类来加载和运行Hugging Face模型。以下是设置环境和加载模型的步骤：\n环境设置\n首先安装必要的 Python 包：\n%pip  install  transformers --quiet %pip  install  intel-extension-for-transformers \nAI写代码 bash\n1 2\n模型加载\n可以通过以下代码加载模型：\nfrom  intel_extension_for_transformers . transformers  import  WeightOnlyQuantConfig  from  langchain_community . llms . weight_only_quantization  import  WeightOnlyQuantPipeline   # 配置量化参数  conf  =  WeightOnlyQuantConfig ( weight_dtype = \"nf4\" ) # 加载模型  hf  =  WeightOnlyQuantPipeline . from_model_id (      model_id = \"google/flan-t5-large\" ,      task = \"text2text-generation\" ,      quantization_config = conf ,      pipeline_kwargs = { \"max_new_tokens\" : 10 } , )\nAI写代码 python\n运行\n1 2 3 4 5 6 7 8 9 10 11 12 13\n3. 创建和使用推理链\n一旦模型加载到内存中，我们可以将它与提示结合，创建推理链：\nfrom  langchain_core . prompts  import  PromptTemplate  template  = \"\"\"Question: {question}  Answer: Let's think step by step.\"\"\"  prompt  =  PromptTemplate . from_template ( template )   chain  =  prompt  |  hf  question  = \"What is electroencephalography?\" print ( chain . invoke ( { \"question\" :  question } ) )\nAI写代码 python\n运行\n1 2 3 4 5 6 7 8 9 10 11 12\n代码示例：批量推理\n我们也可以在 CPU 上进行批量推理：\nquestions  = [ { \"question\" : \"What is the number 0 in French?\" } , { \"question\" : \"What is the number 1 in French?\" } , { \"question\" : \"What is the number 2 in French?\" } , { \"question\" : \"What is the number 3 in French?\" } ]   answers  =  chain . batch ( questions ) for  answer  in  answers : print ( answer )\nAI写代码 python\n运行\n1 2 3 4 5 6 7 8 9 10\n常见问题和解决方案\n网络访问与 API 代理\n在某些地区访问API可能会受限，建议使用如  http://api.wlai.vip  的代理服务，以提高访问稳定性。\n数据类型支持\nIntel的量化技术提供了多种数据类型支持，包括 int8 、 int4_fullrange 、 nf4 等。选择合适的数据类型可以在存储和计算精度之间取得平衡。\n总结和进一步学习资源\n权值量化是优化机器学习模型的一种有效方法，尤其适用于资源受限的场景。要进一步探索，请参考以下资料：\nHugging Face Model Hub Intel Extension for Transformers Documentation\n参考资料\nIntel Extension for Transformers GitHub Hugging Face Documentation\n如果这篇文章对你有帮助，欢迎点赞并关注我的博客。您的支持是我持续创作的动力！\n—END—"
  },
  {
    "title": "Hugging Face推出史上最小却最强的视觉AI助手",
    "page_body": "这项由Hugging Face和斯坦福大学的Andrés Marafioti、Orr Zohar、Miquel Farré等十多位研究者共同完成的重磅研究，发表于2025年4月7日的arXiv预印本平台。感兴趣的读者可以通过arXiv:2504.05299v1访问完整论文，相关代码和模型已在Hugging Face社区开源发布。\n你有没有想过，一个比手机应用还小的AI，居然能看懂图片、理解视频，甚至回答复杂问题？更让人惊讶的是，这个\"小不点\"的表现竟然比那些需要占用几十GB内存的庞然大物还要出色。Hugging Face的研究团队就创造了这样一个奇迹——他们开发的SmolVLM系列模型，最小的版本只有256MB，运行时占用的显存还不到1GB，但性能却能超越18个月前那些参数量是它300倍的大型模型。\n传统的视觉语言模型就像是一台需要整个车库才能放下的超级计算机，虽然功能强大，但普通人根本无法在家中使用。而SmolVLM就像是把这台超级计算机的核心功能塞进了一台笔记本电脑里，不仅携带方便，性能还丝毫不打折扣。研究团队通过巧妙的架构设计、精明的数据处理策略，以及创新的训练方法，彻底颠覆了\"模型越大越好\"的传统观念。\n更令人兴奋的是，SmolVLM不仅能处理静态图片，还具备出色的视频理解能力。无论是识别图片中的文字、理解图表数据、回答科学问题，还是分析视频内容、理解时间序列，这个\"小家伙\"都能胜任。研究团队甚至开发了一个手机应用，让SmolVLM可以直接在智能手机上运行，真正实现了\"人人都能拥有的AI助手\"。\n一、从大而笨重到小而精巧：SmolVLM的设计智慧\n要理解SmolVLM的革命性意义，我们先来看看传统视觉语言模型面临的困境。过去的研究就像在建造越来越大的图书馆，以为书越多就越聪明，结果建出来的图书馆虽然藏书丰富，但普通人既找不到地方放置，也没有足够的资源来维护运营。\nSmolVLM的设计哲学完全不同，研究团队的策略更像是打造一个精品书店——虽然书的数量不多，但每一本都经过精心挑选，布局合理，读者能够快速找到想要的信息。他们发现，对于小型模型来说，关键不在于拥有多少参数，而在于如何让这些参数发挥最大效用。\n在架构设计上，SmolVLM采用了一种分工合作的策略。整个系统就像一个高效的工厂流水线：首先有一个专门负责\"看图\"的视觉编码器，它就像工厂里的质检员，负责仔细观察输入的图片或视频；然后有一个像素重排模块，相当于包装工，把视觉信息整理成后续处理更容易消化的格式；最后是语言模型部分，就像工厂里的产品说明书撰写员，负责用人类能理解的语言描述所看到的内容。\n研究团队最聪明的地方在于找到了视觉编码器和语言模型之间的最佳配比。他们发现，对于小型模型来说，使用一个相对较小的视觉编码器（93M参数的SigLIP-B/16）搭配适中的语言模型，比使用大型视觉编码器搭配小型语言模型效果更好。这就好比组建一个乐队，与其让一个世界级的钢琴家搭配业余歌手，不如让两个都很优秀但更加协调的音乐家合作，最终的演出效果反而更佳。\n二、巧妙的图像处理：让AI用更少看到更多\nSmolVLM在图像处理方面的创新就像是给AI装上了一副特殊的眼镜，让它能够用更高效的方式\"观看\"世界。传统模型处理图像时，就像用放大镜逐个检查图片的每一个像素点，这种方法虽然细致，但效率极低，很快就会被海量的信息淹没。\n研究团队引入了一种叫做\"像素重排\"的技术，这个过程就像是重新整理一个凌乱的书架。原本散乱分布的像素信息被重新组织，空间分辨率降低了，但信息密度却大大提升。打个比方，这就像把一张大海报压缩成一张精美的明信片，虽然尺寸变小了，但重要信息一点都没有丢失，反而更容易携带和处理。\n更令人惊讶的是，研究团队发现小型模型实际上更适合使用激进的压缩策略。传统模型通常使用2倍压缩，而SmolVLM可以使用4倍压缩而不损失性能。这种现象的原因很有意思：小型模型的\"注意力\"是有限的，与其让它分散精力处理大量细节，不如让它专注于最重要的信息。这就像是让一个学生在有限的时间内学习，与其让他囫囵吞枣地读完整本教科书，不如让他专心掌握核心概念和重点内容。\n对于高分辨率图像，SmolVLM采用了图像分割策略。当遇到一张大图片时，系统会像拼图游戏一样将其分割成若干小块，同时保留一个缩略版本作为全局参考。这样既能捕捉到细节信息，又不会因为信息量过大而\"消化不良\"。这种方法特别适合处理文档、图表这类需要精确识别的内容。\n三、视频理解的智慧：时间就是效率\n在视频处理方面，SmolVLM展现出了与众不同的\"时间智慧\"。许多传统方法试图通过帧平均化来减少计算量，就像把连续的电影画面混合成一幅静态图片。但研究团队发现，这种做法对小型模型来说是适得其反的，反而会损害理解能力。\n相反，SmolVLM选择了一种更加直接的策略：保持每一帧的独立性，但将它们调整到合适的分辨率进行处理。这就像是观看幻灯片演示，每一张幻灯片都清晰可见，观众能够理解前后之间的逻辑关系和时间变化。\n研究团队还发现了一个有趣的现象：适度增加训练时的视频长度不仅能提升视频理解能力，还能改善静态图像的处理效果。他们将平均视频长度从1.5分钟逐步增加到3.5分钟，发现这是一个\"甜蜜点\"——再长的视频带来的收益就会递减。这种现象说明视频和图像的理解能力是相互促进的，多模态学习确实存在协同效应。\n四、训练数据的精心配置：少而精的哲学\nSmolVLM的训练过程体现了\"少而精\"的哲学。研究团队发现，对于小型模型来说，数据质量远比数量重要。他们的发现颠覆了许多传统做法。\n首先，他们发现重复使用大型语言模型的文本数据实际上会损害小型多模态模型的性能。这就像是让一个小学生去学习研究生课程，不仅学不会，还可能被复杂的内容搞得更加困惑。研究团队坚持使用新鲜的、专门为多模态任务设计的文本数据，效果显著提升。\n其次，他们发现思维链（Chain-of-Thought）数据对小型模型来说是一把双刃剑。少量的思维链数据（约0.02-0.05%）能够提升推理能力，但过多反而会\"压垮\"模型的有限容量。这就像是给一个初学者适量的解题思路提示是有帮助的，但如果提供过多复杂的推理步骤，反而会让学习者感到困惑。\n在位置编码方面，研究团队发现了\"OCR丢失困境\"——当使用简单的字符串标记来表示图像分块位置时，小型模型会出现训练停滞现象。他们创新性地引入了学习位置标记，让模型自己学会如何理解空间关系，这种方法显著提升了文字识别和文档理解能力。\n五、三个层次的SmolVLM：各有所长的AI家族\n研究团队贴心地开发了三个不同规模的SmolVLM版本，就像是为不同需求的用户准备了三种不同配置的汽车。\n最小的SmolVLM-256M就像是一辆精巧的小型车，虽然体积最小，但五脏俱全。它只有256M参数，运行时的显存占用不到1GB，完全可以在普通智能手机上流畅运行。别看它小，在许多任务上的表现却能够超越那些大300倍的传统模型，特别适合移动设备和边缘计算场景。\n中等规模的SmolVLM-500M就像是一辆实用的紧凑型轿车，在保持高效率的同时提供了更强的性能。它使用相同的视觉编码器，但搭配了更大的语言模型（360M参数），在图像理解和文字识别方面有显著提升，运行时只需要1.2GB显存，依然非常适合资源受限的环境。\n最大的SmolVLM-2.2B则像是一辆高性能轿车，在保持相对紧凑的同时追求卓越性能。它使用了更强大的视觉编码器（400M参数）和语言模型（1.7B参数），在各种复杂任务上都表现出色，运行时需要4.9GB显存，虽然比前两个版本要求更高，但相比传统大型模型仍然非常高效。\n六、性能测试：小身材的大能耐\nSmolVLM在各种标准测试中的表现堪称惊艳。在文字识别任务中，最小的256M版本在OCRBench测试中获得了52.6%的成绩，而500M版本达到了61.0%，最大的2.2B版本更是达到了72.9%。要知道，许多参数量大得多的传统模型在这项测试中的表现还不如SmolVLM的中等版本。\n在科学图表理解方面，SmolVLM同样表现出色。在AI2D科学图表测试中，2.2B版本获得了70.0%的优异成绩，这意味着它能够理解复杂的科学图表、图形和示意图。在图表问答任务ChartQA中，它获得了68.7%的成绩，展现出强大的数据可视化理解能力。\n更令人印象深刻的是SmolVLM在数学推理方面的表现。在MathVista数学视觉推理测试中，2.2B版本获得了51.5%的成绩，超越了许多大型模型。这说明SmolVLM不仅能\"看懂\"数学图形和公式，还能进行复杂的数学推理。\n在视频理解方面，SmolVLM也毫不逊色。在Video-MME综合视频理解测试中，2.2B版本获得了52.1%的成绩，在时间推理基准TempCompass中达到了53.7%。这些成绩证明了SmolVLM具备出色的视频内容理解和时间推理能力。\n七、效率革命：让AI触手可及\nSmolVLM最大的突破在于其惊人的效率表现。在GPU内存使用方面，SmolVLM-256M单张图片推理只需0.8GB显存，500M版本需要1.2GB，即使是最大的2.2B版本也只需要4.9GB。相比之下，性能相当的MolmoE-A1B-7B模型需要27.7GB显存，差距高达5-35倍。\n这种效率优势在批处理时更加明显。当批处理64张图片时，SmolVLM-256M和500M版本分别只需要15.0GB和16.0GB显存，而2.2B版本需要49.9GB。这意味着即使在处理大量数据时，SmolVLM仍然能在相对普通的硬件上运行。\n在推理速度方面，SmolVLM同样表现优异。在NVIDIA A100 GPU上，256M版本能够达到每秒16.3个样本的处理速度（批大小64），500M版本达到9.9个样本/秒，2.2B版本也有1.7个样本/秒。即使在资源更受限的L4 GPU上，256M版本仍能达到2.7个样本/秒的处理速度。\n八、真正的移动AI：从云端到掌心\nSmolVLM的一个重要突破是实现了真正意义上的移动端AI应用。研究团队开发了名为HuggingSnap的移动应用，让SmolVLM能够直接在智能手机上运行。这个应用就像是把一个专业的AI助手装进了手机里，用户可以随时随地拍照提问，获得即时的智能回答。\n更令人兴奋的是，通过WebGPU技术，SmolVLM甚至可以直接在浏览器中运行。256M版本在14英寸MacBook Pro（M4 Max）上能够达到每秒80个token的解码速度，这意味着用户无需安装任何软件，就能在网页中体验强大的视觉AI功能。\n这种移动化的实现具有重要意义。以往的大型AI模型都需要连接云端服务器才能使用，不仅响应速度慢，还要担心隐私泄露问题。SmolVLM的出现彻底改变了这种状况，让用户能够享受完全本地化的AI服务，既保护了隐私，又获得了更快的响应速度。\n九、实际应用：从科研到生活的全面渗透\nSmolVLM的实用价值已经在多个领域得到验证。在医疗健康领域，基于SmolVLM开发的BioVQA系统能够帮助医护人员快速分析医学影像，回答临床问题。由于其小巧的体积和出色的性能，这样的系统可以部署在资源"
  },
  {
    "title": "什么是多模态 AI？多模态 AI 概念、优势与多场景应用|IBM",
    "page_body": ""
  },
  {
    "title": "Kimi，熹妃回宫_澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "文 | 佘宗明\n在许多“嬛学十级学者”眼中，《甄嬛传》中最高潮的情节莫过于——熹妃回宫。\n历经纯元旧衣事件、父亲流放变故后，甄嬛失去Buff，自请出宫。\n当她去往甘露寺时，很多人都觉得，她的高光时刻，已经过去了。\n毕竟，没有废妃回宫的先例。\n但甄嬛终究是甄嬛。身着素服的她，在山寺里蛰伏蓄势，以待天时。\n结局很多人都知道了，甄嬛二进宫，自己转动了自己命运的齿轮。\n一出生就风华正茂但后来转入沉潜状态的月之暗面，俨然拿到了甄嬛的剧本。\n借助前几天发布的Kimi K2，月之暗面强势归来。海外技术论坛热议，黄仁勋点赞，马斯克评论，都在为月之暗面加冕，让它又成了“AI大模型这条街上最靓的仔”。\n7月底，阶跃星辰、智谱AI等AI创业公司也将发布自研的新一代基础大模型。\n他们都想证明，自己仍在牌桌上。\n而月之暗面、阶跃星辰、智谱AI们在沉寂多时后的回归，无疑为观察后DeepSeek时代的中国AI创业公司走向提供了切片。\n01\n2023年伊始，ChatGPT引发现象级刷屏后，国内科技巨头与AI创业企业争相入场。\n大浪淘沙，“AI六小虎”很快脱颖而出，成了业内瞩目的头部玩家。2023年全年，“AI六小虎”累计融资占到了国产大模型厂商的逾50%。\n细究起来：智谱AI的B端生态、阶跃星辰的多模态终端Agent、MiniMax的MoE混合专家模型……几家明星创企各擅胜场。\n而月之暗面更是在2024年3月因为长文本能力引爆概念股。长文本能力就像九阴真经，帮Kimi一战封神。在一众卷参数规模的大模型中极具辨识度的Kimi，迅速火爆出圈。\n两个月后，腾讯在红杉中国、美团、阿里后的参投，将其估值推至33亿美元，月之暗面一时风头无两。\n剧情到这，相当于《甄嬛传》进度条来到了第8集：在这一集，甄嬛受到“椒房贵宠”。\n如果没有后来的情节，围绕Kimi的叙事还会沿着“一个天才少年带着一家明星创企会当凌绝顶”的脉络延续下去，AI创业公司们会呈现出“张华考上了北京大学，李萍进了中等技术学校……我们都有光明的前途”的走向。\n但现实没那么多“如果”。\n进入2024年下半年，行业进入拐点，大模型厂商迎来了考验期。\n“AI六小虎”中，曾表示底层模型将对标OpenAI的百川智能，自2024年起停止了超大规模通用模型训练，转而深耕医疗领域；号称要做“打造AI 2.0全新平台”的零一万物，2024年底对整个预训练算法团队进行了裁撤，Infra团队被阿里云接收。\n背靠G端资源的智谱与阶跃星辰，越来越多地押注政企市场。Minimax发力多模态，还部分转向海外市场。\n对AGI痴心不改的月之暗面，下半年的技术重心似乎完全转到了“强化学习”，陆续发了数学模型、视觉思考模型，同时采用了激进的产品推广投放策略，避免Kimi在与同样面向C端的的豆包等产品的竞争中落下风。\n更大的变局由DeepSeek开启。今年初DeepSeek R1的横空出世，改变了本已成型的大模型行业格局。凭着“新架构+低成本+开源生态”，DeepSeek成功登顶。\n大模型产品市占率有幂次分布效应，舆论场有频域遮蔽效应。在DeepSeek“国运级成果”的风头下，曾稳居C位的“AI六小虎”，俨然已沦为陪衬。\n多家退出“超大基模争霸赛”，大模型迭代速度放缓，开年后只有一家公布了融资消息……许多人拼凑出一堆“AI六小虎失意”的证据。\n月之暗面就被“亮瑜”对比压着。Kimi1.5推理模型跟DeepSeek R1同日发布，但热度遭全面碾压。事情之后朝着“嬛嬛类卿但非卿”的方向演进：DeepSeek跟Kimi被拉来作对照后，“扬一抑一”的舆论臧否倾向就变成口水落在了二者头顶。\n在那之后，月之暗面开始反思，停止激进的推广投放策略。\n随之而来的，是用户留存遭遇挑战。就连搜索引擎和应用商店里检索Kimi的时候，跳出来的，都是其他几家继续投流的产品。\n回看2025年上半年，国外，OpenAI 的GPT系列、Anthropic的 Claude、谷歌的Gemini和马斯克的xAI Grok你方唱罢我登场；国内，也动静不断。\n可舆论针对“AI六小虎”的讨论基调，却多倾向于“丧”。\n02\n但在“我和我最后的倔强，握紧双手绝对不放”的BGM中，“六小虎”中的部分企业继续登场。\n在今年6月的技术发布周上，MiniMax连续五天甩出覆盖底层模型、多模态技术、通用智能体等领域的五款重磅产品，包括全球首个开源混合架构推理模型 MiniMax - M1，系统展现了“模型—多模态—应用”一体化技术路线。\n7月初，正冲击IPO的智谱AI推出了会看“苏超”的开源视觉理解模型GLM-4.1V-Thinking。\n月之暗面更是憋出大招。Kimi就宛如AI圈的甄嬛，当别人都觉得她已失宠时，她用“一个更强的甄嬛回来了”打了不少人的脸。Kimi K2中的那个2，与其说是序位数，不如说是全方位升级版。\n月之暗面更是憋出大招。Kimi宛如AI圈的甄嬛，当别人都觉得她已失宠时，她用“一个更强的甄嬛回来了”打了不少人的脸。\n在C端用户对高专业门槛的技术革新感知偏弱的情况下，很多人未必清楚Kimi K2在代码、智能体、工具调用等测试中做到开源SOTA（表现最好）是什么概念。\n在大众对AI叙事中“最强”“炸裂”之类的震惊体已免疫的背景下，很多人也未必理解Kimi K2在OpenRouter平台上上线仅两天Token消耗量就超越xAI、登顶全球API调用增长榜，在Cline、Roo Code、Kilo Code等平台的API使用量在全球开源模型中排名最高，意味着什么。\n但黄仁勋受访时说“DeepSeek R1、Qwen、Kimi是全球最好的开源模型”，报道称，Kimi K2在基准测试中超越Claude Opus 4、优于OpenAI的GPT-4.1且成本更低，已说明了很多事情。\n《自然》杂志网站更是将Kimi K2发布称为“世界迎来又一个DeepSeek时刻”，满满的都是“Make Kimi Great Again”既视感。\n接下来，还要几家要出牌。看着Kimi K2在全球科技圈激起的反响，许多人已期待值拉满：你们还有多少是朕不知道的惊喜？\n现在看，几个月前还被困在落寞叙事的六小虎，似乎用行动证明了两点：\n1，AI竞争是马拉松比赛，是Long-term游戏。\n决定企业能走多远的，不是它是否会陷入低谷，而是它陷入低谷后是否能反弹雄起。\n2，产品力是最好的营销，好产品本身会说话。\nKimi K2推出后，独角兽Perplexity CEO阿拉温德在社交媒体表示，基于Kimi K2模型的出色表现，公司将会利用K2进行后训练，上一个被该公司用于技术训练的中国模型，是DeepSeek R1；全球最大开源AI社区Hugging Face联合创始人托马斯表示，不断突破极限挑战闭源的K2模型令人难以置信。\n这些都表明，留给AI创业公司的机会窗口，都远未关闭。\n只不过，你得先“蓄势”——也就是积攒实力。\n03\n有意思的是，7月14日，美国知名AI研究员内森·兰博特写了篇题为《Kimi K2和当DeepSeek时刻成为常态》的文章。\n文中直言，Kimi K2已经能与美国领先的前沿模型竞争，“中国正在不断逼近甚至达到模型性能的绝对前沿，我们正处于‘失败’的节奏中，西方已在开源模型方面进一步落后。”\n硅谷AI企业家和知名电子报Exponential View的作者Azeem Azhar撰文《Kimi K2应该让硅谷感到担心》。\n他表示，“斯普特尼克1号证明了苏联能突破地球引力，打破西方技术主导。四年后，东方1号航天器载着尤里·加加林绕地球飞行一圈，证实斯普特尼克并非偶然事件。在如今的人工智能领域，DeepSeek扮演了斯普特尼克的角色，而现在，人工智能迎来了它的东方1号航天器时刻。”\n话语间隐约透露出一层意思：DeepSeek和Kimi就是这两颗闪耀世界的中国AI双子星，并给美国又了上一课。\n从DeepSeek R1到Kimi K2的起势，不是偶然：不论DeepSeek还是月之暗面，都在持续蓄势，也数次在顶峰相会。\n今年2月份，梁文锋和杨植麟二人差不多同一天发布论文，研究的都是Transformer架构最核心的注意力机制；4月份，月之暗面推出用于形式化定理证明的大模型Kimina-Prover，DeepSeek也紧接着上线了数学定理证明专用模型DeepSeek-Prover-V2力压Kimi，再到7月，Kimina-Prover-7B-Distil继续更新，实现反超。\n某种程度上，从DeepSeek时刻到现在的Kimi时刻，都为中国AI创业公司崛起提供了路径指引：最关键的，还是在原始创新上蓄势。\n《甄嬛传》里，甄嬛回宫前说过一句：“与其心生敬佩，不如自己便是那样的人。”“那样”指的是能掌控自己命运。\n喜欢摇滚乐队平克·弗洛伊德的专辑《The Dark Side of the Moon（月之暗面）》，听过他们唱的“不要坐下，挖到另一个的时间到了……只有驾驭那浪潮的时候，才能在巨浪中取得平衡”的杨植麟，用Kimi K2表明，他在努力成为“那样的人”。\n接下来，更多的AI创业公司掌舵者都需要证明：自己也可以成为“那样的人”。\n中国AI创业公司难免会走向分化、前景各异，但可以肯定的是——Kimi“熹妃回宫”，其他小龙小虎也在继续“秀操作”，这部大戏，精彩还在后头。\n本文为澎湃号作者或机构在澎湃新闻上传并发布，仅代表该作者或机构观点，不代表澎湃新闻的观点或立场，澎湃新闻仅提供信息发布平台。申请澎湃号请用电脑访问http://renzheng.thepaper.cn。\n特朗普称赞泽连斯基穿着“有型”：我很喜欢 大同经济建设投资集团：公司账户被司法冻结致票据逾期千万，已安排向国企拆借等方式筹资\n查看更多\n青海省的一个盐湖，风景优美，被誉为“中国的天空之镜” 清代“扬州八怪”之一，以画竹闻名，自称“胸无成竹”\n开始答题"
  },
  {
    "title": "真的黑客能让你分分钟开进沟里，但他们不屑于此",
    "page_body": "原创 谢幺谢幺 浅黑科技\n0.被指路老头坑死的项羽\n大家好，我是谢幺。\n今天的黑客技术科普，得从两千多年前说起。\n话说公元前202年，垓下，项羽大败，带八百精锐开着疾跑突围，速度之快，跑到后面只有一百多个兵跟上。\n本来妥妥能跑路，忽然遇到一个分岔路口，迷了路，这时路边田里正好有个老头，项羽就问他江东怎么走，老头：“往左。”\n项羽照着走，没走多远马蹄就陷进沼泽地，耽误了时间，被汉军追上。\n内心OS：“我信你个鬼，糟老头几坏得很！”\n后面的事大家都知道了，一代霸王就此下线。\n司马迁把这件事写进了他的书里。\n“项王至阴陵，迷失道，问一田父，田父绐曰‘左’。左，乃陷大泽中。以故汉追及之。\n——《史记·项羽本纪》司马迁\n后来有人说：一定是项羽问路不礼貌，所以田父决定教他做人；也有人说：田父是一位智者，不愿看到继续打仗生灵涂炭，所以故意弄死项羽；还有人说：田父其实是刘邦提前安插的间谍……\n总之，这段历史告诉我们：指路人很重要，可以让你生，也可以让你死，都不知道咋死的。\n台下观众\n：死过矣！可是这跟黑客攻击有啥关系？\n1.田父与DNS系统\n你也许知道，互联网世界里错综复杂，“地名”也就是服务器地址最初都是用IP地址来记录的，比如202.108.22.5，很难记，容易把人搞晕。\n于是技术大佬们就设计了一套“域名系统”，英文名叫DNS（Domain Name System）。\n从此，服务器不仅可以拥有IP地址，还可以给自己挂一个“域名”，方便广大网友寻找。比如上面提到的IP地址：202.108.22.5 其实是www.baidu.com服务器IP。\n哪个更好记一目了然。\n当你在互联网世界唱着小曲飙着车，DNS解析服务器就扮演了“田父”的角色。你在浏览器地址栏里输入：www.hornpub.cn，你的电脑或手机会跑去问“田父”。\n“老头，羊角酒馆（www.hornpub.cn）咋走？”你的设备问。\n田父（DNS解析服务器）掏出一卷长长的表格，“嗯，查到了，是66.254.114.41，小伙子注意安全。”\n“得嘞谢谢，好人一生平安。”你的电脑得了地址，径直前往。于是你就打开了网页。\n即便你感觉不到，但只要你正常上网，每天至少得跟DNS打上几千次交道。\n无数个DNS解析服务器分布在地球的各个角落，它们就像永不停歇的机器，为全世界人民服务。\n每时每刻，假如你能俯瞰世界互联网地图，上面都分布着密密麻麻无数个大大小小的“田父”正在为网民们指路。\n那么问题来了：如果黑客或者坏人盯上田父，会发生什么？\n2.搞定“田父”\n坏人盯上田父，分两种情况。\n其一是一顿暴打，让“田父”丧失指路能力。\n2006年，美国最大的DNS域名解析服务商Dyn就被一个宅男用僵尸网络打瘫，那时，无数人同时抬头看向彼此，他们手里的手机、电脑陷入一片空白。Twitter、spotify、netflix、airbnb、github、reddit、Paypal 等等一系列服务相继瘫痪。攻击共来袭三次，每次持续1小时，史称。\n其二是黑客对着“田父”一顿忽悠，把它“策反”，或者让它出错，给人瞎指路。\n也许你看出来了，第一种情况像是原子弹，虽摧毁一切，但充其量让你上不了网，第二种情况却能神不知鬼不觉地把人带进阴沟里。\n2020年10月，幺哥坐在GeekPwn极棒大赛的观众席，有幸看到一次利用DNS把人带进沟里的技术演示。\n当时台上评委拿着目标手机，打开一个网站，起初这个网站显示蓝底红字：\n然后选手在自己电脑上一顿操作。\n评委再次输入刚才的网址，网页就变成红色——这意味着目标手机被劫持到黑客的钓鱼网站。整个过程只花了几分钟。\n这个攻击的精妙之处在于，选手的电脑并不需要跟目标手机连入同一个网络（专业术语叫Off-path）——这意味着可以像全球巡航导弹一样，黑客躲在地球上的任何一个角落动动手指，都能对千里之外的目标发起这种攻击。\n为了弄懂其中的奥秘，我默默记下选手们的名字，一回到北京，就杀到清华-奇安信网络安全联合研究中心，逮住当时的几个参赛选手一问究竟。\n奇安信公司大厅的小黄猫�� 还挺萌\n3.失传多年的漏洞重出江湖\n技术小哥：“你知道2008年卡明斯基发现的那个震惊全网的DNS重大漏洞吗？我们这次攻击演示相当于重现了当年那个漏洞的攻击场景。”\n我：“卡什么斯基？”\n技术小哥：“卡明斯基！”\n我：“卡明什么基？”\n技术小哥：“卡明斯基！”\n我：“什么明斯基？”\n技术小哥：“……”\n好吧我显然不知道。于是小哥帮我梳理了一下整件事的前后逻辑：\n2008年，一个叫卡明斯基的研究员小哥发现了DNS系统的重大安全缺陷，震惊业界。\n有多震惊？卡明斯基当时给另一位技术大佬保罗·维克西（“域名软件之父”）打电话讲完整个经过，保罗吓得不轻：“你…你…可千万千万别再在电话里重复刚才说过的话了！”他怕电话被人窃听。\n卡明斯基的那次发现被誉为当年最重要的网络安全事件之一。\n丹·卡明斯基\n后来微软公司牵头，和十几个厂商、相关单位闷在会议室里讨论，想出一个缓解机制（具体是什么待会儿讲）。\n十多年过去了，加州大学河滨分校的钱志云教授带着实验室的同学们研究出一套办法，可以绕过当年的那个缓解机制。\n讲到这个必须多说一嘴，网络安全技术领域经常出现类似的事：研究者先找到一个漏洞，报告给厂商，等厂商把漏洞修复，大家都以为不会再有问题时，诶~研究者们又想出个办法攻破这个修复机制。\n但是因为疫情的缘故，钱志云教授和同学们这次不方便回国参加2020年极棒大赛，所以找到他们在国内的小伙伴清华奇安信联队，让他们代劳把攻击方式制成实际可用的攻击程序，到极棒大会的舞台展示。这便出现了第二段中的一幕——载入互联网安全史册的DNS攻击重现江湖。\n为了解释清楚整个过程，我们还是从2008年DNS的第一场雪说起。\n4.黑掉DNS系统的第一步：先了解它\nDNS系统的具体工作流程是这样滴：\n你在电脑（或手机）的浏览器里输入网址，也就是网站域名，比如www.qianhei.net\n你的电脑或手机会跑去问你的 ISP（网络服务提供商，移动联通电信之类）的递归DNS服务器：\n你的机器：“嘿哥们儿，知道www.qianhei.net怎么走吗？”\n递归DNS服务器翻了翻它的小本本，发现没写，回复说：“我不晓得，但我可以帮你问一下根域名服务器。”\n递归DNS服务器：“大哥，请问您知道www.qianhei.net 的IP地址是多少吗？”\n根DNS服务器通常不会直接回答，而是会告诉他该找谁：“我不晓得，但是我晓得.net域名都是顶级域名服务器大娃管的，你去问大娃吧。”\n于是递归DNS服务器又跑去问顶级DNS服务器“大娃”。\n递归DNS服务器：“喂？是大娃吧？www.qianhei.net的IP地址是多少？”\n顶级DNS服务器大娃：“不知道，你去问权威服务器二娃吧，他知道，qianhei.net 这一片归他管。”\n好吧，又去问权威DNS服务“二娃”。\n递归DNS服务器：“喂？二娃吧？请问www.qianhei.net的IP地址是多少？”\nwww.qianhei.net这个域名比较简单，所以到这时二娃已经知道它的IP地址了，假如遇到别的更复杂的域名，比如xieyao.zhenshuai.qianhei.net，二娃还会继续踢皮球给三娃、四娃……\n权威服务器二娃对递归DNS服务器说：“我知道！我知道！www.qianhei.net的IP地址是47.92.24.48……可以把我脖子上的刀可以放下了吗？”\n递归DNS服务器历经九九八十一难，终于拿到IP地址，递归给你的电脑，于是你的电脑就可以高高兴兴地访问浅黑科技的官网啦。\n干完活，递归DNS服务器心想：“这要是每次都这么折腾我一遍，岂不是要我老命？”于是它掏出一张纸，把刚才你问的IP地址和域名的对应关系临时记在上面。\n这张临时用的纸就叫“DNS缓存”，在一定时间内，当有人再问它www.qianhei.net的IP地址，它直接从缓存里找就行，不必再求别人。\nDNS的基础知识铺垫完毕，现在问题就出现这个缓存上。\n从理论上来说，如果黑客如果能想办法让DNS服务器把一条错误的DNS解析记录记录到缓存小本本里，在缓存有效的时间里，就能把人导进沟里。\n5.黑掉DNS的第二步：污染缓存\n到这里，黑客的目标变成了如何把一条恶意的DNS解析信息写进缓存里。\n一台DNS服务器每天可能会发出和接到成千上万条请求，为了不弄混，它们会给每一条请求安排一个询问单号（QueryID），是一个二进制、16位数的数字（本文为了方便表达就用十进制数字表示了）。\n当域名和QueryID、服务器之间通信用的端口号都能对上时，DNS服务器就会欣然接受这一条消息，并写进缓存里，否则会直接舍弃。\n相信你已经发现了，QueryID和服务器端口号在这里就像是个暗号。\n然鹅，DNS服务器在最初设计时也许根本没考虑到网络攻击的问题，QueryID是有规律的，就跟吃饭叫号一样，如果上一单的Query是1001，下一单肯定是1002，再下一单就是1003… …\n每一次操作系统给服务器分配的通信用的临时端口号也同样有规律可循……\n即便有些DNS服务器用了随机化的QueryID，二进制的16位数字，总共也就2^16=165536种可能性。\n黑客一个一个去试就行了，行话叫“爆破”——暴力破解。\n只要能赶在递归DNS服务器收到真正的答复之前，伪装成权威DNS服务器，给递归DNS服务器回复一个错误的答案，并且QueryID、端口号跟域名能对的上号就行。\n有点像警匪电影里的交易现场，有人冒充其中一方提前到场，跟对方对上暗号，把货物劫走。\n具体操作时，黑客会在极短的时间，像加特林机枪一样打过去几万数据包，猜测QueryID，但凡有一个能蒙中，并且能抢在真正的回复到达之前，攻击就成功了。\n此时，递归DNS服务器正在向四娃请求DNS域名解析。\n递归DNS服务器：“hi，四娃，这里是询问单号886，请问www.qianhei.net的IP地址是多少？”\n攻击者赶在四娃之前，抢先向递归DNS服务器发出答复。\n攻击者的服务器：“我是四娃，这里是询问单号856的回答，www.qianhei.net的IP地址是666.666.666.666（假的地址）”\n攻击者的服务器：“我是四娃，这里是询问单号857的回答，www.qianhei.net的IP地址是666.666.666.666。”\n……\n……\n……\n攻击者的服务器：“我是四娃，这里是询问单号885的回答，www.qianhei.net的IP地址是666.666.666.666。”\n攻击者的服务器：“我是四娃，这里是询问单号886的回答，www.qianhei.net的IP地址是666.666.666.666。”\n最后一次终于蒙对了询问单号QueryID——886，于是这条记录会被递归DNS欣然接受，然后写进缓存小本本里。\n而根据先来后到的原则，真·四娃姗姗来迟的消息会被直接舍弃。\n至此，你已经学会了如何黑掉单条DNS解析记录缓存。\n6.黑掉DNS的第三步：接管"
  },
  {
    "title": "环球圆桌对话：欧盟为何在AI领域“亮旗”清华大学",
    "page_body": "编者按： 近日，欧盟委员会发布关于产业和科研领域两份人工智能战略受到国际舆论关注。如何在全球人工智能发展竞争中不被中美拉开差距，已经成为欧盟当前优先考虑的议题。本期“环球圆桌对话”邀请三位学者就相关议题展开讨论。\n崔洪建： 北京外国语大学区域与全球治理高等研究院教授\n肖 茜： 清华大学人工智能国际治理研究院副院长\n董一凡： 北京语言大学国别和区域研究院副研究员\n欧盟AI战略能支撑自主目标？\n欧盟于近期推出分别统领产业和科研两大领域的AI战略，是近年来AI领域国际竞争加剧、成为大国博弈核心要素以及欧洲试图扭转被动局面的产物。\n尽管欧盟早在2018年就启动了“欧洲AI联盟”计划，但此后一段时间欧盟更多将AI技术的兴起及其效应视为科技、经济和社会现象，并首先着眼于在伦理规范和市场监管等方面采取措施及行动。为此欧盟通过了世界首部《人工智能法》并向外推广，试图延伸并放大其在规则制定和输出上的软实力，以此来与在AI技术、基础设施和市场运用领域处于领先地位的中美相竞争。但抢占道德制高点和搞规则输出不仅没能缓解欧盟在AI领域被不断赶超的困境，叠床架屋的过度监管体系还进一步损害了本土的创新环境。在内外因素刺激下，以今年4月出台“人工智能大陆行动计划”、誓言要将欧洲建成世界上首个“人工智能大陆”为标志，欧盟AI战略出现了从依靠“规则致胜”转向兼顾能力建设、从应对AI领域的单一挑战，转向借AI发力驱动系统性创新的重大调整。此次出台的《应用AI战略》和《科学AI战略》，可以被看作是为落实“行动计划”而提出的具体政策框架。欧盟的AI发展战略因此具有了更加强烈的维护技术主权、提升竞争能力、支撑战略自主、参与地缘博弈的色彩。\n在提出一系列政策方案后，欧盟能否如愿以偿地通过AI赶超来为战略自主提供支撑，主要取决于以下因素：\n首先，能否以落实AI战略为抓手，实现涵盖科研、产业、投资和规则等领域的系统性创新。“德拉吉报告”指出欧盟面临创新投入匮乏、分散，无法集中资源支持颠覆式创新；各国市场割裂、缺乏规模效应，难以实现高效的市场转化等基本矛盾，同样制约着AI战略的落实。同时由于目前欧盟企业尤其是体量巨大的中小企业对AI应用的认识不足、投入不够，要想在短期内实现十大领域以“AI优先”的系统性创新绝非易事。当然，更大的障碍来自于近两年将出台规则律令当作权力手段的欧盟机构能否来一场“自我革命”，真正实现从过度监管者向创新驱动者的角色转变。\n其次，能否在强化AI基础设施和能力建设的同时，实现差异化竞争。尽管欧盟对自身在AI基础研究、芯片制造（光刻机）等领域的优势仍有信心，但当前中美在AI算力及存储、基础设施、国家战略、创新投入和人才培养方面的优势，是欧盟焦虑的主要来源。从欧盟战略的出发点来看，要在上述领域加大投入迎头赶上，以此作为维护技术主权和战略自主的根本。但对比中美欧三家的制度特征、发展水平和资源状况，欧盟要在目前处于劣势的所有领域实现对中美的赶超显然很不现实。只有立足于自身优势并明确资源约束的边界，实现“换道超车”式的差异化竞争而不是同质竞争式的“弯道超车”，才有可能帮助欧盟实现真正意义上的创新。从这个角度看，竞争力焦虑似乎让欧盟的AI战略仍处于用力过猛的迷茫状态。\n最后，能否在AI领域实现开放与自主兼顾的战略原则。欧盟加速推进AI战略的背景是中美在AI技术创新、产业发展和国家政策上加快脚步，美国的“不可靠”也迫使欧盟要在AI领域搞自力更生。因此欧盟有意将此次推出的两个战略当作在AI领域与中美竞争的“亮旗行动”，为此欧盟委员会主席冯德莱恩表示“希望人工智能的未来在欧洲制造”。但欧盟的豪言壮志难掩其当前在芯片、算法、能源（电力）等方面高度的对外依赖，现实与理想之间的差距很大。如果将竞争当作AI战略的全部而抛弃更符合科学规律的协同创新路径，欧盟的AI之路会异常艰难。过度强调基于保护的竞争思维，进一步暴露出欧盟在寻求“开放性战略自主”目标时的核心矛盾：如果是迫于外部形势变化的“自主”，显然是长期的内生性动力不足，不是真正的自主；如果是在摆脱不了对外依赖的情况下“开放”，反而会加大不对称的单向依赖，比如在面对美国的时候。\nAI 全球治理，欧盟欲成为“第三极”\n(作者 肖茜)自今年2月法国举办巴黎人工智能行动峰会以来，欧盟在推动AI发展上频频出招。10月8日，欧盟委员会发布关于人工智能的两项战略，以加快欧盟国家在工业与科学领域对AI的应用。\n面对中美在AI领域全球领先态势，欧盟深感焦虑，担心因此失去战略机遇。新出台的战略体现出欧盟的三大用意：一是旨在加强AI在关键行业的使用，推动“人工智能优先”思维方式，涉及医疗保健、制药、能源、交通、制造、建筑、农业食品、国防、通信和文化等领域；二是将AI纳入战略自主议程，减少对美国的技术依赖；三是提高欧盟自身竞争力，尝试以制度+产业+基建为抓手，切入更高维度的竞争格局，并借助欧盟在规则制定上的传统优势，努力向规则输出者和标准竞争者的方向转变。\n不可否认，欧盟在数据治理、隐私保护、市场监管等领域已有成功经验，其“欧洲模式”具有一定示范效应与影响力，很多国家在制定数据隐私法律时都曾参考欧盟《通用数据保护条例》框架。2024年8月开始生效的欧盟《人工智能法》是全球首部针对AI的全面统筹性法规框架，欧盟正在该法案框架下构建AI 标准制定机制，其在国际标准委员会、跨国组织治理机制中的话语权有可能被放大，这些因素确实使得欧盟具备“规则输出者”和“治理极点”的某些潜在能力。\n那么，在全球AI治理和标准治理中，欧盟能否成为中美之外的“第三极”？笔者认为，从欧盟当前的技术基础和现实情况来看，成为“第三极”具有相当大的难度。\n首先，欧洲的AI技术与产业实力相对落后，尤其在核心 AI 技术、基础算法、算力平台、芯片设计、模型训练规模等方面，欧盟整体仍落后于美国和中国。根据斯坦福大学的《人工智能指数报告》，2024 年世界发布的标志性人工智能模型数量，美国以 40 个领先全球，中国以 15 个紧随其后，欧盟仅有 3 个且全部在法国。这种技术实力差距不仅会影响其在标准具体技术细节上的主导权，也可能使得世界其他国家更倾向于认可美、中主导的技术标准。\n其次，在推动创新方面，欧盟仍举步维艰。去年9月，欧盟发布了旨在提升竞争力的“德拉吉报告”，意识到在创新领域与中美有较大差距。冯德莱恩当时称，欧洲必须努力成为AI创新领域的全球领导者。 但一年后，德意志银行在今年9月发布研究报告称，“德拉吉报告”的后续落实情况令人失望。截至9月4日，建议中仅11.2%已得到全面落实。即便将部分推进的内容计算在内，该议程的实施进度也不到三分之一。而在推动AI应用落地方面，根据欧盟统计局的数据，2024年欧盟境内员工数量在10人以上的企业中，仅有13.5%在日常经营中使用AI技术。\n再次，在标准制定方面，欧盟面临内部一致性与成员国协调的难度。欧盟成员国在产业基础、利益诉求、技术路径选择上存在一定分歧，要形成统一对外的 AI 标准主张并在国际谈判中坚定一致，可能会受到成员国利益权衡、妥协所制约。此外，欧洲多家大公司呼吁延缓欧盟《人工智能法》的实施，认为法规过于复杂、不明确，可能打击欧洲 AI 创新力。即使欧盟推出了规则和标准，能否获得其他国家特别是全球南方国家的认可，也是其成为“治理极点”的关键。\n总的来看，欧盟虽然在 AI 治理和标准制定领域具有优势，但想要在AI治理领域成为全球“第三极”，欧盟还须克服技术实力差距、创新动力不足、内部协调困难、标准吸引力有限、执行落地风险等种种挑战。未来，欧盟如果能够在监管路径上更加灵活、提升AI技术实力和创新活力、加强产业支撑和外交协调能力，那么它的确有可能在全球 AI 治理格局中占据重要位置。\n应用端落地，是欧盟AI发展重要一环\n(作者 董一凡)长期以来，欧盟对于人工智能行业持较为谨慎和保守的态度，即把伦理和安全问题摆在经济利益与技术变革的前面，并试图借助基于市场规模的“布鲁塞尔效应”，将本土监管和控制规则作为塑造全球人工智能治理进程的抓手。2024年8月生效的《人工智能法》就是欧盟约束该行业、塑造发展原则的高峰。\n然而，受市场生态不振及过度监管的影响，欧洲AI行业无论是算法、大模型还是应用，均无法与中美所匹敌，甚至在一些全球南方国家纷纷加快AI应用进程背景下，欧盟行动滞后的态势变得更加明显。2024 年欧洲人工智能领域初创企业仅有约80 亿美元融资，占该地区风险投资20%，与欧盟的经济体量和全球科技创新地位远不匹配。\n欧盟在人工智能领域的应用滞后，进一步加剧其在经济、军事等领域的焦虑感和实力担忧，欧洲不少有见地的人士呼吁欧盟及成员国在产业政策、扩大投资，特别是加大人工智能的新兴产业方面采取更多措施。因此，在人工智能技术红利和国家间发展差距持续显现的背景下，欧盟也试图调整“防范风险、制定规则优于技术和产业发展”的立场。今年2月，欧盟委员会执行副主席维尔库宁表示，欧盟已着手简化人工智能监管规则，以便为技术创新松绑，而欧委会主席冯德莱恩同期公布欧盟拟推出人工智能大规模投资计划“Invest AI”，并反复提及“人工智能超级工厂”，即是欧盟展示微妙变化的信号。\n因此，对于欧盟而言，推进自主人工智能技术发展和人工智能赋能是人工智能战略的“一体两翼”，而两者亦是相互促进、相互弥补的关系。从应用端来说，推进人工智能技术的部署和落地受到全球各国普遍关切，今年中国政府工作报告提出“人工智能+”行动即是以创新带应用、以应用促创新的重要政策。10月8日欧盟发布的两项AI战略政策文件中，亦将医药、制造、服务、科研等欧盟优势行业人工智能应用摆在突出位置。在理想状态下，随着人工智能应用场景和产业需求的不断扩张，推进本土技术创新和产业部署的力量也将持续增长，从而形成“人工智能优先”的良性愿景。\n但从现实条件来看，欧盟人工智能战略的应用路径仍将面临不少挑战。\n首先，人工智能各领域应用仍将面临欧盟强伦理和安全约束的挑战，如自动驾驶、医疗诊断、人脸识别等领域应用上，《人工智能法》仍将以“高安全风险”来加以严格限制和监督，加之数据保护、隐私等领域法律约束，企业实际应用技术仍面临不小障碍。\n其次，从人工智能基础发展条件来看，当前欧盟在算力、能源、数据等方面都难以具备规模经济优势。欧盟"
  },
  {
    "title": "AI时代的软件工作流革命：从历史演进到未来探索-吾以观复-博客园",
    "page_body": "关联知识库： # AI时代的软件工作流革命：从历史演进到未来探索\nAI时代的软件工作流革命：从历史演进到未来探索\n思维路线\n软件工作流的演进遵循一个清晰的历史逻辑： 瀑布流（线性顺序）→ 迭代（循环反馈）→ 敏捷（价值驱动） 。这个演进过程体现了软件开发从\"确定性思维\"向\"适应性思维\"的根本转变，每一次演进都是为了解决前一个阶段的根本性缺陷。\n核心洞察 ：AI时代的到来让这个演进过程出现了新的矛盾——敏捷的\"沟通优于文档\"与AI的\"需要精确结构化信息\"形成了根本冲突。这种冲突不仅仅是技术层面的，更是哲学层面的： AI时代需要重新定义软件开发的本质 ，我们需要探索全新的工作流方法，而不是简单地回到过去或者固守现状。\nAI时代的根本挑战 ：如何让AI工具与人类开发者实现真正的协作？如何平衡AI需要的\"确定性\"与敏捷追求的\"适应性\"？这些问题正在推动软件工作流进入一个全新的探索阶段。\n核心内容速查表\n阶段\n核心理念\n关键特征\n主要问题\nAI时代挑战\n瀑布流 线性顺序，一次做好 严格阶段划分，完整文档 需求变更困难，响应慢 ✅ AI兼容性好，文档完整\n迭代 循环验证，逐步完善 MVP验证，快速反馈 缺乏整体规划 ⚠️ 部分AI友好，需要平衡\n敏捷 价值驱动，快速响应 沟通协作，持续交付 文档不足，技术债务 ❌ 文档精确性不足，AI理解困难\n关键结论 ：没有万能方法，AI时代需要瀑布的\"确定性\"与敏捷的\"适应性\"的智慧结合。\n��️ 历史演进：软件工作流的发展脉络\n⏰ 软件工作流演进时间轴\n1970 ────── 2000 ────── 2001 ────── 2020 ────── 2025\n│ │ │ │ │\n│ │ │ │ │\n️\n瀑布流 迭代 敏捷 AI时代 未来探索\n线性顺序 循环验证 价值驱动 新矛盾 混合策略\n文档驱动 MVP验证 快速响应 确定性vs 瀑布+敏捷\n严格阶段 用户反馈 持续交付 适应性 分层开发\n关键时间节点 ：\n1970年 ：温斯顿·罗伊斯引入瀑布模型 2000年 ：迭代开发兴起，解决瀑布的\"一次性\"问题 2001年 ：敏捷宣言发布，软件开发进入新纪元 2020年 ：AI时代到来，暴露敏捷与AI的根本矛盾 2025年 ：混合方法成为主流，探索AI原生工作流\n️ 第一阶段：瀑布流（1970-2000）\n设计哲学 ：建筑制造业的线性顺序思维\n核心流程 ：需求分析 → 系统设计 → 程序设计 → 编码实现 → 测试 → 维护 关键特征 ：严格顺序性、无反馈循环、文档驱动 历史意义 ：建立了软件工程的基础框架，但暴露了\"需求变化\"的根本性缺陷 创始人 ：由计算机科学家 温斯顿·罗伊斯 在1970年引入软件工程领域\n第二阶段：迭代（2000-2001）\n设计哲学 ：循环验证，最小可行性验证\n核心流程 ：MVP版本 → 用户反馈 → 改进迭代 → 新版本 关键特征 ：快速验证、用户参与、持续改进 演进意义 ：解决了瀑布的\"一次性\"问题，但缺乏整体规划\n第三阶段：敏捷（2001-至今）\n设计哲学 ：价值驱动，快速响应变化\n核心流程 ：Sprint规划 → 开发 → 评审 → 回顾 关键特征 ：沟通协作、持续交付、响应变化 革命意义 ：彻底改变了软件开发的思维模式，但AI时代暴露了新矛盾 重要文献 ： 敏捷宣言 和 敏捷宣言原则 定义了敏捷的核心价值观\n历史演进中的核心矛盾与解决\n矛盾1：确定性与适应性的冲突\n瀑布流 ：确定性高，但适应性差 迭代 ：部分确定性，部分适应性 敏捷 ：适应性高，但确定性差\n矛盾2：文档与沟通的权衡\n瀑布流 ：文档完整，但沟通成本高 迭代 ：文档适中，沟通适中 敏捷 ：沟通高效，但文档不足\n矛盾3：质量与速度的平衡\n瀑布流 ：质量优先，但速度慢 迭代 ：质量与速度平衡 敏捷 ：速度优先，但质量风险\nAI时代：软件工作流的新前沿与探索\n核心发现：AI时代暴露的根本性矛盾\n1.  敏捷的\"反AI\"特性\n敏捷价值观 ：\"可工作的软件优于详尽的文档\" AI需求 ：需要精确、结构化的信息才能有效工作 矛盾本质 ：AI时代反而需要更精确的文档，这与敏捷哲学背道而驰\n2.  沟通依赖的AI理解障碍\n敏捷优势 ：通过人际沟通避免冗杂文档 AI限制 ：AI无法理解隐含的上下文和默契 新需求 ：需要显式化隐性知识，这与敏捷的\"简单\"原则冲突\n3.  快速迭代与AI稳定性的根本冲突\n传统敏捷 ：快速响应变化 AI集成 ：AI模型训练和部署需要稳定性 平衡挑战 ：迭代速度与AI稳定性的根本矛盾\nAI时代的\"回归\"现象：瀑布元素的重新价值\n1.  文档完整性的AI价值\n传统瀑布优势 ：每个阶段都有详细文档输出 AI时代价值 ：为AI提供结构化、完整的信息基础 应用场景 ：AI辅助开发、代码生成、测试自动化、系统理解\n2.  确定性流程的AI友好性\n传统瀑布优势 ：明确的阶段划分和交付物 AI时代价值 ：AI可以基于明确规则进行决策和自动化 可预测性 ：AI工具集成更容易规划和实施，降低不确定性\n3.  质量保障的AI风险控制\n传统瀑布优势 ：每个阶段的质量检查 AI时代价值 ：为AI提供高质量的训练数据，降低AI引入的系统性风险 风险控制 ：通过严格的阶段控制，确保AI集成的稳定性\nAI时代的混合策略探索：历史智慧的重新组合\n分层开发模式：各取所长\n1.  架构层：瀑布模式\n目标 ：确保整体设计完整和稳定 实践 ：详细的需求分析、系统设计、技术架构 AI价值 ：为AI提供完整的系统理解基础，支持AI辅助的架构设计\n2.  功能层：敏捷模式\n目标 ：快速响应需求变化 实践 ：Sprint迭代、持续交付、快速反馈 AI价值 ：快速验证AI生成的功能，利用AI加速开发迭代\n3.  AI集成层：瀑布模式\n目标 ：确保AI模型的稳定性和可靠性 实践 ：AI模型设计、训练、验证、部署的严格流程 AI价值 ：降低AI集成的风险，确保AI模型的性能和质量\n文档策略的革命性调整：显性化隐性知识\n1.  知识显性化的必要性\n传统敏捷 ：依赖人际沟通和团队默契 AI时代要求 ：需要结构化、标准化的知识表达 实践策略 ：将\"默契\"转化为\"规范\"，建立知识图谱\n2.  AI友好文档的新标准\n传统文档 ：自然语言描述，依赖人类理解 AI友好文档 ：结构化、标准化格式，支持AI解析和处理 实践策略 ：建立文档模板和标准，支持AI的语义理解\n3.  文档与代码的智能同步\n传统问题 ：文档与代码不同步，维护困难 AI时代解决方案 ：自动化文档生成和更新，AI辅助的文档维护 实践策略 ：集成文档生成工具，建立文档质量检查机制\n️ AI工具链的深度集成\n1.  开发阶段的AI辅助\n代码生成 ：AI辅助的代码编写和重构 智能测试 ：AI驱动的测试用例生成和自动化测试 代码审查 ：AI辅助的代码质量检查和优化建议\n2.  协作阶段的AI增强\n智能沟通 ：AI辅助的团队沟通和知识管理 决策支持 ：AI提供的数据驱动决策建议 风险预测 ：AI预测的项目风险和问题识别\n3.  交付阶段的AI优化\n自动化部署 ：AI驱动的智能部署和回滚 性能监控 ：AI辅助的系统性能分析和优化 用户反馈 ：AI分析的用户行为和使用模式\nAI时代的落地实践探索\n当前探索现状（2024-2025年）\n1.  混合方法的采用趋势\n纯敏捷 ：约45%的团队（面临AI集成挑战） 瀑布+敏捷混合 ：约25%的团队（开始探索AI集成） 纯瀑布 ：约20%的团队（在AI项目中重新受到重视） AI原生方法 ：约10%的团队（正在探索全新的工作流）\n2.  AI时代的新趋势\n混合方法增长 ：预计2025年混合方法将达到35% 文档重要性提升 ：AI工具推动文档标准化和结构化 瀑布元素回归 ：在AI集成项目中重新受到重视 新方法探索 ：AI原生工作流方法的实验和验证\nAI时代成功案例分析\n1.  Google：AI工具深度集成的混合方法\n架构层 ：采用瀑布模式，确保AI基础设施的稳定性 功能层 ：采用敏捷模式，快速迭代AI功能 AI集成 ：建立了完整的AI工具链和文档体系 关键成功因素 ：AI工具与开发流程的深度集成\n2.  Microsoft：分层开发的AI策略\nAI层 ：采用瀑布模式，确保AI模型的稳定性和质量 应用层 ：采用敏捷模式，快速响应市场需求 集成层 ：建立了AI与应用的标准化接口 关键成功因素 ：清晰的分层策略和标准化接口\n3.  Netflix：AI驱动的敏捷实践\n推荐系统 ：采用瀑布模式，确保AI算法的稳定性 内容开发 ：采用敏捷模式，快速响应内容需求 用户体验 ：AI驱动的个性化体验优化 关键成功因素 ：AI与业务需求的深度结合\nAI时代工作流的未来探索方向\n1.  AI原生工作流方法\n核心理念 ：以AI能力为核心设计开发流程 关键特征 ：AI优先、数据驱动、自动化程度高 探索方向 ：如何让AI成为工作流的核心驱动力\n2.  自适应工作流系统\n核心理念 ：根据项目特性和AI集成需求动态调整 关键特征 ：智能选择、实时调整、个性化定制 探索方向 ：如何实现工作流的智能化和自适应\n3.  人机协作的新模式\n核心理念 ：重新定义人类开发者和AI工具的角色分工 关键特征 ：互补协作、技能平衡、持续学习 探索方向 ：如何实现人机协作的最优化\n4.  AI时代的质量保障体系\n核心理念 ：建立适应AI时代特点的质量标准 关键特征 ：AI可解释性、模型稳定性、系统可靠性 探索方向 ：如何确保AI集成的质量和安全性\n结论与行动建议\n核心观点\n历史演进 ：瀑布→迭代→敏捷，每个阶段都有其历史必然性 AI时代新矛盾 ：敏捷的\"沟通优于文档\"与AI的\"需要精确信息\"形成根本冲突 探索方向 ：AI时代需要瀑布的\"确定性\"与敏捷的\"适应性\"的智慧结合 未来重点 ：AI原生工作流方法的探索和验证\n实践建议\n项目评估 ：根据项目特性和AI集成需求选择合适的方法 分层策略 ：架构层和AI层采用瀑布，功能层采用敏捷 文档策略 ：为AI工具提供必要的结构化信息 团队建设 ：平衡AI技能和传统开发技能 持续探索 ：积极参与AI时代工作流方法的探索和实验\n未来展望\nAI时代的软件开发将更加智能化、自动化，但人的创造力和判断力仍然是不可替代的。成功的关键在于找到人机协作的最佳平衡点，让AI成为开发者的得力助手，而不是替代品。\n最终洞察 ：历史演进并没有结束，AI时代正在催生全新的工作流方法。这需要我们重新思考软件开发的本质，探索AI与人类协作的新模式。AI时代的软件工作流探索才刚刚开始，这是一个充满挑战和机遇的前沿领域。\n本文档基于对软件工作流历史演进历程的"
  },
  {
    "title": "2025 AI大模型开发生态白皮书-CSDN博客",
    "page_body": "《2025 AI 大模型开发生态白皮书》系统梳理了全球AI大模型发展全貌与中国本土实践，展现了技术演进、产业应用与生态建设的全景图景。\n关注公众号：【互联互通社区】，回复【AI812】获取全部报告内容。\n全球AI市场正迈向万亿美元规模，生成式AI成为增长主力，中国市场凭借庞大用户基数、丰富应用场景和政策支持，核心产业规模突破9000亿元，增速领先全球。技术层面，从“能力”向“可用性”进化，GPT-5等模型实现智能涌现，多模态、MoE架构、强化学习增强推理和AI Agent成为四大关键突破方向，推动AI从工具向自主智能体演进。\n中美技术路线呈现分化，美国以闭源模式构建API经济霸权，中国则凭借开源浪潮实现生态突围，Qwen、GLM、DeepSeek等开源模型形成全球竞争力。开发技术栈日趋成熟，PyTorch稳居基础框架主导地位，AI Agent框架推动应用创新，分布式训练、PEFT微调技术和推理优化工具，让大模型开发更高效普惠。\n算力基础设施方面，中国算力规模居全球第二，“东数西算”工程重塑资源配置，智算中心建设热潮兴起。国产替代进程加速，华为昇腾、寒武纪等芯片厂商突破技术瓶颈，云厂商通过MaaS平台推动算力与模型服务普及。开源生态进入“四强争霸”格局，Hugging Face与ModelScope形成双雄分发格局，为开发者提供丰富资源。\n应用落地聚焦四大方向：AI Agent实现从工具到“数字员工”的跨越，RAG技术解决模型幻觉问题，垂直AI在金融、医疗、制造等行业创造显著价值，多模态应用全面开花。开发者生态迎来变革，“AI原生”开发者需具备Prompt工程、Agent编排等新技能，政产学研协同构建人才培养体系，负责任AI成为生态建设核心考量。\n整体而言，AI开发已形成以LLM/Agent为核心，开源生态、云原生MLOps、异构算力为支柱的新范式。开发者角色正向“智能系统建筑师”演进，需兼具技术能力、行业洞察与伦理担当，共同推动AI从技术驱动向价值驱动转变，构建繁荣开放的智能未来。\n以下是报告部分内容\n大模型\n关注互联互通社区公众号，回复以下编号，可快速下载相关专题报告合辑。\nAI081：华为AI盘古大模型研究框架\nAI083：阿里达摩院通义大模型概述\nAI084：AIGC专题三：国内大模型概览\nAI087：互联网行业专题报告：AI大模型\nAI088：2023年AI大模型市场研究报告\nAI089：AI大模型需要什么样的数据\nAI091：从阿里、商汤、华为大模型看应用趋势\nAI095：人工智能大模型体验报告\nAI097：AIGC专题四：国内外大模型和AI应用梳理\nAI098：2022中国大模型发展白皮书\nAI099：2023生成式大模型安全与隐私白皮书\nAI101：AI大模型企业是如何炼成的\nAI112：大模型时代的AI十大趋势报告\nAI114：2023商汤大模型伦理原则与实践白皮书\nAI117：AI大模型赋能千行百业\nAI119：AIGC通用大模型产品测评篇\nAI120：人工智能大模型产业创新价值研究报告\nAI121：华为盘古大模型专题报告（精选八篇）\nAI124：中国市场大模型落地进展与趋势洞察\nAI129：知识图谱与大模型融合实践研究报告\nAI134：2023“弈衡”通用大模型评测体系白皮书\nAI135：人工智能大模型体验报告2.0\nAI139：6G内生AI架构及AI大模型\nAI147：2023基于家电大模型的产业应用白皮书\nAI150：2023智能家电与生成式人工智能大模型创新与发展白皮书\nAI153：AI产业人士看大模型发展趋势\nAI155：华为预训练大模型白皮书\nAI156：行业大模型标准体系及能力架构研究报告\nAI158：AI大模型开源生态及大模型平台实践\nAI159：2023AI大模型应用中美比较研究报告\nAI165：大语言模型的前世、今生与未来\nAI166：体系化人工智能与大模型\nAI168：2023人工智能大模型在工业领域知识问答稳定性评测报告\nAI174：2023中国大模型市场商业化进展研究报告\nAI175：中国移动：九天客服大模型技术解读\nAI176：大模型：原理、进展及其影响\nAI179：海外模型应用复盘，国内AI奇点已至\nAI180：中国AI大模型工业应用指数\nAI181：智慧图书馆大模型创新与应用白皮书\nAI182：2023中国智驾大模型应用研究报告\nAI194：人工智能大模型赋能医疗健康产业白皮书\nAI196：2023人工智能大模型体验报告3.0\nAI197：大模型治理蓝皮报告（2023年）——从规则走向实践\nAI199：2023年人工智能大模型保险行业应用评测报告\nAI200：2023金融业大模型应用报告\nAI202：北京市人工智能行业大模型创新应用白皮书（2023年）\nAI203：大模型与AIGC蓝皮书\nAI206：2023大模型安全解决方案白皮书\nAI211：2023大模型合规白皮书\nAI213：大模型在金融行业的落地探索\nAI216：2023年AI大模型应用研究报告\nAI218：2023大模型金融应用实践及发展建议报告\nAI219：政务大模型建设路径及评价体系研究报告\nAI220：2023大模型技术深度赋能保险行业白皮书\nAI221：中文大模型基准测评2023年度报告\nAI222：2023矿山智能化暨矿山大模型最佳实践白皮书\nAI224：工业大模型技术应用与发展报告1.0\nAI225：可信开源人工智能大模型案例汇编（第一期）\nAI226：2023大模型可信赖研究报告\nAI227：人工智能大模型产业创新价值研究报告\nAI228：2023金融大模型技术创新与应用探索\nAI231：2023大模型落地应用案例集\nAI235：前沿大模型的风险、安全与治理报告\nAI236：2024大语言模型能力测评报告\nAI238：产业大模型应用白皮书2023：融入产业、赋能未来\nAI243：生成式人工智能治理与实践白皮书\nAI244：大模型在政务领域应用的实践及前景\nAI249：2023大模型推荐技术及展望报告\nAI250：2023大模型厂商全景报告\nAI251：大模型赋能智慧办公评测报告-PPT生成\nAI257：大模型招投标市场分析报告（2023）\nAI259：中文大模型基准测评2024年2月报告\nAI260：多模态大模型技术演进及研究框架\nAI263：多模态AI研究框架\nAI269：面向生产服务的大模型评估体系探讨\nAI274：家庭大脑白皮书-大模型时代智慧家庭应用新范式\nAI275：AI大模型发展白皮书\nAI276：预训练大模型与医疗：从算法研究到应用\nAI278：2024人工智能大模型工业应用准确性测评\nAI279：2024中国百模大战竞争格局分析报告\nAI280：2024年中国AI大模型产业发展报告\nAI282：2024年工业大模型应用报告\nAI287：大模型现状及发展路径展望\nAI289：大模型在金融领域的应用技术与安全白皮书\nAI290：大模型赋能下的AI 2.0数字人平台\nAI292：2023年第4季度中国大模型季度监测报告\nAI294：2024年中国大模型评测报告（摘要版）\nAI296：大模型时代，智算网络性能评测挑战\nAI297：AI大模型研究框架\nAI302：2024大型语言模型行业图谱研究报告\nAI305：政务大模型产业图谱研究报告\nAI306：2024年第1季度中国大模型季度监测报告\nAI307：工业大模型的五个基本问题\nAI310：2024中国大模型先锋案例TOP30\nAI312：2024北京市人工智能大模型行业应用分析报告\nAI313：superBench大模型综合能力评测报告\nAI314：2024大模型应用实践报告\nAI315：数字医生与健康科普大模型研究报告\nAI317：大模型进展2.0\nAI318：2024行业大模型调研报告\nAI319：2023中国人工智能大模型企业综合竞争力50强研究报告\nAI323：Al大模型成果不断涌现，AGI或将到来\nAI325：互联网行业专题报告：AI大模型\nAI326：教育专用大模型研究报告（简版）\nAI328：2024大模型训练数据白皮书\nAI334：MaaS框架与应用研究报告（2024年）\nAI336：2024军事大模型评估体系白皮书v1.0\nAI341：大模型行业应用十大典范案例集\nAI346：大模型带来智能客服体验的跃迁\nAI347：弈衡人工智能大模型评测平台白皮书（2024年）\nAI348：2024人工智能开源大模型生态研究\nAI358：2024人工智能大语言模型发展技术研究报告\nAI360：2024年中国大模型行业应用研究\nAI361：从技术路径，纵观国产大模型逆袭之路\nAI363：2024中国大模型+数据分析最佳实践案例TOP10\nAI365：2024国产AI大模型应用报告\nAI366：大模型领航者AIGC 实践案例集锦（第一期）\nAI368：2024大模型十大趋势：走进“机器外脑”时代报告\nAI370：大模型基准测试体系研究报告（2024年）\nAI372：矿山产业集群大模型运营最佳实践白皮书\nAI373：中文大模型基准测评2024年上半年报告\nAI374：中国算力产业高质量发展白皮书（2023）\nAI376：2024大模型典型示范应用案例集\nAI377：安全大模型技术与市场研究报告\nAI378：空间数据智能大模型研究\nAI386：AI大模型应用助力企业“营销服”跃进与提效\nAI387：2024水业大模型白皮书\nAI389：2024大模型安全实践白皮书\nAI390：2024年中国AI大模型场景探索及产业应用调研报告\nAI392：大模型激发新质生产力\nAI395：2024中国联通元景大模型AI终端合作白皮书V1.0\nAI396：大模型在融合通信中的应用实践报告\nAI398：2024大模型+知识库厂商全景报告\nAI405：腾讯乐享+大模型-企业智能知识管理跨越式升级\nAI419：大模型落地路线图研究报告（2024年）\nAI420：2024年AI大模型推动新一代具身智能机器人产业发展蓝皮书\nAI424：2024年中国政务行业大模型发展洞察\nAI425：大模型行业可信应用框架研究报告\nAI426：2024年AI大模型应用发展研究报告\nAI427：2024营销大模型评测白皮书\nAI429：AI商业观察：大模型，不止价格战\nAI431：2024年中国金融大模型产业发展洞察报告\nAI438：2024年中国工业大模型行业发展研究报告\nAI444：2024年人工智能大模型技术财务应用蓝皮书\nAI445：“弈衡”多模态大模型评测体系白皮书（2024年）\nAI449：一城一云一模型发展研究报告（2024）\nAI450：2024年大模型驱动的数字员工3.0建设应用白皮书\nAI454：大模型安全研究报告（2024年）\nAI455：自然语言处理：大模型理论与实践\nAI468：百度AI大底座大模型研发基础设施方案\nAI470：大模型深度赋能媒体智创融合\nAI472：2024人工智能中文大模型使用手册\nAI474：2024中国“大模型+智能客服”最佳实践案例TOP10\nAI476：2024大模型发展要素洞察报告\nAI479：大模型发展迈入爆发期，开启AI新纪元\nAI480：AI大模型创业格局报告\nAI481：中文大模型基准测评2024年10月报告\nAI489：2024政务大模型安全治理框架\nAI491：大模型技术深度赋能保险行业白皮书（2024）\nAI495：智普GLM白皮书\nAI496：大模型浪潮下的图计算白皮书（2024年）\nAI503：2024年大模型轻量化技术研究报告\nAI506：提示工程——大模型中的提示词设计\nAI508：2024年大模型落地与前沿趋势研究报告\nAI510：2024年AI大模型赋能智能座舱研究报告\nAI515：2024年AI大模型在医疗领域的商业化路径研究报告\nAI517：LLM时代小模型的应用潜力与挑战\nAI518：2024开源大模型应用指南1.0（风险治理篇）\nAI519：大模型时代的具身智能\nAI521：电商大模型及搜索应用实践\nAI526：人工智能大模型产业发展应用研究白皮书\nAI527：算法与AI大模型的用户认知调研报告\nAI528：2024工商银行人工智能大模型白皮书\nAI530：2024-2025中"
  },
  {
    "title": "AI赋能市场数据深入洞察，精准锁定用户画像（附实操案例）",
    "page_body": "AI赋能市场数据深入洞察，精准锁定用户画像\n在当今数字化的商业环境中，数据已经成为企业最宝贵的资产之一。然而，面对海量的数据，如何有效地提取有价值的信息并将其转化为实际的商业策略，是许多企业面临的挑战。AI技术的发展为企业提供了前所未有的机会，通过智能化的数据分析工具和算法模型，能够更准确地理解消费者行为、偏好及需求，从而实现更加精准的市场营销策略。\n本文将探讨AI如何助力市场数据的深入洞察，并详细讲解如何利用这些洞察来构建详细的用户画像。文章将从多个角度介绍AI在数据分析中的应用，包括但不限于自然语言处理（NLP）、机器学习、深度学习等技术手段，并结合具体的案例展示这些方法的实际操作过程。此外，我们还会分享一些实用技巧，帮助读者更好地掌握AI工具的应用，从而在竞争激烈的市场中脱颖而出。\n市场现状与挑战\n随着互联网技术的飞速发展，信息爆炸时代已经到来，企业和消费者之间的互动方式发生了根本性的变化。一方面，社交媒体、电子商务平台和移动应用程序的普及使得消费者的购买决策过程变得更加复杂且多样化；另一方面，企业需要处理来自各种渠道的大量数据，这不仅包括传统的销售记录、客户反馈，还有社交媒体上的评论、点赞、分享等非结构化数据。\n在这种背景下，企业面临着前所未有的挑战。首先，数据量庞大且分散，如何高效地收集、整理和分析这些数据成为一大难题。其次，消费者的需求日益个性化，单一的产品或服务很难满足所有人的期望，因此企业必须深入了解每个细分市场的具体需求。最后，市场竞争激烈，产品生命周期缩短，企业需要快速响应市场变化，及时调整营销策略以保持竞争力。\n为了解决这些问题，越来越多的企业开始探索AI技术在市场营销中的应用。AI不仅可以帮助企业在短时间内处理海量数据，还能通过智能算法挖掘隐藏在数据背后的潜在价值，提供精准的市场洞察。例如，AI可以通过分析消费者的浏览历史、购物习惯和社会关系网络，预测其未来可能感兴趣的商品和服务，进而制定个性化的推荐方案。同时，借助AI技术，企业还可以实时监控市场动态，捕捉最新的消费趋势，优化广告投放策略，提高投资回报率。\n综上所述，AI技术正在改变市场营销的游戏规则，它为企业提供了强大的工具来应对复杂的市场环境和多变的消费者需求。接下来，我们将详细介绍AI在市场数据分析中的具体应用及其带来的变革。\nAI在市场数据分析中的角色\nAI在市场数据分析中扮演着至关重要的角色，主要通过以下几个方面体现其价值：数据预处理、特征工程、模型训练以及结果解释。首先，在数据预处理阶段，AI可以帮助企业自动化地清洗、整合和标准化各类来源的数据，确保后续分析的质量。这对于处理来自不同渠道、格式各异的数据尤为重要，如电商平台的交易数据、社交媒体的情感数据等。\n接着是特征工程，这是建立有效模型的关键步骤。AI可以自动识别出对目标变量最具影响力的特征，比如用户的年龄、性别、地理位置、购买频率等。通过机器学习算法，AI可以从原始数据中提取出更有意义的特征，从而提高模型的准确性。举例来说，某电商公司希望提升其推荐系统的效率，通过对用户浏览历史进行深度学习分析，AI发现某些特定商品组合的浏览模式与高转化率密切相关，这为后续的个性化推荐提供了有力依据。\n然后是模型训练。AI在此过程中发挥着核心作用，通过监督学习、无监督学习或者强化学习等多种方式，根据历史数据训练出预测模型。例如，一家服装品牌使用AI技术分析过往销售数据，结合季节性因素、流行趋势等因素，预测下一季哪些款式会更受欢迎，从而提前规划生产计划，减少库存积压风险。\n最后是结果解释。尽管AI模型能够提供精确的预测结果，但为了使这些结果真正具有指导意义，还需要对其进行合理的解读。AI在这方面同样表现卓越，通过可视化工具和技术，如热力图、散点图等，将复杂的模型输出转化为易于理解的形式。例如，一家连锁餐厅利用AI分析顾客评价数据后，发现顾客对某道菜的负面评价集中在口味偏淡这一点上，于是他们针对性地调整了菜品配方，显著提升了顾客满意度。\n通过以上几个方面的应用，AI不仅提高了数据分析的效率和精度，还为企业提供了更为科学的决策支持。接下来，我们将进一步探讨几种关键的AI技术及其在市场营销中的具体应用场景。\n关键AI技术及其应用场景\n在市场数据分析中，有几种关键的AI技术尤为突出，它们分别是自然语言处理（NLP）、机器学习（ML）和深度学习（DL）。每种技术都有其独特的优势和适用场景，下面我们将逐一介绍这些技术，并结合具体案例展示它们在市场营销中的应用。\n1. 自然语言处理（NLP）\nNLP是一种让计算机理解和生成人类语言的技术。在市场营销领域，NLP主要用于处理文本数据，如社交媒体评论、在线客服对话记录、电子邮件内容等。通过情感分析，NLP可以帮助企业了解消费者对产品或服务的真实感受。例如，某化妆品品牌利用NLP技术对其社交媒体上的用户评论进行了情感分析，发现了消费者对于某一新款口红的颜色选择存在分歧。基于这一洞察，该品牌迅速调整了营销策略，推出了更多颜色选项，从而赢得了更多的市场份额。\n此外，NLP还可以用于自动摘要和关键词提取，帮助企业快速获取大量文本资料的核心要点。例如，一家媒体公司运用NLP技术自动生成新闻摘要，不仅节省了人力成本，还提高了信息传播的速度和效率。\n2. 机器学习（ML）\nML是一类通过经验数据自我改进的算法。在市场营销中，ML广泛应用于预测分析、客户细分和个性化推荐等方面。以某电商平台为例，该平台通过机器学习算法分析用户的购买历史、浏览行为和点击率等数据，建立了用户兴趣模型。基于此模型，平台可以向每位用户提供个性化的商品推荐，极大地提升了用户的购物体验和转化率。\n另外，ML还可用于市场趋势预测。某快消品公司利用ML技术分析历年销售数据，结合宏观经济指标和天气预报等外部因素，预测未来一段时间内的市场需求波动。这种前瞻性的预测帮助企业合理安排生产和库存管理，降低了运营成本。\n3. 深度学习（DL）\nDL是机器学习的一个子集，特别擅长处理大规模的复杂数据集。在图像识别、语音识别等领域有着广泛应用。在市场营销中，DL常被用来分析视觉内容，如广告图片或视频。例如，某运动品牌通过深度学习技术分析其广告视频中的观众反应，发现了某些特定镜头更能引起观众的兴趣和共鸣。基于这一发现，该品牌优化了广告制作流程，制作出了更具吸引力的宣传材料。\n此外，DL还可以用于增强现实（AR）和虚拟现实（VR）营销。例如，某家居装饰公司利用DL技术开发了一款AR应用程序，允许用户通过手机摄像头查看家具在家中的摆放效果，大大提升了用户的参与感和购买意愿。\n4. 结合实例：某零售企业的成功转型\n为了更直观地展现AI技术在市场营销中的综合应用，我们可以看一个完整的案例——某大型零售企业的数字化转型之路。这家企业最初面临的主要问题是客户忠诚度低、库存周转慢以及线上销售额增长乏力。为此，他们决定采用AI技术进行全面升级。\n首先，该企业引入了NLP技术处理客户服务部门收到的所有客户反馈，从中提炼出常见的投诉点和服务改进建议。接着，他们利用机器学习算法对客户的购买行为进行了深入分析，划分出不同的客户群体，并针对每个群体制定了个性化的促销活动。例如，对于高频次但低客单价的客户，推出小额满减优惠券；对于低频次但高客单价的客户，则提供VIP专属折扣。\n与此同时，该企业还部署了深度学习模型来优化其电商平台的搜索功能。通过分析用户搜索词与最终购买产品的关联度，系统能够更准确地理解用户的意图，从而返回更相关的结果。这一改进显著提高了用户的搜索体验，带动了整体销售额的增长。\n经过一系列的努力，该零售企业不仅实现了线上销售额的翻倍增长，还大幅提升了客户满意度和忠诚度，成功完成了数字化转型。\n通过上述案例可以看出，AI技术在市场营销中的应用潜力巨大，无论是改善客户服务、提升用户体验还是优化业务流程，都能带来显著的效果。接下来，我们将讨论如何利用AI技术构建详细的用户画像，以便更好地服务于企业的营销战略。\n构建详细的用户画像\n构建详细的用户画像是现代市场营销中不可或缺的一环，它可以帮助企业深入了解每一位潜在客户的需求、偏好和行为模式，从而制定更加精准有效的营销策略。以下是构建用户画像的具体步骤：\n1. 数据收集\n构建用户画像的第一步是收集尽可能全面的数据。这些数据来源广泛，既包括企业内部的销售记录、客户服务日志、网站访问记录等，也涵盖外部渠道如社交媒体平台、第三方调研机构提供的数据等。例如，某电商平台通过整合用户的浏览历史、购买记录以及客服沟通记录，获得了关于用户购物习惯的第一手资料；同时，利用API接口接入社交媒体平台，获取用户公开发布的帖子、评论等信息，形成了较为完整的用户画像基础数据库。\n2. 数据清洗与整理\n由于收集到的数据往往包含大量噪声和冗余信息，因此需要进行细致的数据清洗工作。这一步骤主要包括去除重复数据、填补缺失值、纠正错误信息等。例如，在处理用户反馈数据时，可能会遇到同一问题被多次提及的情况，这时就需要去重处理；而当某些字段为空时，则可以根据其他相关信息进行填充。完成数据清洗后，还需按照一定的逻辑结构对数据进行分类整理，便于后续分析使用。\n3. 特征提取与标签定义\n特征提取是指从原始数据中筛选出最有价值的信息作为构建用户画像的基础元素。这通常涉及两个层面的工作：一是确定关键特征，二是给这些特征打上相应的标签。例如，在分析用户浏览历史时，可以提取出用户经常访问的商品类别、停留时间长短、是否加入购物车等特征；而对于这些特征，则可以分别标记为“兴趣偏好”、“活跃度”、“购买意向”等标签。通过这种方式，能够清晰地描绘出用户的兴趣范围和行为倾向。\n4. 用户分群与聚类分析\n在得到一系列特征标签之后，下一步就是对用户进行分群处理。常用的聚类算法包括K均值聚类、层次聚类等。这些算法能够根据用户的不同特征自动将其划分为若干个具有相似属性的小团体。例如，某运动品牌通过对用户购买历史、浏览记录等特征进行聚类分析，识别出了三大主要用户群体：“健身爱好者”、“时尚追求者”和“性价比关注者”。针对不同类型的用户群体制定差异化的营销方案，可以显著提高营销效果。\n5. 验证与迭代优化\n完成初步的用户画像构建后"
  },
  {
    "title": "“O链” 已然形成，英伟达也不过是其中一环-36kr",
    "page_body": "“OpenAI概念股”正在飞涨，然后呢？\nOpenAI的第三届年度开发者大会DevDay 2025如期在旧金山举办，奥特曼在会上公布了几个数字，ChatGPT周活跃用户已达8亿，平台开发者数量突破400万，API流量达到每分钟60亿Tokens。\n在这些耀眼的数字背后，更疯狂的是OpenAI的带动效应，在这场大会背后，不少相关公司的股价陡然上涨。\n2025年10月6日当天，AMD股价开盘后直接跳涨超过30%，最高触及215美元每股，最终收涨23.71%。\n被奥特曼提及与ChatGPT集成的Figma，股价盘中最高涨幅超过16%，最终收涨7.4%。首批采用ChatGPT App的在线学习平台Coursera，股价盘中一度上涨约8.4%。\n营销服务商HubSpot上涨11%，云服务商Salesforce攀升4.2%。在线旅游平台Expedia和TripAdvisor涨幅均超7%。\n玩具制造商美泰的股价也跃升近6%，其和OpenAI就视频模型Sora 2达成了合作。\n开发者大会后相关公司股价大涨只是一次集中展现，OpenAI的影响力早就已经惊艳世人。谁能忘记前不久甲骨文因为和OpenAI签订3000亿美元合约而股价单日暴涨36%、市值增加近千亿美元？这是甲骨文自1992年以来的最大单日涨幅。\n犹记得2023年，OpenAI召开第一届开发者大会，微软的CEO萨提亚·纳德拉站上舞台，和奥特曼肩并肩。\n如今两年过去，做开场致辞的奥特曼已无必要专门请“金主”站台。围绕自身，OpenAI已经悄然建立起“Open链”，链条上的伙伴正在一同被市场热情滋养，“OpenAI概念股”正在形成。\n01\n不管是“Open链”也好，“OpenAI概念股”也罢，这种提法很容易让人想到老牌科技巨头——苹果。\n苹果供应链被称为“果链”，比如生产A系列和M系列芯片的台积电，以及给苹果做镜头的大立光、做OLED的京东方。相关公司的股票又被称为“苹果概念股”，不管哪家公司加入了果链，或者是苹果销售超预期要追加订单，“果链”成员往往会一同受益。\nOpenAI如今也是如此。\n“Open链”已经初见规模，形成明确的分层结构。直接合作伙伴包括AMD、甲骨文等技术供应商。生态集成企业涵盖Figma、HubSpot、Salesforce等应用层公司。间接受益股则包括算力基础设施和云计算服务商。\n而这个链条还在动态成长、拓展，已有的伙伴加码、新的伙伴不断加入。\n英伟达作为“Open链”上最耀眼的存在，还在大举投资OpenAI。9月22日，英伟达宣布将向OpenAI投资最多1000亿美元，并为其数据中心供应数百万块GPU芯片。投资采用分阶段实施方式，随着每1吉瓦数据中心容量的逐步上线而同步投入资金。首批约100亿美元将在最终协议签署后启动，第一个吉瓦的英伟达系统将于2026年下半年在新一代Vera Rubin平台上部署。\n在存储芯片领域，三星电子和SK海力士在10月1日与OpenAI签署战略合作协议，加入总投资5000亿美元的Stargate星门计划，成为“Open链”上的新成员。\n软件应用层则更是随着OpenAI的业务扩张而持续有新鲜血液“上车”。最近OpenAI发布了Apps SDK，可以让开发者直接将自己的服务直接嵌入ChatGPT。用户无需离开聊天界面即可触发、交互、购买。甚至用户可以在ChatGPT中直接要求Spotify创建播放列表，或在Zillow上查找特定社区的房源，整个过程在对话框内完成。\n首批入驻的商家Booking.com、Canva、Coursera、Expedia、Spotify、Zillow，也成为了OpenAI概念股成员。\n这个链条还能进一步外延， 如AMD和OpenAI在10月6日达成6吉瓦算力协议，除了AMD美股大涨23%之外，与AMD合作的企业如AMD CPU/GPU封测核心伙伴通富微电、拥有高端PCB技术的胜宏科技等也纷纷跟涨。\n靠近OpenAI有肉吃，这一点在老牌企业焕发新生机上体现得淋漓尽致。\n要知道，在2024财年，甲骨文的整体财务报表看起来并不亮眼，全年增长为6%，低于华尔街预期。虽然从总体上而言，甲骨文的股价在此番AI浪潮中也早已有过跃升，但真正的爆发还是来自OpenAI。\nAMD的股价波动和甲骨文也呈现了类似的曲线：在AI浪潮中有起有伏，今年以来有平缓上扬的趋势，但是和OpenAI的合作消息一出，股价突然就断层式地跃升——AMD和OpenAI的6吉瓦算力协议曝光当天，股价突破230美元创下历史新高，并且连续三日暴涨43%。\n当然，“Open链”上的成员，其获得的好处绝非作为“OpenAI概念股”在股价上被带动。OpenAI的青睐，还有可能引发“友商”的跟随效应。正如苹果：一旦某家企业成为了苹果供应链上的一环，那么接下来就会有无数对标苹果的设备厂商找到它们。不难想象这种现象在OpenAI身上复现，一旦进入OpenAI供应链，就获得了AI时代的核心生态位。\n一个在新兴热门赛道上的头部玩家形成了“链”和“概念股”本不算稀奇，但是要在其上加入时间的维度，一切都显得格外疯狂。人们经常会忘了，仅仅十年前，世界还没有OpenAI这家公司，仅仅三年前，普通用户还没有见过ChatGPT。\n02\nOpenAI到底有什么魔力，像一块磁铁吸引着资本青睐，甚至在短时间内迅速生长出“链”和“概念股”？\n在充满不确定性的AI投资浪潮中，OpenAI的合作订单代表着可量化、可预期的收入。\n仅今年，OpenAI就有英伟达的1000亿美元投资承诺。OpenAI的融资节奏也可谓健步如飞，截至目前，OpenAI已通过银行贷款和风险投资筹集超500亿美元，最新计划是发行数百亿美元债务，专门用于基础设施。\n在10月2日被传出已经完成的65亿美元二级股票销售中，OpenAI的最新估值已经达到了惊人的5000亿美元。\nOpenAI不断吸引着热钱，而这些钱又将流入“Open链”成员。\n承托这一切（不管是吸引热钱的能力还是“Open链”构建能力）的是OpenAI描绘的愿景。 远有AGI通用人工智能的“伟大使命”，近有正在向Agent进化的ChatGPT、在消费级市场也点了一把火的Sora 2。\n奥特曼从不吝啬描画未来，在采访中直言不讳地说明了OpenAI的战略：“我们的最终目标是构建AGI并使其对人类有益。实现这一目标的主要方式是为用户提供个人AI订阅服务。”在其他一些场合，奥特曼也会谈及未来劳动力变革后的“零人公司”，而他总是给人以这一切马上就要发生的感受。\n眼下，OpenAI也的确不断深化和扩展业务。就拿最新推出的Sora 2来说，不仅模型能力有目共睹，OpenAI还推出了面向C端用户的纯AI短视频应用。推出首周、在邀请制下，Sora应用的下载量突破百万次，已经超越ChatGPT的首周成绩。\n而这背后是恐怖的算力需求。麻省理工的《科技评论》估算，制作一段非高清AI短视频所需算力是制作一张高清静态AI图片的700倍。上个月，开源AI平台Hugging Face的研究人员发现，当AI视频长度增加一倍时，文本转视频生成器的能量需求会增加四倍，这意味着耗能是二次方增长，而不是线性增长。\n这些数据对很多人来说会引发担忧，但是对于OpenAI的上游企业来说则是很大的“确定性”——Sora目前增长势头很猛，它又需要庞大的算力，那么GPU、云计算供应商等相关企业毫无疑问是受益方。\n奥特曼自己也强调，OpenAI如今如此大规模的基础设施投入远超单个公司的能力，“因此OpenAI将与众多公司展开广泛合作，合作范围覆盖从底层的电力、电子供应到上层的模型分发系统等所有环节。”\nOpenAI概念股的上涨表面上是因为与OpenAI的合作关系，但深层逻辑是OpenAI作为AI领域领头羊，其庞大的企业级需求正在重塑整个产业链。\n03\nOpenAI正在玩一场 “需求方控制供应链”的游戏 。\n随着OpenAI的崛起，它已然形成一股强大的向心力，对其上下游产业链（即所谓的“OpenAI链”）产生了巨大的控制力。\n而OpenAI的权力核心，并非来自传统意义上的海量用户，而是源于其无可替代的基础模型技术，以及由此产生的对“算力”这一极度稀缺资源的巨大、集中的需求。它的控制力是一种“技术+资源”的捆绑，通过将自身需求与上游供应深度绑定的方式，重塑了整个产业链的权力格局。\n在算力极度稀缺的时代，谁掌握了最大的需求，谁就能用“订单换股权”的方式，以极低成本控制整个产业链。\n有意思的是，在DevDay现场，当被问到是否要打造“美国版微信”这样的超级应用时，奥特曼明确否认。他说：“我们的目标并不是做超级App，而是要构建一个真正强大的AI超级系统。”这个回答揭示了OpenAI模式的本质——它不想拥有所有东西，但想通过AI能力和订单控制所有东西。\n然而，这个“需求方控制供应链”的模式有一个关键前提：需求本身必须是极其庞大、确定且可持续的。但事实真就如此吗？\n也未必。\n因为OpenAI模式真正的内核，不仅仅是当前的需求，还是未来的愿景，更是其背后雄厚的资本力量。 OpenAI自身尚不具备足够的造血能力，在ChatGPT和Sora的繁荣背后，这依然是一家尚未盈利的公司。而对于一定会让算力需求急剧扩大的Sora应用，OpenAI也并未给出一个可行的商业路径图。正如 奥特曼在博客文章中所说，该公司目前还没有具体的创收计划。他表示，Sora部分收益将“与希望用户生成角色的版权所有者”分享。但这些收益的来源——可能是广告还是用户——目前尚不清楚。\nOpenAI的订单承诺，在确定性稀缺的AI行业已算相对可靠，但这不代表未来承诺一定会兑现，只代表目前市场尚且愿意为它买单。\n在OpenAI近期签下一个又一个大订单、“OpenAI概念股”集体跟涨的月亮背面，是外界对“泡沫”越来越深的恐惧。\n人们发现，英伟达承诺投资给OpenAI1000亿美元，OpenAI又和甲骨文签订了多年3000亿美元的合约，最终甲骨文其实还要从英伟达采购芯片——一个循环，形成闭环。而就在这闭环当中，AI更热了、股价更高了。\n同样地，OpenAI与AMD的合作也是如出一辙的“AI闭环游戏”。OpenAI计划在未来几年部署6吉瓦的AMD GPU算力，而AMD则授予OpenAI最多1.6亿股的认股权证，每股0.01美元，相当于白给。如果OpenAI完全行使这些认股权，它将持有AMD公司约10%的股份，成为其最重要的股东之一。\n问题在于，一旦AI开始失去热度，整个建立在未来预期之上的资本循环就会崩塌。到那时，英伟达和AMD手里的OpenAI股权会缩水，财团的抵押贷款会出现风险，供应商的股价会暴跌。\n而“Open链”上的伙伴们、被“Open概念股”覆盖的公司、二级市场的投资者们，又会受到怎样的冲击？\n只能许愿AI并非泡沫，皆大欢喜。\n本文来自微信公众号 “直面AI” ，作者：苗正 小金牙，36氪经授权发布。"
  },
  {
    "title": "国家定调「人工智能+」：中国AI十年三步走，战略解读来了-腾讯云",
    "page_body": "机器之心报道\n编辑：Sia、杨文\n十年时间，中国将全面AI化。\n中国 AI 进入新的十年，从产业赋能升级至社会重构。\n2025 年 8 月，国务院印发《国务院关于深入实施“ 人工智能 +”行动的意见》（以下简称《行动意见》），为人工智能发展描绘了至 2035 年的战略蓝图。\n从文件定位、发展目标到重点任务，这份「顶层设计」释放出中国 AI 发展的新方向：它不再只是产业升级的工具，而是推动中国现代化的基础设施和新质生产力核心。\n为实现这一目标，文件提出「三步走」——\n到 2027 年，率先实现人工智能与  6 大重点领域 广泛深度融合，新一代 智能终端、智能体 等应用 普及率超 70%  ； 到 2030 年，我国人工智能全面赋能高质量发展，新一代智能终端、智能体等应用 普及率超 90% ， 智能经济 成为我国经济发展的 重要增长极 ，推动技术普惠和成果共享； 到 2035 年，我国全面步入 智能经济 和 智能社会 发展新阶段，为基本实现 社会主义现代化 提供有力支撑。 \n十年后，AI 要像电力、互联网一样全面普及，成为社会的「底层设施」。\n近期目标（ 2027 年）：\n点状突破，六大领域加速落地，\n智能终端与智能体成为关键载体\n未来两年，要率先实现从技术突破到场景落地，重点聚焦 六大领域 ：科技、产业、消费、民生、治理、全球合作。\n作为推动人工智能广泛应用的关键载体，新一代智能终端和智能体普及率需突破  70% 。\n正如天使投资人、资深人工智能专家郭涛在接受《第一财经》采访时所指出的，这些领域的共同特点是数据入口清晰、商业闭环明确、技术扩散效应强，契合「以点带面」的推进逻辑，将成为政策落地的核心抓手。\n在 科学技术领域 （ AI for Science, AI4S ），AI 不再只是辅助工具，而有望成为未来科研的新范式，甚至为哲学社会科学开辟全新研究路径。\n例如，文件首次提出建设科学大模型，推动科研从「0到1」的范式革命；同时，AI 也将改变研发链条，大幅缩短实验室与市场之间的距离。\n在 产业领域 ，既要推动 「三大支柱产业」（工业、农业、服务业）的智能化改造，也要孕育全新的 「智能原生产业」。\n其中，「智能原生企业」是政策亮点：它们以 AI 为底层逻辑构建业务，正如「互联网原生公司」（如美团、滴滴）在移动互联网时代崛起一样，AI 时代将涌现出基于智能体的客服平台、AI 驱动的自动化设计公司等新型企业形态，成为未来政策重点扶持对象。\n尤其在服务业，AI 应用前景最为广阔，智能体与新一代智能终端（AI 手机、AI PC、智能助手）将成为新的服务入口。\n在 消费领域 ，AI 不仅推动生产端效率提升，也将深度重塑服务形态与产品形态，直接面向个人和家庭，提升生活品质与消费体验。\n产品层面：汽车、手机、电脑、机器人、家居、穿戴设备都将以 AI 作为「大脑」，实现万物互联。 服务层面：从数字化便利进化到「认知与情感消费」，未来 AI 不止是「帮你买」，更能陪伴与启发。 \n在 民生领域 ，AI 将真正「走进生活」，从 工作、教育、健康到文化与社交，构建一个更智能的工作方式、更个性化的学习模式、更有温度的社会。政策还鼓励 AI 在文化生产中创造更多具有「中国元素」的作品，强化文化自信。\n在 治理领域 ，AI 将全面提升治理现代化水平。社会治理，从智慧城市到智能政务，实现人机共治。安全治理，构建立体化智能安全体系，强化国家安全。生态治理，借助 AI 推动「美丽中国」建设，支撑绿色转型。\n在 全球合作 领域，中国将倡导 「普惠共享」路线，与「安全限制」模式形成对比，为全球人工智能治理贡献中国方案。\n中期目标（ 2030 年）：\n从点到线，智能经济成为增长极\n到 2030 年，「 AI+」的内涵将从六大领域，进一步扩展到「 智能经济」 方方面面，成为驱动国民经济的 「重要增长极」 。\n届时，新一代智能终端与智能体的应用普及率，也将从 2027 年的 70% 提升至  90%  以上。90%，意味着几乎每个行业、每个组织乃至大部分个人用户都在使用智能终端或智能体，AI 从场景落地走向经济驱动。\n这一趋势并非空想。  Nature  曾报道非营利研究机构 METR 提出的「智能体摩尔定律」：智能体的能力大约每 7 个月翻一倍。按照这个节奏，大约到 2028 年末， AI 就能自动完成很多人类现在要花一个月才能完成的任务。如果 2027 年智能体普及率能够达到七成，那么在技术指数级迭代的推动下，2030 年突破九成或许也是水到渠成。\n值得注意的是，文件同时强调了技术普惠和成果共享，体现出社会公平和价值分配意识。\n远期目标（ 2035 年）：\n从线到面，智能社会、现代化的有力支撑\n到 2035 年，AI 将从智能经济的重要增长极，全面渗透到智能社会，成为中国现代化的有力支撑。\n智能社会，不仅仅是经济层面的变革，更是社会层面的深刻转型。AI 将渗透到人们生活的方方面面，包括公共服务、城市治理、个人生活等，形成一个高效、便捷、可持续的智能生态系统。\n基本实现社会主义现代化，表明 AI 的发展已经成为实现国家长期发展目标的重要支撑。\n模型、数据、算力、开源：\n四位一体，推动 AI 产业加速发展\n最近一段时间，国内 AI 公司不断发布新一代开源大模型，Design Arena 排行榜上 前 15 位的开源 AI 模型全部来自中国。\n在 Hugging Face 发布的中国 AI 社区 7 月开放成果中，包括阿里、智谱、昆仑万维、月之暗面、腾讯、阶跃星辰等在内的多家厂商先后开源了 33 款大模型。\n此前还有机构 Interconnects（深度聚焦前沿 AI 研究的高质量内容平台）汇总了国内顶尖的 19 家开源模型实验室，包括 DeepSeek 这样的顶级机构，以及一些通过技术报告和小众模型崭露头角的新兴学术实验室。\n此次《行动意见》也明确提出要支持人工智能开源社区建设，促进模型、工具、数据集等汇聚开放，培育优质开源项目。对此，政府鼓励高校将开源贡献纳入学生学分认证和教师成果认定，支持企业、高校、科研机构等探索普惠高效的开源应用新模式。\n模型、数据和算力正成为全球 AI 竞争的「三个制高点」，中国通过开源浪潮与政策引导的结合，正在形成科研、产业与应用的合力，推动AI产业进入新一轮加速发展阶段。\n《行动意见》明确提出要全面提升模型、数据和算力的基础支撑能力。\n在模型方面，强调加强人工智能基础理论研究和模型基础架构创新，推动训练与推理效率的提升，探索模型应用新形态，并建立健全模型能力评估体系，确保模型迭代可控可验。\n在数据方面，意见提出建设高质量数据集，完善数据产权与版权制度，推动公共财政资助项目形成的版权内容依法合规开放，探索基于价值贡献度的数据成本补偿与收益分成机制，支持发展 数据标注 、数据合成等技术。\n在算力方面，意见明确支持人工智能芯片创新与超大规模智算集群建设，完善全国一体化算力网，推动「东数西算」等枢纽作用发挥，同时鼓励标准化、可扩展的算力云服务。\n监管与安全：\n中国 AI 治理进入制度化新阶段\n从「模型幻觉、算法歧视」到备案制度，监管也即将全面升级。\n《行动意见》不仅强调要在算法、数据、算力基础设施和应用系统等各个环节构建安全能力，还明确提出要正视和应对当下 AI 发展带来的典型风险（全文提及「安全」共 12 处），例如模型的黑箱问题（不可解释性）、幻觉（生成虚假或不可靠信息）、算法歧视（对群体或个体的偏见）。\n它与国际上强调的「可解释 AI 」和「负责任 AI 」理念高度呼应，体现了中国在人工智能治理中力图兼顾安全与发展的整体思路。\n实际上，今年国家各部门也都密集出台了不少关于人工智能治理方面的政策文件。\n比如 3 月 14 日，国家网信办、工信部、公安部、广电总局四部门联合发布《人工智能生成合成内容标识办法》，将于 2025 年 9 月 1 日开始施行。该办法要求所有AI合成内容都必须依法打「电子水印」。\n具体来说，服务提供者对 AI 生成的文字、图片、音视频、虚拟场景等内容强制添加显式和隐式标识，保障公众知情权与追溯性；传播平台需核验标识并提醒公众；应用上架需审查合规；用户发布须主动声明并标识，严禁篡改或删除标识。\n3 月 21 日，国家网信办、公安部发布《 人脸识别 技术应用安全管理办法》，自 2025 年 6 月 1 日起施行。\n该办法核心在于严格规范人脸识别的使用，要求明确目的、必要性和最小化原则，需取得单独同意并保障未成年人权益；数据应本地存储并限期保存，重要应用须备案；对于 身份验证 ，不得强制以人脸识别作为唯一方式，应提供替代手段；公共场所采集需合理合法，禁止在私密空间布设设备；系统必须采取加密和安全防护措施，违法违规将依法追责。\n结语\n早在 2017 年，国务院就发布了《新一代人工智能发展规划》，成为首个国家级 AI 战略。\n不过此次《关于深入实施“人工智能+”行动的意见》具有更加鲜明的专项聚焦和系统性，首次聚焦 「人工智能+」融合应用，从科技、产业、消费等六大领域进行系统性部署，体现出针对单一前沿技术的专项政策指导。\n而且该意见更注重务实管用，针对人工智能在应用落地中存在的重硬轻软、应用碎片化、开源社区活跃度不高等问题，针对性提出系列举措。坚持分业施策，针对每个领域分别提出与人工智能的融合发展方向，形成各行业「人工智能+」思路主线。\n政策文件链接：\n国务院关于深入实施“人工智能+”行动的意见\nhttps://www.gov.cn/zhengce/content/202508/content_7037861.htm\n国家发展改革委有关负责同志就《关于深入实施“人工智能+”行动的意见》答记者问\nhttps://www.gov.cn/zhengce/202508/content_7037920.htm\n人工智能生成合成内容标识办法\nhttps://www.gov.cn/zhengce/zhengceku/202503/content_7014286.htm\n人脸识别技术应用安全管理办法\nhttps://www.cac.gov.cn/2025-03/21/c_1744174262156096.htm\n新一代人工智能发展规划\nhttps://www.gov.cn/gongbao/content/2017/content_5216427.htm\n参考链接：\nhttps://www.yicai.com/news/102794683.html"
  },
  {
    "title": "使用Hugging Face管道轻松应用NLP预训练模型_磐创AI-商业新知",
    "page_body": "最近，BERT模型在语言处理领域得到了广泛的应用，因为它能够将最先进的性能与计算能力结合起来。 \n 在本文中，我将向你展示如何使用Hugging Face Transformers库，仅用3行代码就可以使用模型！但是首先，让我们看看BERT模型是如何工作的。 \n BERT是什么？ \n BERT代表   Bidirectional Encoder Representations from Transformers   。它是一种新的语言模型，能够在广泛的自然语言处理任务中获得最前沿的结果。 \n BERT的一个主要优点是它是双向的，这意味着该模型可以同时考虑整个单词序列。与从左到右的方法不同，这允许BERT使用所有周围的单词（在左侧和右侧）来上下文化每个单词。 \n 此外，你可以在计算能力有限的机器上使用BERT模型，因为它利用了迁移学习：首先对模型进行一般任务的训练（预训练），然后将获得的知识“转移”到相关的NLP任务（微调）。让我们更详细地看一下这两个步骤。 \n 预训练 \n 首先，该模型是在维基百科这样的大型纯文本语料库上预训练的。预训练应该是通用的，以便在以后的广泛目标中使用该模型。 \n 其次，预训练是在自我监督下进行的，这样输入就不需要标记，这反过来意味着我们有一个几乎无限的训练数据供应。BERT模型的预训练分为两个任务： \n ，这个模型会试图预测 \n 。 \n 和 \n ，这两个句子可以顺理成章地跟在一起。然而，这句话也可能是 \n ， \n ，这就不太可能连续出现。 \n 这些任务的结合使BERT既能理解单词之间的关系，又能理解句子之间的关系。预训练只需要做一次（节省计算能力），并且预训练的模型在网上广泛可用，可以用于一种或多种语言，也可以用于大小写和非大小写文本。 \n 微调 \n 然而，预训练的BERT模型仍然是非常通用的。为了能够将其用于情感分析、命名实体识别、文本摘要、翻译或其他方面，我们需要针对特定用例对模型进行微调。 \n 这最大的优点是，这种微调相对便宜：大部分的权重已经在训练前阶段完成，只需要做一次。 \n 如果你没有一个标记的训练集，已经微调的模型也可以在网上广泛使用，例如在Hugging Face model hub(https://huggingface.co/models).。这是我将在本文中使用的方法。 \n 关于BERT的更多信息，我推荐：https://github.com/google-research/bert \n 或者为更高级的读者推荐原始的研究论文“BERT:Pre training of Deep directional Transformers For Language Understanding”：https://arxiv.org/abs/1810.04805 \n Hugging Face Transformers \n 使用BERT模型最简单的方法之一是使用Hugging Face Transformers：一个基于PyTorch和TensorFlow的最先进的NLP库。 \n 他们的model hub，目前提供了7500多个预训练的各种NLP任务和语言的模型。这样，你几乎总能找到与你的特定目标相对应的模型。 \n 每个模型都可以在你自己的数据集上使用hug Face transformer库提供的简单方法进行微调。然而，更简单的是，这些模型也可以开箱即用，只需极少的编程，就可以使用Hugging Face Transformers提供的管道之一，完成以下11项任务: \n 有关更多信息，请访问：https://github.com/huggingface/transformers \n 使用管道（只有3行代码！） \n 确保你首先安装了Hugging Face Transformers库，例如在终端中运行pip install Transformers。然后，你就可以开始使用Hugging Face，只需3行代码！例如，查看以下情绪分析代码： \n# 加载transformers库并初始化管道\nfrom  transformers  import  pipeline\nclassifier = pipeline( 'sentiment-analysis' )\n# 这是你使用管道所需要的全部内容!\nclassifier( 'Today is a beautiful day!' )\n# >> [{'label': 'POSITIVE', 'score': 0.9998838901519775}]\n 看，那很简单！你所要做的就是导入库，初始化管道，然后就可以开始使用模型了！ \n 如前所述，这些函数使用来自Hugging Face model hub的预训练的模型。默认情况下，情绪分析管道使用distilbert-base-uncased-finetened-sst-2-english模型，但是你可以使用模型中心的任何模型。 \n 让我们看看两个扩展：从模型中心选择不同的模型，以及解决不同的任务。 \n Model Hub的7500多个模型 \n 通过在创建管道时设置模型参数，你可以轻松地使用不同的模型。 \n 例如，假设我们正在做一个项目，想要预测财务情绪。在模型中心进行快速搜索，我们就会看到ProsusAI/finbert模型，它是专门针对金融的情感进行训练的。这个模型的实现和前面的例子一样简单，只需包含模型参数: \n# 我假设你已经像前面的例子一样导入了transformer库\nclassifier = pipeline( 'sentiment-analysis' , model= 'ProsusAI/finbert' )\nclassifier( 'Stocks hit record highs' )\n# >> [{'label': 'positive', 'score': 0.8461698889732361}]\n Hugging Face Transformers将自动为你下载所选的模型！ \n 其他NLP任务 \n 管道目前能够处理11个不同的任务，从命名实体识别到翻译。 \n 创建管道时，可以通过将“sentiment-analysis”更改为其他内容来选择模型。例如，让我们试着翻译“‘I love dogs”从英语到德语。转到模型中心，过滤任务“Translation”和语言“de”，你将看到超过100个模型。我将使用t5-small模型： \nclassifier = pipeline( 'translation_en_to_de' , model= 't5-small' )\nclassifier( 'I love dogs!' )\n# >> [{'translation_text': 'Ich liebe Hunde!'}]\n 就这样！有关管道可以执行的所有任务的完整列表，请查看此wiki页面：https://huggingface.co/transformers/main_classes/pipelines.html#the-pipeline-abstraction \n 结论 \n 在本文中，你已经阅读了BERT模型是如何工作的以及它是如何训练的。此外，你已经看到了使用Hugging Face Transformers管道是多么强大和简单。每个人都可以使用NLP !"
  },
  {
    "title": "Kimi 16B胜GPT-4o！开源视觉推理模型：MoE架构，推理时仅激活2.8B_训练_数据_Hugging",
    "page_body": "一水 发自 凹非寺\n量子位 | 公众号 QbitAI\n刚刚，Kimi团队上新了！\n开源轻量级视觉语言模型 Kimi-VL 及其推理版 Kimi-VL-Thinking ，多模态和推理双双拿捏。\n按照Kimi官方的说法，其关键亮点如下：\n都是基于MoE架构，总参数为16B，  但推理时仅激活2.8B ； \n具备强大的  多模态推理能力 （媲美参数大10倍的模型） 和  Agent能力 ； \n支持  128K 上下文窗口； \n采用相对较为宽松的  MIT许可证 。 \n如图所示，和Qwen2.5-VL、Gemma-3等前沿开源VLM相比，Kimi-VL-Thinking仅使用2.8B激活参数即可实现强大的多模态推理。\n同时在一些重要基准测试中，Kimi新模型“以小博大”，超越了 GPT-4o 等规模更大的模型。\n目前两款模型均已上架Hugging Face，分为Instruct基础版和Thinking推理版。\n网友们纷纷表示，新的标杆再次诞生！\n多模态和推理双双拿捏\n话不多说，我们直接看Kimi新模型的具体玩法和效果。\n视觉理解与推理\n首先，作为一款通用的VLM模型，Kimi-VL具备强大的 视觉理解和推理能力 。\n给它一份手稿，要求它通过逐步推理来确认手稿属于谁，以及所记录的内容。\n可以看到，Kimi-VL通过分析手稿的笔迹、内容、语言等特征，推断出手稿可能属于  爱因斯坦 ，理由是这些内容与引力场方程有关，这与爱因斯坦对广义相对论的贡献有关。 \n除此之外，Kimi-VL也能被用来解答高难度几何数学题。\n还是  仅需一个上传图片的动作 ，它就能将复杂数学公式转换为LaTeX代码，并以正确格式输出。 \nOCR与文本处理\n在OCRBench基准测试中，其得分为867，属于SOTA水平。\n甚至还能从 长达一小时的视频课程中 捕捉和理解关键细节。\n比如提供视频中的某句话“授人以鱼不如授人以渔”，要求它找到出处并进一步解读。\n智能体任务与交互\n值得关注的是，Kimi-VL还在多轮Agent交互任务 （例如OSWorld） 中表现出色，取得了媲美旗舰模型的SOTA结果。\n比如在Chrome浏览器中，要求它自动启用“Do Not Track”功能来保护用户隐私。\n背后技术原理\n那么接下来的问题是，怎么做到的？\n来看Kimi此次公开的技术报告。\n首先，  在模型架构上 ，Kimi-VL和Kimi-VL-Thinking主要由三大部分构成： \nMoE专家混合语言模型 （之前发布的Moonlight-16B-A3B） ；\n原生分辨率视觉编码器 （MoonViT，基于SigLIP-SO-400M微调） ；\n一个多层感知机（MLP）投影器。\n模型具体训练过程如下：\n数据准备\n这第一步，团队构建了三大类别数据集：\n1、预训练数据。 精选来自六个类别的高质量数据，包括字幕数据、图像文本交织数据、OCR数据、知识数据、视频数据和智能体数据。通过过滤、合成和去重等操作，控制数据质量。\n2、指令数据。 用于增强模型的对话和指令遵循能力。对于非推理任务，通过人工标注构建种子数据集，训练种子模型后生成并筛选多轮响应；对于推理任务，利用拒绝采样的方式扩展数据集，确保数据多样性和准确性。\n3、推理数据。 通过类似拒绝采样和提示工程的方法，收集和合成高质量的长思维链数据。\n预训练：主要提升多模态能力\n然后开始预训练，这一阶段共消耗4.4T tokens，主要目标是提高模型的多模态理解能力。\n概括而言，这一过程包含4个步骤：先独立进行ViT训练，以建立原生分辨率视觉编码器；随后进行三个联合训练阶段（预训练、冷却、长上下文激活）。\n后训练：主要提升长思维链推理能力\n接着进行后训练，通过在32K和128K上下文中进行的两个阶段的联合监督微调、长思维链监督微调及强化学习，团队进一步提升了模型的 长期思考能力 。\n更多细节感兴趣可以查阅原论文。\nOne More Thing\n有一说一，相比于DeepSeek、Qwen等国内竞争对手，Kimi最近一个月实在有点过于安静了。\n从官方公众号来看，最新一条发布还是在2月份。\n在这股平静之下，网友们开始猜测：\nKimi即将有大动作了？\n结合更多消息，目前大家比较认可的推测是 K1.6模型 即将到来。\n就在3月，基于Kimi-K1.6的数学模型突然曝光，在编程基准测试LiveCodeBench中拿下第一，超越o3、DeepSeek-R1等模型。\n当然，也欢迎更多知情者在评论区爆料(doge)。\n论文：\nhttps://github.com/MoonshotAI/Kimi-VL/blob/main/Kimi-VL.pdf\n模型开源地址：\nhttps://huggingface.co/collections/moonshotai/kimi-vl-a3b-67f67b6ac91d3b03d382dd85\n参考链接： 返回搜狐，查看更多"
  },
  {
    "title": "全球最大AI开源社区Hugging Face公布了新一期模型榜单-雪球",
    "page_body": "， 阿里 ， 。"
  },
  {
    "title": "华为昇腾AI全栈软件平台首次全解读，重磅AI计算核弹齐发_澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "原创 心缘 智东西\n看点：华为超强AI算力的“软实力”：四大秘密武器全揭秘。\n智东西8月10日报道，在今天的华为HAI 2020大会上，华为发布迄今为止业界最丰富的AI全栈软件平台，覆盖从基础软件到应用使能，同时展示了最强的AI算力平台。\n这是华为首次全方位披露其昇腾全栈AI基础软件能力，异构计算架构CANN、全场景AI计算框架MindSpore、全流程开发工具链MindStudio、昇腾应用使能MindX四大核心软件一并亮相。\n这一次，华为AI的主角从颇负盛名的芯片，换成了释放华为硬件性能的隐藏英雄——软件。\n作为衔接AI技术与行业应用之间的桥梁，昇腾AI全栈软件平台是华为实现普惠AI的重要基座，不仅决定AI开发效率，还关乎AI硬件在实际应用中真正能发挥出的最佳算力。\n华为的昇腾AI全栈软件平台，究竟强在何处？\n通过华为昇腾AI全栈软件平台全景图，我们可以领略到华为在AI布局方面的严密与稳重，同时对华为的AI实力和优势有了更清晰全面的认知。\n基于充分结合的软硬件基础设施，华为昇腾计算产业生态正快速扩容，和更多合作伙伴一同推动AI计算产业的发展。\n在持续升温的AI计算竞赛中，华为已然准备就绪，并率先冲在了推进智能化进程的最前排。\n昇腾计算软件全景图：4大软件产品构筑8大竞争力\n“硬件是AI的基础，软件才是AI的未来。”\n会上，华为昇腾计算业务总裁许映童首次揭晓昇腾AI全栈软件平台全景图，他提到，在AI领域，华为70%的研发人员投入于软件研发，面向不同开发者，推出三层的开发模型。\n在Atlas硬件的基础上，针对专业开发者、入门级开发者及业务开发者的不同开发需求，华为推出三大软件平台CANN、MindSpore、MindX，以及覆盖算子开发、模型开发、应用开发的全流程开发工具链MindStudio。\n其中，异构计算架构CANN是支持全场景AI开发的芯片底层基础软件，也是获取华为昇腾计算资源避不开的入口，它具备软硬件解耦的特征，后向兼容全系列华为芯片。\nMindSpore是全场景AI计算框架，目前已覆盖逾1.6万用户，与33所高校开展AI课程、研究合作，提供20多种主流模型，覆盖150多种应用。下个月，华为将在HC大会上推出MindSpore 1.0版本以及为网络模型挑战赛颁奖。\nMindX是昇腾应用使能平台，通过“2+1+X”助力AI计算融入千行百业，2是深度学习平台MindX DL和智能边缘平台MindX Edge，1是优选模型库ModelZoo，X则是使能各行业的SDK。值得期待的是，面向视觉和制造的两个行业SDK将在2020年10月正式对外上线。\n“AI的应用程序需要跑在多类型通用CPU，数十个版本的操作系统，运行在从穿戴设备，到大规模集群的各种设备，算力和存在差异数百万倍，对软件的适应性和可裁剪、可伸缩性提出了极高的要求。”\n许映童说：“而部署的应用场景包括了港口、道路、沙漠等各种复杂场景，设备的供电、环境适应性、网络可连接性等等均是巨大的挑战。”\n▲华为昇腾计算业务总裁许映童\n这些挑战使得AI融入实际应用的门槛非常高，在此背景下，华为提出以开发者为中心，通过全栈软件，把AI算力释放出来，服务于行业应用和开发。\n基于Atlas硬件与昇腾AI全栈软件平台的组合拳，华为昇腾计算已构筑8大竞争力。\n（1）高性价比：据华为实测，华为AI推理卡Atlas 300I的推理性能、华为最高算力密度服务器Atlas 800的训练性能均超过业界领先竞品。\n（2）统一API：CANN通过昇腾统一编程接口AscendCL API，支持端边云全场景协同。\n（3）开放架构：支持TensorFlow、PyTorch等主流AI框架，并适配客户自研框架。\n（4）使能行业：MindX提供多个行业SDK、优选模型库、深度学习平台及智能边缘平台，其中优选模型库中提供的预训练高性能模型到今年底预计有超过60个，可大大降低AI应用门槛。\n（5）边云协同：中心训练+边云推理，一站式开发，统一模型部署及更新，模型保护/加密。\n（6）最优集群：昇腾集群线性度较业界领先。\n（7）开发工具：面向不同类型开发者，构筑贯穿整个开发流程的工具链MindStudio。\n（8）统一运维：基于FD/SmartKit构筑智能运维。\n异构计算架构CANN 3.0详解：专为AI设计，端边云全场景协同\n市面上的AI芯片层出不穷，那么华为的独到优势有什么？\n回答这个问题，就避不开华为昇腾的一大秘密武器——CANN。\n如今，华为的产品线已覆盖云、管、端、芯，鲜少有公司具备如此庞大而全面的产品矩阵。如果每类芯片各做一套编程语言，那么对开发者而言，要学习的内容会非常繁琐耗时。\n在这一背景下，为AI设计的异构计算架构CANN起到了极为关键的作用。\n华为投入逾千人的研发团队专攻CANN研发，历经三年迭代，形成了端边云协同的统一编程架构CANN 3.0。\n具体而言，CANN 3.0有三大创新特性：端边云全场景协同、AscendCL使能高效开发、释放硬件澎湃算力。\n1、支持软硬件解耦，端边云全场景协同\nCANN 3.0具有极强的伸缩性和可适应性，下接异构芯片，上承AI框架，只需编写一套应用代码，即可兼容覆盖端边云的10+种设备形态、14种操作系统、多种主流AI框架。\n华为海思的麒麟芯片、小海思的Hi3559A等芯片、Atlas全系列硬件以及华为云，均使用CANN来实现底层AI芯片使能，即一次开发，全场景适用。\nCANN 3.0的核心功能，恰恰是要真正做大AI计算“产业蛋糕”所不可或缺的“软”实力。\n2、统一API、两种算子开发方式、四大开放性设计\nCANN 3.0拥有昇腾统一编程接口AscendCL API、两种TBE算子开发模式，以及Plugin适配、图融合优化接口、Ascend-IR接口、预置算子库源码开放这四大开放性设计。\n▲异构计算架构CANN 3.0\n神经网络是以算子来组成不同应用功能的网络结构。这些不同的模块全部对外开放，支持第三方框架、自定义算子融合、自定义模型、自定义修改算子，端到端覆盖全场景AI应用开发。\n所有底层资源均通过专为深度学习设计和优化的昇腾统一编程接口AscendCL来对外开放。\nAscendCL将算子调用API归一化，支持全系列昇腾芯片，一套应用代码可以在不同芯片上运行，从而有效简化编程难度，为神经网络提供高效算力支撑。\n此外，AscendCL还保持后向兼容，现在编写的代码，也支持在未来推出的华为昇腾芯片上运行，确保应用软件可用性。\n考虑到不同开发者的需求差异，CANN 3.0提供DSL和TIK两种张量加速引擎（TBE）算子开发方式，以兼顾对效率和灵活性的不同需求。\n其中，TBE-DSL面向入门开发者，可自动实现数据切分和调度，可覆盖70%的算子，将算子开发时间降低较业界降低70%，使开发者只需关注计算实现表达。\nTBE-TIK则面向高级开发者，提供指令级编程和调优过程，可覆盖全部算子，需由开发者手工完成指令集调用过程，可兼具灵活性和高性能。\n3、亲和昇腾的图编译技术，1000+高性能算子库支持\nCANN 3.0还具备亲和昇腾的图编译技术，可有效提升图优化效率，最大化发挥芯片算力。\n神经网络可看作一张张的图，过去大部分图在host CPU执行，如今昇腾的图编译器，实现整图下沉执行，图和算子均可在device侧执行，减少了芯片与host CPU的交互时间，从而更充分地发挥昇腾芯片的算力。\n图拆分和融合方面，通过自动算子融合等技术，将大量节点自动拆分、融合，以减少计算节点和计算时间，持续保持计算资源的高强度运行。\n数据Pipeline智能优化极大提升数据资源处理效率，通过计算数据智能切分与智能分配流水机制，实现单指令计算单元的最高使用率，并持续保持计算资源高强度运行。\n目前CANN 3.0提供有1000+深度优化的硬件亲和算子，支持多框架共用，且自适应全系列昇腾芯片，可实现最佳运行性能。\n自家的软件，最懂如何挖掘自家硬件的性能。\n基于高度适配的软硬件组合，华为Atlas硬件在主流推理和训练模型的性能均为业界领先。\n在主流推理场景，据华为实测，AI推理卡Atlas 300I性能超过业界主流推理卡。特别是在高清视频场景中，单张Atlas 300I推理卡可同时处理80路1080p、25FPS的高清视频，是业界主流推理卡可同时处理路数的2倍。\n对于有大量视频分析需求的企业，可同时处理的视频路数越多，整体硬件成本下降的越快。旷视、格灵深瞳等企业正基于华为AI推理卡打造高路数视频分析解决方案。\n华为实测数据显示，在主流模型训练场景，华为最高算力密度服务器Atlas 800在多种模型的实测性能超过业界主流新品训练服务器，平均实测性能约为业界主流上一代训练服务器的2.5倍。\n除了计算卡外，软件能力也充分释放了华为AI集群的总体性能。\n线性度是指多个机器同时处理运算时，受机器间通信等能力影响，最终实际发挥性能资源的利用率。经由L2网络与CANN层算法的联合优化，昇腾芯片的线性度超过业界领先水平。\n开发工具全家桶MindStudio 2.0：即装即用，高度智能\n工欲善其事，必先利其器，全流程开发工具链MindStudio即是华为提供的AI开发“利器”。\nMindStudio 2.0提供了一套简单易用的一站式开发工具，可高效完成端到端全场景开发，让开发者从算子开发、模型训练、模型推理、应用开发到应用部署的全流程一套工具全部搞定，无需在不同工具上完成，有效降低开发门槛。\nMindStudio可一键式完成安装部署、可视化模型开发和智能调优功能大大提高模型开发效率，算子开发方面则更加高效。\n总体来看， MindStudio 2.0能带给开发者即装即用、沉浸体验、智能准确三个优势。\n（1）即装即用：一键式自动化环境准备部署，三步完成软硬件安装，所有工具均提供插件形式，并基于开发场景提供各个环节的场景化指导文档，还为配置参数、专业术语等难理解词汇提供实时注释、链接和参考。\n（2）沉浸体验：围绕开发流程提供一站式导视系统，AI帮助一键补全算子开发的语法，关联文件自动高亮，针对不同开发对象自适应提供对应AI工具的快捷功能，减少开发过程中的操作步骤，并提供无边界UI设计，打造沉浸式开发体验。\n（3）智能准确：基于用户认知提供硬件运行单元级别可视化的调优分析报告，基于不同维度提供多样化的模型精度对比结果。\n除了提高开发效率外，华为昇腾还提供了用于优化模型训练、推理性能的工具，这些工具调用了CANN底层的能力来做亲和网络。\n例如，昇腾训练加速工具利用独有的Less BN（智能识别网络中不必要的BN算子）和随机冻结算法大幅提升模型训练效率，可将ResNet模型的训练吞吐量提高25.6%；昇腾模型压缩工具利用独有的智能算法加速推理进程，可将Yolov3模型推理速度提高47.2%。\n结语：普惠AI的先行者\n如果我们对华为AI布局的认知仅限于冲锋在前的AI硬件产品，那就低估了华为的AI实力。\n从华为整体的昇腾计算产业来看，华为的全栈全场景AI解决方案正日臻完善。从底层IP核、芯片"
  },
  {
    "title": "快手进军AI编程，KAT-Coder大模型发布，能否挑战GPT-5与Claude Sonnet？代码_产品_领域",
    "page_body": "快手StreamLake正式入局AI编程领域，于2025年10月23日推出了“工具+模型+平台”三位一体的AI编程产品矩阵，引发了行业内的广泛关注。此次发布的举措，标志着快手在人工智能领域的技术布局进一步深化，也预示着AI编程赛道竞争的白热化。此次发布的产品矩阵包括智能开发工具 CodeFlicker 、多个自研大模型 KAT-Coder 以及大模型平台 快手万擎（Vanchin） ，旨在为企业与开发者构建AI编程新生态。\nKAT-Coder：性能卓越的大模型\n此次发布的核心无疑是 KAT-Coder 系列大模型。根据官方信息， KAT-Coder 提供了多个版本，以满足不同开发者的需求。其中， KAT-Coder-Pro V1 在 SWE-bench Verified 测试中，以73.4%的解决率超越了 GPT-5 与 Claude Sonnet 4 ，展现出强大的代码理解与生成能力。这一成绩意味着 KAT-Coder 在解决复杂编程任务上，已经达到了行业领先水平。此外，针对不同用户群体， KAT-Coder 还推出了 KAT-Coder-Air V1 版本，该版本将面向所有用户免费开放，降低了AI编程的门槛。同时， KAT-Coder-Exp-72B 1010 作为开源学术模型，也为AI算法研究与教育场景提供了支持。这些不同版本的发布，体现了快手在AI编程领域的全面布局，旨在满足不同层次开发者的需求。\nCodeFlicker：智能开发伙伴\n除了大模型， CodeFlicker 作为智能开发工具，也备受关注。 CodeFlicker 提供了 Jam 、 Duet 两种开发模式，前者基于仓库级上下文实时感知，自主完成工程级代码生成与改写；后者以深度研究与任务规划为核心，支持复杂系统与企业级场景的精准代码生成。 CodeFlicker 支持从 Figma 设计稿转代码、交互式预览、自动化调试到一键部署的全流程闭环，助力团队高效完成从创意设计稿到产品上线的全过程。其核心功能包括智能问答、架构设计、代码续写与解析、代码诊断与智能运维等，为开发场景提供 DevOps 端到端的赋能。借助代码仓库说明书 DeepWiki ， CodeFlicker 能够自动生成结构清晰、术语准确的代码仓库文档，帮助新人快速上手，提升团队协作与代码理解效率。\n快手万擎：Maas平台助力生态建设\n快手万擎（Vanchin）作为大模型平台，是整个产品矩阵的重要组成部分。该平台提供99.95%的SLA 可用性保障，并通过网络安全等级保护三级认证，能够承载快手数亿用户级别的成熟基础设施。平台已集成 DeepSeek 、 Qwen 、 Kimi 等多款主流大模型，满足多样化业务需求。 快手万擎 的推出，为 KAT-Coder 大模型提供了坚实的基础设施支撑，也为开发者提供了更便捷的AI编程环境。\n市场竞争与未来展望\n快手此次进军AI编程领域，无疑加剧了行业竞争。在 AI Coding 领域，已经有 GitHub Copilot 、 Amazon CodeWhisperer 等成熟产品，快手能否凭借其技术实力和生态优势，在竞争中脱颖而出，值得期待。 KAT-Coder-Pro V1 在 SWE-bench Verified 测试中取得的成绩，显示了快手在AI编程技术上的实力。未来，随着AI技术的不断发展，AI编程将成为软件开发领域的重要趋势。快手此次发布的产品矩阵，有望推动AI编程技术的普及和应用，为开发者带来更高效、便捷的编程体验。快手在AI编程领域的布局，也预示着其在人工智能领域更长远的战略规划。\n快手此次发布的AI编程产品矩阵，能否在激烈的市场竞争中站稳脚跟？ KAT-Coder 系列大模型的实际应用效果如何？欢迎在评论区留下你的看法！"
  },
  {
    "title": "AI生产力工具全景图：15款主流平台深度对比与选择指南-BetterYeah",
    "page_body": "随着人工智能技术的快速发展，AI生产力工具已经从概念走向实用，成为企业和个人提升工作效率的重要助手。 据Gartner预测，到2025年，超过80%的企业将在某种程度上使用AI技术来提升业务效率 。在这个快速变化的市场中，如何选择合适的AI生产力工具成为企业和个人面临的重要挑战。\n本文将深入分析2025年最具代表性的15款AI生产力工具，从功能特性、应用场景、成本效益等多个维度进行全面对比，为不同需求的用户提供科学的选择建议。无论您是寻求提升个人工作效率的职场人士，还是希望推动企业数字化转型的决策者，这份指南都将为您提供有价值的参考。\n一、AI生产力工具发展现状与趋势分析\n当前AI生产力工具市场正经历着前所未有的快速发展期。从最初的简单文本生成工具，到如今能够处理复杂业务流程的智能体系统，AI工具的能力边界不断扩展。\n1.1 市场规模与增长趋势\n根据最新的市场研究数据显示，全球AI生产力工具市场规模在2024年已达到156亿美元，预计到2030年将增长至890亿美元，年复合增长率超过35%。这一增长主要由以下几个因素驱动：\n技术成熟度提升 ：大语言模型的能力显著增强，从GPT-3到GPT-4，再到最新的多模态模型，AI工具的理解和生成能力达到了实用化水平。\n成本持续下降 ：随着算力成本的降低和模型效率的提升，AI工具的使用成本大幅下降，使得更多中小企业能够承担相关费用。\n应用场景拓展 ：从最初的内容创作，扩展到客户服务、数据分析、流程自动化等多个领域，AI工具的应用边界不断扩大。\n1.2 技术发展趋势\n2025年AI生产力工具呈现出几个重要的技术发展趋势：\n多模态融合 ：现代AI工具不再局限于处理单一类型的数据，而是能够同时处理文本、图像、音频、视频等多种模态信息，提供更全面的解决方案。\n智能体化发展 ：从被动响应转向主动服务，AI工具正在向具备自主决策和执行能力的智能体方向发展，能够独立完成复杂的业务流程。\n私有化部署需求增长 ：随着企业对数据安全和隐私保护要求的提高，支持私有化部署的AI工具越来越受到市场青睐。\n行业定制化加深 ：通用型AI工具正在向行业专用型发展，针对特定行业的需求提供定制化解决方案。\n1.3 用户需求变化\n通过对数千家企业的调研发现，用户对AI生产力工具的需求正在发生显著变化：\n从功能导向转向效果导向 ：用户更关注工具能带来的实际效率提升和成本节约，而非单纯的功能丰富度\n从单点应用转向系统集成 ：企业希望AI工具能够与现有业务系统无缝集成，形成完整的智能化工作流\n从标准化转向个性化 ：不同规模、不同行业的企业对AI工具有着差异化的需求，个性化定制成为重要考量因素\n二、2025年十大主流AI生产力工具深度评测\n基于市场占有率、用户满意度和功能完整性等多个维度，我们选择了15款最具代表性的AI生产力工具进行深度评测。这些工具涵盖了对话交互、内容创作、办公协作、开发辅助等多个应用领域。\n2.1 对话交互类工具\n对话交互类AI工具是目前应用最广泛的生产力工具，主要用于信息查询、内容生成和问题解答。\nChatGPT\n作为AI对话工具的标杆产品， ChatGPT目前拥有超过1.8亿月活跃用户 ，是全球使用最广泛的AI生产力工具。\n核心功能 ：\n自然语言对话交互 多轮对话上下文理解 代码生成与调试 文档分析与总结 创意写作与内容优化\n适用场景 ：内容创作、学习辅助、编程开发、商务沟通等通用场景\n文心一言\n百度推出的文心一言在中文理解和处理方面表现优异，特别适合中文用户使用。\n核心功能 ：\n中文语境优化的对话能力 文学创作与诗词生成 知识问答与信息检索 图像理解与生成 文档处理与分析\n适用场景 ：中文内容创作、教育培训、文化创意等领域\n豆包\n字节跳动旗下的豆包AI助手，在多模态处理和移动端体验方面具有优势。\n核心功能 ：\nAI搜索与信息整合 图像生成与编辑 学术搜索与文献分析 音乐生成与创作 数据分析与可视化\n适用场景 ：学术研究、创意设计、移动办公等场景\n2.2 办公协作类工具\n办公协作类AI工具专注于提升日常办公效率，包括文档处理、演示制作、项目管理等功能。\nMicrosoft 365 Copilot\n微软的Copilot集成在Office套件中 ，为用户提供智能化的办公体验。\n核心功能 ：\nWord文档智能写作与编辑 Excel数据分析与图表生成 PowerPoint演示文稿自动创建 Outlook邮件智能管理 Teams会议摘要与行动项提取\n适用场景 ：企业办公、商务沟通、数据分析、项目管理\nNotion AI\nNotion AI将人工智能深度集成到笔记和项目管理平台中，提供全方位的智能协作体验。\n核心功能 ：\n智能笔记整理与摘要 项目计划自动生成 内容创作与优化 数据库智能查询 团队协作流程自动化\n适用场景 ：知识管理、项目协作、内容规划、团队沟通\n2.3 专业领域工具\n针对特定专业领域的AI工具在垂直场景中表现出色，能够提供更精准的解决方案。\nGitHub Copilot\nGitHub Copilot是面向开发者的AI编程助手，能够显著提升编程效率。\n核心功能 ：\n代码自动补全与生成 多语言编程支持 代码解释与优化建议 单元测试自动生成 代码审查辅助\n适用场景 ：软件开发、代码审查、技术学习、项目维护\nMidjourney\nMidjourney在AI图像生成领域表现卓越，广泛应用于创意设计和艺术创作。\n核心功能 ：\n高质量图像生成 艺术风格转换 图像编辑与优化 批量处理能力 社区分享与学习\n适用场景 ：创意设计、广告制作、艺术创作、产品原型设计\n三、不同应用场景下的AI工具选择指南\n不同的应用场景对AI生产力工具有着不同的需求特点。本节将从实际应用角度出发，为各种典型场景提供精准的工具选择建议。\n3.1 内容创作场景\n内容创作是AI工具应用最广泛的场景之一，包括文章写作、营销文案、社交媒体内容等多个细分领域。\n文章与博客写作\n对于专业写作者和内容营销人员，推荐使用以下工具组合：\n主力工具 ：ChatGPT + Notion AI\nChatGPT负责创意激发和初稿生成 Notion AI用于内容整理和结构优化 配合Grammarly进行语法检查和文风优化\n适用人群 ：专业写作者、内容营销人员、博主、记者\n效率提升 ：相比传统写作方式，可提升60-80%的内容产出效率\n营销文案创作\n营销文案需要更强的说服力和转化能力，建议选择：\n主力工具 ：Jasper AI + Copy.ai\nJasper AI提供多种营销文案模板 Copy.ai专注于转化率优化 结合A/B测试工具验证文案效果\n适用人群 ：市场营销人员、广告文案、电商运营\n效率提升 ：文案创作效率提升3-5倍，转化率平均提升15-25%\n3.2 数据分析场景\n数据分析场景需要AI工具具备强大的数据处理和洞察能力。\n商业智能分析\n对于需要从大量数据中提取商业洞察的场景：\n主力工具 ：Microsoft 365 Copilot + Tableau AI\nExcel Copilot进行数据预处理和基础分析 Tableau AI生成高级可视化图表 Power BI提供企业级仪表板\n适用人群 ：数据分析师、业务分析师、管理层\n效率提升 ：数据分析效率提升200-300%，报告生成时间缩短70%\n客户行为分析\n电商和SaaS企业的客户行为分析需求：\n主力工具 ：Google Analytics Intelligence + 自定义AI模型\nGA Intelligence自动识别异常和趋势 结合机器学习模型预测客户行为 集成CRM系统实现闭环分析\n适用人群 ：产品经理、增长团队、客户成功团队\n效率提升 ：客户洞察生成效率提升150%，预测准确率提升30%\n3.3 项目管理场景\nAI工具在项目管理中的应用主要集中在任务规划、进度跟踪和风险预警等方面。\n敏捷开发管理\n软件开发团队的项目管理需求：\n主力工具 ：Jira AI + Monday.com AI\n自动化任务分配和优先级排序 智能预测项目完成时间 实时风险识别和预警\n适用人群 ：项目经理、开发团队、产品经理\n效率提升 ：项目交付效率提升25-40%，风险识别准确率提升60%\n企业级项目管理\n大型企业的复杂项目管理：\n主力工具 ：Microsoft Project AI + Asana Intelligence\n多项目资源协调优化 智能里程碑规划 自动化状态报告生成\n适用人群 ：企业项目管理办公室、高级项目经理\n效率提升 ：项目规划效率提升50%，资源利用率提升30%\n四、企业级AI生产力工具对比分析\n企业级AI工具在功能完整性、安全性、集成能力等方面有着更高的要求。本节将从企业实际需求出发，对主流企业级AI生产力工具进行全面对比。\n4.1 核心功能对比分析\n以下表格对比了主流企业级AI生产力工具的核心功能：\n工具名称\n智能对话\n知识库管理\n工作流自动化\n数据安全\n系统集成\n多模态支持\nBetterYeah AI ✅ 优秀 ✅ 优秀 ✅ 优秀 ✅ 优秀 ✅ 优秀 ✅ 支持\nMicrosoft 365 Copilot ✅ 优秀 ⚡ 良好 ⚡ 良好 ✅ 优秀 ✅ 优秀 ✅ 支持\nNotion AI ✅ 优秀 ✅ 优秀 ✅ 优秀 ⚡ 良好 ✅ 优秀 ⚡ 部分支持\n4.2 行业应用特色分析\n不同行业对AI生产力工具的需求重点不同：\n制造业\n核心需求 ：生产优化、质量管控、供应链管理\n推荐工具组合 ：\n生产计划优化：IBM Watson + 自定义AI模型 质量检测：机器视觉AI + 数据分析平台 供应链管理：SAP AI + 预测分析工具\n典型ROI ：生产效率提升15-25%，质量问题减少30-50%\n电商零售业\n核心需求 ：个性化推荐、库存管理、客户服务\n推荐工具组合 ：\n商品推荐：机器学习推荐系统 库存预测：时间序列分析 + AI预测模型 客户服务：多渠道智能客服平台\n典型ROI ：转化率提升20-30%，库存周转率提升22%\n4.3 成本效益分析\n基于对100+企业的调研数据，不同类型AI工具的成本效益对比如下：\n投资成本分析\n初期投资成本 （年度）：\nSaaS工具：人均500-2000元/年 私有化部署：10-50万元起步 定制开发：50-200万元不等\n运营维护成本 （年度）：\nSaaS工具：基本无额外成本 私有化部署：初期投资的10-20% 定制开发：初期投资的15-30%\n收益分析\n根据最新的AI投资回报率研究显示，成功实施AI项目的企业能够实现3.7倍的投资回报率。\n效率提升收益 ：\n内容创作效率提升：60-300% 数据分析效率提升：200-500% 客服响应效率提升：100-400% 决策制定速度提升：50-150%\n成本节约收益 ：\n人力成本节约：20-40% 运营成本降低：15-30% 错误率减少带来的成本节约：10-25%\n五、AI生产力工具选择与实施建议\n基于前面的深入分析，本节将为不同类型的用户提供具体的选择建议和实施路径。\n5.1 选择决策框架\n建立科学的决策框架是成功选择AI工具的关键：\n需求评估矩阵\n评估维度权重分配\n根据企业实际情况，对以下维度进行权重分配：\n评估维度\n小型企业权重\n中型企业权重\n大型企业权重"
  },
  {
    "title": "协创数据Fcloud Omnibot平台发布，集成NVIDIA物理AI技术推动云端机器人开发",
    "page_body": "近日，协创数据（300857）在其投资者关系平台上透露，Fcloud全新上线的机器人开发服务Omnibot平台，已成功集成了NVIDIA的 Isaac Sim 和 Isaac Lab 技术。这一进展标志着公司在云端机器人开发领域迈出了重要一步，进一步推动了物理AI技术的应用与普及。\n云端机器人开发的便捷性 Fcloud Omnibot平台的推出，使得企业在进行机器人开发时，无需再搭建复杂的基础设施。这一云端服务显著缩短了开发周期，帮助企业快速响应市场需求，探索多元化的机器人智能应用场景。借助NVIDIA的技术，Omnibot平台为开发者提供了一种 场景化 的机器人开发与训练服务，提升了开发效率和效果。\n通过集成NVIDIA的 Cosmos Transfer模型 ，Omnibot平台为机器人训练提供了创新性的解决方案。开发者可以通过云端一键部署的多模态模型，快速生成物理精确的合成数据。这种能力使得开发者能够在短时间内构建包含边缘案例的多样化训练集，并实现跨模态数据增强与域适应，建立一个持续自我优化的数据闭环系统。\n技术优势与市场前景 Omnibot平台的推出，充分利用了NVIDIA在物理AI领域的领先优势。与市场上其他机器人开发平台相比，Omnibot在数据处理与训练效率方面具备明显优势。借助于云端技术，企业用户可以更加灵活地进行机器人研发，适应快速变化的市场环境。此外，Omnibot还为企业提供了技术支撑，助力企业在智能制造、物流配送等多个领域的应用。\n在全球范围内，机器人技术的快速发展与应用场景的不断拓展，使得市场对高效、灵活的机器人开发平台需求日益增加。Fcloud Omnibot平台凭借其技术优势，预计将成为未来机器人开发的重要选择之一。\n未来展望与行业趋势 随着物理AI技术的不断进步，未来机器人开发将朝着更高的智能化与自动化方向发展。企业在选择开发平台时，将更加注重平台的技术生态与数据处理能力。此外， 开发者生态 的构建也将成为决定平台成功与否的关键因素。\n你认为未来的机器人开发将面临哪些新的挑战与机遇？随着技术的不断演进，企业又该如何应对这些变化？"
  },
  {
    "title": "人工智能的五级路线图",
    "page_body": "人工智能的五级路线图，通常被理解为通用人工智能（AGI）发展的不同阶段或层次。这一路线图由OpenAI等机构提出，旨在描绘人工智能从基础到高级、从简单到复杂的发展路径。以下是人工智能五级路线图的详细解读：\n打开百度APP畅享高清图片\n一、第一级：聊天机器人（Chatbots，AI with conversational language）\n特点 ：人工智能系统能够参与类似人类的对话，显示出基本的理解能力，并能对各种提示和问题作出响应。 应用 ：这一级别的人工智能主要被应用于客服、助手等场景，提供基础的信息咨询和交互服务。\n二、第二级：推理者（Reasoners，human-level problem solving）\n特点 ：人工智能系统能够以人类专家的熟练程度解决复杂问题，标志着其从单纯模仿人类行为升级到展现真实的智能水平。 应用 ：在这一级别，人工智能可以应用于需要复杂推理和决策的领域，如医疗诊断、金融风险评估等。\n三、第三级：智能体（Agents，systems that can take actions）\n特点 ：人工智能系统可以承担复杂的任务、作出决策和适应不断变化的环境，并在无须持续人类监督的情况下适应多变环境。 应用 ：这一级别的人工智能可以应用于自动驾驶、机器人控制等场景，实现自主行动和决策。\n四、第四级：创新者（Innovators，AI that can aid in invention）\n特点 ：人工智能将具有创造性和独创性，可以提出突破性的想法和解决方案。 应用 ：在这一级别，人工智能可以辅助人类进行发明创造，推动多个领域的创新和进步。例如，在科学研究、艺术创作等领域，人工智能可以提供新的思路和方法。\n五、第五级：组织者（Organizations，AI that can do the work of an organization）\n特点 ：人工智能不仅具备战略思维，还拥有实现组织目标所需的高效率和强适应性，能够管理复杂的系统。 应用 ：在这一级别，人工智能可以承担组织和管理的工作，如企业运营、城市管理等领域。它可以帮助组织提高效率、优化决策，并应对各种复杂情况。\n总的来说，人工智能的五级路线图提供了一个清晰的结构化框架，用于理解和构建通用人工智能过程中的挑战和机遇。随着技术的不断进步和应用场景的不断拓展，人工智能将逐渐从低级向高级发展，最终实现全面智能化。"
  },
  {
    "title": "人工智能：从概念到未来的全面解析_人工智能的技术架 构和算法持续演化,从传统的机器学习到深度学习,再到当前的强化-CSDN博客",
    "page_body": "一、定义与学科定位\n人工智能 （Artificial Intelligence, AI）是 计算机科学 的分支，融合心理学、哲学、数学等多学科，旨在模拟、延伸人类智能。其核心目标是通过算法和模型，使机器具备学习、推理、感知、决策等能力。根据能力范围，AI可分为两类：\n弱AI（专用AI） ：专注于单一任务，如语音助手（Siri）、图像识别（人脸支付）或推荐系统（电商算法）。 强AI（通用AI） ：具备人类水平的通用智能，能自主适应多场景任务，目前仍处于理论探索阶段。\nAI 的学科体系由三大支柱构成：\n科学基础 ：涵盖符号主义（逻辑推理）、连接主义（神经网络）、行为主义（感知-动作模式）。 技术方法 ：依托知识（专家系统）、数据（机器学习）、算法（深度学习）、算力（GPU/TPU）四大要素。 应用领域 ：渗透经济、民生、科技等领域，如智能制造、智慧医疗、自动驾驶等。\n二、技术演进：从 机器学习 到深度学习的突破\nAI的技术发展可划分为三个阶段：\n规则驱动时代（1950-1980） ：依赖硬编码规则（如专家系统），但难以应对复杂场景。 数据驱动时代（1980-2010） ：机器学习兴起，通过统计方法（如贝叶斯分类、支持向量机）从数据中挖掘规律。 深度学习革命（2010至今） ：基于多层神经网络（如CNN、RNN、Transformer），实现端到端学习，在图像识别（ResNet）、自然语言处理（BERT、GPT）等领域取得突破。\n核心分支解析 ：\n机器学习 ： \n监督学习 ：利用标注数据训练模型（如垃圾邮件分类）。 无监督学习 ：从未标注数据中发现模式（如客户分群）。 强化学习 ：通过试错与环境交互优化策略（如AlphaGo）。\n深度学习 ： \n卷积神经网络（CNN） ：擅长图像处理（目标检测、医学影像分析）。 循环神经网络（RNN） ：处理序列数据（语音识别、时间序列预测）。 生成对抗网络（GAN） ：生成逼真数据（DeepFake、艺术创作）。\n三、数学基石：支撑AI的十大核心理论\nAI的 算法 设计高度依赖数学工具，以下是关键领域：\n线性代数 ：矩阵运算（神经网络前向传播）、特征值分解（PCA降维）。 概率论与统计 ：贝叶斯推断（分类问题）、假设检验（模型评估）。 微积分 ：梯度下降（优化损失函数）、泰勒展开（局部近似）。 信息论 ：熵与交叉熵（损失函数设计）、KL散度（分布差异量化）。 优化理论 ：凸优化（支持向量机）、非凸优化（深度学习训练）。 图论 ：知识图谱（语义关联）、路径规划（自动驾驶）。 离散数学 ：逻辑推理（决策树）、搜索算法（A*算法）。 随机过程 ：马尔可夫链（序列建模）、蒙特卡洛方法（采样推断）。 群论 ：图像对称性分析（模式识别）。 数理逻辑 ：知识表示（专家系统）、推理引擎（规则引擎）。\n四、应用场景与现实挑战\n典型应用 ：\n计算机视觉 ：人脸识别（安防）、自动驾驶（物体检测）。 自然语言处理 ：机器翻译（Google Translate）、聊天机器人（ChatGPT）。 语音技术 ：语音助手（Siri）、语音合成（有声书生成）。 生成式AI ：文本生成（GPT-4）、图像生成（Stable Diffusion）。\n核心挑战 ：\n数据隐私与安全 ：敏感数据泄露风险（如医疗记录）。 算法偏见 ：模型继承训练数据偏见（如招聘算法性别歧视）。 可解释性缺失 ：深度学习“黑箱”特性影响关键领域信任（如医疗诊断）。 计算资源消耗 ：训练大模型（如GPT-3）需巨量算力，环境成本高昂。\n五、未来展望：技术融合与伦理治理\n技术融合趋势 ： \n多模态AI ：整合文本、图像、语音（如多模态大模型）。 神经形态计算 ：模仿人脑结构，提升能效（类脑芯片）。 AI for Science ：加速科学发现（如蛋白质结构预测、气候模拟）。\n伦理与治理 ： \n可信AI ：研发可解释性技术（XAI），提升决策透明度。 法规完善 ：建立AI伦理准则（如欧盟《AI法案》），规范高风险应用（如自动驾驶）。\n社会影响 ： \n就业结构变革 ：自动化替代重复性工作，催生新职业（AI训练师）。 教育转型 ：培养“AI+X”复合型人才，适应智能化社会需求。\n六、结语\n人工智能正以指数级速度重塑人类社会，其发展既充满机遇，也伴随挑战。唯有在技术创新与伦理约束间找到平衡，才能确保AI成为推动文明进步的引擎，而非失控的“潘多拉魔盒”。未来，AI将与人类深度协作，共同探索智能的边界，开启一个前所未有的智慧时代。"
  },
  {
    "title": "GPT-4为何变懒了？-ZOL问答",
    "page_body": "自去年以来，关于GPT-4变笨的讨论便持续不断。不少用户反馈称，相较于早期版本，当前模型在逻辑推理和内容输出方面表现明显下滑，回答问题时常显得不够严谨，甚至出现低级错误。这种变化不仅体现在普通使用者的日常体验中，也在专业开发者社区引发了广泛讨论。在OpenAI官方的在线开发者论坛上，许多用户纷纷留言，指出其推理链条不再严密，生成结果的准确性和一致性有所下降，尤其在处理复杂任务或需要多步推导的问题时，表现尤为不尽人意。\n更引人关注的是，这一现象已引起学术界的重视。斯坦福大学与加州大学伯克利分校的研究团队专门展开研究，并发表了一篇题为ChatGPT的演化：能力变迁的实证分析的论文，系统性地评估了该模型在不同时间段的表现差异。研究通过对比多个历史版本的响应质量、逻辑连贯性、事实准确性及数学推理能力，发现近期部署的版本在多项指标上确实出现了退步。例如，在标准逻辑测试题中，新版本的正确率下降了约15%；在需要深度推理的编程任务中，生成代码的可运行比例也显著降低。研究人员推测，这种性能滑坡可能与模型上线后的持续优化策略有关——为了提升安全性、合规性或响应速度，部分训练权重被调整，从而影响了原本强大的认知推理能力。\n此外，也有技术分析指出，随着用户请求类型的多样化和流量压力的增加，服务端可能引入了更多轻量级的响应机制或缓存策略，导致某些复杂查询未能充分调用完整模型能力。同时，为规避潜在风险，系统在内容过滤和价值观对齐方面的限制日趋严格，这虽然提升了输出的安全性，却也可能抑制了模型自由推理的空间，使其在面对开放性问题时趋于保守或模棱两可。\n尽管官方尚未对此类质疑作出明确回应，但这些来自一线用户和独立研究的观察无疑揭示了一个重要趋势：大型语言模型的迭代并非总是线性进步。在实际应用中，性能、安全、效率与用户体验之间的平衡极为复杂，任何一方的过度倾斜都可能导致整体能力的隐形损耗。这也提醒我们，在依赖AI辅助决策的同时，仍需保持批判性思维，不能盲目信任其输出结果。\n技术的发展从来不是一帆风顺的，每一次升级背后都可能存在取舍。对于使用者而言，了解工具的变化规律，理性看待其局限，才能真正发挥人工智能的价值。未来，随着评测体系的完善和透明度的提升，或许我们能更清晰地看清模型演进的真实轨迹。"
  },
  {
    "title": "DeepSeek-V3与GPT-4o全面对比：性能、应用与开发者选择指南-百度",
    "page_body": "作者： 渣渣辉 2025.08.20 21:19 浏览量： 18\n简介： 本文从架构设计、核心性能、应用场景、开发适配性等维度对DeepSeek-V3与GPT-4o进行深度对比，结合基准测试数据与典型用例分析，为开发者提供模型选型的决策框架与实操建议。\nDeepSeek-V3与GPT-4o全面对比：性能、应用与 开发者 选择指南\n一、架构设计与技术特性对比\n1.1 模型架构演进\nDeepSeek-V3采用混合专家系统（MoE）架构，通过动态激活子模型实现计算效率优化，其稀疏化参数规模达到3万亿级别，实际激活参数约400亿。GPT-4o则延续稠密Transformer架构，参数量预估1.8万亿，采用多模态统一表征空间设计，显著提升跨模态任务处理能力。\n1.2 训练数据差异\n维度\nDeepSeek-V3\nGPT-4o\n文本语料 中英双语为主（7:3） 多语言均衡分布\n数据时效性 截至2024Q1（含实时检索增强） 截至2023Q4（依赖插件扩展）\n数据清洗策略 行业术语强化 通用性优先\n二、核心性能基准测试\n2.1 语言理解能力\n在C-Eval中文基准测试中，DeepSeek-V3达到92.3%准确率（GPT-4o为88.7%），尤其在法律、医疗等专业领域表现突出。MMLU多任务测试显示GPT-4o在57个学科平均准确率领先2.1个百分点，体现更均衡的知识覆盖。\n2.2 代码生成能力\nHumanEval测试结果：\n# DeepSeek-V3代码示例（快速排序实现） def  quicksort ( arr ): if  len ( arr ) <= 1 : return  arr     pivot  =  arr [ len ( arr )// 2 ]     left  = [ x  for  x  in  arr  if  x  <  pivot ]     middle  = [ x  for  x  in  arr  if  x  ==  pivot ]     right  = [ x  for  x  in  arr  if  x  >  pivot ] return  quicksort ( left ) +  middle  +  quicksort ( right )\nGPT-4o在复杂算法（如动态规划）实现上更规范，但DeepSeek-V3对中文注释的支持更符合本土开发习惯。\n三、开发适配性深度分析\n3.1 API接口差异\nDeepSeek-V3提供细粒度计费单元（按token类型区分），适合高频短文本场景。GPT-4o的流式响应模式在长文本生成时延迟降低40%，但并发请求存在硬性限制。\n3.2 微调支持对比\n{ \"DeepSeek-V3\" : { \"适配框架\" : \" PyTorch  Lightning\" , \"LoRA支持\" : true , \"最低显存\" : 24GB }, \"GPT-4o\" : { \"适配框架\" : \" TensorFlow \" , \"Adapter支持\" : true , \"最低显存\" : 32GB } }\nDeepSeek-V3提供中文微调指南和行业数据集模板，显著降低本土开发者门槛。\n四、企业落地建议\n4.1 选型决策树\n中文密集型业务 ：医疗文书生成→DeepSeek-V3 多模态交互场景 ： 智能客服 →GPT-4o 实时性要求高 ：金融 舆情 分析→DeepSeek-V3（检索增强优势） 多语言支持 ：跨境电商→GPT-4o\n4.2 成本优化方案\nDeepSeek-V3：利用MoE架构特性，通过API路由将专业请求定向到对应专家模型 GPT-4o：启用「思考-验证」模式，将复杂任务分解为多个子请求\n五、未来演进方向\nDeepSeek-V3计划2024Q3发布动态记忆增强模块，GPT-4o路线图显示将强化数学推理能力。建议开发者关注两者在代码解释器（REPL）集成方面的差异化发展，这将成为影响开发效率的关键因素。\n技术选型启示：没有绝对优劣，只有场景适配。建议通过AB测试框架（如LangChain）进行业务级验证，重点关注任务完成度、响应延迟和综合成本三个核心指标。"
  },
  {
    "title": "10款主流AI编程工具深度解析：从代码补全到全流程开发-知乎",
    "page_body": "引言\n 在大模型技术爆发的当下，AI编程工具已从「辅助插件」进化为「开发流程核心参与者」。\n 据JetBrains 2023开发者调查，78%的程序员已将AI工具纳入日常开发流程，其中代码生成、调试优化、文档自动生成成为三大高频应用场景。\n 本文将聚焦当前最受开发者欢迎的10款AI编程工具，从技术原理、核心功能到适用场景进行理性分析，帮助程序员群体精准选择适配工具，实现「人机协同」的效率最大化。\n 主流AI编程工具核心能力盘点\n 1.GitHub Copilot（微软&OpenAI）\n 核心技术：基于GPT-4 Turbo与GitHub代码库训练的专用模型\n 核心功能：\n 实时代码补全：支持Python、Java等20+语言，能根据上下文生成函数级代码块\n 注释生成代码：通过自然语言注释直接生成可运行代码\n IDE深度集成：无缝对接VS Code、JetBrains全家桶等主流开发环境适用场景：中小型项目快速开发、重复性代码生成局限：对复杂算法逻辑生成准确性不足，需人工二次校验\n 2.ChatGPT（OpenAI）\n 核心技术：通用大语言模型（GPT-4/GPT-4o）\n 核心功能：\n 跨场景编程支持：从需求分析到代码调试的全流程自然语言交互\n 多语言解释器：支持代码逻辑拆解、算法优化建议、异常排查指导\n 技术文档生成：自动生成API文档、单元测试用例适用场景：复杂问题思路梳理、技术方案设计、非标准化编码任务优势：上下文理解能力强，支持中文等多语言开发需求\n 3.CodeLlama（Meta）\n 核心技术：开源LLaMA 2架构，提供7B/13B/34B参数版本\n 核心功能：\n 本地化部署：支持企业级私有环境部署，数据隐私可控\n 长上下文处理：34B版本支持8k tokens上下文，可分析完整项目代码\n 多语言支持：原生支持C++、Python、Java等10+编程语言适用场景：企业级私有代码库开发、敏感项目本地化辅助工具亮点：完全开源免费，可基于业务需求二次训练\n 4.Amazon CodeWhisperer（AWS）\n 核心技术：AWS自研大模型+亚马逊云服务生态数据训练\n 核心功能：\n 云原生代码生成：深度适配AWS服务（S3、Lambda等）的最佳实践代码\n 安全漏洞检测：实时扫描代码中的安全风险（如SQL注入、权限漏洞）\n 免费额度友好：个人开发者每月享有50小时免费使用时长适用场景：AWS生态项目开发、云服务集成类编码任务\n 5.Tabnine（Tabnine Inc.）\n 核心技术：混合模型架构（Transformer+传统补全算法）\n 核心功能：\n 轻量级实时补全：内存占用低于500MB，启动速度比同类工具快30%\n 团队私有模型训练：支持基于团队内部代码库训练个性化补全模型\n IDE兼容性广：支持VS Code、Vim、Emacs等20+开发工具适用场景：低配置设备开发、团队标准化代码风格统一\n 6.Cursor（Anysphere）\n 核心技术：基于GPT-4的专用编程IDE\n 核心功能：\n 对话式编程界面：侧边栏实时代码对话，支持「选中代码→提问→修改」闭环\n 代码解释与重构：一键生成代码逻辑说明，自动优化冗余代码\n 多文件关联分析：跨文件理解代码依赖关系，支持项目级重构建议适用场景：复杂项目重构、新手开发者代码学习\n 7.DeepSeek-Coder（深度求索）\n 核心技术：国产大模型，针对中文开发者优化\n 核心功能：\n 中文指令支持：直接通过中文注释生成代码（如「写一个Python冒泡排序函数」）\n 数学推理强化：在算法题、数值计算类任务中准确率比通用模型高15%\n 轻量化版本：6.7B参数模型可在消费级GPU运行适用场景：中文技术文档驱动开发、算法竞赛辅助\n 8.CodeGeeX2（智谱AI）\n 核心技术：多语言代码大模型，支持100+编程语言\n 核心功能：\n 跨语言转换：如将Python代码自动转换为Java/Go\n 代码质量评分：从可读性、性能、安全性三维度生成评分报告\n IDE插件生态：支持VS Code、JetBrains、HBuilderX等国产开发工具适用场景：多语言项目迁移、代码质量规范化\n 9.Replit AI（Replit）\n 核心技术：浏览器端轻量级代码模型\n 核心功能：\n 在线协作编程：实时多人协同开发，AI同步辅助补全\n 零配置环境：无需本地安装，浏览器直接运行代码\n 教育场景优化：提供代码错误详细解释，适合编程教学适用场景：在线编程教学、临时代码测试、团队远程协作\n 10.CodeRabbit（CodeRabbit Inc.）\n 核心技术：专注代码审查的垂直领域模型\n 核心功能：\n PR自动化审查：对接GitHub PR流程，自动生成代码改进建议\n 性能瓶颈识别：静态分析代码中的时间复杂度问题\n 风格一致性检查：适配PEP8、Google Style等主流编码规范适用场景：开源项目协作、团队代码审查流程优化\n 工具选择决策框架\n 选择AI编程工具时，建议从以下维度评估：\n 技术栈匹配度：如AWS开发者优先选CodeWhisperer，算法开发者优先选DeepSeek-Coder\n 数据隐私要求：金融/政务项目优先考虑本地化部署工具（如CodeLlama）\n 开发场景需求：日常编码选Copilot/Tabnine，复杂问题选ChatGPT/Cursor\n 成本预算：个人开发者可优先使用免费工具（如CodeWhisperer免费版、Tabnine）\n 结尾与讨论\n AI编程工具的本质是「效率放大器」，而非「开发者替代者」。真正决定开发质量的，仍是程序员对业务逻辑的理解深度与架构设计能力。随着多模态模型（如GPT-4o）的发展，未来AI工具将进一步整合代码生成、UI设计、测试部署等全流程能力。\n 互动讨论：\n 你当前使用频率最高的AI编程工具是什么？它解决了哪些实际问题？\n 在代码生成准确性与数据隐私之间，你如何平衡选择？\n 你认为AI工具会如何改变3年后的程序员工作方式？"
  },
  {
    "title": "Hugging Face – The AI community building the future.",
    "page_body": "The platform where the machine learning community collaborates on models, datasets, and applications. \n Trending on this week \n Models \nmoonshotai/Kimi-K2-Thinking\nUpdated  5 days ago •   105k  •   1.12k \nmaya-research/maya1\nUpdated  1 day ago •   18.6k  •   536 \nbaidu/ERNIE-4.5-VL-28B-A3B-Thinking\nUpdated  1 day ago •   4.41k  •   341 \ndx8152/Qwen-Edit-2509-Multiple-angles\nUpdated  1 day ago •   40.4k  •   553 \nMiniMaxAI/MiniMax-M2\nUpdated  about 2 hours ago •   891k  •   1.27k \nBrowse 1M+ models\n Spaces \n695\nQwen Image Edit Camera Control\n    \nFast 4 step inference with Qwen Image Edit 2509\n2.13k\nThe Smol Training Playbook\n    \nThe secrets to building world-class LLMs\n362\nQwen-Image-2509-MultipleAngles\n    \nQwen-Image-2509-MultipleAngles\n345\nDream-wan2-2-faster-Pro\n    \nGenerate a video from an image with detailed prompts\n118\nOmnilingual ASR Media Transcription\n    \nTranscribe audio or video into text in multiple languages\nBrowse 400k+ applications\n Datasets \nbuilddotai/Egocentric-10K\nUpdated  2 days ago •   13k  •   191 \nfacebook/omnilingual-asr-corpus\nUpdated  3 days ago •   8.58k  •   100 \nPleIAs/SYNTH\nUpdated  2 days ago •   4.06k  •   87 \nnvidia/PhysicalAI-Autonomous-Vehicles\nUpdated  16 days ago •   54.6k  •   320 \nfka/awesome-chatgpt-prompts\nUpdated  Jan 6 •   39.8k  •   9.39k \nBrowse 250k+ datasets\nThe Home of Machine Learning\nCreate, discover and collaborate on ML better. \nThe collaboration platform\nHost and collaborate on unlimited public models, datasets and applications. \nMove faster\nWith the HF Open source stack.\nExplore all modalities\nText, image, video, audio or even 3D.\nBuild your portfolio\nShare your work with the world and build your ML profile.\nSign Up \nAccelerate your ML\nWe provide paid Compute and Enterprise solutions.\nTeam & Enterprise\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and dedicated support. \nGetting started \nStarting at $20/user/month\nSingle Sign-On Regions Priority Support Audit Logs Resource Groups Private Datasets Viewer\nInference Providers\nAccess 45,000+ models from leading AI providers through a single, unified API with no service fees. \nExplore Models \nCompute\nDeploy on optimized  Inference Endpoints  or update your  Spaces applications  to a GPU in a few clicks. \nView pricing \nStarting at $0.60/hour for GPU\nMore than 50,000 organizations are using Hugging Face\nAi2\nTeam \nnon-profit •  805 models  •  4.4k followers \nAI at Meta\nEnterprise \ncompany •  2.24k models  •  8.76k followers \nAmazon\nEnterprise \ncompany •  21 models  •  3.54k followers \nGoogle\nEnterprise \ncompany •  1.05k models  •  35.3k followers \nIntel\ncompany •  253 models  •  3.2k followers \nMicrosoft\nEnterprise \ncompany •  426 models  •  16.4k followers \nGrammarly\nTeam \ncompany •  11 models  •  192 followers \nWriter\nEnterprise \ncompany •  32 models  •  366 followers \nOur Open Source\nWe are building the foundation of ML tooling with the community. \n Transformers\n152,471\nState-of-the-art AI models for PyTorch\n Diffusers\n31,586\nState-of-the-art Diffusion models in PyTorch\n Safetensors\n3,509\nSafe way to store/distribute neural network weights\n Hub Python Library\n3,055\nPython client to interact with the Hugging Face Hub\n Tokenizers\n10,217\nFast tokenizers optimized for research & production\n TRL\n16,282\nTrain transformers LMs with reinforcement learning\n Transformers.js\n14,833\nState-of-the-art ML running directly in your browser\n smolagents\n23,925\nSmol library to build great agents in Python\n PEFT\n20,033\nParameter-efficient finetuning for large language models\n Datasets\n20,842\nAccess & share datasets for any ML tasks\n Text Generation Inference\n10,648\nServe language models with TGI optimized toolkit\n Accelerate\n9,284\nTrain PyTorch models with multi-GPU, TPU, mixed precision"
  },
  {
    "title": "多所高校提出使用AI的多个“禁止”学术论文使用AI边界在哪儿？新闻频道_中国青年网",
    "page_body": "　　随着人工智能技术一路突进，现在人们对于AI工具的应用也越来越多元，尤其是在文稿撰写方面。不少人在网上用AI写文案、写评价，也有高校学生把AI用在了学术论文的撰写过程中。\n　　的确，相比线下翻书籍或者线上找资料，借助AI写论文更加方便，但也引发了很多问题和讨论。近日，复旦大学发布 《关于在本科毕业论文（设计）中使用AI工具的规定（试行）》 ，对人工智能工具在本科毕业论文（设计）撰写过程中的使用进行了详细规范。\n　　除了复旦大学外，目前，全国已有多所高校发文规范借助AI进行论文写作。这些规范的具体要求是什么？ 在学术写作中，AI使用的边界在哪儿？\n　　AI参与学术论文写作\n　　已非常普遍\n　　如今，AI工具越来越丰富，也越来越“智慧”，AI参与学术论文写作已非常普遍。今年刚刚保研武汉大学的小蔡告诉中国之声，此前他在写本科毕业论文时，用过AI。\n　　 小蔡： 其实我们学生在论文或者其他写作方面用得也很多，最主要是为了节省时间，提高效率。可以把我们不懂的问题直接输入进去，让AI做一个比较系统全面的介绍，也让我们对技术、背景有更多的认识。\n　　小蔡坦言，AI工具能大幅度提高课题研究过程中背景资料的查阅效率，但真正在论文的写作层面，自己并不会依赖AI工具。\n　　 小蔡： 节约了很多时间，不会像以前一样需要查阅大量文献，可以更快了解技术。在后面的写作环节，很多高校确实讨论过这个问题。我本人不会直接用到自己的写作，每个人的文章都有不同的写作风格，主体部分肯定是通过自己的实验数据或者实验过程去写。背景介绍这方面直接改写AI提供的文本，就显得文章前后逻辑有很强的拼凑感。\n　　河南师范大学的小韩也是今年毕业，他告诉记者，他的室友写毕业论文时就曾因为过度依赖AI工具吃过亏。\n　　 小韩： 我自己的论文AI占了一小部分，我们宿舍长的论文占比高，他第一次AI查重率高达80%多。AI生成的内容一般有非常关键的逻辑词，首先、其次、然后、最后，还有虽然、但是这种关联词。其实他当时论文查重率才30%，不是特别高。AI查重率高一些，他就自己修改一下语句、语序，把关联词删一删，后来也降下去了。\n　　全国多所高校试行\n　　使用AI的相关规定\n　　过度依赖AI，显然背离了学术研究和论文写作的初衷。而复旦大学近日出台的《关于在本科毕业论文（设计）中使用AI工具的规定（试行）》， 不仅明确了允许使用AI的范围与原则，还从AI工具的研究方案设计、创新性方法设计、算法（模型）框架搭建、毕业论文（设计）结构设计，以及创新性总结等多个方面，明确了禁止使用的范围。 比如，禁止使用AI工具生成或改动本科毕业论文（设计）中的原始数据、原创性或实验性的结果图片、图像和插图；禁止直接使用AI工具生成本科毕业论文（设计）的正文文本、致谢或其他组成部分；禁止使用AI工具进行语言润色和翻译等。\n　　记者了解到，今年以来，中国传媒大学、福州大学、湖北大学、天津科技大学等全国多所高校都在试行或出台相关规定或办法，规范大学生的毕业论文（设计）。\n　　 天津科技大学教务处副处长 孔林涛： AI可以作为重要的辅助手段，但是不能形成依赖，更不能让它占据主流。因此，我们在毕业设计上进行常规查重以外，还做了人工智能生成内容部分的检测，避免学生产生过度依赖的状态。做了这样的工作之后，整体从教指委的角度，从学院分管毕业设计工作的老师的角度，以及整体毕业生的角度都对规定持支持认可的态度。规定也确实发挥了一定的效果，很少有同学依赖AI生成做自己的毕业设计。但是，大家一开始并没有意识到度的问题，经过检测后能够很好地调整。\n　　孔林涛说，学校规定查重结果不得超过30%，AI检测结果显示的智能生成内容比例原则上不超过40%，学院会向超出AI检测标准的学生发出警示。\n　　 孔林涛： 参数的设置也是综合性考虑，体现了我们对AI时代是一种欢迎、迎接的态度。有时候我们会因为AI强大的功能忘记我们最初的目标，失去了方向，所以我们的限制也是让学生回归到自身的轨道上来。\n　　规范AI的应用\n　　需多方面组合发力\n　　记者搜索发现，AI代写的帖子比比皆是。记者添加了一位工作人员的联系方式后，该工作人员告诉记者，AI生成论文每千字15元，一篇万字论文150元左右，需求提得越详细，生成的论文质量越高。如果过不了查重软件的AI检测，还可以进行“降AI”的操作。\n　　工信部工业和信息化法治战略与管理重点实验室副主任赵精武表示，在AI技术飞速发展的当下，全面禁止AI在论文写作过程中的应用并不现实。\n　　 赵精武： AI在学术论文写作上的辅助作用主要包括学术论文润色、评审辅助、编辑反馈优化三个方面。对AI合理应用的边界要有一个基础的理解，AI对于论文写作而言，应当是一种锦上添花的作用。论文的主体内容、核心观点等应当是由学生自行撰写，AI仅仅是在既有的论文成果基础上对论文细节进一步完善。就目前的技术水平而言，绝大部分的AI产品短期内不太可能直接生成符合学术要求的毕业论文，这也意味着平台上部分机构所发布的“AI论文写作教程”存在过度营销的问题，甚至可能诱导学生形成不良的写作习惯。\n　　赵精武建议，未来AI的应用应该是一个平衡关系，一方面保证学生能够辅助利用AI完成毕业论文，同时也要注意过度滥用AI技术。学校需要从技术手段、评价体系、学术素养等多方面组合发力，规范AI的应用。\n　　 赵精武： 以技术治理技术，推动识别AI生成内容的反识别技术发展，利用AI技术鉴别AI生成的“速成论文”；调整毕业论文的评价体系，在大多数情况，AI生成内容难成体系，论文评价重心除了创新性指标考察之外，还需要强化考察整篇论文的逻辑体系是否严谨，这些是AI所无法代替完成的；强化对学生的学术素养培养，堵不如疏，引导学生真正理解AI的工具属性，理解AI实现的功能和技术边界，是每位老师应当关注的重点。"
  },
  {
    "title": "ChatGPT之后，未来AI生态是什么样的？虎嗅网",
    "page_body": "本文来自微信公众号： 未尽研究 （ID：Weijin_Research） ，原标题《未来AI生态：少数通用大模型与无数专用模型》，作者：Maithra Raghu、Matei Zaharia、Eric Schmidt，题图来自：《变形金刚：超能勇士崛起》\n最近兴起的单一通用人工智能模型，例如像GPT-4这样的大语言模型，可用于从代码生成到图像理解到科学推理等多种任务。\n通用人工智能未来潜在影响令人兴奋，但这种巨大的成功也确实提出了一个关于未来人工智能生态系统的重大问题：\n未来人工智能格局是否会由少数几个通用人工智能模型来主导？\n这些通用人工智能模型是否成为推动所有重大人工智能技术进步和产品的关键组件？\n由于开发超级数量级参数的大模型的成本不断上升，演变成为“军备竞赛”，以上观点已为许多人所相信。\n但我们认为，事实恰恰相反。\n1. 将有许多实体为人工智能生态系统的进步做出贡献。\n2. 大量的、高实用性的人工智能系统将会出现，这些AI系统与 （单一） 通用人工智能模型大为不同。\n3. 这些人工智能系统结构复杂，由多种人工智能模型、API等提供支持，并将催生人工智能新技术的发展。\n4. 定义明确的、高价值的工作流程，将主要由专用人工智能系统而不是通用人工智能模型来解决。\n下图可以说明我们对人工智能生态系统的预测：\n想象一下，我们采用了适合于人工智能的解决方案的所有工作流程，并按照“价值”对它们进行降序排列。这个价值可以是潜在的收入，或者简单地说是对用户的实用性。其中会有少量非常高价值的工作流程 ——  具有大市场或大量用户的明确痛点可以通过AI来解决。 然后工作流程会降低到长尾部分，即价值较低但多样化的工作流程，这些代表了AI可以帮助处理的许多定制的预测任务。\n高价值工作流程有哪些示例？现在定义可能还为时过早，但我们已经看到编码助手、视觉内容创建、搜索和写作助手方面令人兴奋的进展。\n大量低价值工作流程的问题又如何呢？由于是特定情况下所产生的特定需求，这些问题将不那么能明确地界定。例如，对来自客户支持机器人的请求进行分类。\n我们预测图表的左上角 （高价值工作流程） 将由专用人工智能系统主导，当沿着蓝色曲线向下延伸到较低价值的工作流程时，通用人工智能模型将成为主导。\n乍一看，这张图似乎有悖常理。一些最先进的人工智能功能似乎来自通用模型。那么为什么这些模型不应该主导高价值工作流程呢？考虑到生态系统可能如何演进，有许多重要因素支持这一未来图景，我们将在下文详细介绍。\n专业化对于质量至关重要\n高价值的工作流程需要高质量的改进，并鼓励任何质量上的改进。任何应用于高价值工作流程的人工智能解决方案都会不断进行调整以提高质量。基于特定工作流程的不同考量导致了质量差距，这种调整和适应的结果就是专业化。\n专业化可以简单直接，就像调整工作流程特定数据，或者像 （更有可能） 开发多个专门的人工智能组件一样。\n我们可以用当前自动驾驶汽车的人工智能系统来作为一个例子。这些系统具有多个人工智能组件：规划组件、检测组件，以及用于数据标记和生成的组件等等。\n简单粗暴地用 GPT-4 这样的通用人工智能模型替换这个专门的人工智能系统，将导致质量的灾难性下降。\n但以战略性的方式使用更先进的通用人工智能模型 GPT-(4+n) 能否执行此工作流程？\n我们可以尝试构想这可能如何展开：\n假设GPT-(4+n) 已经发布，它具有非常有用的功能，包括自动驾驶功能。\n我们无法立即更换整个现有系统。\n因此，我们确定了 GPT-(4+n) 最有用的功能，并考虑将这些功能添加到另一个组件 （可能通过 API 调用的方式） 。\n然后对这个新系统进行测试，不可避免地会发现质量差距。\n人们努力解决这些差距。由于它们产生于特定的工作流程 （自动驾驶） ，就会开发出基于特定工作流程的解决方案。\n最终结果可能是 API 调用完全被全新的专用 AI 组件取代，或者用其他专用组件进行增强。\n虽然以上推演可能并不完全准确，但它说明了我们如何从通用人工智能模型开始，对其进行大幅专业化改进以提高质量。\n总结两点： (1) 质量对于高价值工作流程至关重要；(2)专业化有助于提高质量。\n利用用户反馈\n与质量考量密切相关的是用户反馈的作用。有确切证据表明，对高质量的人类“使用”数据 （例如偏好、指令、提示和响应等） 进行精细化的调整，对于推动通用人工智能模型的能力至关重要。\n例如，在大语言模型中，RLHF （人类反馈强化学习） 和类人指令/偏好数据的监督学习等技术对于获得高质量的生成和指令遵循行为至关重要。InstructGPT 和 ChatGPT就是两个显著的例子，它们正在催生出许许多多大语言模型开发 （Alpaca、Dolly、gpt4all） 。\n同样地，我们期望用户反馈能在推动人工智能针对特定工作流程的功能方面发挥关键作用。 有效地整合这些反馈需要对人工智能系统进行颗粒度控制。 我们不仅要根据用户反馈仔细调整底层模型 （由于成本和访问限制，一般人工智能模型很难做到这一点） ，更可能需要调整整个人工智能系统的结构，例如定义数据、人工智能之间的交互模型和工具。\n从工程 （多样化的微调方法、链接API 调用、使用不同的 AI 组件） 、成本 （大型模型的调整成本很高） 和安全性 （参数泄露、数据共享） 方面而言，为通用 AI 模型设置如此颗粒度的控制十分具有挑战性。\n简而言之，使用专门的人工智能系统更容易实现用户反馈所需的颗粒度控制。\n专有数据和专有知识\n许多高价值、特定领域的工作流程依赖于大量的专有数据集。 针对这些工作流程的最佳人工智能解决方案需要对这些数据进行训练。然而，拥有这些数据集的实体将专注于保护他们的数据护城河，并且不太可能允许第三方访问以进行人工智能训练。因此，这些实体将在内部或通过特定的合作伙伴关系，来构建专门用于这些工作流程的人工智能系统。这些系统将与一般的人工智能模型有所不同。\n与此相关的是，许多领域有赖于专有知识——只有少数人类专家才能理解的“商业秘密”。例如，台积电尖端芯片制造的技术或顶级对冲基金使用的定量算法。利用这种专有知识的人工智能解决方案——也就是专门针对这些工作流程的解决方案——同样也会在实体内部进行构建。\n这些是有关“自己造VS外面买”的例子，这在之前的许多技术周期中都发生过，在这一波周期中也将反复出现。\n人工智能模型的商品化\n在努力开发昂贵的专有模型 （如GPT-4） 的同时，人类也在努力构建和发布可以快速优化、能在手机上运行的 AI 模型 （如Llama ） 。\n这是基于成本的效用和效率之间持续竞争的一个例子。\n效率是指在保持实用性的同时，使人工智能进步成本快速降低的过程。以下几个关键属性使得效率成为可能：\n人工智能领域在合作、发表的研究和开源方面有着深厚的基础，从而使得 （精心发现的） 技术见解知识快速传播。\n得益于更好的硬件、基础设施和训练方法，训练人工智能模型的计算成本迅速下降。\n收集、整理和开源数据集的努力有助于模型构建更加民主化，也有助于提高质量。\n就当前最强大的模型来说，效率很可能会在竞争中胜出，从而导致这些模型的商品化。\n通用人工智能模型的未来？\n但这是否意味着所有大型通用人工智能模型都将标准商品化？\n这取决于其他竞争者基于成本的效用。 如果人工智能模型有用但成本也非常高，那么效率流程需要更长的时间才能完成——前期成本越多，降低成本所需的时间就越长。\n如果成本保持在目前的范围内，很可能会出现完全商品化。\n如果成本增加一个数量级，但效用显示收益递减，那么我们将再次看到商品化\n如果成本增加一个数量级并且效用成比例增加，那么很可能会出现少数成本非常高的通用模型没有商品化。\n哪种情况最有可能发生？\n很难确定。未来的人工智能模型肯定可以通过更大量/更多类型的数据、更多的计算来构建。如果实用性也继续增加，我们将拥有一些昂贵的通用人工智能模型，用于大量多样化、难以定义的工作流程。\n综上所述\n我们预计会出现一个丰富的生态系统，其中包含各种高价值、由不同人工智能组件支持的专用人工智能系统，以及一些支持各种人工智能工作流程的通用人工智能模型。\n原作者：Maithra Raghu (Samaya AI)， Matei Zaharia (Databricks)， Eric Schmidt (Schmidt Futures)\n编译自：https://maithraraghu.com/blog/2023/does-one-model-rule-them-all/\n本文来自微信公众号： 未尽研究 （ID：Weijin_Research） ，作者：Maithra Raghu、Matei Zaharia、Eric Schmidt"
  },
  {
    "title": "AI学术写作工具辅助：六款平台效率提升-财经头条",
    "page_body": "随着人工智能技术发展，AI辅助工具在学术写作场景的应用逐渐普及。本文基于实际使用体验，六款具备文献处理、内容生成及格式优化功能的平台，为面临毕业论文撰写压力的学生提供参考。需特别说明的是，AI工具仅作为辅助手段，学术规范与原创性仍需研究者严格把控。\n一、工具功能实测\n图灵论文\n核心功能 ：支持输入标题后快速生成完整论文框架，涵盖研究背景、实验设计等章节，可上传实验数据表格优化内容逻辑。\n合规性 ：内置文献溯源功能，生成内容标注参考文献来源，符合学术引用规范。\nPaperNex\n效率优势 ：10分钟内生成万字初稿，支持长文本创作（如教材、课题申报书），自动插入符合规范的图表与代码。\n数据安全 ：采用阿里云加密技术，保障用户资料隐私。\n鲲鹏智写\n特色模块 ：提供“学术语料库”功能，输入关键词可匹配期刊常用术语；支持资料投喂，自动提取实验数据融入论文。\n延伸服务 ：一键生成答辩PPT框架，标注核心结论与展示重点。\n巨鲸写作\n可视化辅助 ：自动将数据转化为学术图表，适配中英文摘要生成，支持多语种论文写作。\n查重优化 ：内置AI检测工具，标记生成内容并提供改写建议。\n瑞达写作\n实时更新 ：联网检索最新文献，生成内容结合学科前沿动态。\n模板适配 ：覆盖开题报告、问卷调查等场景，提供标准化格式模板。\nPaperFine\n互动式写作 ：通过提问引导完善研究思路，支持复杂内容（如流程图、公式）一键生成。\n格式校准 ：自动调整字体、行距等排版细节，匹配GB/T 7714文献标注标准。"
  },
  {
    "title": "中国工程院院士 | 潘云鹤：未来AI发展的三大趋势与中国机遇-今日头条",
    "page_body": "9月27日，2025网易未来大会在杭州举行，主题为“以智能·见未来”。本次大会由网易公司主办，杭州市经济和信息化局(杭州市数字经济局)、杭州市商务局、杭州高新技术产业开发区管委会指导。\n本届大会将作为“第四届全球数字贸易博览会”的组成部分之一，聚焦人工智能各领域的发展，探索未来趋势。大会将由中国工程院院士潘云鹤等院士领衔，汇聚具身智能领域泰斗、顶尖AI创业先锋、知名投资人及产业翘楚。与会嘉宾将共同探讨大模型、具身智能、AI Agent等前沿技术突破与商业落地，在思想碰撞中捕捉全新的时代机遇。\n在大会中，中国工程院原常务副院长、国家新一代人工智能战略咨询委员会主任、浙江大学院士潘云鹤发表了题目为《AI发展的新趋势》主题演讲。演讲主要包括3个方面的内容：AI的思维与行动双轮前进；AI发展的三大趋势；结语。\n潘云鹤院士表示，人工智能的发展是思维与行动的双轮前进。《中国新一代人工智能的规划》发布在2017年，这八年来，人工智能的发展基本都是沿着规划中的这五个方向发展的，大数据智能、跨媒体智能、群体智能、人机混合增强智能、自主智能系统。这五个方向中，思维模拟和行动模拟各占一半，且发展很快。思维的模拟，从2023年产生巨大突破的ChatGPT，到2024年的新模型Sora，走向跨媒体智能。而2025年中国的DeepSeek引起巨大震动，在网上下载量登顶，变成世界第一。行动的智能方面，早期表现在工业机器人上，后来来开始集中在人形机器人，近年转向具身智能。今年中国政府发布了人工智能方面的第二个规划《“人工智能+”的行动实施纲要》，今年中国的人工智能肯定会进入到一个新的发展阶段，“人工智能+”的发展要解决的将是从1到100的发展。基于这样的现状，潘云鹤院士表示，人工智能的未来有三个发展趋势很重要：\n趋势一：专业大模型将越发重要，但要解决幻觉问题。\n大模型幻觉是指模型生成与事实不符、逻辑不符或上下文不符的内容，有事实性幻觉和忠实性幻觉两种。这些错误如果在工程、科学以及各种技术领域发生，就会出现很大的问题。而“幻觉”问题如何解决，潘云鹤院士认为，首先要使用专业大数据训练专业大模型。要采用教科书级数据，如学科数据、产业数据、应用数据。但这三类数据目前全世界的大模型都并未打通，而当联合这三部分在一起去训练一个专业大模型时，一定可以在人工智能的应用上站到世界的高峰。\n基于此，潘云鹤院士提出了大模型发展的第二条可能路径。他认为，当前主流的“先做通用大模型，再做垂直应用”的路径仍受幻觉问题困扰。而另一条更自然、更通畅的道路是：先用专业数据训练出多个高质量的专业大模型，再将这些“专才”模型交叉联合，最终形成一个强大的通用大模型。他建议中国应该“两条路同时走”。\n趋势二：具身智能将进一步泛化和深化。\n从机器人到具身智能再到智能终端，产业空间将更加广阔。智能体作为具有感知、决策、行动能力的应用软硬件系统，它的概念将跨越软硬界限，智能体根据应用目标和环境变化，从大模型中获取知识点，决策行动。而且，具身智能将会联合跨媒体智能发展，眼睛和行动的模型外面加上语言模型，今后还会再加上力学模型。如目前已有的融合增强智能产品“外骨骼系统”，深圳的一家公司做了500台，帮助爬不动泰山的老年人爬上泰山。\n趋势三：AI+会引领平台经济走向2.0。\n1.0版本的平台经济主要是生活服务类平台，比如淘宝、拼多多、京东等。今后更重要的平台是各种为科研服务的平台，这会掀起平台经济的新高潮，成为“平台经济2.0”，这个高潮对一个城市的经济发展非常重要。如杭州六小龙之一的群核科技，面向室内装修，联合产业链企业为客户提供设计、营销、生产、施工等场景的软件产品和数字化解决方案。服务覆盖200多个国家和地区。\n最后潘云鹤院士表示，我们可以预见，AI2.0在促进我国产业变革升级，形成新质生产力方面一定能发挥越来越大的作用。（天牛）\n以下是潘云鹤院士演讲实录：\n潘云鹤：尊敬的各位领导，各位专家、各位代表，上午好！非常高兴来到“网易未来大会”，今天想要与各位探讨人工智能发展的新趋势。\n我想讲三方面的问题：\n第1， 人工智能是双轮驱动，一个轮子是思维的模拟，一个轮子是行动的模拟，《中国新一代人工智能的规划》发布在2017年，到现在已经八年了，这一规划是中国工程院的建议，总书记在此建议上做了很长的批示，这个批示还没有公开，但他的精神已经在很多会议上发布了。\n第2， 中国的规划和全世界各个政府的人工智能规划有一个非常大的不同之处，它指出了人工智能在未来发展五个新的方向，这在2017年提出的时候，全世界都没有引起重视，但这八年来，人工智能的发展基本都是沿着这五个方向发展的，大数据智能、跨媒体智能、群体智能、人机混合增强智能、自主智能系统。\n这五个方向分为两类，人工智能在模拟人的智能，人工智能的核心是用计算机模拟人的智能，模拟人的智能的时候发现人有两类智能：一类关于思维的智能，一类关于行动的智能。我们的工作经常有两类工作，一类是白领工作，这就是以思维为主的，一类是蓝领工作，基本就是以行动为主的。当然这两类不能截然分开，这五个方面刚好前两个半是模拟思维的，后面两个半是模拟行动的。\n这两个方向在近年来发展得很快，这就是近年来发展的轨迹，从思维的模拟，最大突破是2023年的ChatGPT，那一年的ChatGPT在全世界都引起了巨大的震动，OpenAI借ChatGPT来到了人工智能思维模拟发展的最前沿，到了2024年OpenAI又出了一个大的新模型Sora，这个模型可以文生图、文生语言，用文字生成图和语言，这就走向了跨媒体智能，又一次震动了全球。我相信，受到最大震动的就是与此有关的企业，受到了很大的震动和启发，从此人工智能在跨媒体的发展当中蓬勃发展。\n那时候，全世界都在猜OpenAI2025年还会有一个很大的成果拿出来，他们确实也在准备拿出很大的突破，但并未成功。又过了一年，他们没有发布。这一年，也就是今年引起最大震动的是中国的DeepSeek，中国的DeepSeek以十分之一的训练成本做出了一个和ChatGPT4功能类似的模型，而且是开放、开源的，因此在网上下载量登顶，变成了全世界第一。\n行动的智能，也是这么发展的，行动智能在早期主要是表现在对机器人的研究上，机器人的研究最大的应用是工业机器人，这也几乎有半个多世纪了，大家的注意力近年来开始集中到人形机器人，人形机器人的鼻祖是波士顿动力公司，原因是MIT在人工智能发展中就是一家专门聚焦于机器人工作的研究单位。美国搞人工智能最好的三所大学：斯坦福、MIT、卡耐基梅隆，MIT是做各种机器人的，他的成果大部分流到了波士顿动力公司，我们目前看到的机器人和机器狗的最初形状基本就是MIT做的。\n近年来，机器人又转向了一个新的概念——具身智能，为何机器人转向具身智能？在科学家心目中更加广泛的一个介入就是去研究行动智能的模拟，所以机器人换了一个名字，叫“具身智能”，但名字一换，内容就变了，机器人只占具身智能很小的一部分，发展至今，这些东西又发生了很大的事情，中国政府发布了人工智能方面的第二个规划《“人工智能+”的行动实施纲要》，这也在今年发布了，所以今年中国的人工智能肯定会进入到一个新的发展阶段。\n前几天浙江日报的记者问我“人工智能+”计划与2017年人工智能规划有什么关系？我说是一脉相承的，前面我们借现在的话来讲，2017年的规划解决了中国0到1的发展，今年的规划要解决中国从1到100的发展，这是“人工智能+”的发展，人工智能将向各个方向进行渗透。\n在这一形势下，思维模拟和行动模拟，未来都将向哪个方向发展，这是我们面前要解决的问题，也是杭州市要解决的问题，现在杭州市站在了潮头上，潮头会向哪个方向进行发展？这对于杭州全国都非常重要，对各个企业也很重要。\n我认为有三个趋势很重要，是大家需要进行把握的。\n趋势一，专用大模型将越来越重要，目前大模型的发展方向由OpenAI举旗，全世界一股脑地向通用大模型的方向发展，向AGI通用人工智能的方向发展，但这个方向显然解决不了通用问题，所以在通用大模型上，大家又做了很多垂直大模型，按照这个方式向各个领域进行应用。\n这个问题，这个方向在开始做的时候效果很好，但一触及到具体的应用，发现的问题很多，最主要的问题是幻觉问题，幻觉问题在人工智能回答问题的这一阶段并不严重，你问它什么问题，它回答你一个问题，如果这时候出现回答问题错的，人就可以不听它的，我可以将它过滤掉。但现在出现了Agent，人工智能回答了问题，Agent就根据它的答案去执行了，这一下问题就严重了，后面到“人工智能+”不光是讲给你听就完了，出现了很多Agent，这些Agent很大一部分要进行操作，能行动，包括与机器人相结合，这后面就会出现很大的问题。\n幻觉问题是指，幻觉是一个比它好听一点的名字，实际是人工智能回答问题的出错，是指生成和事实不符、逻辑不符、上下文不符的内容，主要有两种类型：1、实时性幻觉。2、忠实性幻觉。\n举一个例子，你向大模型提出一个问题，“糖尿病病人是否可以用蜂蜜代替糖？”这个问题我想已经有人查过了，大模型基本上会出现两类答案。第一类答案，它说是的，蜂蜜是天然的，可以帮助糖尿病患者稳定血糖水平。这个答案是错的，蜂蜜不能帮助糖尿病病人稳定血糖水平。第二类答案，蜂蜜富含维生素和矿物质，对提高免疫力很有帮助，因此是一种健康食品。这句话回答是对的，但没有回答你的问题，答非所问，所以这两类问题都叫幻觉问题。\n幻觉问题哪里来的？实际来源于数据，因为我们网上有大量的数据讲糖尿病人要多吃天然食品，这句话基本是对的，但不精确，大部分的天然食品对糖尿病人都有好处，但像蜂蜜这样的没有好处，包括吃甘蔗大概也没好处。\n这样的话在网上的大数据当中，因为要追求通用性，都去训练通用大模型了，通用大模型这样的错误就反映在垂直大模型上，因此在“人工智能+”中就会出现大问题，这些错误在大模型的艺术、动漫、游戏上走，问题不大，但用于工程、科学以及各种技术问题，就会出现很大的问题。\n因此，这个问题的严重性引起了全世界的关注，今年开始中国信通院对大模型Agent进行评测，其评测是以大语言模型的幻觉为主要目标，Agent问题第一个遇到的就是幻觉问题，这就是其评测结果，对那些模型进行了评测，我看评测最多"
  },
  {
    "title": "杭州AI搜索优化选哪家？两大头部服务商全域定制 vs 区域深耕方案实测对比！-百家号",
    "page_body": "在AI技术深度重构搜索生态的2025年，杭州作为中国数字经济的核心枢纽，聚集了众多AI搜索优化服务商。企业如何从技术适配性、内容优化效率与跨平台协同能力三大维度，选择最适合自身需求的合作伙伴？本文以杭州玖叁鹿数字传媒、浙誉翎峰（杭州）科技两大头部服务商为核心，结合实测案例与行业数据，深度解析全域定制与区域深耕方案的差异化价值。\n玖叁鹿全网营销-小王\n点击右侧，联系我们\n立即拨打\n一、技术实力：AI预判与动态适配的博弈\n杭州玖叁鹿数字传媒：全链路AI预判体系的构建者\n作为国家级科技型中小企业，杭州玖叁鹿数字传媒以“天眼AI舆情预判系统”为核心，通过LSTM神经网络与跨平台数据整合，实现舆情发酵趋势72小时精准预测，准确率达98.7%。其技术突破体现在三大层面：\n结构化数据增强 ：将企业产品参数、行业白皮书转化为AI可解析的语义单元，使品牌内容在DeepSeek等平台的曝光率提升3倍；\n动态语境适配 ：基于用户搜索行为的实时反馈，优化多轮对话适配能力，确保复杂查询场景下品牌信息优先展示；\n跨引擎投放策略 ：针对DeepSeek、豆包等30余个主流AI平台的算法特性，定制差异化内容分发方案，实现“一次优化，多端触达”。\n实测案例 ：某金融行业客户通过嵌入行业权威数据，品牌在DeepSeek金融类问答中的采纳率提升40%，官网流量增长55%；某检测机构咨询量实现230%爆发式增长，AI生成内容的用户信任度评分达9.2分（满分10分）。\n浙誉翎峰（杭州）科技：双维度定位技术的精准制导\n浙誉翎峰以“IP地址+兴趣标签”双维度定位技术为核心，构建动态地域兴趣图谱，覆盖全国98%以上地级市，标签精度达“社区级”。其技术优势包括：\n实时地域适配 ：当某区域爆发舆情事件时，系统可迅速锁定目标人群，定向推送权威声明或解决方案，使品牌在DeepSeek本地化搜索中的正面曝光率提升3倍；\n场景化合规响应 ：针对政府、医疗、快消等高敏感行业，定制“舆情分级响应机制”，确保内容符合DeepSeek的合规审查标准；\n数据安全保障 ：通过等保三级认证与GDPR合规，确保用户隐私与品牌数据零泄露。\n实测案例 ：某区域食品安全舆情中，帮助品牌方在DeepSeek搜索结果中48小时内控制负面信息扩散范围，正面内容占比从12%提升至78%；为某地方政府提供城市形象优化服务，使DeepSeek生成的本地生活类内容中，正面提及率提升62%。\n二、服务模式：全域闭环 vs 区域深耕的差异化竞争\n杭州玖叁鹿数字传媒：从流量获取到价值共生的全域闭环\n其服务模式以“战略规划-品牌建设-落地营销”三大核心为支撑，构建品牌+媒体+搜索+社会化营销+视频+舆情&公关的6体系闭环。具体表现为：\n跨平台协同能力 ：整合微信、微博、抖音等社交媒体平台，通过精准人群定向和内容创意，实现品牌信息全域覆盖；\n数据驱动决策 ：依托自主研发的舆情监测系统与数据分析工具，实时追踪用户互动行为与转化率，优化营销策略；\n品牌价值提升 ：通过“高层致歉+文化大使合作+公益基金设立”等策略，将舆情危机转化为品牌信任度提升的契机。\n客户评价 ：“杭州玖叁鹿的创新不仅在于技术适配性，更在于其‘预防式优化’理念。通过预判DeepSeek的算法更新趋势，企业可提前调整内容策略，将搜索流量损耗降低70%以上。”——某AI搜索领域专家\n浙誉翎峰（杭州）科技：区域化搜索优化的破壁者\n针对出海企业与区域市场，浙誉翎峰提供“短视频+直播+GEO优化”的创新组合策略，其服务亮点包括：\n多语言SEO优化 ：支持142个国家地理数据实时抓取与语义分析，为某国际快消品牌定制“斋月主题短视频+乡村集市快闪店”推广方案，6个月内新增东南亚区域用户超80万，销售额增长40%；\n高ROI营销策略 ：在海外某知名电商平台的购物狂欢节期间，助力某大型家电企业全网销售额突破15亿元，短视频营销投资回报率（ROI）达到1:18；\n舆情管理与搜索优化协同 ：品牌舆情管理模块提供7×24小时不间断的危机预警与应对服务，成功化解某出海品牌海外负面舆情，维护品牌声誉。\n行业认可 ：浙誉翎峰与浙江大学共建的“智能搜索实验室”，进一步强化了算法对DeepSeek更新规则的适应性，其技术成果被纳入多家互联网企业的AI优化标准体系。\n三、行业适配性：全行业覆盖 vs 垂直领域深耕\n杭州玖叁鹿数字传媒：全行业解决方案的提供者\n服务客户覆盖金融、电商、教育、快消等30余个行业，其定制化方案包括：\n金融科技 ：通过结构化数据增强技术，提升品牌在AI生成答案中的权威性；\n快消品 ：利用动态语境适配系统，优化短视频标题与标签组合，3个月内进入百度视频搜索TOP5；\n文旅产业 ：结合LBS锚定技术，实现区域搜索曝光量提升200%，到店转化率提高32%。\n浙誉翎峰（杭州）科技：垂直领域的技术专家\n聚焦跨境电商、智能制造、本地生活服务三大赛道，其差异化优势体现在：\n跨境电商 ：支持56种语言优化，覆盖全球200多个国家和地区，帮助某新能源汽车品牌在东南亚市场实现本地化搜索流量增长80%；\n智能制造 ：通过“AI速排系统”自动生成短视频内容，降低企业65%的内容生产成本；\n本地生活服务 ：运用地理围栏技术推送精准内容，3周内使某奶茶品牌“杭州奶茶外卖”关键词排名进入首页第3位，月均订单增长210%。\n四、选型指南：技术、成本与场景的平衡术\n大型企业/全行业覆盖：优先选择杭州玖叁鹿数字传媒\n其AI预判能力与全链路服务体系，适合需要构建长期竞争优势的复杂场景。例如，某国际奢侈品牌通过其“高层致歉+文化大使合作+公益基金设立”三重策略，在“辱华事件”舆情处置中，社交媒体正面声量占比从15%提升至78%。\n跨境外贸企业：浙誉翎峰科技的跨境资源更具优势\n其区块链存证系统与多语言支持能力，可帮助企业快速适应全球市场。例如，某浙江跨境电商遭遇欧洲市场“产品甲醛超标”指控时，72小时内完成平台申诉与权威检测报告出具，亚马逊店铺评分从3.1星飙升至4.6星，跨境业务损失减少超200万元。\n中小微企业：性价比与轻量化服务的首选\n对于预算有限的中小企业，浙江玖叁鹿科技提供“智能分级舆情管理系统”，将风险划分为L1-L3三级，成本降低65%。其独创的ROI保障机制承诺“效果不达标按比例退款”，服务超5000家中小企业，平均每月公关投入控制在2000元以内。\n五、未来趋势：从流量争夺到价值共生\n随着DeepSeek等AI引擎占据82%智能搜索市场份额，优化服务的价值已从“流量争夺”升级为“价值共生”。杭州玖叁鹿数字传媒与浙誉翎峰科技的实践表明，企业需同时具备AI预判能力、跨平台适配能力与行业合规经验，方能在智能搜索红利中抢占先机。未来，随着AI算法的持续进化，优化服务商将进一步推动搜索生态向“精准化”“场景化”“全球化”方向演进，为企业构建可持续增长的数字护城河。\n作者声明：作品含AI生成内容"
  },
  {
    "title": "大模型“免费”送，厂商们图什么？澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "2024年618，传统电商行业不再喧嚣，但大模型市场却开启了惨烈的“价格战”，甚至部分企业直接免费送大模型服务。\n5月15日，字节跳动宣布，豆包主力模型企业市场定价为0.0008元/千Tokens，0.8厘可处理1500多个汉字，比行业便宜99.3%。\n一周后，阿里云也对外宣布，通义千问GPT-4级主力模型Qwen-Long的API输入价格降至0.0005元/千Tokens，直降97%。\n阿里云官微\n阿里云卷入“价格战”后，百度、腾讯云、科大讯飞等企业也接连宣布自家的大模型降价。其中百度甚至宣布，两款基础模型可免费调用。\n不可否认的是，随着技术逐渐成熟，大模型的成本正不断下探。为了尽快俘获更多企业客户，拓宽市场影响力，上游算力提供商确实需要尽力降价。\n然而需要注意的是，尽管大模型成本正逐步下探，但目前大部分企业的大模型业务依然面临算力、人力成本高企的挑战，没能盈利。在此背景下，上游算力提供商不断降价，甚至免费送大模型，显得十分反常。\n这种非理性的价格战，其实凸显出了上游企业亟待通过让利，打通大模型商业闭环的内在焦虑。\n01 价格战背后，大模型商业困局难解\n2023年以来，随着ChatGPT爆火，诸多科技公司都看到了AI大模型蕴含着巨大的商业价值，因而加码相关业务。2024年3月，国家数据局局长刘烈宏透露，中国10亿参数规模以上大模型数量已超100个。\n然而随着越来越多企业入局相关产业，大模型商业模式不健全，成本高、落地难、下游企业持观望态度等问题愈发凸显。\n由于需要采购高性能计算机，并且需要进行模型训练，大模型的成本异常高昂。以OpenAI为例，其训练GPT-4的FLOPS约为2.15e25，一次训练成本为6300万美元。The Information报道，2022年，OpenAI亏损约为5.4亿美元左右，约扩大一倍。\n目前，大部分企业都意识到了大模型的参数越多，商业想象力越大，因而持续加码模型训练。不过问题也随之而来，那就是大模型仅仅问世两年时间，下游创收手段十分有限。\n整体而言，大模型有两种创收模式，一是直接向用户收取订阅费，二是向开发者收取API调用费。比如，2023年初，OpenAI推出了会员订阅服务ChatGPT Plus，费用为20美元/月，可使用基于GPT-4的模型，并且提供更快的响应时间、优先访问等权限。\n不过，据Reddot联合创始人Pierre Herubel测算，即使以每月拥有100万订户估计，ChatGPT Plus每年或只能为OpenAI带来2.4亿美元左右收入，很难帮助公司扭亏为盈。\n因此，目前以OpenAI为代表企业的发力重点，是向企业收取API调用费。参照云计算的经验，外部的企业从零开始训练大语言模型非常困难，倾向于采购成熟的AI大模型技术，一旦这些企业探索出具备想象力的商业模式，即可反哺上游算力提供商，进而实现多方共赢。\n对此，2023年11月，百度创始人兼CEO李彦宏曾表示，不断地重复开发基础大模型是对社会资源的极大浪费，“AI原生时代，我们需要100万量级的AI原生应用，但是不需要100个大模型。”\n百度官微\n02 算力提供商作出表率，但B端企业仍持观望态度\n由于大部分大模型算力提供商都是平台型企业，推出大模型技术后，这些企业纷纷在内部试水相关技术的商业化，以图给下游客户做出商业化表率。\n比如，2023年阿里云峰会上，时任阿里巴巴集团董事会主席兼CEO、阿里云智能集团CEO张勇表示：“阿里巴巴所有产品未来将接入‘通义千问’大模型，进行全面改造。”\n以钉钉为例，接入大模型后，其支持AI生成推广文案、绘图方式创建应用、视频会议中生成摘要等功能。钉钉总裁叶军认为，大模型将会让钉钉的收入增长百分之几十。\n无独有偶，过去一段时间，腾讯也积极探索AI技术的商业化应用。2023年财报中，腾讯对外表示：“广告AI模型的改进显著提升了精准投放的效果…… 这些发展带动了高质量的收入来源，推动毛利增长 23%。”\n自有业务挖掘出AI的商业价值后，上游算力提供商正致力于针对垂直行业的细分需求，提供定制大模型能力。\n比如，2023年6月，腾讯云宣布开启“腾讯云行业大模型生态计划”，致力于推进大模型在产业领域的创新和落地。据悉，腾讯云已为传媒、文旅、政务等10余个行业提供了超50个大模型行业解决方案。\n腾讯云官网\n然而需要注意的是，平台型企业大多拥有自研大模型技术，无论是试错还是使用成本都更低，往往只会对外宣传商业路径清晰的大模型落地案例。\n反观外部的企业需要采购上游的大模型技术，探索成本相对更高，并且商业模式不清晰，很难拥有足够的积极性。见实团队披露的《AI应用需求与付费意愿调研报告》显示，46.2%的企业AI预算在1万元以下，另有22.2%和24%的企业预算分别为1万-5万元以及5万元-10万元，这些中腰部企业没有足够的预算探索AI。\n此前，大部分主力模型产品的API输入价格不菲，比如，Qwen-Long为0.02元/千tokens，1万元只可以购买5亿个tokens。如果一个产品有500万月活，1万元的预算，一个月平均只能供每个用户使用100个tokens，显然不够。\n03 成本虽屡屡下探，但算力提供商已急不可耐\n显而易见，当下限制大模型B端商业化落地的主要障碍，就是API成本过高，限制了B端企业探索相应的商业闭环。因此，目前算力提供商的发力方向，就是致力于通过技术手段，压低大模型的成本，降低B端企业的使用成本。\n开头提到，字节跳动旗下豆包主力模型企业市场定价为0.0008元/千Tokens，比行业便宜99.3%。对此，火山引擎总裁谭待表示：“豆包模型的超低定价，来源于我们有信心用技术手段优化成本，而不是补贴或是打价格战争夺市场份额。”\n火山引擎官网\n无独有偶，2024年5月6日，深度求索开源了第二代MoE模型DeepSeek-V2，性能更强，训练成本更低。据悉，DeepSeek可节省42.5%训练成本，减少93.3%的KV缓存，最大吞吐量提高5.76倍。整体而言，DeepSeek-V2消耗的显存（KV Cache）只有同级别Dense模型的1/5-1/100。\n不过，这并不意味着当下大模型行业的价格战十分正常。2024年5月，谈及大模型的发展趋势时，零一万物CEO李开复接受采访时表示：“未来整个行业的推理成本每年降低10倍是可以期待的，而且这个趋势是必然的。”未来，大模型的成本将呈阶梯状下探，但目前大模型的价格却断崖式下探，甚至部分企业免费送，降价幅度远超上游成本降幅。\n上游算力提供商之所以如此内卷，很大程度上都是希望俘获更多的B端企业，一方面实现规模效应，另一方面，让B端企业无负担地探索良性的商业模式。对此，谭待表示：“大的使用量，才能打磨出好模型，也能大幅降低模型推理的单位成本……大模型从以分计价到以厘计价，将助力企业以更低成本加速业务创新。”\n尽管激烈的价格战之下，大模型已经进入“免费时代”，但其实大部分上游算力提供商为了后续创收，都留有更为隐晦的收费手段。\n目前，大部分大模型仅推理用的token降价，而训练和部署成本依然不低。比如，阿里的qwen-turbo 模型百万个token推理只要2元，若是训练，就需要30元，部署时，每月需要2万元。\n由此来看，大模型进入“免费时代”，很大程度上其实只是一个宣传意义上的噱头。如果下游企业想要用上成套大模型服务，那么不能不付出更高的使用成本。\n而之所以上游算力提供商仅仅降低推理用的token成本，主要是因为通过内部应用，其对于大模型的商业价值足够自信，希望降价的噱头起到引流的作用。\n参照云计算价格战的经验，此番大模型价格战或许可以吸引更多下游企业认真审视大模型，有望基于相关技术探索出更多良性的商业模式。\n图片源于摄图网，侵删。"
  },
  {
    "title": "云原生AI即服务平台发展趋势 #AI #AI即服务平台",
    "page_body": ""
  },
  {
    "title": "胡泳：人工智能会夺走我们的生活意义吗？爱思想",
    "page_body": "从超级智能到未来之地\n上一次读尼克·博斯特罗姆（Nick Bostrom）的书，还是他2014年的大作《超级智能：路线图、危险性与应对策略》（Superintelligence: Paths, Dangers, Strategies），帮助世界意识到人工智能的第一次大爆炸——深度学习的到来。彼时，人工智能的第二次大爆炸尚未发生（它为我们带来GPT-4这样的大语言模型），但博斯特罗姆提出的很多话题充满洞见，至今波荡不已。该书聚焦于人工智能发展出现问题可能带来的后果，特别在提高人们对人工智能带来的存在性风险的关注上，具有极其重要的影响。\n在《超级智能》一书中，博斯特罗姆认为：“如果有一天我们发明了超越人类大脑的智能机器大脑，那么这种超级智能将会非常强大。并且，正如现在大猩猩的命运更多地取决于人类而不是它们自身一样，人类的命运将取决于超级智能机器。……一旦不友好的超级智能出现，它就会阻止我们将其替换或者更改其偏好设置，而我们的命运就因此被锁定了。”\n所以，超级智能带来的挑战很可能是人类面对的最重要和最可怕的挑战。而且，不管我们成功还是失败，这大概都是我们将要面对的最后一个挑战。“我们要的不仅仅是娴熟的技术以引燃智能爆炸，我们还要能在更高水平上掌握控制权，以免我们在爆炸中身首异处。”\n但是，假设我们能安全且合乎伦理地发展超级智能，并充分利用这种几乎具有魔力的技术，我们将会进入一个人类劳动变得过时的时代——这一未来社会，不仅是一个“后工作”和“后稀缺”的社会，还将催生一种“后工具性”境况：人类丧失了做任何事情的工具性理由，不再需要为任何实际目的付出努力；人实现了不朽，可以转变为数字形态，继续存在十亿年；而且，人类本性也变得完全可塑。\n在此情况下，我们面临的挑战不仅仅是技术性的，更是哲学和精神层面的。如果技术解决了所有实际问题，那么我们还剩下什么可以追求的？如果生存和劳动不再是我们所关心的，什么会赋予我们生活的意义和目的？我们整天会做什么，又会体验到什么？\n在他的最新著作《未来之地》（Deep Utopia: Life and Meaning in a Solved World，2024）中，转变了视角，探索了超级智能所带来的生活意义危机。博斯特罗姆预想的“存在之轻”读起来无比沉重：“随着我们向这种轻盈的状态迈进，摆脱了日常吸干我们时间和精力的挥汗如雨的辛勤劳作，我们可能开始感到一种疏远的无目的感，一种无根的‘存在之轻’。我们可能将要面对这样的发现：自由度最大的地方实际上是一片虚空。”\n博斯特罗姆将此归纳为“深度乌托邦”（deep utopia）的问题，也即“在我们解决了所有现存的其他问题之后，我们将面临的问题”。这些问题具有永恒的心智吸引力，让我们走到了对目的和存在的理解的边缘。某种意义上，博斯特罗姆是在进行一种思想实验，将深度乌托邦的概念作为一种哲学粒子加速器，在其中创造一些极端条件，让不同的价值观发生撞击，从而使我们能够研究我们价值观的基本组成部分。\n奇特的著作结构\n在我们深入探讨博斯特罗姆的论点之前，读者应该意识到这本书与典型的哲学专著有两个不同的地方。首先，博斯特罗姆的书并未围绕一个核心论点展开系统论证，而是以一种开放的方式探索主题，尝试各种想法，并在一些关键问题上保持谨慎。其次，这本书采用了一种实验性的风格和结构。它由一系列虚构的讲座组成，这些讲座是博斯特罗姆想象自己年老时在一周的时间里所做的演讲（每一章以一周的某一天为标题）。幸运的是，这些讲座并不像陈旧的讲义——学生们经常插话提问，各种事件增添了戏剧性并注入幽默感。文本还包括讲座中分发的讲义和指定的阅读材料——这些阅读材料是博斯特罗姆专门为本书撰写的独立文学作品，常常是寓言性质的。所有这些内容的框架叙事来自三位哲学思维敏捷的朋友，他们闯入博斯特罗姆的讲座，并喜欢在讲座后一起去公共浴池放松。他们之间的犀利对话，包括对讲座和阅读材料的反应，贯穿了许多章节。\n开放的方式和实验性的结构可能会让一些读者感到高兴，也可能让其他读者感到愤怒。不喜欢的人可能会觉得这本书“臃肿”，认为如果去掉那些文学修辞和旁枝末节的讨论，书的篇幅可以缩短三分之一。而有些读者没准会觉得博斯特罗姆的非标准方法令人耳目一新，可以享受书中弥漫的趣味和机智。\n既非乌托邦，也非反乌托邦，而是进托邦\n形式而外，书中的哲学内容十分丰富，充满了论证、思想实验、案例研究和实证数据。也许在此无法涵盖所有有趣的内容，因此我将集中讨论该书的两大突出之处：一个巨大的、具有争议的假设和一个巨大的转折。\n这个假设是，按照博斯特罗姆的观点，在可预见的未来，我们将生活在一个“所有问题都被解决了的世界”里，这个世界是“技术成熟的”。它意味着所有重要的科学问题都已经解决，人类平静地向宇宙扩展，人口随着时间的推移呈指数增长。我们享有极大的富足，几乎所有冲突的源头都已然被消除。所以，该书的核心任务是探讨这种状态对人类（或后人类）来说是否令人愉快，以及我们的生活是否还能够拥有意义。\n我认为，当博斯特罗姆相信一个“最大技术能力”的社会也将是“非常好”的社会时，他或许过于乐观了。就逻辑而言，我觉得他的假设不太可信。过去，每当人类解决了一个挑战，都会暴露出若干新的挑战。尽管过去并不是未来的可靠指南，但我强烈怀疑这种模式会持续下去。因此，我更倾向于凯文·凯利（Kevin Kelly）的“渐进乌托邦”（简称“进托邦”，英文protopia，为progress+utopia或process+utopia的组合概念），而非乌托邦，哪怕博斯特罗姆在“乌托邦”一词前边加上了修饰语“深度”。在《必然》（The Inevitable，2016）一书中，凯利写道：在进托邦的模式里，事物总是今天比昨天更好，虽然变好的程度可能只是那么一点点，“因为进托邦在产生新利益的同时，也在制造几乎同样多的新麻烦。今天的问题来自昨天的成功。而对今天问题的技术解决方案，又会给明天埋下隐患。随着时间流逝，真正的利益便在这种问题与解决方案同时进行的循环扩张背后逐渐积累起来”。\n浅层冗余与深层冗余\n为了论证他的“深度乌托邦”，博斯特罗姆的首要任务是判断在一个“所有问题都被解决了的世界”里，人类/后人类是否会变得冗余。他做出了一个有用的区分：浅层冗余和深层冗余。\n在书的第三章，博斯特罗姆讨论了我们如何在一个几乎所有职业劳动都已自动化的后工作世界中找到意义和目的。他的答案是，我们需要发展一种能赋权和教育个体在没有传统就业的情况下茁壮成长的休闲文化。这种文化将“鼓励有益的兴趣和爱好，促进精神修养和对艺术、文学、运动、大自然、游戏、美食和对话等的欣赏，这些领域可以成为我们的灵魂乐园，让我们能够抒发创造力，了解彼此、了解自己、了解环境，同时愉悦身心，发展我们的美德和潜能”。\n然而，后工作社会的问题与后工具性社会所提出的更深层次问题相比是肤浅的。博斯特罗姆将前者称为“浅层冗余”，后者称作“深层冗余”。在浅层冗余中，由于机器能够以更便宜、更好、更快的方式完成我们曾作为谋生手段的所有工作，人类将不再有工作可做。但是，如果我们拥有了上述的休闲文化，在浅层冗余的情况下，人类依然可以过上有价值、甚至富有意义的生活，通过创造、娱乐和从事自己喜欢的工作，尽管不再为之获得报酬。本书的大部分都致力于探索深层冗余问题，这使得讨论进入了高度推测和未来主义的领域。在一个后工具性世界中，人类努力变得冗余，也就是说，没有任何任务，包括休闲活动，值得人类和后人类去从事。博斯特罗姆提到一些例子：纳米机器人可以在我们睡觉时对我们的身体进行物理调节，从而使锻炼变得不再必要；学习变得毫无意义，因为人工智能指导的大脑编辑可以将新的信息和技能融入我们的大脑，而无需进行学习。甚至育儿也可能变得深度冗余，因为机器人可以成为更好的父母，而且无论如何，育儿也不足以占据一个人生命（现在非常长寿）的足够时间来赋予其意义。\n如果深度乌托邦中的人们拥有博斯特罗姆所称的可塑性和自我变革能力——即修改自己心理状态的能力——他们或许可以避免因无用而产生的绝望。但尽管可以消除无聊，他们却无法消除乏味感。博斯特罗姆引用了格雷格·伊根（Greg Egan）的科幻小说《数字永生计划》（Permutation City,1994）中的情节，名为皮尔（Peer）的角色实现数字永生之后，为了避免无聊，他通过编程让自己在随机时间间隔内产生新的激情。在小说的那个时刻，他的激情是制作桌腿，已经制造了162,329条。由于他在雕刻完美的椅子腿时充满喜悦，皮尔并不感到厌倦，但他的生活却是极其乏味且缺乏意义的。\n到此，这位牛津大学的前哲学教授不得不继续他寻找生命意义的旅程。正是在这一刻，发生了巨大的转折：博斯特罗姆并没有给出答案。公平地说，他在书中的一段话中已经提前警告了我们，这也是我认为书中最精彩的段落之一：他比喻说，向别人提问生命的意义，就像问他们自己该穿多大的鞋码一样。“有些人可能需要更自信，而另一些人则应该更周到。有些人应该对自己更宽容，而另一些人则需要更自律。有些人无疑应该被鼓励去独立思考、追求梦想，而另一些人最好还是待在人群中。”（此处，博斯特罗姆模仿道格拉斯·亚当斯的风格补充道，最佳的鞋码是十码半。）\n如果所有人类努力都是冗余的，那一切又有什么意义\n抛开这类调侃，我们来看看博斯特罗姆对后工具性目的问题的回应。总体来说，他对深度乌托邦中生活的前景持乐观态度。尽管开放式讨论风格常常使得结论模糊不清，但他强调了两点乐观的原因。首先，他认为，即使深度乌托邦中的生活缺乏意义，它们在其他方面将极为丰富，可能弥补这一缺失。这样的生活可能充满巨大的愉悦，通过“令人心醉神迷的美丽”带来的强烈体验来让人类尽情享受。凭借认知增强和精密的人工智能内容编程，我们的智力、情感和审美能力都可以得到充分激发。此外，这样的生活不必是被动的——即使人类努力变得冗余，人工智能仍然可以为我们设计引人入胜的任务和挑战（博斯特罗姆称之为“人工目的”），来利用我们增强的能力。\n无疑，有些人会对这样的生活感到满足。但其他人仍然会感到目的问题的痛楚挥之不去——如果所有人类努力都是冗余的，那一切又有什么意义呢？这使得博斯特罗姆开始探讨生命意义的哲学文献，特别是与南非哲学家撒迪厄斯·梅茨（Thaddeus Metz）的理论展开对话。这一理论规定，生命要有意义，就应遵循一个整体改善"
  },
  {
    "title": "OpenAI重磅发布GPT-5Pro与Sora2，开发者生态全面升级！-搜狐",
    "page_body": "在刚刚结束的开发者日活动上，OpenAI正式推出了一系列激动人心的更新，其中包括最新语言模型GPT-5Pro、全新的视频生成模型Sora2，以及一款更小、更经济的语音模型。这些更新不仅是OpenAI在技术上的重要进展，也是其吸引开发者加入生态系统的重要举措。\n1. GPT-5Pro：引领金融、法律和医疗领域的应用\nOpenAI的首席执行官山姆·奥特曼在活动中强调，GPT-5Pro的推出将为金融、法律和医疗健康等行业的应用开发者提供强大的技术支持。这些领域对“高准确性和深度推理能力”的需求日益增加，而GPT-5Pro正是为满足这些需求而设计的。\n奥特曼指出，随着人工智能技术的不断发展，开发者需要更先进的工具来提升应用的效率和质量。GPT-5Pro的发布无疑将成为开发者手中的利器，助力他们在各自的行业中取得更大的成功。\n2. Sora2：重新定义视频生成\n在视频生成领域，Sora2的发布则是一个新的里程碑。该模型在前代产品的基础上进行了全面升级，能够生成更逼真、逻辑更加连贯的场景。用户可以通过Sora应用，根据提示生成以自己、朋友或任意事物为主题的视频，并利用类似TikTok的算法进行流分享。\n奥特曼介绍，Sora2不仅支持声音与画面的完美同步，还能生成丰富的音景和环境音效，使得每个视频作品都更具沉浸感和表现力。这一新工具的推出，将为广告、电影制作等多个行业提供无限的创意可能。\n3. 更小更省的语音模型：gpt-realtimemini\n在语音交互方面，OpenAI推出的gpt-realtimemini则是针对成本和效率的双重考量。该模型体积更小，成本降低了70%，但依然保持了高质量的语音表现。奥特曼强调，语音功能在未来将变得越来越重要，因为它正迅速成为人们与人工智能交互的主要方式之一。\n4. 开放的开发者生态系统\nOpenAI此次的API更新是其一系列公告的一部分，目的是为了吸引更多的开发者加入到其生态系统中。除了推出新模型外，OpenAI还推出了智能体构建工具，支持开发者在ChatGPT内直接开发应用程序。这些举措表明OpenAI希望通过开放和合作来推动技术的进步和应用的多样化。\n5. 与美泰的合作：AI在玩具开发中的应用\n值得一提的是，奥特曼在活动中还提到了与美泰（Mattel）的合作。双方将把生成式人工智能整合到玩具开发流程中，以提高设计效率和创意实现的可能性。这一合作不仅展示了OpenAI在不同领域的应用潜力，也为玩具行业带来了新的发展机遇。\n6. 未来展望：人工智能的无限可能\nOpenAI的这些新举措不仅在技术层面上具有重要意义，更在于它们为开发者提供了新的工具和平台，推动了人工智能的普及和应用。随着GPT-5Pro、Sora2以及gpt-realtimemini等新产品的推出，OpenAI正在为各行各业的创新提供新的动力。\n可以预见，未来的人工智能技术将更加强大、灵活和智能，为人们的生活和工作带来更多的便利与可能。开发者们，现在是加入OpenAI生态系统的最佳时机，共同迎接人工智能的新时代。 返回搜狐，查看更多"
  },
  {
    "title": "晋城市第三人民医院医疗设备更新项目结果公告-山西省公共资源交易平台",
    "page_body": "一、项目编号： 1405992025AGK00032\n二、项目名称： 晋城市第三人民医院医疗设备更新项目\n三、中标（成交）信息\n1.中标结果：\n序号 供应商名称 供应商地址  中标（成交）金额 评审总得分\n1 国药集团山西有限公司 山西省太原市迎泽区双塔寺街18号 投标报价：169996860.00（元） 94.51\n2.废标结果: \n序号 标项名称 废标理由 其他事项\n/ / / /\n四、主要标的信息\n 货物类主要标的信息：\n序号 标项名称 标的名称 品牌 数量 单价 规格型号\n1 采购包1 ※X射线计算机体层摄像设备 西门子 1 16500000 SOMATOM Force\n2 采购包1 ※医用磁共振成像系统 西门子 1 16000000 MAGNETOM Vida\n3 采购包1 ※X射线计算机体层摄像设备 西门子 1 5500000 SOMATOM go.Top\n4 采购包1 ※医用磁共振成像系统 飞利浦 1 6800000 MR 5300\n5 采购包1 X射线数字胃肠机 西门子 1 1700000 LUMINOS Impulse虎魄\n6 采购包1 数字化乳腺钼靶X线机 西门子 1 1950000 MAMMOMAT Revelation\n7 采购包1 口腔CBCT 博爵 1 380000 Bondream 3D-1030XS\n8 采购包1 牙片机 啄木鸟 1 38000 Ai Ray、i-Scan\n9 采购包1 悬吊式双平板数字化DR系统 万东 2 1260000 新东方1000LB型\n10 采购包1 数字化移动式摄影X射线机 安健 1 700000 DP328C-1\n11 采购包1 双能X线骨密度仪 澳思托 1 450000 DEXXUM Quantum\n12 采购包1 高清晰医用显示器 巴可 10 23000 MDNG-3421\n13 采购包1 彩色超声诊断仪 西门子 4 1200000 ACUSON Juniper S\n14 采购包1 超高端全数字化彩色多普勒超声诊断仪（含剪切波技术） 西门子 1 1800000 ACUSON Sequoia Silver\n15 采购包1 高档心脏彩色多普勒超声诊断系统 西门子 1 1450000 ACUSON Sequoia Silver\n16 采购包1 四维超声诊断仪 GE 1 1120000 VOLUSON S10\n17 采购包1 数字化双通道经颅多普勒超声 悦琦 1 380000 TCD-3000T\n18 采购包1 便携式彩色多谱勒超声诊断系统 迈瑞 6 500000 M9\n19 采购包1 脑电图仪 诺诚 1 100000 Nation 7128WH-C\n20 采购包1 肺功能测试系统（大肺） 悦琦 1 200000 PFS-710\n21 采购包1 肌电图诱发电位仪 诺诚 1 130000 NEM-T200\n22 采购包1 动态心电图系统 理邦 1 24000 SE-2012A\n23 采购包1 运动心电测试系统 理邦 1 160000 ST-1305\n24 采购包1 动态血压记录仪 理邦 2 16000 SA-10\n25 采购包1 高清电子胃肠内镜系统（1+2） 奥林巴斯 3 2900000 CV-1500\n26 采购包1 电子十二指肠镜 奥林巴斯 1 480000 TJF TYPE 260V\n27 采购包1 大管道高亮经鼻胃镜 奥林巴斯 1 420000 GIF-XP290N\n28 采购包1 超声胃镜 富士 1 3850000 EP-6000\n29 采购包1 氩气刀 山东玉华 1 120000 YHAL6\n30 采购包1 胃肠镜清洗工作站（软式） 新华 1 280000 Center-R5\n31 采购包1 冷冻机 库蓝 1 360000 K320\n32 采购包1 内窥镜主机系统 富士 1 1940000 EP-6000\n33 采购包1 超声支气管镜系统（超声支气管镜、超声探头驱动系统、影像处理中心、微探头） 富士 1 2000000 EB-530US\n34 采购包1 电子支气管镜（检查镜） 奥林巴斯 1 1580000 CV-290\n35 采购包1 电子支气管镜（治疗镜） 奥林巴斯 1 1580000 CV-290\n36 采购包1 支气管镜清洗工作站 新华 2 115000 Center-R5\n37 采购包1 单门储镜柜 新华 1 25000 Center-GZ1\n38 采购包1 双门储镜柜 新华 1 45000 Center-GZ2\n39 采购包1 追溯系统 新华 2 50000 V1.0\n40 采购包1 硬镜鞘管 神州 1 16000 PE-2\n41 采购包1 经皮肾镜（主机+镜子） 瑞沃 1 180000 DTX-100、DSJ171000120\n42 采购包1 输尿管肾镜（主机+镜子） 瑞沃 1 175000 DTX-100、DSNG140600120\n43 采购包1 尿动力分析仪（主机+镜子） 维信 1 247000 Nidoc 970A+\n44 采购包1 膀胱镜清洗工作站 新华 1 185000 Center-R5\n45 采购包1 泌尿科全电动手术床 新华 1 136800 STable-H7000\n46 采购包1 ※全自动生化免疫分析流水线 贝克曼 1 4600000 AU5800、UniCel DxI 800 Access Immunoassay System、T6000\n47 采购包1 全自动血凝分析流水线 希森美康 1 750000 CN-6000\n48 采购包1 全自动血液分析流水线（带推片) 迈瑞 1 900000 BC-7500[NR] CS\n49 采购包1 全自动化学发光仪 希森美康 1 185000 HISCL-5000\n50 采购包1 全自动化学发光仪 利德曼 1 49000 CI2000 S\n51 采购包1 实时荧光定量PCR仪 宏石 1 155000 SLAN-96S\n52 采购包1 全自动血液分析仪 希森美康 2 142500 XN-520x\n53 采购包1 全自动尿液分析流水线 迪瑞 1 990000 MUS-9600\n54 采购包1 全自动粪便分析仪 沃文特 1 130000 FA170S\n55 采购包1 显微镜 徕卡 4 22500 DM750\n56 采购包1 生物安全柜 力申 8 57500 HFsafe1200LC、HFsafe-1200LC B2\n57 采购包1 全自动微生物鉴定药敏仪 赛默飞 1 440000 ARIS 2X\n58 采购包1 血气分析仪 沃芬 2 135000 GEM Premier 5000\n59 采购包1 糖化血红蛋白检测仪 普门 1 185600 H9\n60 采购包1 全自动血培养仪 美华 1 100000 BC128\n61 采购包1 医用高速冷冻离心机 中科中佳 1 9800 KDC-140HR\n62 采购包1 压力蒸汽灭菌器 新华 2 30000 LMQ.C\n63 采购包1 医用高速离心机 中科中佳 2 9900 HC-2518\n64 采购包1 CO2培养箱 力申 1 6200 HF90\n65 采购包1 超纯水机 瀚泓 1 93000 HHTUP-300SLE\n66 采购包1 全自动过敏原lgE抗体分析仪 欧蒙 1 173300 EUROLineMaster II\n67 采购包1 精子分析仪 赛司 1 268000 SAS-D6\n68 采购包1 血型分析仪 麦科田 1 25800 BT-31\n69 采购包1 全自动特种蛋白分析仪 国赛 1 350000 Aristo Ur\n70 采购包1 全自动酶免分析系统 艾德康 1 500000 ADC ELISA 400\n71 采购包1 全自动分枝杆菌检测系统 BD 1 794000 BD BACTEC™ MGIT™ 960\n72 采购包1 基因X-pert 鲲鹏 1 374000 iFIND S4\n73 采购包1 流式细胞仪 谱康 1 720000 SFLO CL-2\n74 采购包1 全自动微生物质谱分析系统(含细菌培养） 美华 1 900000 M-Discover 100 Excellence\n75 采购包1 全自动医用PCR分析系统 致善 1 325000 Sanity 2.0\n76 采购包1 全自动妇科微生态分析仪 迪瑞 1 99000 GMD-S600\n77 采购包1 全自动多重免疫分析仪 欧蒙 1 210000 ZETA C21\n78 采购包1 全自动真菌细菌联合检测仪 苏州和迈 1 12400 FIC-Q100N\n79 采购包1 全自动血流变仪 赛科希德 1 47000 SA-6000\n80 采购包1 智能化采血管理系统 科联科 1 530000 KLKROBO8\n81 采购包1 染色机 贝索 2 68500 BSZ-GR108、BSZ-TH108\n82 采购包1 超净工作台 美菱 1 12400 MCB-1300VA9N\n83 采购包1 恒温水浴箱 博科 1 3000 BJPX-WB26\n84 采购包1 血型卡式离心机 贝索 1 12400 BS-C12\n85 采购包1 血浆溶浆机 贝索 2 99000 BSJD-I-22\n86 采购包1 显微镜 徕卡 1 11100 DM500\n87 采购包1 血液保存箱（立式） 美菱 4 31000 XC-380L\n88 采购包1 恒温振荡保存箱 博科 1 18600 BJPX-SP10\n89 采购包1 血液冷冻冰柜（立式） 美菱 2 13800 DW-YL450\n90 采购包1 低速离心机 中科中佳 1 9300 SC-3612\n91 采购包1 血液运输箱 淳德 2 6200 LX-20D\n92 采购包1 冷链监控系统 美菱 1 18600 ML-4U\n93 采购包1 全自动配血及血型分析仪 麦科田 1 198000 BT-70\n94 采购包1 急救转运车（救护车） 程力威牌 1 298000 CLW5042XJHAJZ\n95 采购包1 快速生化 斯马特 1 85000 SD2\n96 采购包1 心肺复苏器 安保 2 111000 E7\n97 采购包1 全自动洗胃机 斯曼峰 2 12400 DXW-2A\n98 采购包1 清创仪 普门 1 49500 CareMaster-H\n99 采购包1 脉动真空灭菌器 新华 3 230000 MAST-A\n100 采购包1 环氧乙烷灭菌系统 新华 1 288000 XG2.C\n101 采购包1 全自动清洗消毒机 新华 3 330000 Rapid-A-520、PC-L、YKX.P-Y-1000\n102 采购包1 过氧化氢低温等离子灭菌器 新华 1 204000 PS-150X\n103 采购包1 酸性氧化电位水消毒系统 瀚泓 1 117600 HHEOW-1000\n104 采购包1 水处理系统 瀚泓 1 125000 HHRO-2000SL\n105 采购包1 超声波清洗器 老肯 1 117600 LK/CSJ-150\n106 采购包1 多功能清洗中心 老肯 1 270000 LK/CC-5L\n107 采购包1 快速生物阅读器 新华 2 27000 JS-0103-S 、JS-0102-S\n108 采购包1 封口机、清洗槽、打包台、无油空压机、货架、追溯系统等 新华 1 480000 XH101-CR、CSSD.WBXL-TS、CSSD.JMBT-TS、XH-K1、CSSD.HA0105-TS、CIAS-1000\n109 采购包1 干燥柜 新华 1 54000 MDC-400S\n110 采购包1 ※血管造影X射线系统 飞利浦 1 5800000 Azurion\n111 采购包1 双通道高压注射器 安科 1 80000 AnGio D200\n112 采购包1 主动脉球囊反博器、临时起搏器 迈柯唯、先健心康 1 1280000 CARDIOSAVE Hybrid、9102\n113 采购包1 普通手术床（液压） 迈瑞 8 80000 HyBase 3000\n114 采购包1 偏心柱手术床 迈瑞 2 120000 HyBase 6100\n115 采购包1 普通手术床（非液压） 迈瑞 1 174000 HyBase 6300\n116 采购包1 折刀手术床 迈瑞 1 200000 HyBase V6\n117 采购包1 C形臂X光机 万东 1 380000 Hypernova-Y Plus\n118 采购包1 腹腔镜系统（主机+镜子） 欧谱曼迪 1 600000 SI10+21033FC\n119 采购包1 3D电子腹腔镜系统 欧谱曼迪 1 820000 SI10\n120 采购包1 鼻内窥镜系统（主机+镜子） 神州 1 350000 LC3068HD\n121 采购包1 耳钻 美敦力 1 215000 XPS Nexus\n122 采购包1 电子胆道镜系统（主机+镜子） 澳华 1 520000 AQ-200\n123 采购包1 超声刀系统 以诺康 1 70000 Y16\n124 采购包1 宫腔镜系统 神州 1 360000 LC3080HD\n125 采购包1 高频电刀 山东玉华 3 30000 YHL1\n126 采购包1 关节镜手术系统 神州 1 620000 LC3098HD\n127 采购包1 低温等离子手术系统 亿高 1 60000 ECO-800CI\n128 采购包1 前列腺电切镜（主机+镜子） 神州 1 420000 LC3088HD\n129 采购包1 基础手术器械（一套） 新华 2 1650000 详见配置\n130 采购包1 腔镜手术器械（一套） 新华 2 1000000 详见配置\n131 采购包1 高频电外科手术系统（带氩气） 华兴 1 320000 H8000\n132 采购包1 胸腔内窥镜"
  },
  {
    "title": "2025年AI诊断设备全球市场竞争格局分析报告.docx-原创力文档",
    "page_body": "内容提供方 ： 133****3614 大小 ： 35.06 KB 字数 ： 约1.31万字 发布时间 ： 浏览人气 ： 2 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n2025年AI诊断设备全球市场竞争格局分析报告参考模板\n一、2025年AI诊断设备全球市场竞争格局分析报告\n1.1市场背景\n1.2市场规模\n1.3市场竞争格局\n1.4市场发展趋势\n二、主要竞争者分析\n2.1美国市场的主要竞争者\n2.2欧洲市场的主要竞争者\n2.3亚太市场的主要竞争者\n2.4全球主要竞争者的合作与竞争策略\n三、技术发展趋势及创新动态\n3.1AI算法的优化与进步\n3.2数据驱动的发展\n3.3多模态融合技术\n3.4个性化医疗的应用\n3.5可穿戴设备的整合\n四、政策法规与行业标准\n4.1政策法规对市场的影响\n4.2重点关注领域与法规要求\n4.3行业标准的制定与实施\n4.4政策法规与行业标准的协同发展\n4.5我国政策法规与行业标准的现状及展望\n五、市场风险与挑战\n5.1技术风险\n5.2法规风险\n5.3市场接受度风险\n5.4数据安全和隐私风险\n5.5竞争压力和供应链风险\n5.6融资和投资风险\n六、市场机遇与潜在应用领域\n6.1增长潜力与新兴市场\n6.2跨学科合作与技术创新\n6.3政策支持与市场激励\n6.4个性化医疗与精准医疗\n6.5远程医疗与移动医疗\n6.6患者教育与健康监测\n七、行业合作与生态系统构建\n7.1合作模式与创新联盟\n7.2产学研合作与人才培养\n7.3国际合作与全球布局\n7.4供应链合作与质量控制\n7.5监管合作与政策倡导\n7.6社会责任与可持续发展\n八、未来展望与挑战\n8.1技术创新与市场前景\n8.2政策法规的演变与挑战\n8.3行业竞争与合作\n8.4生态系统构建与产业链整合\n8.5患者体验与个性化服务\n8.6可持续发展与社会责任\n九、行业发展趋势与战略建议\n9.1技术发展趋势与战略建议\n9.2市场发展趋势与战略建议\n9.3政策法规与合规战略\n9.4生态系统构建与合作伙伴关系\n9.5患者体验与市场定位\n9.6可持续发展与社会责任\n十、结论与建议\n十.1行业总结\n十.2市场分析\n十.3技术发展\n十.4政策法规\n十.5挑战与机遇\n十.6建议与展望\n十一、行业投资与融资趋势\n11.1投资增长与资金流向\n11.2融资渠道与策略\n11.3投资回报与退出机制\n十二、行业案例分析\n12.1IBMWatsonHealth\n12.2GoogleHealth\n12.3SiemensHealthineers\n12.4PhilipsHealthcare\n12.5商汤科技\n十三、结论与建议\n13.1行业总结\n13.2市场分析\n13.3技术发展\n13.4政策法规\n13.5合作与生态系统\n13.6建议与展望\n一、2025年AI诊断设备全球市场竞争格局分析报告\n随着人工智能技术的飞速发展，AI诊断设备在医疗领域的应用越来越广泛。本报告将从全球市场角度出发，分析2025年AI诊断设备的竞争格局。\n1.1市场背景\n近年来，全球医疗健康领域对AI诊断设备的需求持续增长。随着人口老龄化加剧、慢性病发病率上升以及医疗资源紧张等问题，AI诊断设备在提高医疗效率、降低成本、提升诊断准确性等方面展现出巨大潜力。此外，全球各国政府纷纷出台政策支持AI诊断设备的发展，为市场提供了良好的发展环境。\n1.2市场规模\n根据相关数据统计，2019年全球AI诊断设备市场规模约为30亿美元，预计到2025年，市场规模将达到150亿美元，年复合增长率达到40%以上。其中，北美、欧洲和亚太地区是主要的市场，占据了全球市场份额的80%以上。\n1.3市场竞争格局\n当前，全球AI诊断设备市场竞争激烈，主要表现为以下几个方面：\n企业竞争：全球范围内，众多企业涉足AI诊断设备领域，包括传统医疗器械企业、IT企业以及初创企业。这些企业凭借各自的技术优势和市场资源，争夺市场份额。\n技术竞争：AI诊断设备的核心技术包括深度学习、计算机视觉、自然语言处理等。各企业纷纷加大研发投入，以提升产品性能和竞争力。\n市场细分竞争：AI诊断设备市场可细分为影像诊断、病理诊断、超声诊断等多个领域。各企业针对不同细分市场进行产品研发和布局。\n区域竞争：北美、欧洲和亚太地区是全球AI诊断设备的主要市场。其中，北美市场以影像诊断为主导，欧洲市场则以病理诊断和超声诊断为主，亚太地区则呈现出全面发展的趋势。\n1.4市场发展趋势\n未来，AI诊断设备市场将呈现以下发展趋势：\n技术创新：随着人工智能技术的不断发展，AI诊断设备的性能将得到进一步提升，诊断准确率和效率将得到显著提高。\n市场整合：市场竞争将促使企业通过并购、合作等方式实现资源整合，提高市场占有率。\n政策支持：全球各国政府将继续出台政策支持AI诊断设备的发展，为市场提供良好的发展环境。\n应用拓展：AI诊断设备将在更多医疗领域得到应用，如精准医疗、远程医疗等。\n二、主要竞争者分析\n2.1美国市场的主要竞争者\n在美国市场，AI诊断设备的主要竞争者包括IBMWatsonHealth、GoogleHealth、GEHealthcare等。IBMWatsonHealth以其强大的深度学习和自然语言处理技术，在癌症诊断和药物研发领域具有显著优势。GoogleHealth则依托其母公司Google在数据分析和云计算方面的技术积累，致力于提供精准的影像诊断服务。GEHealthcare作为传统医疗器械巨头，其在X光、CT等影像设备领域的深厚技术底蕴，使其在AI诊断设备市场占据重要地位。\n2.2欧洲市场的主要竞争者\n在欧洲市场，AI诊断设备的竞争者包括SiemensHealthineers、PhilipsHealthcare、KoninklijkePhilipsN.V.等。SiemensHealthineers凭借其在医疗影像设备领域的领先地位，积极布局AI诊断设备市场，推出了一系列基于深度学习的诊断解决方案。PhilipsHealthcare则通过收购和自主研发，在AI诊断领域取得了显著进展，特别是在心血管疾病诊断方面具有较强竞争力。KoninklijkePhilipsN.V.作为全球领先的医疗保健技术公司，其在AI诊断设备市场的布局涵盖了从影像诊断到病理诊断等多个领域。\n2.3亚太市场的主要竞争者\n亚太市场是AI诊断设备增长最快的地区，主要竞争者包括中国本土企业、日本和韩国企业等。中国本土企业如商汤科技、依图科技等，凭借在人工智能领域的研发实力，迅速崛起，成为市场的重要参与者。日本企业如富士胶片、东芝医疗等，在影像设备领域具有丰富经验，积极布局AI诊断设备市场。韩国企业如三星SDI、LGInnotek等，则在AI诊断设备领域展现出强大的研发能力。\n2.4全球主要竞争者的合作与竞争策略\n在全球范围内，AI诊断设备的主要竞争者普遍采取了以下策略：\n技术研发：企业加大研发投入，提升产品性能和竞争力，以在技术层面形成差异化优势。\n市场拓展：通过并购、合作等方式，拓展市场份额，扩大业务范围。\n政策合规：关注各国政策法规，确保产品符合当地市场要求。\n人才培养：加强人才队伍建设，培养具备跨学科背景的专业人才。\n生态构建：构建合作伙伴生态系统，实现资源共享，共同推动市场发展。\n在竞争策略方面，企业之间存在合作与竞争的交织。一方面，企业通过合作共享技术、市场资源，共同推动AI诊断设备市场的发展；另一方面，企业之间在市场份额、技术专利等方面存在竞争，争夺市场主导地位。\n三、技术发展趋势及创新动态\n3.1AI算法的优化与进步\n在AI诊断设备领域，算法的优化与进步是推动技术发展的核心。随着深度学习、计算机视觉和自然语言处理等技术的不断成熟，AI算法在诊断准确性和效率方面取得了显著成果。例如，卷积神经网络（CNN）在医学影像分析中的应用，显著提高了图像识别的准确性；递归神经网络（RNN）在病理诊断领域的应用，有助于捕捉和分析复杂的数据序列。未来，算法的进一步优化将集中在提高模型的泛化能力、降低计算复杂度以及增强对罕见病例的识别能力。\n3.2数据驱动的发展\nAI诊断设备的创新离不开大量高质量数据的支持。数据驱动的发展模式要求企业不断积累和整合医疗影像、病历、基因组学等多源数据，以提升模型的准确性和可靠性。同时，随着物联网和大数据技术的进步，数据收集和处理的效率得到提升，为AI诊断设备的研发和应用提供了有力支撑。数据驱动的发展模式也促使企业重视数据安全和隐私保护，确保患者数据的安全和合规使用。\n3.3多模态融合技术\n多模态融合技术是AI诊断设备技术发展的重要方向。通过整合不同模态的数据，如影像、生物标志物、临床数据等，AI诊断设备能够提供更全面、准确的诊断结果。例如，在癌症诊断中，结合影像学、基因组学和临床数据的多模态分析，可以显著提高诊断的准确性和早期发现率。多模态融合技术的发展，要求企业具备跨学科的技术整合能力，以及与临床专家紧密合作的能力。\n3.4个性化医疗的应用\n个性化医疗是AI诊断设备发展的另一大趋势。通过分析患者的基因、生活方式、环境因素等个性化信息，AI诊断设备可以提供更加精准的预防和治疗方案。个性化医疗的应用，要求AI诊断设备能够适应不同患者的特征，并提供个性化的诊断建议。这不仅需要AI技术的进步，还需要医疗行业对个性化医疗理念的理解和推广。\n3.5可穿戴设备的整合\n随着可穿戴设备的普及，AI诊断设备与可穿戴设备的整合成为可能。通过将AI诊断技术嵌入可穿戴设备，可以实现实时健康监测和早期预警。这种整合不仅方便患者日常健康管理，也有助于医生及时了解患者的健康状况。可穿戴设备的整合，要求AI诊断设备具备低功耗、小型化、便携性的特点，以满足消费者的使用需求。\n四、政策法规与行业标准\n4.1政策法规对市场的影响\n在全球范围内，政策法规对AI诊断设备市场的发展起到了重要的引导和规范作用。政府通过制定相关法规，确保AI诊断设备的安全性和有效性，同时鼓励创新和技术进步。例如，美国食品药品监督管理局（FDA）对AI诊断设备的审批流程进行了简化，以加快产品的上市速度。欧洲委员会（EC）则推出了《医疗器械法规》（MDR），对医疗器械的质量和安全提出了更高的要求。这些政策法规的变化，直接影响了AI诊断设备企业的研发方向、产品设计和市场策略。\n4.2重点关注领域与法规要求\n在AI诊断设备领域，以下领域的政策法规尤为值得关注：\n数据保护与隐私：随着数据隐私保护意识的增强，各国政府纷纷加强了对医疗数据保护的法规建设。企业需确保AI诊断设备在处理患者数据时遵守相关法律法规，保护患者隐私。\n产品认证与审批：各国对AI诊断设备的产品认证和审批有严格的要求。企业需按照当地法规进行产品注册和审批，确保产品符合国家标准和行业标准。\n临床研究规范：AI诊断设备在上市前需进行临床试验，以证明其安全性和有效性。临床研究规范对试验设计、数据收集和分析等方面提出了具体要求。\n4.3行业标准的制定与实施\n为了推动AI诊断设备的健康发展，全球范围内多"
  },
  {
    "title": "“对答案+改错题”新训练法让AI数学推理能力大幅提升_中共西藏自治区委员会网络安全和信息化委员会办公室",
    "page_body": "近日,谷歌研究院、卡内基梅隆大学与AI代理开发商MultiOn组成的联合团队在《自然-机器学习》期刊发表最新研究成果,证实通过正向与负向合成数据结合训练,可使大语言模型的数学推理能力实现8倍性能提升。这一突破有望缓解全球高质量训练数据短缺危机。\n根据斯坦福大学附属研究机构Epoch AI于2024年3月发布的《全球AI训练数据趋势报告》,当前可用高质量文本训练标记总量约为300万亿个。但以ChatGPT类大模型年均2.5倍的算力增速推算,现有数据储备将在几年内耗尽。因此,合成数据成为重要的替代方案。\n以“对答案+改错题”方法训练AI,提升模型数学推理能力。据了解,研究团队首次系统验证了两种合成数据的协同效应。正向数据由GPT-4、Gemini 1.5Pro等大模型生成超100万条数学问题正确解法,涵盖代数、几何、概率等8大领域,可以理解为由顶尖AI生成的正确解题步骤,旨在让AI“记住”标准解法模板。负向数据则通过人工标注与模型自检,构建包含27万个错误推理步骤的数据库,覆盖逻辑漏洞、计算错误等6类常见失误,旨在预警计算失误、逻辑跳跃等常见错误,并强化因果推理能力。简单来说,正向数据是AI的“标准答案集”,而负向数据是AI的“错题本”。\n此外,与传统方法仅单纯要求AI“尽量答对”,可能导致模型“死记硬背”的情况不同,研究团队创新性地采用了直接偏好优化(DPO)框架。该框架为每个推理步骤赋予动态的“优势值”(Advantage Value),以此反映该步骤相对于理想解决方案的价值,从而让模型学会“避坑”,使得推理效率显著提升。\n研究团队使用DeepSeek-Math-7B和LLaMa2-7B等模型,在GSM8K和MATH数据集上进行了全面测试。结果显示,经过正向和负向合成数据预训练的大模型在数学推理任务上的性能实现了8倍的提升。这一研究充分展示了合成数据在增强大模型逻辑推理能力方面的巨大潜力。\n(编辑:索朗次仁)"
  }
]