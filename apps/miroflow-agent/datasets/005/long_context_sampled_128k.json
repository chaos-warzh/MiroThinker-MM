[
  {
    "title": "高质量数据集典型案例｜中国移动研发大模型高质量数据集-今日头条",
    "page_body": "中国移动研发大模型高质量数据集\n推荐单位：江苏省数据局\n申报单位：中移（苏州）软件技术有限公司\n一、背景\n代码数据质量和动态利用方式，已成为大模型推理能力的“暗物质”，是推理基础设施的核心燃料，在软件工程等领域具有重要应用价值。针对当前代码数据来源广、质量参差不齐、评估手段专业化不足等问题，本案例构建了“数据采集－数据处理－数据质量评估”的高质量数据处理引擎，形成了一套高质量研发大模型数据集，并基于此数据集训练形成了具备代码补全、单元测试等能力的研发大模型，可支撑研发全流程赋能需求。\n研发大模型高质量数据集架构图\n二、方案和成效\n一是构建海量异构数据采集引擎，实现多源数据融合。 针对开源代码数据分散、内容多样化、噪声多等问题，从异构内容自动提取、低熵噪声自动去除等层面，提升数据采集的准确性与完整性，实现代码数据高效、实时汇聚，形成超PB级别原始数据。\n二是打造高质量数据处理流水线，提升自动化处理效率。 针对代码数据质量不足、研发场景数据缺失等问题，打造文本数据处理流水线和多模态数据合成流水线，支持多样化数据预处理、数据合成、数据探索分析等，整体自动化率达90%，沉淀超50+核心数据处理算子，支持1500万文档/小时。\n三是设计高质量数据评估体系，全方位评估数据质量。 针对代码数据质量评估手段专业化不足的问题，结合行业标准和数据特性，设计一套支持多粒度代码评估、多维度代码评估的高质量综合评估体系，覆盖12个核心维度，支持100+研发领域数据标签，实现研发大模型数据的全方位质量评估。\n三、创新点\n一是技术创新牵引数据质量升级。 基于多元化规则体系及大小模型协同技术，实现对代码数据的去重、敏感数据的脱敏以及场景化标签的标注，将原始代码数据转换为可应用于大模型预训练微调及研发全流程场景需求的高质量研发大模型数据集。\n二是流程闭环加速数据质量跃升。 打造专门面向代码数据的采集、处理、训练等全流程闭环质量优化体系，综合考虑代码数据的技术专业性和复杂性，以规则阈值融合大模型测评等方式，实现模型加数据飞轮良性循环。\n三是机制完善推进数据循环共享。 构建数据安全合规审查体系和数据资产共建共享办法，并形成产业生态闭环，为数据全生命周期注入安全与合规基因，确保其高效流动与价值最大化。\n来源：数据资产搜索整理自网络\n特别声明：本信息来源于网络，经过小编汇总整理生成。小编和本账号公司并不能保证本文信息的真实性和准确性，不对信息真实性准确性负责。请阅读者合理评估信息质量和来源。如果本文包含小编的分析结论等描述，相关分析结论仅仅代表作者个人在当期某个时点的观点，因此相关分析结论可能随着时间变化而改变。本文并无其他任何商业用途。读者如需转载，请务必注明每项内容出处。因读者转发产生的一切经济纠纷和法律责任均由转发者承担，和本账号运营公司以及小编无关。如涉及材料内容、版权和其它问题，请联系小编留言，我们将在第一时间删除。\n北京传世博润科技有限公司（简称：传世博润）成立于2015年，国家高新技术企业，是国内领先的医疗医药数字化与数据价值服务商。作为医疗医药行业头部数商，传世博润深耕医疗医药行业，为药企和医疗机构提供数据资产化解决方案和数字化服务。\n（1）数据资产化解决方案\n传世博润实现了行业数据资产的首登记、首入表、首交易。将基于自身在医疗医药领域数据要素服务的先发优势，为药企和医院开展数据资源开发利用的研究服务，交付高质量数据集、算法模型以及数据产品等成果；\n凭借着自身数据资产化的经验和实践，已经成为北京国际大数据交易所、深圳数据交易所、广州数据交易所、西部数据交易中心、贵阳大数据交易所、江苏数据交易所等多个知名数据交易机构数据商，帮助企业和医疗机构将数据研究成果进行数据资产登记和数据产品交易，积极推动医疗医药数据产品在法定场所内的资产化和流通。\n（2）数字化服务\n在医药流通领域，通过人工智能，结合数据成果，为企业和医疗机构提供精准营销和物流优化以及院内供应链智慧管理等服务；\n在医疗服务领域，通过人工智能，结合数据成果，为医疗机构及学术带头人提供临床科研成果转化服务以及成果商业化服务；\n在智能硬件领域，形成智能化存储、智能化配送、智能化分拣三大产品体系，为物流供应链的各个环节提供一站式创新科技产品。"
  },
  {
    "title": "法学教授也能出圈？罗翔的讲课视频在B站一出锅便炸了_澎湃号·媒体_澎湃新闻-The Paper",
    "page_body": "法学教授也能出圈？最近在B站，中国政法大学教授罗翔的讲课视频一出锅便炸了，经常是一条视频，几百万的点击率，不到一个月时间，吸粉四百多万。除了自身的人气，这些数据，也坐实了罗老师被人喜欢的硬核实力。\n站在互联网的风口上，罗翔讲的却是严肃的刑法课程，这种反差让许多学生觉得很上头，而且他还能随手就抛出一个梗来。“为什么要给罪大恶极的人进行辩护，这种行为也太渣了吧？”下一秒话锋一转，“如果有一天，你也成了被告人，你说自己是无辜的，没有人相信你怎么办？”代入感立刻呈现出来了，听众也立刻理解了辩护的价值。\n罗翔讲过一个非常经典的粪坑案。20世纪80年代，一位妇女冬天骑车碰到歹徒要强暴她，由于双方力量悬殊，妇女打不过对方，便想出一个缓兵之计假装就范，还找了一个极其为歹徒考虑的借口说，“大哥，这个地方不平坦。”歹徒一听，是这么回事，于是寻觅到一个平坦的冰面上开心地脱起衣服来。当衣服遮住脸时，妇女眼疾手快一把把他推进了旁边的粪坑，歹徒连续三次往上爬，都被妇女给踹了下去，最后彻底掉进粪坑死掉了。\n踹死是不是有点过了，这属于正当防卫吗？如果你是这个妇女，你会不会也这么做？一连串的灵魂发问，学生直呼罗老师把讲课的节奏感带得很过瘾。\n“把自己代入到当时的情境中，进行换位思考，以当时的情况进行判定，采取事前一般人标准，而不是事后理性人标准去看待。我们就是普通人，不要拿上帝视角去说话，最终这个案子被判正当防卫。”罗翔说道。之后他又放出了一句经典补刀：“如果我是这个妇女，不仅会踹下去，还会拿块砖去拍他，不过也要小心不要把粪溅到自己身上了。”\n罗翔的幽默和法律的严谨就这样产生了化学反应，他能把案例讲成一个个段子，经常是弹幕一开，刷屏刷到看不清他的脸。面对数不清的留言，罗翔告诉《方圆》记者，自己偶尔也会去看，那些好的内容他都是一扫而过，而那些批评他的话语，他是会反思的：“我觉得只有看清楚自己的不足，才能走出自己的局限，然后在下一次可以做得更好。”\n惊世骇俗的段子，讲出法律的味道\n阿尔贝·加缪曾说，在写书时可以看到书中自己的角色，而罗翔在讲课中也能找到自己的角色。比如在B站流传甚广的画面里，罗翔口中的段子层出不穷，而他单口相声式的讲解，一度刷新了大家对学习法律的理解。\n“在一起自伤案例中，有人正拿着刀在剁手，啪，剁不断，我看着着急，跟大哥说换这把刀，啪一剁就断了，大哥还跟我说谢谢，大家觉得我构不构成犯罪？”“有个人去买烟，拿出一张钱给老板吓了一跳，面额250，上面有8个头，他跟老板说这是早上刚刚发行的，要买一包最便宜的两块钱的烟，还让老板找了248元，这种行为是伪造货币罪吗？”\n“有一哥们等她女朋友时闲极无聊，拍了一下ATM机，结果吐出100块，他吓坏了，又拍了一下，又吐出100块，后来一共拍出了三万块，你说有谁能抵制住这种诱惑？”\n还有谜一样的张三系列，比如给张三买了100张蹦极票，在第99次蹦极时张三终于摔死了，这属不属于危害行为；再比如张三对前男友怀恨在心，送给前男友一双滚轴溜冰鞋希望他摔死摔残，这种行为构不构成故意伤害罪。\n……\n在罗翔的讲课视频中，“津津有味”成了弹幕中的高频词，“法外狂徒张三”也成了他独树一帜的案例主角，许多让粉丝狂刷的梗是罗翔始料未及的，他成了B站中有独特话语体系的法学老师。\n还有一些惊世骇俗的段子，罗翔硬是讲出了法律的味道。有一起涉嫌组织出卖人体器官的恶性事件，罗翔是这样描述的：“同学，看你长相清秀，我出50万，你把肾卖给我吧。”“老师，我是有尊严的好不好。”“500万行不行？”“老师，我真的有尊严。”“5000万，再加上海的两套房子。”“成交！”“最后一声干脆利索，于是我把他的肾割了下来，做了一个烤腰子，吃了一口，问他要不要也吃一口，他则跟我显摆说我有钱哪。”\n“这是尊严吗”？罗翔反问道。这种尊严不过就是用钱来计算罢了，还涉嫌组织出卖人体器官罪，显然是违法的。这就是为什么法律对自由会进行一定约束，因为自由是不能以彻底放弃自由为代价的。\n另外在一起重大杀人案中，一对农民夫妇杀掉了50多个人，把尸体像摞砖一样放在自己家的地窖里，据说他们抢夺来的财产总共才500多块。后来警察问他们：杀这么多人你们就不害怕吗？他们却回答，你瞧瞧，不就是杀个人吗，多大点事呀。虽然杀第一个人的时候是有点怕的，当时尸体在二楼，我在一楼睡觉，夜深人静的时候听到楼上有血滴答滴答往下淌的声音，但是仔细一想，这个世界上又没有鬼，还有什么可怕的呢。类似这样的案子听起来很震惊，却干货十足，罗翔的各种段子也在网上不断发酵。\n“宝藏老师”\n以上各种奇葩案件，让罗翔把刑法课堂变得热闹非凡。\n法治课程讲得接地气，让一些非法律专业粉丝开始霸屏，会计学专业的慕名而来，安全工程专业前来受教，电气工程专业来报到，高一文科生也开始围观了……他们亲切地称呼罗翔是“宝藏老师”。\n在几百万粉丝的包围中，罗翔一直表现得很平静。在网络之外，罗翔说自己就是一个普通的老师而已。他谦虚地说：“那些视频课程是为一家法律职业资格考试培训机构录制的，被一些听课同学自动搬到了B站，所以受到关注可以说是无心插柳柳成荫。我不觉得自己‘火了’。我个人一直觉得，人在使命中才活得有意义，要向着标杆奔跑。”\n老师这个职业，就是罗翔心中的那杆标杆。\n在微信公众号“罗翔说刑法”上，他曾写过一篇《我的老师》的文章，回忆了读书期间导师对他的帮助。“当年我写博士论文时，导师不时会打电话督工，有时一个电话能打两个小时。每次我打电话向导师请教问题时，他会先挂掉，然后给我回拨过来，他的理由是学生话费有限。有一年大年初二，我在朋友家喝酒聚会，酒兴正浓，结果导师打来电话，说今天已经初二了，年也过得差不多了，该收心写论文了。我们也经常为一个问题争得面红耳赤，毫不客气，一点也不顾忌导师的颜面，不过毕业之后，导师还时常给我打电话，有时一个问题也要和我讨论很久。”\n罗翔觉得自己很幸运，遇到了好的老师，他把人生95%的成就归功于老师的相助，他的人生轨迹，也因为老师而变得有所不同。\n2005年，罗翔从北京大学法学院刑法学博士毕业后，成为中国政法大学的一名老师。他有一种强烈的想法，要把从老师那里接收的祝福传递给更多的学生。但现实是，做和做到之间有一座天然的鸿沟。即使是罗翔自己，有时候也很难做到有教无类。他说耐心是很容易碎掉的，可自己对老师这份职业，心中始终留有一份深厚的感情。\n因为对老师这份职业的执着，罗翔始终想着，要把课堂变得精彩有趣，在严肃和幽默之间找到平衡点。为此，他将各种法律故事契合人的常识、常情、常理进行整合，然后变成一个个带有温度的故事。这让学生找到那种“再来一亿遍”的感觉。\n人生需不断前行，走出舒适圈\n曾经有粉丝给罗翔留言，说自己在喜马拉雅上录制他的书《圆圈正义》给孩子听，录制到一半突然意识到自己是不是侵权了？他则热情地回复道：“用吧，不侵权。”\n《圆圈正义》是罗翔的一本随笔合集，也分享了自己的求学经验和对人生的思考。前言里，罗翔说：“我们画不出一个完整的圆，但是不代表圆不存在，四边形也能成为圆，生活中总有理想，虽不能至，心向往，可以达不到，但是不能放弃，它是我们前进的方向。”\n罗翔也有一些比较有意思的经历。他说自己小时候比较调皮，曾经担任过两个星期的小组长，当时觉得自己很厉害，还让同学帮他写作业，后来被老师和家长知道了，之后父母便对他开展了严格的管理，以至于成年之后他回家乡和朋友聚会，一到十点大家都会催促他赶紧回家。\n而说到自己是如何开始学习法律的，罗翔说当年在高考填报考志愿时，也是有犹豫过的。“我本来是想学医的，但是我物理和化学不好，只有数学好，仅有一门数学好在理科生中是没有优势的，相反如果选择文科的话，数学好就比较有优势了，再加上我喜欢历史，父母觉得文科专业更加适合我，最后在比较热门的经济和法学专业领域中我选择了法学专业。”\n不过罗翔觉得严格的管理教育也是一件好事，可以督促自己去进步和提升，这也让他每年都被学生选为最受欢迎的老师之一，每次一有他的课，学生们很难占到座位，甚至有的同学自愿站着听完整节课。同学们对他的喜欢，对罗翔来说是一份感动，也激励他不断往前走。\n走出舒适圈，跳出自己的局限，罗翔给自己制定了往前的目标，他在国外的留学经历，也将他的视野放得更宽。\n罗翔在美国留学时，有一次违反了交通法。他和朋友开车经过旧金山大桥，在过桥时，看到有一边收费通道没什么人，就把车开过去了，不料几天后收到了罚单。原来他开车通过的车道是电子速通通道，需要在车上装电子速通卡才能通过，如果在早高峰和晚高峰时期，只要车里有三名以上乘客，是可以免交高速费的，他当时没有弄清楚当地的交通规则。\n在美国，不遵守交通规则罚款罚得很重，不过罚单上也会有这么一句话：如果不服罚款，可以在一个月内上诉。于是，罗翔立刻写了一封说明信，警察查了他的驾驶记录，发现他是外国人，且是首次违章，考虑到他可能不懂旧金山的法律规定，于是免除了他的罚款，只需补交过桥费。\n还有一次罗翔在公园里散步，发现地上有掉落的鹿茸，觉得扔在那里很可惜，便捡了起来，在他准备走出公园的时候被警察看到了，说他捡起地上鹿茸的行为涉嫌违法。不经意的一个行为让他陷入了比较尴尬的境遇，后来回过神来他才发现，自己的行为涉嫌运送珍稀物品罪，好在警察对他还比较客气，让他赶紧把鹿茸放回到原来的地方。\n类似的事情也在法国巴黎发生过。罗翔的护照在巴黎游玩时弄丢了，他去巴黎警察局报了案，因为护照是在德国签发的，警察给德国大使馆打了电话。“他们的效率特别高，几分钟之后就找到一位可以说德语、法语和中文的翻译来为我提供帮助。我告知对方我已经买了下一个目的地的火车票，现在没有护照出行很麻烦。”巴黎警察建议罗翔在没有护照的情况下，先暂时不要离开，但他害怕耽误行程，再加上火车票很贵，他还是抱着侥幸的心理去了火车站。\n通常情况下坐火车是不用查护照的，结果那天有个大案子正好发生，每个人通关都必须检查护照。检"
  },
  {
    "title": "大模型Scaling Law深度解析，收藏这篇就够了！-CSDN博客",
    "page_body": "CC 4.0 BY-SA版权\n在 大模型 的研发中，通常会有下面一些需求：\n• 1.计划训练一个10B的模型，想知道至少需要多大的数据？ • 2.收集到了1T的数据，想知道能训练一个多大的模型？ • 3.老板准备1个月后开发布会，给的资源是100张A100，应该用多少数据训多大的模型效果最好？ • 4.老板对现在10B的模型不满意，想知道扩大到100B模型的效果能提升到多少？\n以上这些问题都可以基于Scaling Law的理论进行回答。本文是阅读了一系列 Scaling Law的文章后的整理和思考，包括Scaling Law的概念和推导以及反Scaling Law的场景，不当之处，欢迎指正。\n核心结论\n大模型的Scaling Law是 OpenAI 在2020年提出的概念[1]，具体如下:\n1.对于Decoder-only的模型，计算量( Flops ), 模型参数量N, 数据大小(token数)，三者满足: 。(推导见本文最后)\n2.模型的最终性能 主要 与计算量，模型参数量和数据大小三者相关，而与模型的具体结构(层数/深度/宽度)基本无关。\n固定模型的总参数量，调整层数/深度/宽度，不同模型的性能差距很小，大部分在2%以内\n3.对于计算量，模型参数量和数据大小，当不受其他两个因素制约时，模型性能与每个因素都呈现 幂律关系\n4.为了提升模型性能，模型参数量N和数据大小D需要同步放大，但模型和数据分别放大的比例还存在争议。\n5.Scaling Law不仅适用于 语言模型 ，还适用于其他模态以及跨模态的任务[4]：\n这里横轴单位为PF-days: 如果每秒钟可进行次运算，就是1 peta flops，那么一天的运算就是，这个算力消耗被称为1个petaflop/s-day。\n核心公式\n• 第一项是指无法通过增加模型规模来减少的损失，可以认为是数据自身的熵（例如数据中的噪音） • 第二项是指能通过增加计算量来减少的损失，可以认为是模型拟合的分布与实际分布之间的差。\n根据公式，增大(例如计算量)，模型整体loss下降，模型性能提升；伴随x趋向于无穷大，模型能拟合数据的真实分布，让第二项逼近0，整体趋向于\n大模型中的Scaling Law\nGPT4\n下图是GPT4报告[5]中的Scaling Law曲线， 计算量C和模型性能满足幂律关系\n• 横轴是归一化之后的计算量，假设GPT4的计算量为1。基于10,000倍小的计算规模，就能预测最终GPT4的性能。 • 纵轴是\"Bits for words\", 这也是交叉熵的一个单位。在计算交叉熵时，如果使用以 2 为底的对数，交叉熵的单位就是 “bits per word”，与信息论中的比特（bit）概念相符。所以这个值越低，说明模型的性能越好。\nBaichuan2\n下图是Baichuan2[6]技术报告中的Scaling Law曲线。基于10M到3B的模型在1T数据上训练的性能，可预测出最后7B模型和13B模型在2.6T数据上的性能\nMindLLM\n下图是MindLLM[7]技术报告中的Scaling Law曲线。基于10M到500M的模型在10B数据上训练的性能，预测出最后3B模型在500B数据上的性能。\nScaling Law实操: 计算效率最优\n根据幂律定律，模型的参数固定，无限堆数据并不能无限提升模型的性能，模型最终性能会慢慢趋向一个固定的值\n如图所示，如果模型的参数量为（图中紫色的线），在数量达到，模型基本收敛。所以在数据量达到后，继续增加数据产生的计算量，没有同样计算量下提升模型参数量带来的收益大（计算效率更优）。根据，可以进一步转换成模型参数与计算量的关系，即: 模型参数为，在计算量为，即时基本收敛。也就是右图中紫色线的拐点。\n根据Baichuan[6]的实验，在中英场景下，7B模型收敛时的算力是 FLOPS，对应的数据量应该是\n按照上面的思路，下面进行Scaling Law的实操。\n首先准备充足的数据（例如1T），设计不同模型参数量的小模型(例如0.001B - 1B)，独立训练每个模型，每个模型都训练到基本收敛（假设数据量充足）。根据训练中不同模型的参数和数据量的组合，收集计算量与模型性能的关系。然后可以进一步获得 计算效率 最优时，即同样计算量下性能最好的模型规模和数据大小的组合，模型大小与计算量的关系，以及数据大小与计算量的关系。\n如图所示，根据左图可以看到计算量与模型性能呈现幂律关系（可以认为数据和模型都不受限制），根据中图和右图，可以发现,，即计算效率最优时，模型的参数与计算量的幂次成线性关系，数据量的大小也与计算量的幂次成线性关系。\n根据，可以推算出，但是分别是多少存在分歧。\nOpenAI[1]认为模型规模更重要，即，而DeepMind在Chinchilla工作[2]和Google在PaLM工作[3]中都验证了 a=b=0.5 ，即模型和数据同等重要。\n所以假定计算量整体放大10倍，OpenAI认为模型参数更重要，模型应放大 (5.32)倍，数据放大 (1.86)倍；后来DeepMind和Google认为模型参数量与数据同等重要，两者都应该分别放大 (3.16)倍。\n例如在PaLM的实验中，计算量从放大10倍到， 模型参数也提升了3.2倍，3.35B->10.7B。\n具体最好在自己的数据上做实验来获得你场景下的a和b。\nLLaMA: 反Scaling Law的大模型\n假设遵循 计算效率 最优来研发LLM，那么根据Scaling Law，给定模型大小，可以推算出最优的计算量，进一步根据最优计算量就能推算出需要的 token 数量，然后训练就行。\n但是 计算效率 最优这个观点是针对 训练阶段 而言的，并不是 推理阶段 ，实际应用中 推理 阶段效率更实用。\nMeta在LLaMA[8]的观点是：给定模型的目标性能，并不需要用最优的计算效率在最快时间训练好模型，而应该在更大规模的数据上，训练一个相对更小模型，这样的模型在推理阶段的成本更低，尽管训练阶段的效率不是最优的（同样的算力其实能获得更优的模型，但是模型尺寸也会更大）。根据Scaling Law，10B模型只需要200B的数据，但是作者发现7B的模型性能在1T的数据后还能继续提升。\n所以LLaMA工作的重点是训练一系列语言模型，通过使用更多的数据，让模型在 有限推理资源下有最佳的性能 。\n具体而言，确定模型尺寸后，Scaling Law给到的只是最优的数据量，或者说是一个至少的数据量，实际在训练中观察在各个指标上的性能表现，只要还在继续增长，就可以持续增加训练数据。\n计算量、模型和数据大小的关系推导\n对于Decoder-only的模型，计算量C(Flops), 模型参数量N(除去Embedding部分), 数据大小D(token数), 三者的关系为:\n推导如下，记模型的结构为:\ndecoder层数 :\nattention 隐层维度 :\nattention feedforward层维度 : ， 一般来说\n首先推导模型的参数量（忽略embedding，norm和bias）计算如下:\ntransformer每层包括: self-attetion 和 MLP 两个部分:\nself-attention的参数为，每个矩阵的维度均为，整体参数量:\nMLP的层数的参数为，整体参数量:\n所以每层的参数量为: ，全部的l层的参数量为: ，即\n继续推导模型的前向推理的计算量:\n计算量的单位是FLOPs，floating point operations 对于矩阵，相乘的计算量为，一次加法一次乘法。\n假设Decoder层的输入, 为batch size，为序列长度, 为模型维度。\nself-attention部分的计算 :\n输入线性层: ，计算量为:\natention计算: ，计算量为:\nsocre与V的计算: ，计算量为:\n输出线性层: ，计算量为: 4b * 2 * s * d * d = 2bsd^2$\nMLP部分的计算\n升维: ，计算量为:\n降维: ，计算量为:\n所以整个decoder层的计算量为:，全部l层为:\n反向传播计算量是正向的2倍，所以全部的计算量为:\n平均每个token的计算量为\n所以对于全部包含D个token的数据集:\n如何系统的学习大模型  AI  ？\n由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。\n但是具体到个人，只能说是：\n“最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。\n这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。\n我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。\n我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。\n一直在更新，更多的大模型学习和面试资料已经上传带到CSDN的官方了，有需要的朋友可以扫描下方二维码免费领取【保证100%免费】        \n01.大模型风口已至：月薪30K+的AI岗正在批量诞生\n2025年大模型应用呈现爆发式增长，根据工信部最新数据：\n国内大模型相关岗位缺口达47万\n初级工程师平均薪资28K（数据来源：BOSS直聘报告）\n70%企业存在\"能用模型不会调优\"的痛点\n真实案例：某二本机械专业学员，通过4个月系统学习，成功拿到某AI医疗公司大模型优化岗offer，薪资直接翻3倍！\n02.大模型 AI 学习和面试资料\n1️⃣ 提示词工程：把ChatGPT从玩具变成生产工具\n 2️⃣ RAG系统：让大模型精准输出行业知识\n 3️⃣ 智能体开发：用AutoGPT打造24小时数字员工\n    熬了三个大夜整理的《AI进化工具包》送你：\n ✔️ 大厂内部LLM落地手册（含58个真实案例）\n ✔️ 提示词设计模板库（覆盖12大应用场景）\n ✔️ 私藏学习路径图（0基础到项目实战仅需90天）\n第一阶段（10天）：初阶应用\n该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨论时发表高级、不跟风、又接地气的见解，别人只会和 AI 聊天，而你能调教 AI，并能用代码将大模型和业务衔接。\n大模型 AI 能干什么？ 大模型是怎样获得「智能」的？ 用好 AI 的核心心法 大模型应用业务架构 大模型应用技术架构 代码示例：向 GPT-3.5 灌入新知识 提示工程的意义和核心思想 Prompt 典型构成 指令调优方法论 思维链和思维树 Prompt 攻击和防范 …\n第二阶段（30天）：高阶应用\n该阶段我们正式进入大模型 AI 进阶实战学习，学会构造私有知识库，扩展 AI 的能力。快速开发一个完整的基于 agent 对话机器人。掌握功能最强的大模型开发框架，抓住最新的技术进展，适合 Python 和 JavaScript 程序员。\n为什么要做 RAG 搭建一个简单的 ChatPDF 检索的基础概念 什么是向量表示（Embeddings） 向量数据库与向量检索 基于向量检索的 RAG 搭建 RAG 系统的扩展知识 混合检索与 RAG-Fusion 简介 向量模型本地部署 …\n第三阶段（30天）：模型训练\n恭喜你，如果学到这里，你基本可以找到一份大模型 AI相关的工作，自己也能训练 GPT 了！通过微调，训练自己的"
  },
  {
    "title": "工信安的《大模型2.0产业发展报告：商业落地创涌而现》_大模型2.0产业发展报告商业落地创涌而现-CSDN博客",
    "page_body": "工信安发展研究中心和联想集团最近联合编写了一份技术报告：《大模型2.0产业发展报告：商业落地创涌而现》。这份报告全面深入地探讨了大模型2.0的技术特点、产业生态、社会影响、政策监管、投资与人才需求、关键要素、个人与企业应用以及未来发展趋势，为业界提供了有价值的参考和启示。\n报告的主要内容总结如下：\n1 大模型 2.0 概述\n大模型 2.0 是基于深度学习算法，依托大规模数据进行训练，并能执行复杂下游任务的大型语言模型（LLMs）。它标志着大模型技术从探索期向应用期的转变，实现了技术的规模商业化。大模型 2.0 具备更强的理解能力，能够处理和理解多模态数据，具备更高的逻辑推理能力；拥有更全面的知识储备，数据版权化推动更多行业知识进入大模型训练；采用更高效低碳的训练模式，借助模型压缩技术、异构计算平台等降低训练成本；并展现出更广泛的产业应用能力，以 API 或服务形式提供，满足不同应用场景需求。\n2 大模型 2.0 的技术特点和产业生态\n在技术层面，大模型 2.0 的进步显著。它不仅在理解能力上有了质的飞跃，能够处理复杂的多模态数据并进行深度逻辑推理，还在知识储备上更为丰富，得益于数据版权化的推进，大量行业专业知识被纳入训练范畴。同时，其训练模式也更加高效和低碳，通过模型压缩技术以及异构计算平台的运用，大幅降低了训练成本。在产业应用方面，大模型 2.0 以 API 或服务的形式广泛应用于各个领域，满足了多样化的应用场景需求。\n从产业生态来看，个人大模型生态涵盖了数据供给、技术基础设施、模型应用、服务与产品供给以及安全与隐私等多个方面，形成了一个完整的发展链条。而企业大模型生态则包括基础层、应用层和战略层，推动企业从局部场景智能化向全栈智能化转型，助力企业在经营管理、研发设计、供应链管理、生产制造等多个方面实现智能化升级。\n3 大模型 2.0 的社会影响\n大模型 2.0 对社会产生了深远的影响。在个人层面，它在内容创作、数据分析等领域的应用极大地提高了个人的工作效率，成为提升个人生产力的重要工具。对企业而言，大模型 2.0 推动企业从局部场景的智能化向全栈智能化发展，不仅提升了业务效率，还提高了产品质量，为企业带来了显著的经济效益。从更宏观的社会层面来看，大模型 2.0 推动了生产力的提升，促进了数字经济的高质量发展，成为推动社会进步的重要力量。\n4 政策与监管\n在全球范围内，主要经济体纷纷出台政策支持人工智能的发展。欧盟的《人工智能法案》、美国的《国家人工智能研发战略计划》等政策文件，都为大模型的发展提供了政策指引和支持。中国也将人工智能提升至国家战略层面，出台了一系列政策措施推动大模型的发展，如《新一代人工智能发展规划》《生成式人工智能服务管理暂行办法》等。同时，为了确保大模型技术的安全、可靠和伦理应用，各国也在加强对大模型的监管，推进全国层面的人工智能专门立法，建立完善的监管与治理体系。\n5 科技巨头投资与人才需求\n大模型 2.0 的快速发展吸引了众多科技巨头的布局和投资。谷歌、亚马逊、微软、阿里巴巴、联想等企业纷纷在大模型领域加大投入，推动技术的创新和应用的拓展。随着大模型技术的不断进步，对深度学习、数据科学等专业技能的人才需求也在持续增长。企业和研究机构都在积极寻求相关领域的专业人才，以满足大模型研发、应用和优化等方面的需要。\n6 大模型 2.0 的关键要素\n大模型 2.0 的发展离不开基础层、模型层、应用层和保障层的共同支撑。基础层包括数据、算力、算法和工具，为大模型的发展提供了坚实的基础。模型层则由通用大模型、行业大模型、企业大模型和个人大模型共同构成，形成了丰富多样的大模型生态。应用层是大模型发挥作用的关键环节，大模型在制造业、金融、医疗、交通等多个领域实现了广泛的应用，为各行业的发展带来了新的机遇。保障层则着重于建立产业合规标准，确保数据、模型和应用的安全保障以及伦理治理，为大模型的健康发展保驾护航。\n7 个人大模型的应用与发展\n个人大模型的应用正在不断拓展和深化。它推动了智能手机、智能家居等个人终端产品的智能化升级，使这些产品更加智能、便捷和个性化。智能个人助理成为个人大模型应用的重要方式之一，它能够根据用户的需求和偏好提供个性化的服务，提升用户的使用体验，成为人们日常生活和工作中的得力助手。\n8 企业大模型的应用与案例\n在企业领域，大模型的应用价值得到了充分体现。它构建了一个完善的企业智能化转型价值体系，在经营管理、研发设计、供应链管理、生产制造等方面发挥着重要作用。以联想为例，其在企业智能化转型中的具体应用和成效展示了大模型的强大能力。通过引入大模型技术，联想在多个业务环节实现了智能化升级，提高了运营效率，优化了产品质量，增强了企业的市场竞争力，为其他企业的智能化转型提供了有益的借鉴。\n9 大模型的未来发展趋势\n展望未来，大模型的发展呈现出多方面的趋势。一方面，大模型的通用性将不断提升，随着参数规模的扩大，其泛化能力和多任务学习能力也将进一步增强，能够更好地应对各种复杂任务和多样化场景。另一方面，大模型将朝着轻量化方向发展，通过算法优化，大模型的体量将减小，算力需求也将降低，从而能够更灵活地部署在终端设备上，实现更广泛的应用。此外，大模型与其他技术的融合程度将不断加深，与物联网、大数据、云计算等技术的结合将赋能更多行业和应用场景，创造更多的价值。最后，去概率化大模型将成为新的发展趋势，通过规则与学习相结合的方式，大模型的记忆、推理和决策能力将得到显著提升，为人工智能的发展开辟新的道路。\n普通人如何抓住AI大模型的风口？\n=领取方式在文末==\n为什么要学习大模型？\n目前AI大模型的技术岗位与能力培养随着人工智能技术的迅速发展和应用 ， 大模型作为其中的重要组成部分 ， 正逐渐成为推动人工智能发展的重要引擎 。大模型以其强大的数据处理和模式识别能力， 广泛应用于自然语言处理 、计算机视觉 、 智能推荐等领域 ，为各行各业带来了革命性的改变和机遇 。\n目前，开源人工智能大模型已应用于医疗、政务、法律、汽车、娱乐、金融、互联网、教育、制造业、企业服务等多个场景，其中，应用于金融、企业服务、制造业和法律领域的大模型在本次调研中占比超过  30%。\n随着AI大模型技术的迅速发展，相关岗位的需求也日益增加。大模型产业链催生了一批高薪新职业：\n人工智能大潮已来，不加入就可能被淘汰。如果你是技术人，尤其是互联网从业者，现在就开始学习AI大模型技术，真的是给你的人生一个重要建议！\n大模型目前在人工智能领域可以说正处于一种“炙手可热”的状态，吸引了很多人的关注和兴趣，也有很多新人小白想要学习入门大模型， 那么，如何入门大模型呢？\n下面给大家分享一份2025最新版的大模型学习路线，帮助新人小白更系统、更快速的学习大模型！\n*有需要完整版学习路线* ，可以 微信扫描下方二维码 ，立即免费领取!\n一、2025最新大模型学习路线\n一个明确的学习路线可以帮助新人了解从哪里开始，按照什么顺序学习，以及需要掌握哪些知识点。大模型领域涉及的知识点非常广泛，没有明确的学习路线可能会导致新人感到迷茫，不知道应该专注于哪些内容。\n我们把学习路线分成L1到L4四个阶段，一步步带你从入门到进阶，从理论到实战。\nL1级别:AI大模型时代的华丽登场\nL1阶段：我们会去了解大模型的基础知识，以及大模型在各个行业的应用和分析；学习理解大模型的核心原理，关键技术，以及大模型应用场景；通过理论原理结合多个项目实战，从提示工程基础到提示工程进阶，掌握Prompt提示工程。\nL2级别：AI大模型RAG应用开发工程\nL2阶段是我们的AI大模型RAG应用开发工程，我们会去学习RAG检索增强生成：包括Naive RAG、Advanced-RAG以及RAG性能评估，还有GraphRAG在内的多个RAG热门项目的分析。\nL3级别：大模型Agent应用架构进阶实践\nL3阶段：大模型Agent应用架构进阶实现，我们会去学习LangChain、 LIamaIndex框架，也会学习到AutoGPT、 MetaGPT等多Agent系统，打造我们自己的Agent智能体；同时还可以学习到包括Coze、Dify在内的可视化工具的使用。\nL4级别：大模型微调与私有化部署\nL4阶段：大模型的微调和私有化部署，我们会更加深入的探讨Transformer架构，学习大模型的微调技术，利用DeepSpeed、Lamam Factory等工具快速进行模型微调；并通过Ollama、vLLM等推理部署框架，实现模型的快速部署。\n整个大模型学习路线L1主要是对大模型的理论基础、生态以及提示词他的一个学习掌握；而L3 L4更多的是通过项目实战来掌握大模型的应用开发，针对以上大模型的学习路线我们也整理了对应的学习视频教程，和配套的学习资料。\n二、大模型经典PDF书籍\n书籍和学习文档资料是学习大模型过程中必不可少的，我们精选了一系列深入探讨大模型技术的书籍和学习文档， 它们由领域内的顶尖专家撰写，内容全面、深入、详尽，为你学习大模型提供坚实的理论基础 。 （书籍含电子版PDF）\n三、大模型视频教程\n对于很多自学或者没有基础的同学来说，书籍这些纯文字类的学习教材会觉得比较晦涩难以理解，因此，我们 提供了丰富的大模型视频教程 ，以动态、形象的方式展示技术概念， 帮助你更快、更轻松地掌握核心知识 。\n四、大模型项目实战\n学以致用  ，当你的理论知识积累到一定程度，就需要通过项目实战， 在实际操作中检验和巩固你所学到的知识 ，同时为你找工作和职业发展打下坚实的基础。\n五、大模型面试题\n面试不仅是技术的较量，更需要充分的准备。\n在你已经掌握了大模型技术之后，就需要开始准备面试，我们将提供精心整理的大模型面试题库，涵盖当前面试中可能遇到的各种技术问题，让你在面试中游刃有余。\n全套的AI大模型学习资源已经整理打包 ，有需要的小伙伴可以 微信扫描下方二维码 ，免费领取\n****如果这篇文章对你有所帮助，还请花费2秒的时间** 点个赞+收藏+分享 ，**让更多的人看到这篇文章，帮助他们走出误区。"
  },
  {
    "title": "给小白的大模型入门科普-20250304003342.docx-原创力文档",
    "page_body": "内容提供方 ： 文库新人 大小 ： 53.56 KB 字数 ： 约2.82万字 发布时间 ： 浏览人气 ： 10 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n给小白的大模型入门科普.docx 原文免费试下载\n给小白的大模型入门科普\n目录\n内容概括．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．3\n1.1大模型简介．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．3\n1.2小白入门的重要性．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．4\n1.3本文档的目标和结构概览．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．5\n大模型基础概念．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．6\n2.1什么是大模型？．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．6\n2.2大模型的组成．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．6\n2.2.1输入层．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．7\n2.2.2隐藏层．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．8\n2.2.3输出层．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．9\n2.3大模型与传统机器学习模型的区别．．．．．．．．．．．．．．．．．．．．．．．．．9\n大模型的训练过程．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．10\n3.1数据预处理．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．11\n3.1.1数据清洗．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．11\n3.1.2特征工程．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．13\n3.2损失函数与优化算法．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．14\n3.2.1损失函数的类型和作用．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．14\n3.2.2常见的优化算法及其特点．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．16\n3.3训练流程．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．17\n3.3.1初始化参数．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．18\n3.3.2前向传播．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．19\n3.3.3反向传播和梯度下降．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．19\n3.3.4正则化与防止过拟合．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．20\n3.4评估指标．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．21\n3.4.1准确率、召回率和F1分数．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．22\n3.4.2混淆矩阵．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．23\n大模型的应用案例．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．24\n4.1自然语言处理．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．25\n4.1.1文本分类．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．26\n4.1.2机器翻译．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．27\n4.1.3情感分析．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．28\n4.2计算机视觉．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．29\n4.2.1图像识别．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．30\n4.2.2物体检测．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．31\n4.2.3图像分割．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．32\n4.3推荐系统．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．33\n4.3.1协同过滤．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．33\n4.3.2内容基推荐．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．34\n4.3.3混合推荐系统．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．36\n常见问题与解决策略．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．37\n5.1过拟合与欠拟合．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．37\n5.2模型选择与调参．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．39\n5.3数据增强与迁移学习．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．40\n5.4超参数优化技巧．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．40\n未来趋势与展望．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．41\n6.1新兴技术的影响．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．42\n6.2大模型在特定领域的应用前景．．．．．．．．．．．．．．．．．．．．．．．．．．．．43\n6.3行业应用案例分享．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．44\n结论与实践指南．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．45\n7.1总结关键要点．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．46\n7.2初学者实践建议．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．47\n7.3后续资源与学习路径规划．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．47\n1.内容概括\n本篇科普文章旨在为初学者介绍大模型的基础知识与应用，我们将从基本概念出发，解释什么是大模型及其在人工智能领域的重要作用。接着，深入探讨大模型的工作原理，包括深度学习算法如何训练模型以及神经网络结构的设计。我们还将讨论大模型的应用场景，如自然语言处理、图像识别和推荐系统等，并分析其在这些领域的优势和挑战。\n本文还特别关注大模型可能带来的伦理和社会影响，例如隐私保护、偏见问题及数据安全风险。我们将提供一些实用建议，帮助读者更好地理解和利用大模型进行实际操作。通过阅读本文，希望每位新手都能对大模型有更全面的认识和理解。\n1.1大模型简介\n在探讨如何踏入大模型的世界之前，让我们首先对“大模型”这一概念进行一番简要的解读。所谓“大模型”，通常指的是那些具备海量数据训练、拥有强大计算能力的人工智能模型。这些模型以其卓越的学习能力和广泛的适用性，在众多领域展现出了巨大的潜力。\n简言之，大模型是由大量数据驱动的智能系统，它们通过不断的学习与分析，能够执行复杂的任务，并在此过程中不断优化自身的性能。在人工智能的发展历程中，大模型扮演着至关重要的角色，它们不仅推动了技术的进步，也为各行各业带来了深刻的变革。\n随着技术的不断演进，大模型的应用范围日益扩大，从自然语言处理到图像识别，从推荐系统到决策支持，大模型都能发挥其独特的作用。对于想要了解和学习大模型的人来说，掌握这一领域的基本知识显得尤为重要。我们将逐步深入，带领大家走进大模型的精彩世界。\n1.2小白入门的重要性\n对于初学者而言，掌握大模型的基础知识至关重要。这不仅有助于他们更好地理解人工智能领域的复杂概念，而且还能为他们后续深入学习提供坚实的基础。通过本文档，我们将详细介绍小白如何能够有效地入门并逐步深入到大模型的学习中。\n了解大模型的基本构成是入门的首要步骤，大模型通常由多个层次组成，包括输入层、隐藏层和输出层等。这些层次之间相互连接，共同构成了整个模型的功能。通过对这些层次的了解，新手可以更好地把握大模型的整体架构，为后续的学习打下坚实的基础。\n掌握基本的算法原理也是小白入门的关键，在深度学习领域，有许多不同的算法和技术可供选择。新手需要了解这些算法的原理和应用场景，以便在实际应用中能够灵活运用。了解常见的优化方法也是必不可少的，例如正则化、dropout等技术可以帮助模型更好地拟合数据，提高性能。\n实践操作是小白学习的重要环节，理论知识虽然重要，但实际操作才能让新手真正掌握知识。通过动手实践，新手可以更好地理解算法的工作原理，发现问题并解决问题。实践还可以帮助新手积累经验，为后续的学习打下良好的基础。\n持续学习和探索也是小白入门的重要途径，人工智能领域不断发展，新的技术和方法层出不穷。作为初学者，需要保持好奇心和"
  },
  {
    "title": "TensorFlow：模型训练与优化.docx-原创力文档",
    "page_body": "内容提供方 ： 找工业软件教程找老陈 大小 ： 28.1 KB 字数 ： 约1.73万字 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\nPAGE1\nPAGE1\nTensorFlow：模型训练与优化\n1TensorFlow基础\n1.1安装与环境配置\n在开始使用TensorFlow之前，首先需要确保你的环境已经正确安装了TensorFlow。以下是在Python环境中安装TensorFlow的基本步骤：\n安装Python：确保你的系统中已经安装了Python，推荐使用Python3.6或更高版本。\n安装pip：pip是Python的包管理器，用于安装和管理Python软件包。如果你的Python环境中没有pip，可以通过以下命令安装：\npythonget-pip.py\n安装TensorFlow：使用pip安装TensorFlow，可以通过以下命令进行安装：\npipinstalltensorflow\n如果你使用的是虚拟环境，确保在虚拟环境中执行上述命令。\n验证安装：安装完成后，可以通过Python脚本来验证TensorFlow是否安装成功。以下是一个简单的示例：\n#验证TensorFlow安装\nimporttensorflowastf\n#打印TensorFlow版本\nprint(tf.__version__)\n#创建一个简单的常量操作\nhello=tf.constant(Hello,TensorFlow!)\nsess=tf.Session()\n#运行会话并打印结果\nprint(sess.run(hello))\n运行上述代码，如果能够成功打印出版本信息和“Hello,TensorFlow!”，则说明TensorFlow已经成功安装。\n1.2张量与操作\n在TensorFlow中，数据以张量的形式表示，张量可以理解为多维数组。以下是一个创建张量和执行基本操作的示例：\n#创建张量\nimporttensorflowastf\n#创建一个1维张量\na=tf.constant([1.0,2.0,3.0],shape=[3],name=a)\n#创建一个2维张量\nb=tf.constant([[1.0,2.0,3.0],[4.0,5.0,6.0]],shape=[2,3],name=b)\n#执行张量操作\nc=tf.add(a,b,name=c)\nd=tf.multiply(a,b,name=d)\n#创建会话并执行操作\nwithtf.Session()assess:\nprint(a+b=,sess.run(c))\nprint(a*b=,sess.run(d))\n在这个例子中，我们创建了两个张量a和b，然后执行了加法和乘法操作。tf.add和tf.multiply是TensorFlow中的操作，它们接收张量作为输入，并返回一个新的张量作为输出。\n1.3构建计算图\nTensorFlow使用计算图来表示计算过程。计算图是一个有向图，其中节点表示操作，边表示张量。以下是一个构建计算图的示例：\n#构建计算图\nimporttensorflowastf\n#创建占位符\nx=tf.placeholder(tf.float32,shape=[None],name=x)\ny=tf.placeholder(tf.float32,shape=[None],name=y)\n#创建变量\nW=tf.Variable(tf.random_normal([1]),name=weight)\nb=tf.Variable(tf.zeros([1]),name=bias)\n#定义模型\ny_pred=tf.add(tf.multiply(x,W),b)\n#定义损失函数\nloss=tf.reduce_mean(tf.square(y_pred-y))\n#定义优化器\noptimizer=tf.train.GradientDescentOptimizer(0.01)\ntrain=optimizer.minimize(loss)\n#初始化变量\ninit=tf.global_variables_initializer()\n#创建会话并执行计算图\nwithtf.Session()assess:\nsess.run(init)\nforstepinrange(200):\nsess.run(train,feed_dict={x:[1,2,3,4],y:[0,-1,-2,-3]})\nif(step+1)%20==0:\nprint(step+1,sess.run([W,b]))\n在这个例子中，我们首先创建了两个占位符x和y，它们用于在运行时接收数据。然后，我们创建了两个变量W和b，它们用于存储模型的参数。接着，我们定义了模型y_pred，它是一个线性模型。然后，我们定义了损失函数loss，它是一个均方误差损失函数。最后，我们定义了优化器optimizer，它是一个梯度下降优化器，用于最小化损失函数。\n1.4会话与执行\n在TensorFlow中，所有的操作都在会话中执行。会话是一个运行计算图的环境。以下是一个使用会话执行计算图的示例：\n#使用会话执行计算图\nimporttensorflowastf\n#创建张量\na=tf.constant(5.0)\nb=tf.constant(6.0)\n#创建操作\nc=tf.add(a,b)\n#创建会话并执行操作\nwithtf.Session()assess:\nprint(a+b=,sess.run(c))\n在这个例子中，我们首先创建了两个张量a和b，然后创建了一个操作c，它是一个加法操作。然后，我们创建了一个会话，并在会话中执行了操作c。sess.run(c)会返回操作c的输出结果。\n会话是TensorFlow中的重要概念，所有的操作和变量都在会话中执行和初始化。在会话中，你可以通过feed_dict参数向占位符传递数据，通过run方法执行操作，通过eval方法获取张量的值。\n2TensorFlow：模型训练与优化\n2.1模型训练\n2.1.1数据预处理\n数据预处理是机器学习和深度学习项目中至关重要的第一步。在TensorFlow中，我们可以使用tf.data.Dataset来高效地加载和预处理数据。下面是一个使用MNIST数据集的例子，展示了如何对数据进行预处理：\nimporttensorflowastf\nfromtensorflow.keras.datasetsimportmnist\n#加载数据\n(x_train,y_train),(x_test,y_test)=mnist.load_data()\n#数据预处理\nx_train,x_test=x_train/255.0,x_test/255.0#归一化\ntrain_dataset=tf.data.Dataset.from_tensor_slices((x_train,y_train))\ntest_dataset=tf.data.Dataset.from_tensor_slices((x_test,y_test))\n#批量处理和缓存数据\nBATCH_SIZE=64\ntrain_dataset=train_dataset.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\ntest_dataset=test_dataset.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n2.1.2构建模型\n构建模型是使用TensorFlow创建神经网络的下一步。我们可以使用tf.keras中的Sequential或Model类来定义模型。下面是一个简单的多层感知器（MLP）模型的构建示例：\nfromtensorflow.keras.modelsimportSequential\nfromtensorflow.keras.layersimportDense,Flatten\n#构建模型\nmodel=Sequential([\nFlatten(input_shape=(28,28)),#将输入数据从2D转换为1D\nDense(128,activation=relu),#添加一个具有ReLU激活函数的全连接层\nDense(10)#输出层，10个节点对应10个类别\n])\n2.1.3损失函数与优化器\n选择合适的损失函数和优化器对于模型的训练至关重要。损失函数衡量模型预测与实际标签之间的差异，而优化器则用于更新模型参数以最小化损失。以下是一个使用交叉熵损失和Adam优化器的例子：\nfromtensorflow.keras.lossesimportSparseCategoricalCrossentropy\nfromtensorflow.keras.optimizersimportAdam\n#定义损失函数和优化器\nloss_fn=SparseCategoricalCrossentropy(from_logits=True)\noptimizer=Adam(learning_rate=0.001)\n#编译模型\npile(optimizer=optimizer,\nloss=loss_fn,\nmetrics=[accuracy])\n2.1.4训练模型\n训练模型涉及使用训练数据和标签来调整模型参数。在TensorFlow中，我们可以使用model.fit方法来训练模型。以下是一个训练模型的例子：\n#训练模型\nEPOCHS=5\nmodel.fit(train_dataset,epochs=EPOCHS)\n2.1.5评估模型性能\n评估模型性能通常在测试数据集上进行，以检查模型的泛化能力。我们可以使用model.evaluate方法来评估模型的性能。下面是一个评估模型的例子：\n#评估模型性能\ntest_loss,test_acc=model.evaluate(test_dataset)\nprint(Testaccuracy:,test_acc)\n通过以上步骤，我们可以在TensorFlow中完成一个模型的训练和优化过程。数据预处理确保数据适合模型训练，构建模型定义了神经网络的结构，损失函数和优化器的选择影响了模型的学习过程，而训练和评估则分别用于调整模型参数和检查模型的性能。\n2.2代码示例解释\n在上述代码示例中，我们首先加载了MNIST数据集，这是一个包含手写数字的图像数据集。数据预处理包括将图像数据归一化，使其范围在0到1之间，这有助于模型训练。然后，我们使用tf.data.Dataset来创建训练和测试数据集，并对其进行批量处理和缓存，以提高训练效率。\n构建模型时，我们定义了一个简单的多层感知器，它将输入图像从2D转换为1D，然后通过两个全连接层进行处理。损失函数选择了SparseCategoricalCrossentropy，适用于多分类问题，而优化器选择了Adam，这是一种自适应学习率优化算法。\n模型训练通过model.fit方法完成，我们指定了训练的轮数（epochs）。最后，我们使用model.evaluate方法在测试数据集上评估模型的性能，输出了测试集上的准确率。\n这个过程展示了如何使用TensorFlow进行模型训练和优化的基本步骤，从数据预处理到模型评估，每一步都是构建高效机器学习模型的关键。\n3模型优化\n3.1超参数调整\n超参数调整是模型优化的关键步骤，它涉及选择模型训练过程中的参数，这些参数不能通过训练过程本身学习得到。在TensorFlow中，常见的超参数包括学习率、批次大小、优化器类型、正则化系数等。调整超参数的目标是找到一组参数，使得模型在验证集上的性能最佳。\n3.1.1代码示例：使用GridSearchCV进行超参数调整\n#导入所需库\nfromsklearn.model_selectionimportGridSearchCV\nfromtensorflow.keras.wrappers.scikit_learnimportKerasClassifier\nfromtensorflow.keras.modelsimportSequential\nfromtensorflow.keras.layersimportDense\nimportnumpyasnp\n#定义模型\ndefcreate_model(optimizer=adam,init=glorot_uniform):\nmodel=Sequential()\nmodel.add(Dense(12,input_dim=8,kernel_initializer=init,activation=relu))\nmodel.add(Dense(8,kernel_initializer=init,activation=relu))\nmodel.add(Dense(1,kernel_initializer=init,activation=sigmoid))\npile(loss=binary_crossentropy,optimizer=optimizer,metrics=[accuracy])\nreturnmodel\n#包装模型以适应GridSearchCV\nmodel=KerasClassifier(build_fn=create_model,epochs=50,batch_size=10,verbose=0)\n#定义超参数网格\nparam_grid={epochs:[50,100],\nbatch_size:[10,20],\noptimizer:[adam,sgd],\ninit:[glorot_uniform,normal]}\n#创建GridSearchCV对象\ngrid=GridSearchCV(estimator=model,param_grid=param_grid,n_jobs=-1)\n#假设X_train和y_train是训练数据\n#grid.fit(X_train,y_train)\n#打印最佳参数\n#print(Bestparametersfound:,grid.best_params_)\n3.2正则化技术\n正则化技术用于防止模型过拟合，即模型在训练数据上表现很好，但在新数据上表现不佳。在TensorFlow中，常见的正则化技术包括L1、L2正则化和Dropout。\n3.2.1代码示例：使用L2正则化\nfromtensorflow.keras.modelsimportSequential\nfromtensorflow.keras.layersimportDense\nfromtensorflow.keras.regularizersimportl2\n#创建模型\nmodel=Sequential()\nmodel.add(Dense(12,input_dim=8,kernel_regularizer=l2(0.01),activation=relu))\nmodel.add(Dense(8,kernel_regularizer=l2(0.01),activation=relu))\nmodel.add(Dense(1,activation=sigmoid))\n#编译模型\npile(loss=binary_crossentropy,optimizer=adam,metrics=[accuracy])\n3.3学习率策略\n学习率是模型训练中最重要的超参数之一，它决定了模型权重更新的幅度。在训练过程中，学习率的调整可以显著影响模型的收敛速度和最终性能。TensorFlow提供了多种学习率调整策略，如指数衰减、余弦衰减和学习率调度器。\n3.3.1代码示例：使用学习率调度器\nimporttensorflowastf\nfromtensorflow.keras.callbacksimportLearningRateScheduler\n#定义学习率调度器\ndefstep_decay(epoch):\ninitial_lrate=0.1\ndrop=0.5\nepochs_drop=10.0\nlrate=initial_lrate*tf.math.pow(drop,\ntf.math.floor((1+epoch)/epochs_drop))\nreturnlrate\n#创建学习率调度器实例\nlrate=LearningRateScheduler(step_decay)\n#在模型训练中使用学习率调度器\nmodel.fit(X_train,y_train,epochs=30,batch_size=10,callbacks=[lrate])\n3.4模型融合与集成\n模型融合与集成是通过结合多个模型的预测"
  },
  {
    "title": "大模型+数据资产变现，RAG 驱动企业智能化实践案例-herramientas en línea",
    "page_body": "如果无法正常显示，请先停止浏览器的去广告插件。\n1 . 演讲人：黄佳 \n2 . 黄佳 研究员 / 技术图书作者 / 极客时间专栏作者 《极客时间 LangChain实战课》 《极客时间 RAG进阶训练营》 极客时间 RAG 训练营 Visuals Support: \n3 . 01 为什么我们仍然在谈论RAG 02 RAG落地痛点及优化思路 03 企业文档合规性问答系统落地实践 04 医疗术语标准化系统的落地实践 05 知识图谱在医疗术语标准化系统中的应用 06 MCP和A2A时代的RAG \n4 . \n5 . 01 \n6 . —— \n7 . 1. 人类与大模型直接对话 3. 大模型进行自主推理 2. 大模型进行知识检索 \n8 . \n9 . \n. \n11 . 02 \n12 . 落地难点 文档的导入和解析（图、表） 如何将相关联的内容整体切片或建立起相关联的索引 如何处理大规模、分布式向量数据 的精细化设计 如何构建程序代码的检索系统 图数据库和知识图谱和 系统的结合 如何设计有权限的 系统 \n13 . 系统 图 系 问 问 RAG 问 性 问 性 进行文档 合 问 问 问 问 问 问 问 性文档 问 图 答 问 文 系 大模型 问 大模型 实 问 实性 性 文档 时 文档 寻 找 瓶 颈 点 合 时 大模型 文档 文档 图 模 专 模型 答 进行 专 文 答 模型 者 模 文 文 文 文档 模 \n14 . 03 \n15 . Sustainability Report ESG 1. E 1. 2. 3. 2. Scope 1, Scope 2, Scope 3 S 1. 2. 3. 3. D&I G 1. 2. 3. Sustainability Report GRI \n16 . + • • PDF • • • • • • • 缺乏统 缺少高 有效 难 追踪 统难 持续 真实 与改进 准 • 与 文档导入 索引设计 如何评估 指标体系 致 闭环 系 \n17 . 文档 预处理模块 文档入库 提取元数据信息 文档切块 嵌入 向量数据库 索引 预处理Agent 政策法规 合规文档 技术文档 API文档 财务报表 年报文档 技术白皮书 （公式/图形） \n18 . 文档加载器 PyPDF Unstructured 说明 使 使 Unstructured 使 Amazon Textract MathPix pypdf 使 开 AWS API MathPix Package/API 特点 PDF文件 Package 高效轻 合 简单PDF文档 兼容 种文档格 支持内容 取 PDF文件 Package/API PDF文件 PDF文件 API API PDFPlumber PyPDFDirectry 使 PDFPlumber PDF文件 目录 PDF文件 Package Package PyPDFium2 使 PyPDFium2 Package PDF文件 PyMuPDF 使 PyMuPDF PDF文件 Package PDFMiner 使 PDFMiner PDF文件 Package 云服务支持 合大批 文档 OCR 专为 学公 计 准 内容 丰富 PDF内容控制 功 批 便 个PDF文档 高效 支持PDF页面 渲染 换 速 支持 PDF 细 合文 抽取 文 PDF 内容 \n19 . \n20 . from langchain_unstructured import UnstructuredLoader 除Markdown之外，我还需要构建一套索引系统 from typing import List from langchain_core.documents import Document page_url = \"https://zh.wikipedia.org/wiki/黑神话：悟空\" def _get_setup_docs_from_url(url: str) -> List[Document]: loader = UnstructuredLoader(web_url=url) setup_docs = [] # parent_id = None # 初始化 parent_id # current_parent = None # 用于存储当前父元素 for doc in loader.load(): # 检查是否是 Title 或 Table if doc.metadata[\"category\"] == \"Title\" or doc.metadata[\"category\"] == \"Table\": parent_id = doc.metadata[\"element_id\"] current_parent = doc # 更新当前父元素 setup_docs.append(doc) elif doc.metadata.get(\"parent_id\") == parent_id: setup_docs.append((current_parent, doc)) # 将父元素和子 元素一起存储 return setup_docs \n21 . PDF SimpleDirectoryReader SentenceSplitter \n22 . \n23 . 系统 图 系 问 问 问 性 问 性 进行文档 合 问 问 问 问 问 问 问 性文档 问 图 答 问 文 系 寻 找 瓶 颈 点 大模型 问 大模型 实 问 实性 性 文档 时 文档 合 时 大模型 文档 文档 图 模 专 模型 答 进行 专 文 答 模型 者 模 文 文 文 文档 模 \n24 . \n25 . \n26 . \n27 . 1. 构建两个向量数据库（Summary 和 Details），通过 Metadata进行链接 2. 通过LlamaIndex的IndexNode和PandasQueryEngine 3. 也可以通过查询先检索相关表名，然后做Text2SQL 4. 对于这个例子，也可以提取年份，用元数据进行Filter \n28 . 思路1：元数据提取 Year = 2023 思路2：直接检索Summary节点 2023年的碳排量 2024年的碳排量 2025年的碳排量 \n29 . 系统 图 系 问 问 问 性 问 性 进行文档 合 问 问 问 问 问 问 问 性文档 问 图 答 问 文 系 寻 找 瓶 颈 点 大模型 问 大模型 实 问 实性 性 文档 时 文档 合 时 大模型 文档 文档 图 模 专 模型 答 进行 专 文 答 模型 者 模 文 文 文 文档 模 \n30 . • • 实 实性 性 \n31 . \n32 . \n33 . \n34 . • • • F1 • • • P@K • BLEU • ROUGE • METEOR \n35 . 系统 图 系 问 问 问 性 问 性 进行文档 合 问 问 问 问 问 问 问 性文档 问 图 答 问 文 系 寻 找 瓶 颈 点 大模型 问 大模型 实 问 实性 性 文档 时 文档 合 时 大模型 文档 文档 图 模 专 模型 答 进行 专 文 答 模型 者 模 文 文 文 文档 模 \n36 . 04 \n37 . 系统 医院内存在多种电子病历系统与数据标准 临床医生使用非标准化术语记录病情 医疗数据分析需要统一术语标准以提高准确性 术 录 者 高 化 时 核心挑战 • 专业术语多样性：同义词、缩写、俚语并存 • 领域知识壁垒：需要专业医学背景解读上下文 • 系统适应性：需应对不同科室、不同记录习惯 • 实时性要求：诊疗过程中需快速响应 性 性 难 关 化 难 的 者 性 高 时 难 难 \n38 . 尿病 种 有 标 个 关系 为 尿病 关系 识 尿病 IS A 代谢性疾病 种 有 标 为 有 个 有 标 个 为 标 为“ ” 少有 73211009 疾病 限 种 个 种 少 有 个 系 个IS_A 系 个 件 标 有 个 关系 个 种 有 有 性 性 系 系 \n39 . \n40 . 05 \n41 . 找某 学 “部位” “ 所有 性 系 ” “因 ” 因果关系 获取 个 学 所有 语义网络 文 获取 个 学 概念和属性 性。 \n42 . \n43 . 系统 图 系 问 问 问 性 问 性 进行文档 合 问 问 问 问 问 问 问 性文档 问 图 答 问 文 系 寻 找 突 破 口 大模型 问 大模型 实 问 实性 性 文档 时 文档 合 时 大模型 文档 文档 图 模 专 模型 答 进行 专 文 答 模型 者 模 文 文 文 文档 模 \n44 . 06 \n45 . RAG RAG • LLM Agent RAG • MCP: / Agent \" \" Agent • A2A: Agent Agent \" \" Agent RAG RAG 在这个生态中既是连接 LLM 与外部海量知识的纽带（通过 MCP 的“手”）， 也是多 Agent 协作时的信息载体（通过 A2A 的“嘴”） RAG \n46 . \n47 . 探索 AI 应用边界 Explore the limits of AI applications"
  },
  {
    "title": "从黑箱到显微镜：大模型可解释性的现状与未来-妙投",
    "page_body": "专栏 · 更新中  查看全部 \n专栏 · 更新中  查看全部 \n专栏 · 更新中  查看全部 \n专栏 · 更新中  查看全部 \n专栏 · 更新中  查看全部 \n本文来自微信公众号： 腾讯研究院 （ID：cyberlawrc） ，作者：曹建峰（腾讯研究院高级研究员）、杨浩然（腾讯研究院实习生）\n大模型时代，AI模型的能力持续提升，在编程、科学推理和复杂问题解决等多个领域，已经展现出“博士级”专业能力。AI业界专家纷纷预测，大模型的发展正日益接近实现AGI甚至超级智能的关键拐点。然而，深度学习模型通常被视作“黑箱”，其内在运行机制无法被其开发者理解，大模型更是如此，这给人工智能的可解释性提出了新的挑战。\n面对这一挑战，行业正在积极探索提升大模型可解释性的技术路径，力图揭示模型输出背后的推理依据和关键特征，从而为AI系统的安全、可靠和可控提供坚实支撑。然而，大模型的发展速度却远远领先于人们在可解释性方面的努力，而且这一发展速度仍在迅猛提升。因此，人们必须加快脚步，确保AI可解释性研究能够及时跟上AI发展步伐，以发挥实质性作用。\n一、为什么我们必须“看懂”AI：可解释性的关键价值\n随着大模型技术的快速发展，其在语言理解、推理和多模态任务等领域展现出前所未有的能力，但模型内部决策机制高度复杂、难以解释，已成为学界和产业界共同关注的难题。大模型的可解释性（interpretability/explainability）是指系统能够以人类可理解的方式阐释其决策过程和输出结果的能力，具体包括：识别哪些输入特征对特定输出起关键作用，揭示模型内部的推理路径和决策逻辑，以及解释模型行为的因果关系。可解释性旨在帮助人类理解模型“为什么”作出某个决策，“如何”处理信息，以及在什么情况下可能失效，从而增强模型的透明度、可信度和可控性。简单来说就是，理解模型如何“思考”及运行。\n以生成式AI为代表的大模型的可解释性问题尤其复杂。因为生成式AI系统更像是“培育”出来的，而非“构建”出来的——它们的内部机制属于“涌现”现象，而不是被直接设计出来的。这与种植植物或培育细菌菌落的过程类似：开发者设定了宏观层面的条件，指导和塑造系统的成长，但最终所呈现的具体结构却无法精确预知，也难以理解或解释。1当开发者试图深入这些系统内部时，看到的往往只是由数十亿个数字构成的庞大矩阵。它们以某种方式完成了重要的认知任务，但具体如何实现这些任务却并不显而易见。\n增进大模型的可解释性对于人工智能发展意义重大。大模型的很多风险和担忧，最终源于模型的不透明性。如果模型是可解释的，就更容易应对这些风险。因此，可解释性的实现能够促进人工智能更好地发展。\n其一，有效防范AI系统的价值偏离与不良行为。未对齐的（misaligned）AI系统可能采取有害的行动。开发者无法理解模型的内在机制意味着就无法有效地预测这类行为，从而无法排除这种可能性。例如，研究人员发现模型可能展现出意料之外的涌现行为（emergent behavior），如AI欺骗（AI deception）或权力寻求（power-seeking）。AI训练的本质使得AI系统可能会自行发展出欺骗人类的能力，以及追求权力的倾向，而这些特征是传统确定性软件绝不会出现的。同时，这种“涌现”的特质，也使得发现和缓解这些问题变得更加困难。\n当前，由于缺乏对模型内部的观察手段，开发者无法当场识别模型是否出现了欺骗性的念头，这使得有关这类风险的讨论停留在理论揣测层面。如果模型具备有效的可解释性，人们就可以直接检查它是否存在企图欺骗或不服从人类指令的内部回路。通过查看模型内部表示，有望及早发现模型中潜藏的误导性倾向。\n有研究已经证明了这一思路的可行性：Anthropic团队通过跟踪Claude模型的“思维过程”，抓到了模型在数学题场景中编造虚假推理以迎合用户的行为，相当于“现行抓获”模型试图糊弄用户的证据，这为利用可解释工具检测AI系统的不当机制提供了原理验证。2总体而言，可解释性能为人们提供额外的检测手段，以确定模型是否与开发者的初衷发生了偏离，或者是否存在某些人们仅凭外部行为难以察觉的异常；它也能帮助人们确认模型在生成回答时使用的方法是否合理可靠。\n其二，有效推动大模型的调试和改进。Anthropic最近进行了一项实验，让一个“红队”刻意往模型中引入一个对齐方面的问题，然后让多个“蓝队”去找出问题所在。结果有多支蓝队成功找出了问题，其中一些团队使用了可解释工具去定位模型内部的异常。3这证明了可解释性方法在模型调试中的价值：通过检查模型内部，可以发现是哪部分导致了错误行为。\n例如，如果模型在某类问答上频繁出错，可解释性分析可以显示模型内部产生的原因，可能是缺乏对应知识的表示，或是错误地将相关概念混淆在一起。针对这种诊断结果，开发者可以有针对性地调整训练数据或模型结构，从而改进模型性能。\n其三，更有效地防范AI滥用风险。当前，开发者试图通过训练和规则来避免模型输出有害信息，但完全杜绝并非易事。进一步而言，对于AI滥用风险，产业界通常通过构建过滤器等安全护栏来应对，但恶意分子可以容易地对模型采取“越狱”等对抗性攻击，以实现其非法目的。如果可以深入观察模型内部，开发者也许能够系统性地阻止所有越狱攻击，并且能够描述模型具有什么危险知识。具体而言，如果模型具有可解释性，开发者就能够直接查看模型内部是否存有某类危险知识，以及哪些途径会触发，从而有望系统性地、针对性地封堵所有绕过限制的漏洞。\n其四，推动AI在高风险场景的落地应用。在金融、司法等高风险领域，法律与伦理要求AI决策具备可解释性。例如，欧盟《人工智能法案》将贷款审批列为高风险应用，要求解释决策依据。若模型无法说明拒贷理由，就无法依法使用，因而可解释性成为AI进入某些受监管行业的前提。4事实上，可解释性不仅是法律合规的要求，更直接影响AI系统在实际业务中的信任度和可采纳性。缺乏可解释性的AI推荐极易导致“橡皮图章式”（rubber-stamping）决策，即决策者机械采纳AI结论，缺乏对决策过程的深入理解与质疑。这种盲目信任一旦发生，既削弱了人类的主体性和批判性思维，也让执行者难以及时发现模型中的偏差或漏洞，导致错误决策被不加分辨地执行。5用户只有真正理解系统的推理逻辑，才能在关键时刻发现并纠正模型的错误，提高整体决策的质量与可靠性。因此，可解释性有助于建立用户对AI系统的信任，帮助用户理解模型作出某一决策的依据，增强他们的信任感和参与感。可见，无论出于法律要求还是应用信任，可解释性都是推动AI系统在关键领域落地的基础和核心要素。\n其五，探索AI意识与道德考量的边界。更前瞻地看，大模型的可解释性也可以帮助人们理解模型是否具有意识或者说是有感觉的（sentient），从而需要给予某种程度的道德考量。例如，Anthropic在2025年4月推出了一项关于“模型福祉”(model welfare)的新研究项目，探讨随着AI系统变得越来越复杂和类人化，是否需要对其给予道德关怀的问题，例如未来AI工具是否可能成为“道德主体”，如果有证据表明AI系统值得得到道德对待时该如何应对。6这项前瞻性研究反映了AI领域对于未来可能出现的AI意识和权利问题的重视。\n二、破解AI黑箱：四大技术路径的突破进展\n过去数年来，AI研究领域一直在试图攻克人工智能的可解释性难题，研究者们提出了各种可解释性的方法，致力于创造出类似于精准、高效的MRI（核磁共振成像）那样的工具，以清晰完整地揭示AI模型的内部机制。随着AI领域对大模型可解释性研究的重视程度不断提高，在AI模型的能力达到临界值之前，研究者们或许能够成功地实现可解释性，也就是彻底理解AI系统的内在运行机制。\n（一）自动化解释：利用一个大模型来解释另一个大模型\nOpenAI近年在模型内部机理解析上取得重要进展。2023年，OpenAI利用GPT-4对GPT-2中单个神经元在高激活样本中的共性进行归纳，并自动生成自然语言描述，实现在无需人工逐个检查的情况下，规模化获取神经元功能解释。7相当于自动给神经元“贴标签”，从而形成一个可以查询的AI内部“使用说明书”。\n例如，GPT-4给出某神经元的解释为“这个神经元主要在检测与‘社区’相关的词语”。随后验证发现，当输入文本包含诸如“society（社会）”“community（社区）”等词汇时，该神经元激活很强，证明解释具有一定有效性。8这项成果表明，大模型本身可以成为解释工具，为更小模型提供基于语义的透明度，这种自动化的神经元注释极大提升了可解释性研究的可扩展性。当然，该方法仍有局限，例如GPT-4生成的解释质量参差不齐，一些神经元行为难以用单一语义概念概括。\n（二）特征可视化：整体揭示大模型内部的知识组织方式\n对大模型整体特征的提取和分析也是一个重要方向。2023年底，OpenAI利用稀疏自编码器技术（sparse autoencoder）分析GPT-4模型的内部激活。研究人员成功提取出了数以千万计的稀疏特征（即模型“脑海”中少数被“点亮”的思维关键词），并通过可视化验证发现其中相当一部分特征具有清晰的人类可解释语义。\n例如，有的特征对应“人类不完美”的概念集合，激活在描述人类缺陷的句子上；有的特征表示“价格上涨”相关表述，激活于涉及价格上升的内容上。9短期内，OpenAI希望其发现的特征能够切实用于监测和引导语言模型的行为，并计划在其前沿模型中进行测试，以期可解释性最终能够为他们提供新的方法来思考模型的安全性和稳健性。\n2024年5月，Anthropic在其研究文章中展示他们在Claude模型中定位出数以百万计概念是如何被表示的。这项研究采用了字典学习与稀疏特征提取的方法。研究团队首先在一个小型模型上验证了该方法能够找到诸如“全大写单词”“DNA序列”“数学公式中的名词”等有意义特征；继而攻克工程难题，将算法扩展到大型模型Claude Sonnet，成功发现该模型内部蕴含着大量抽象概念的表示。\nAnthropic指出，由于每个概念往往由多个神经元共同表示、每个神经元也参与表示多个概念，因此直接查看单个神经元难以识别概念，而他们的方法将模型任一内部状态重新表达为少量特征的组合，有效降低了复杂性。比如，对于任意一段输入文本，Claude内部可能有上万个神经元激活，但可以提取出其中几十个显著特征，这些特征对应于高层语义概念，使研究者能够以接近人类思维的方式来看待模型此刻的“想法”。10这种特征化重构不仅增强了对模型内部逻辑的可读性，也为理解AI“当下在想什么”提供了更接近人类认知的分析路径。\n（三）思维链监控：对大模型"
  },
  {
    "title": "【全40集】AI大模型-LLM多模态视觉大模型视频精讲教程_哔哩哔哩_bilibili",
    "page_body": "陆陆续续也整理了不少资源，希望能帮大家少走一些弯路！无论是学业还是事业，都希望你顺顺利利 看在UP这么努力的份上，求个三连+关注嘛 1️⃣ 大模型入门学习路线图（附学习资源） 2️⃣ 大模型方向必读书籍PDF版 3️⃣ 大模型面试题库 4️⃣ 大模型项目源码 5️⃣ 超详细海量大模型LLM实战项目 6️⃣ Langchain/RAG/Agent学习资源 7️⃣ LLM大模型系统0到1入门学习教程 8️⃣ 吴恩达最新大模型视频+课件\n人工智能\n视觉大模型\n大模型入门\n大模型实战\n大模型学习路线\n深度学习\n大模型\nLLM\n多模态"
  },
  {
    "title": "高职商务管理案例教学论文",
    "page_body": "高职商务管理案例教学论文\n　　【摘要】高职商务管理学的实践运用性要求教师在教学过程中必须注重学生能力的培养,加强实践教学方法的运用,面对目前高职院校管理类课程教学过程中存在的问题,本文举例说明了案例教学在提高商务管理课程实践性的重要作用并初步探讨了案例教学的实施方法。\n　　【关键词】商务管理;实践教学;案例教学\n　　【Abstract】High vocational business affairs Principles of Management practice applies nature to require that the teacher must attach importance to student ability culture in the process of teaching, reinforce applying carrying out teaching method, face at present tall duty universities and colleges the case teaching managing kind course teaching process having been hit by have problem, the main body of a book citing an example by way of explanation puts method into practice in improving business affairs managing important course practicality effect and first step having discussed case teaching’s.\n　　【Key words】Business affairs is managed; Carry out teaching; Case teaching\n　　管理是一门理论与实践相统一,且综合性与应用性很强的学科,其涉及的具体内容包括战略管理、人力资源管理、生产运营管理、财务管理、营销管理等方面。这些内容紧贴企业组织管理的实际活动,因而商务管理专业的学生不仅需要系统地掌握企业组织管理的活动规律,还能够灵活地运用有关的方法和策略来解决实际问题,这就要求管理类课程内容安排上要注重以应用为主,教学过程中必须注重学生实际运用能力与素质的培养,设计出更符合课程要求的教学模式,尽可能的采用实践式的教学方法,这与高等职业教育的培养目标在根本上是一致的。但是,目前高职管理类课程的教学要实现这一目标还需要面对多方面的问题,尤其是课程实践教学的实施。\n　　1 商务管理课程教学现状\n　　1.1 教学内容。\n　　高等职业教育主要是为社会培养高等应用型人才,强调教学内容的实践性,因此,商务管理专业需要培养具有运用管理理论和实践方法的专业技术人才。但是,由于高职教育的理论知识只需“够用”,使得课程教授的内容变为本科管理类课程的压缩,理论教学内容简化的同时并没有增加多少实践教学的内容。\n　　1.2 教学手段。\n　　商务管理的教学要求理论与实践相结合,注重实际问题的分析和解决实际问题的方法,培养学生分析问题、解决问题的能力。但是,目前许多高职院校在很大程度上沿袭了过去的课堂讲授模式;而且,学生直接参与企业经营管理活动的机会较少,学生只能从书本中汲取知识和经验,造成商务管理专业的学生能“纸上谈兵”却无法“脚踏实地”。\n　　1.3 成绩评定方法。\n　　但我们国家传统的教学体制是一种应试教育,强调学生对理论知识的记忆。在高校中主要采取的还是以考试方式来测试学生的学习成绩,学生为追求高分而死记硬背,造成学生在学习的过程中就有重理论而轻实践的倾向,忽视了管理类学科本身就是来自于实践的一门科学。\n　　2 案例教学实施的基本方法\n　　针对以上问题笔者认为,商务管理专业的教师应该从企业组织等市场主体对人才需求的特点出发,以提高学生的兴趣和分析运用能力为导向,来设计和组织教学。不仅要告诉学生理论与方法的形成和应用,还要学生树立如何在变化的管理环境中去对理论与方法进行完善和创新的意识。在管理案例教学实践中,教师可视实际情况采用课内讨论法或分析报告法,即有学生课堂讨论或书写分析报告。以下是笔者在对企业员工忠诚度的案例教学中的实施过程。\n　　2.1 案例选择。\n　　案例选择应具有启发性,案例的描述应尽可能的简洁生动,便于学生理解;案例的思考题应该能够帮助学生对案例存在的问题进行思考,问题必须揭示案例的本质,而不能过于简单肤浅。\n　　2.1.1 案例正文。\n　　“深圳有家电子企业非常重视员工的技能培训,几年下来便拥有一批得力的技工,成为生产骨干,很能解决问题,一时间订单不断,利润大增。老板欣喜若狂,对这批骨干宠爱有加,频频加薪宴请,嘘寒问暖。老板颇为得意:一手抓金钱,一手抓酒瓶,还怕你们不卖命?\n　　谁知好景不长,那些技术骨干的工头目本是老实人,但几年下来满脑子只有钞票美酒,逐渐变得自私贪婪。和老板酒酣耳熟之际竟萌生了歪念:我有一批骨干,老板没我不行,何不敲他一笔?见得手容易,便公开讲数,得寸进尺,一发不可收拾。稍不遂意便带头怠工,再以集体跳槽相威胁,最后竟然在外商验货之际做了手脚,使企业损失惨重。老板怒不可遏,把这批技工全部炒掉,企业元气大伤。”①\n　　2.1.2 案例思考:\n　　问题一:企业能否仅仅通过增加员工的薪水和福利来提高员工的忠诚度?\n　　问题二:员工技能培训是否能够真正提高员工的素质并提高员工的忠诚度?\n　　问题三:员工忠诚的培养是靠私人感情还是制度管理?\n　　2.2 案例分析:\n　　案例分析一方面是一个搜集信息、分析理解信息的过程,教师需要引导学生积极思考,剔除干扰信息,找到揭示案例本质问题的段落或字句,同时结合理论知识对案例的要点进行讲解。它包括案例的详细解读与问题的讨论。\n　　2.2.1 通过详细解读解剖案例。这一环节的关键是培养学生获取信息和分析、判断的方法,寻找问题的根源是什么。另一方面,在课堂讨论中,学生往往会因为理论知识不扎实,缺乏实践工作经验而是讨论不能正常进行,因此教师要尽可能的引导学生,提供更多类似的管理信息或案例分析方案,作为举例,引导学生在本案例中做出类似的思考或解决方法。\n　　2.2.2 问题的讨论与解答。不论是分组讨论还是自由回答,教师都必须尊重学生的自发形成观点,不论观点是否成熟都应该给与鼓励,强调其观点合理的部分,指出其观点的不足之处,同时引发其他学生的思考,保证积极的、良性的争论能够有序地进行。此外,相对于部分性格外向且口才较好的学生,性格内向的同学往往不适应这种方式,教师如果强迫学生回答,可能会引起这类学生的逆反情绪,因此可以提前要求学生在课前做好准备,形成文字稿,能够在课上自信的回答问题。\n　　针对这个案例所提出的问题,学生所的观点主要包含以下三个部分: 2.2.2.1 忠诚度的培养不应该仅仅依靠物质刺激。企业员工的忠诚度是通过对薪资、培训等激励制度中融入企业文化等一系列的物质和精神投入来提高的。在现实中物资激励虽有较大的激励作用,但也要避免过多采用物资激励的方式带来的负面效应,应使物质与精神激励相结合。所以除了加薪以外,企业具有良好的人际关系、更多的晋升机会、人员之间的竞争及发展前景等也能加强对人才的吸引。\n　　2.2.2.2 员工培训不只是技能培训,还要包括企业文化培训。企业员工培训不仅是要培养符合企业需要的技术人才,更具有传递企业文化价值观、道德伦理观以及诚信意识,改变员工观念,提高员工忠诚度,更新知识,发展能力的作用,是为企业培养人才的有利手段。另一方面,企业的培训计划应使所有员工都有接受培训的机会,尤其是对新人创新能力和学习能力的培养,避免少数人控制企业的重要技术资源,加大了企业的人员流失的风险。最后要对培训结果进行科学的测试。不仅要测试人员的技术能力,更要了解他们对企业经营理念、价值观以及各种制度、规范有没有清楚的认识和正确地工作态度,即员工忠诚度的测试。凡是对企业缺乏认同的员工不以赋予重任,以减少人员流失带来的成本。\n　　2.2.2.3 提高员工的忠诚度要在完善企业制度的框架之下,以企业制度均衡各方利益,形成企业的制度化管理,无论是对员工的奖励还是惩罚都要有理有据。以企业各方利益最大化为基础的员工满意所产生的员工忠诚才是企业所追求的忠诚。否则,以牺牲企业整体利益换取员工的“忠诚”是没有意义的。\n　　2.3 总结归纳,强化技能。\n　　案例的总结应将讨论的结果再次升华到理论高度。教师需要对学生的观点进行详细的分析、评价,但不需要立即将案例分析总结全盘托出,而是由学生自己对所有人的分析做出总结。这是培养学生理论实践运用的最佳时机,培养学生对现实问题的反思和创新的思维,避免形成教师权威或书本权威的思维定势,从而进一步提高学生知识和技能的分析、运用、反思和创新的能力。在此过程中,教师可以通过分析学生的总结来发现理论教学中存在的不足之处,在以后的教学过程中改进。\n　　案例教学实施过程流程:\n　　3 正确处理案例教学与课堂讲授方式的关系\n　　案例教学法在解决管理类课程实践教学的问题上虽有其优势,还是不能代替一般的课堂理论教学,因为学生只有通过掌握的基本知识和理论,才能进行问题的分析,理论是分析问题的依据和方法,如果没有理论和知识,单纯进行案例分析是无法提高于学生实践能力的。此外,而案例教学需要学生的积极参与,对与我国的学生习惯于听而不善于讲的情况下,必须对其进行有效的激励,确保学生能够参与到案例的分析中来,因而需要将学生在案例讨论中的表现纳入考核范围。\n　　注释:\n　　①案例来源:金羊网2004-08-09 12:00:18\n　　参考文献\n　　[1]黄仲龙.管理案例教学法的实践与探索,经济与社会发展,2005.11\n　　[2]戴良铁.MBA人力资源管理课程案例教学法探索,广东外语外贸大学学报,2003.9\n　　[3]王妙.实践型教学的探索:高职市场营销学课程改革实例分析[M].上海:立信会计出版社,2005\n　　[4]李季鹏.体验式教学法在“管理学”教学中的应用[J].黑龙江教育(高教研究与评估,2006(10)\n【高职商务管理案例教学论文】相关文章：\n高职商务文秘英语实训教学初探论文 05-02\n高职院校教学管理建设论文 04-27\n高职院校教学管理的建设分析论文 05-02\n基于DACUM法高职商务管理专业课程的构建论文 05-01\n高职教学管理效能浅探的论文 04-27\n刍议高职英语教学创新管理分析论文 05-01\n商务英语案例教学探索 04-27\n高职院校学生管理研究论文 05-02\n高职英语教学论文 05-02\n高职体育教学探析论文 05-01"
  },
  {
    "title": "学术报告—怎样写好毕业论文-豆丁网",
    "page_body": "下面是赠送的合同范本，不需要的可以编辑删除！！！！！！ 　教育机构劳动合同范本 为大家整理提供，希望对大家有一定帮助。 　　一、_________培训学校聘请_________籍_________(外文姓名)_**______(中文姓名)先生**士/小姐为_________语教师，双方本着友好合作精神，自愿签订本合同并保证认真履行合同中约定的各项义务。 　　二、合同期自_________年_________月_________日起_________年_________月_________日止。 　　三、受聘方的工作任务(另附件1) 　　四、受聘方的薪金按小时计，全部以人民币支付。 　　五、社会保险和福利： 　　1.聘方向受聘方提供意外保险。(另附2) 　　2.每年聘方向受聘期满的教师提供一张_________至_________的来回机票(金额不超过人民币_________元整)或教师凭机票报销_________元人民币。 　　六、聘方的义务： 　　1.向受聘方介绍中国有关法律、法规和聘方有关工作制度以及有关外国专家的管理规定。 　　2.对受聘方提供必要的工作条件。 　　3.对受聘方的工作进行指导、检查和评估。 　　4.按时支付受聘方的报酬。 　　七、受聘方的义务： 　　1.遵守中国的法律、法规，不干预中国的内部事务。 　　2.遵守聘方的工作制度和有关外国专家的管理规定，接受聘方的工作安排、业务指导、检查和评估。未经聘方同意，不得兼任与聘方无关的其他劳务。 　　3.按期完成工作任务，保证工作质量。 　　4.遵守中国的宗教政策，不从事与专家身份不符的活动。 　　5.遵守中国人民的道德规范和风俗习惯。 　　八、合同的变更、解除和终止： 　　1.双方应信守合同，未经双方一致同意，任何一方不得擅自更改、解除和终止合同。 　　2.经当事人双方协商同意后，可以变更、解除和终止合同。在未达成一致意见前，仍应当严格履行合同。 　　3.聘放在下述条件下，有权以书面形式通知受聘方解除合同： 　　a、受聘方不履行合同或者履行合同义务不符合约定条件，经聘方指出后，仍不改正的。 　　b、根据医生诊断，受聘放在病假连续30天不能恢复正常工作的。 　　4.受聘方在下述条件下，有权以书面形式通知聘方解除合同： 　　a、聘方未经合同约定提供受聘方必要的工作条件。 　　b、聘方未按时支付受聘方报酬。 　　九、本合同自双方签字之日起生效，合同期满后即自行失效。当事人以方要求签订新合同，必须在本合同期满90天前向另一方提出，经双方协商同意后签订新合同。受聘方合同期满后，在华逗留期间的一切费用自理。 　　十、仲裁： 　　当事人双方发生纠纷时，尽可能通过协商或者调解解决。若协商、调解无效，可向国家外国专家局设立的外国文教专案局申请仲裁。 　　本合同于_________年_________月_________日在_________签订，一式两份，每份都用中文和_________文写成，双方各执一份，两种文本同时有效。 　　聘方(签章)_________ 　　受聘方(签章)_________ 　　签订时间：年月日 二手房屋买卖合同范本由应届毕业生合同范本 　　卖方：_______________(简称甲方) 　　身份证号码：_____________________ 　　买方：_______________(简称乙方) 　　身份证号码：_____________________ 　　根据《中华人民共和国经济合同法》、《中华人民共和国城市房地产管理法》及其他有关法律、法规之规定，甲、乙双方在平等、自愿、协商一致的基础上，就乙方向甲方购买房产签订本合同，以资共同信守执行。 　　第一条　乙方同意购买甲方拥有的座落在______市_____区________________________拥有的房产(别墅、写字楼、公寓、住宅、厂房、店面)，建筑面积为_____平方米。(详见土地房屋权证第_______________号)。 　　第二条　上述房产的交易价格为：单价：人民币________元/平方米，总价：人民币___________元整(大写：____佰____拾____万____仟____佰____拾____元整)。本合同签定之日，乙方向甲方支付人民币__________元整，作为购房定金。 　　第三条　付款时间与办法： 　　1、甲乙双方同意以银行按揭方式付款，并约定在房地产交易中心缴交税费当日支付 　　首付款(含定金)人民币____拾____万____仟____佰____拾____元整给甲方，剩余房款人 　　民币____________元整申请银行按揭(如银行实际审批数额不足前述申请额度，乙方应在 　　缴交税费当日将差额一并支付给甲方)，并于银行放款当日付给甲方。 　　2、甲乙双方同意以一次性付款方式付款，并约定在房地产交易中心缴交税费当日支 　　付首付款(含定金)人民币____拾____万____仟____佰____拾____元整给甲方，剩余房款 　　人民币____________元整于产权交割完毕当日付给甲方。 　　第四条　甲方应于收到乙方全额房款之日起____天内将交易的房产全部交付给乙方使用，并应在交房当日将_________等费用结清。 　　第五条　税费分担甲乙双方应遵守国家房地产政策、法规，并按规定缴纳办理房地产过户手续所需缴纳的税费。经双方协商，交易税费由_______方承担，中介费及代办产权过户手续费由______方承担。 　　第六条　违约责任甲、乙双方合同签定后，若乙方中途违约，应书面通知甲方，甲方应在____日内将乙方的已付款不记利息)返还给乙方，但购房定金归甲方所有。若甲方中途违约，应书面通知乙方，并自违约之日起____日内应以乙方所付定金的双倍及已付款返还给乙方。 　　第七条　本合同主体 　　1.甲方是____________共______人，委托代理人________即甲方代表人。 　　2.乙方是____________，代表人是____________。 　　第八条　本合同如需办理公证，经国家公证机关____公证处公证。 　　第九条　本合同一式份。甲方产权人一份，甲方委托代理人一份，乙方一份,厦门市房地产交易中心一份、________公证处各一份。 　　第十条　本合同发生争议的解决方式：在履约过程中发生的争议，双方可通过协商、诉讼方式解决。 　　第十一条　本合同未尽事宜，甲乙双方可另行约定，其补充约定经双方签章与本合同同具法律效力。 　　第十二条　双方约定的其他事项： 　　出卖方(甲方)：_________________ 　　　　　　购买方(乙方)：__________________ 　　身份证号码： __________________　 　　　　　身份证号码： ___________________ 　　地　　　址：___________________　　 　　　　地　　　址：____________________ 　　邮　　　编：___________________ 　　　　　　邮　　　编：____________________ 　　电　　　话：___________________　　 　　　　电　　　话：____________________ 　　代理人(甲方)：_________________ 　　　　　　代理人(乙方)： _________________ 　　身份证号码: ___________________　　 　　　　身份证号码： ___________________ 　　鉴证方： 　　鉴证机关： 　　地　　址： 　　邮　　编： 　　电　　话： 　　法人代表： 　　代　　表： 　　经 办 人： 　　日　　期：　　年　　月　　日 　　鉴证日期：_______年____月____日 1选题 1.1选题要恰当 毕业论文写作，选题是关键，在学习撰写毕业论文时首先就应该学会如何选题。在进行毕业论文的选题时，应着重注意选题要恰当。题目大小适中，对实际工作有一定指导意义；应结合当前科技和经济发展，尽可能选择与社会发展及实际工作相结合的题目。一个题目太小了则不利于展开理论上的探讨。如果做一篇2-3千字的小型论文就可以将这种制度上的变革目的和效果阐释清楚，但是拿它来做一篇1万字左右的毕业论文就显得小题大做了。这种具体业务做法上的些许改变其意义一般也不是太大的。反过来，一个题目太大则不利于抓住重点展开论述。论文题目太大，撰写论文时就无法落笔，往往是什么都涉及到一点儿，但什么都不深入、谈不透。一个适当的题目应当是着眼点十分清楚的。某个方面的问题可能有不同的见解，有一些因素使得它不能一下子得出结论，需要做一些分析才能看出结果；但是，假如站在不同的角度，得出的结论也不同。这种问题很适合于一篇1万余字的毕业论文规模，也是学生尝试着用自己的知识分析问题、解决问题的好题目。 1.2选题最好能建立在平日比较注意探索的问题的基础上 写论文主要是反映对问题的思考，所以假如对问题了解甚少或几乎没有什么感想，那么，要挖空心思讨论一个问题就难了，因为他将不知道到底应该持有什么样的见解才是对的。假如对一个问题已经有一定的观察和思考，那么，剩下来的事就只是将能够支持其感想的一些理论和事实数据找出来加以整理，用以支持和表达他的论点。俗话说：\"有话则长，无话则短\"，一篇6000余字的论文没有一点儿自己的感受是很难写成的，除非做裁缝，将他人的文章相互拼凑在一起完事。 大量阅读某个方面的学术文章，看别人在这方面有些什么见解，一边看一边将自己的感想记录下来，经过一定的阅读就会在这方面积累相当多的知识，而自己的见解也可能慢慢形成。有时候学生可能对一些观点有所怀疑，不妨将自己的怀疑提出来，用实事去分析它们是否合理，通过对不同的观点所依据的条件的对比分析，就可以找到一些依据，证明自己的怀疑是否成立，这本身就是一种论证过程。 1.3选题应鼓励学术创新 避免选择已经完全得到解决的常识性问题；选题要注意与时俱进，鼓励解决实际问题。经济学方面的课题经常是很具有时代性的，一个课题会随着经济形势的变化而变化。 1.4选题应与自己所学专业相关 选题应符合专业培养目标和教学要求，以学生所学专业课的内容为主，不应脱离专业范围，要有一定的综合性，具有一定的深度和广度。国贸专业的学生，毕业论文必须在专业有关的方向上选取。选题必须符合国际经济与贸易专业方向要求，需要实际调研数据资料和分析结论。 1.5坚持理论联系实际的原则 撰写毕业论文必须坚持理论联系实际的原则。理论研究，非凡是社会科学的研究必须为现实服务，为社会主义现代化建设服务，为两个文明建设服务。理论来源于实践，又反作用于实践。科学的理论对实践有指导作用，能通过人们的实践活动转化为巨大的物质力量。科学研究的任务就在于揭示事物运动的规律性，并用这种规律性的熟悉指导人们的实践，推动社会的进步和发展。因此，毕业论文在选题和观点上都必须注重联系社"
  },
  {
    "title": "transformer 位置编码-zhou-snaker-博客园",
    "page_body": "个人学习使用，内容来源于网络，侵权删\n1. 公式\n2. 原理\n3. 代码实现\n# Positional Encoding代码实现 class PositionalEncoding (nn.Module):      def __init__ ( self, d_model, dropout= 0.1 , max_len= 5000 ):          super (PositionalEncoding, self).__init__()           # 偶数和奇数在公式上有一个共同部分，使用log函数把次方拿下来，方便计算 # pos代表的是单词在句子中的索引，如max_len是128，那么索引就是从0，1，2，...,127 # 假设dmodel是512，2i符号中i从0取到255，那么2i对应取值就是0,2,4...510          self.dropout = nn.Dropout(p=dropout)          pe = torch.zeros(max_len, d_model)         position = torch.arange( 0 , max_len, dtype=torch. float ).unsqueeze( 1 )         div_term = torch.exp(torch.arange( 0 , d_model,  2 ). float () * (-math.log( 10000.0 ) / d_model))   # 共有的部分          pe[:,  0 :: 2 ] = torch.sin(position * div_term)    # 从0开始到最后面，补长为2，其实代表的就是偶数位置          pe[:,  1 :: 2 ] = torch.cos(position * div_term)    # 从1开始到最后面，补长为2，其实代表的就是奇数位置 # 上面代码获取之后得到的pe:[max_len * d_model] # 下面这个代码之后得到的pe形状是：[max_len * 1 * d_model]          pe = pe.unsqueeze( 0 ).transpose( 0 ,  1 )          self.register_buffer( 'pe' , pe)   # 定一个缓冲区，简单理解为这个位置编码pe是一个常规参数，不参与更新 def forward ( self, x ):          \"\"\"         x: [seq_len, batch_size, d_model]  经过词向量的输入         \"\"\"          x = x + self.pe[:x.size( 0 ), :]    # 经过词向量的输入与位置编码相加 return  self.dropout(x) \n参考来源：\nTransformer 中的 Positional Encoding\nTransformer原理及Pytorch代码实现"
  },
  {
    "title": "AI大模型全栈学习指南：零基础入门到精通系统性框架(全网最全)建议收藏！人工智能_模型优化师-北京朝阳AI社区",
    "page_body": "01 基本认知\n从 2022 年开始，大语言模型的数量呈爆发式的增长，各大公司和研究机构都在发布不同类型的大语言模型。\n基础模型是指仅经过预训练的模型；\n对话模型是指在预训练模型基础上经过有监督微调和强化学习训练的模型，具备对话和完成任务的能力；\n推理模型是指专注于逻辑推理增强的大语言模型。\n大模型全称 大语言模型 （现发展有多模态大模型）\n≥数百亿参数的深度神经网络\n新范式： 预训练+指令微调！\n训练方式： 大量无标注文本进行自监督学习\n记住下面这些开源模型：\n学习大模型最基本要有深度学习基础，其次是一个大模型中的一个核心模型—— Transformer ，难点也在这里，无论是训练原理、推理、效率优化都以底层原理为基础，其次就是实操工程经验了！\nTransformer中的核心就是“自注意力机制”，且可多头并行，为并行加速提供了契机！\n02 构建流程\n以OpenAI的公开信息，主要包含四个阶段：预训练、有监督微调、奖励建模和强化学习。每个阶段所需的 数据集规模、算法类型、产生的模型、时间和GPU资源 都不相同：\n1、预训练\n预训练的灵感来自CV中的ImageNet，使用训练数据训练出一个 具备通用且强大的自然语言表示能力 ，该模型能有效学习到词汇、语法、语义等信息。\n要理解这点，你需要知道——Transformer训练大模型的本质的是得到一个 预测模型 ，即通过已有的语言序列预测下一个词，不断，反复 在支持的最长上下文限制窗口内 进行。\n（1）预训练数据集\n数据集分类、预处理：\n通用数据集：网页、图书、新闻、对话文本等。规模大、多样性和易获取。\n专业数据集：多语言数据、科学文本数据、代码及领域特有资料等。预训练时引入专业数据集可有效提高大模型解决任务的能力。\n初筛： 质量过滤、去冗余、隐私消除 。\n词元切分： Tokenization 将原始文本分割成词元序列的过程，是数据预处理中至关重要的一步。\n影响分析：数据规模、质量和多样性评估。分析数据对大语言模型训练所需资源或预估模型性能的影响。\n开源数据集：Pile、RefinedWeb、ROOTS、CulturaX、SlimPajama等。\n（2）分布式预训练\n训练是自监督的，并行策略：\n数据并行：每个计算设备都有整个神经网络模型的模型副本 Model Replica ，进行迭代时，每个计算设备只分配一个批次数据样本的子集，并根据该批次样本子集的数据进行网络模型的前向计算。DP、DDP、FSDP、ZeRO等。\n模型并行：用于解决单节点内存不足的问题。分为两种： 层间并行（算子间并行/流水线并行PP）、层内并行（算子内并行/张量并行TP） 。还有SP、EP。\n混合并行：将多种并行策略如数据并行、流水线并行和张量并行等混合使用。\n训练配置： 正则化方法、激活函数、优化器 等。\n训练的集群架构：\n硬件组成：多个计算加速器组成的服务器、架顶交换机、骨干交换机等组成，往往为树形结构。\n其他：参数服务器PS架构、去中心化架构。\n2、指令微调（有监督微调SFT）\n得到预训练完的基础模型后，模型虽然具备了大量的“知识”，但是由于其训练时的目标 仅是进行后续词的预测 ，因此不能够理解并遵循人类自然语言形式的指令。\n要进一步用于下游任务需要再构建 问题与答案的数据集 进行指令微调，在通用语义表示的基础上，适配下游任务特性。\n从训练方式的角度来看，指令微调与预训练大体上较为相似，不过 指令微调的目标函数往往只是针对输出部分来计算损失 。\n（1）指令微调数据集\n相比预训练数据集量级小的多，根据OpenAI公开消息，指令微调阶段也仅仅使用数万条数据。\n构成：文本对，包含“指令输入”与“答案输出”两个关键部分。\n构建方法：手动构建、现有数据集转换、自动构建以及综合模式。都是一个学习点\n数据影响评估：数据质量、数据多样性、数据对结果影响评估等。\n开源数据集：通用、特定领域。\n（2）指令微调\n全量微调：微调全部参数\n高效微调：微调部分参数，旨在仅训练少量参数就使模型适应下游任务。例如 LoRA大语言模型的低秩适配器 ，算法结构如下：\nLoRA 算法不仅在 RoBERTa、DeBERTa、GPT-3 等大语言模型上取得了很好的效果，还应用到了 Stable Diffusion 等视觉大模型中，可以用小成本达到微调大语言模型的目的。引起了企业界和研究界的广泛关注。\n还有一些变体： AdaLoRA、QLoRA、IncreLoRA 及 LoRA-FA 等。\n（3）上下文窗口扩展\n你肯定遇到过经过多轮对话后，AI抽风记不住之前的要求，开始胡乱编撰。随着更多长文本建模需求的出现，多轮对话、长文档摘要等任务在实际应用中越来越多。\n常见上下文窗口扩展技术：\n增加上下文窗口的微调 ：采用直接的方式，即通过使用一个更大的上下文窗口来微调现有的预训练 Transformer，以适应长文本建模需求。\n具备外推能力的位置编码 ：改进的位置编码，如 ALiBi[240]、LeX[241] 等能够实现一定程度上的长度外推。这意味着它们可以在小的上下文窗口上进行训练，在大的上下文窗口上进行推理。\n插值法 ：将超出上下文窗口的位置编码通过插值法压缩到预训练的上下文窗口中。\n3、强化学习（RL）\n有监督微调后的模型初步具备回答指令的能力，但有2个缺陷：\n麻烦：需要构建海量指令-答案对数据集，高质量回复标注需耗费高昂人力成本；\n难以适应多样性：交叉熵损失函数要求模型输出与标准答案逐字匹配，既无法适应自然语言的表达多样性，也难以解决输出对输入微小变动的敏感性。\n针对以上，所以补充上 强化学习 ！\n强化学习（RL）研究的是智能体与环境交互的问题，其目标是使智能体在复杂且不确定的环境中最大化奖励。\n2种演进方向：\n基于人类反馈的强化学习（RLHF） ：模型自主探索更优的回复策略，并使得模型回复与人类偏好和价值观对齐。 面向深度推理的强化学习 ：以 OpenAI 的 O 系列模型和 DeepSeek的 R 系列为代表，通过答案校验引导模型进行多步推理。这类方法将复杂问题分解为长思维链（Chain-of-Thought）的决策序列，在数学证明、代码生成等场景中展现出超越监督学习的推理能力。 比之有监督学习：RL摆脱局部最优束缚、突破数据覆盖的认知边界、复杂系统长期价值建模。\n算法方法：\n传统方法（如 Q-learning） ：通常基于“价值函数”间接优化策略——先评估动作的价值，再选择最优动作。 策略梯度（Policy Gradient）方法 ：摒弃了“先估值再决策”的中间步骤，而是将策略本身参数化（例如用神经网络表示），直接通过梯度上升优化策略参数，让智能体更倾向于选择能带来高回报的动作。\n 学习时可从从策略梯度的基础概念出发，回顾经典算法如  REINFORCE，PPO  等，并讨论在大模型时代流行的  GRPO，RLOO  等方法。\n开源框架：\n字节跳动与香港大学联合开源的 RL 框架 verl（HybridFlow），为大模型强化学习训练带来了创新性的解决方案，有效解决了传统 RL/RLHF 系统灵活性和效率不足的问题。\n开源数据集：\nSummarize from Feedback：OpenAI 在2020年就将RLHF技术引入摘要生成，该数据集分为两部分：对比部分和轴向部分。对比部分共计 17.9 万条数据，标注者从两个摘要中选择一个更好的摘要。轴向部分则有共计 1.5 万条数据，使用 Likert 量表为摘要的质量评分。对比部分仅有训练和验证划分，而轴向部分仅有测试和验证划分 WebGPT的人类反馈数据集：来指导模型提升长文档问答能力，该数据集包含在 WebGPT 项目结束时被标记为适合奖励建模的所有对比数据，总计 1.9 万条数据。 其他：Anthropic 的HH-RLHF数据集、Stanford Human Preferences（SHP）数据集。\n4、推理效率优化（模型、训练、推理）\n大模型的推理过程与其他深度学习模型（如 BERT、ResNet 等）非常不同，BERT 的执行时间通常是确定且高度可预测的。\n但在大语言模型的推理过程中，虽然每次迭代执行时间具有确定性，但 迭代次数（输出长度）是未知的 。\n影响效率指标的关键因素：计算成本、内存访问成本、内存使用情况。\n 核心原因：模型规模、自注意力机制（计算复杂度核心来源）、解码方法。\n效率优化方法：\n模型优化：\n优化模型结构 （ 高效 FFN 设计、注意力机制优化、MoE 架构设计、Transformer 代替架构设计 ）\n模型压缩 （ 修改模型的数据表示（例如量化）、改变其架构（例如稀疏化、结构优化等）、知识蒸馏 来提高推理效率）\n低精度训练：\n前主流训练框架（例如 Megatron-LM、MetaSeq 和 Colossal-AI）仍采用 FP32 全精度或混合精度的 FP16/BF16 策略。\n随着 Nvidia H100 GPU 的推出， FP8  正逐渐成为下一代低精度数据表示的主流格式。面临 数据下溢或上溢问题 。\n推理优化： 算法级 （多模型推测解码、KV-cache 优化）、 系统级 （模型/硬件并行化策略、显存优化、调度优化、网络请求优化、采样解码加速等）。\n5、部署与应用\n三层工作：\n基础层：大模型、深度学习框架（Pytorch/Tensorflow）、硬件算力支持（GPU/TPU集群）。 部署层：模型压缩/量化/剪枝、推理优化（TensorRT、ONNX Runtime）、部署架构（云原生/嵌入式边缘端）、服务化封装（API网关、负载均衡）。 应用层：场景适配（NLP/CV/语音/多模态）、prompt工程、效果评估（准确率、响应速度）。\n本地部署工具：\nllama：llama是Meta的一个大模型，llama.cpp是纯C/C++ 实现的大语言模型推理项目，其主要功能是为用户提供跨硬件的高效推理能力。 Ollama：一个开源的大模型服务工具，基于 llama.cpp，具备简洁的安装和使用流程。 Open Webui：一个功能丰富的大模型管理工具，提供类似 ChatGPT 用户交互界面的工具，方便用户与模型交互。\n本地部署原理图：\n应用场景：内容创作、聊天机器人、翻译、代码编程、智能增强检索等。\n03 其他\n多模态大模型：视觉图像、语音等多模态数据，涉及数据语义关联、多模态文本对齐等关键技术。 Agent检索增强 生成（最近很火！）：结合大语言模型的语义理解与实时搜索能力，为用户提供更精确、即时的查询结果。\n最后\n为什么要学AI大模型\n当下，⼈⼯智能市场迎来了爆发期，并逐渐进⼊以⼈⼯通⽤智能（AGI）为主导的新时代。企业纷纷官宣“ AI+ ”战略，为新兴技术⼈才创造丰富的就业机会，⼈才缺⼝将达 400 万！\nDeepSeek问世以来，生成式AI和大模型技术爆发式增长，让很多岗位重新成了炙手可热的新星，岗位薪资远超很多后端岗位，在程序员中稳居前列。\n与此同时AI与各行各业深度融合，飞速发展，成为炙手可热的新风口，企业非常需要了解AI、懂AI、会用AI的员工，纷纷开出高薪招聘AI大模型"
  },
  {
    "title": "自监督学习：AI应用架构师如何用自监督学习提升模型性能？-CSDN博客",
    "page_body": "自监督学习实战：AI应用架构师的模型性能提升指南\n一、引言：为什么自监督学习是架构师的“数据救星”？\n1. 痛点引入：你是否遇到过这些问题？\n作为AI应用架构师，你可能经常面临这样的困境：\n标签数据不足 ：想要训练一个图像分类模型，但标注10万张图片需要花费数万元和几个月时间； 泛化能力差 ：模型在训练集上准确率很高，但放到真实场景中（比如不同光照、不同角度的图像）就“翻车”； 数据效率低 ：用10万张标签数据训练的模型，性能居然不如别人用1万张标签+100万张无标签数据训练的模型。\n这些问题的核心矛盾是： 监督学习依赖大量高质量标签，但标签数据的获取成本越来越高 。而自监督学习（Self-Supervised Learning, SSL）的出现，正好解决了这个矛盾——它不需要人工标签，而是用数据本身的结构作为监督信号，让模型从无标签数据中学习通用的特征表示。\n2. 文章内容概述：我们要做什么？\n本文将从 自监督学习的核心逻辑 出发，结合 AI应用架构设计 的实际场景，手把手教你：\n如何选择适合自己数据的自监督任务； 如何将自监督预训练集成到现有模型 pipeline 中； 如何用自监督学习提升下游任务（比如图像分类、文本分类）的性能； 一些关键的优化技巧（比如冻结与解冻、学习率调整）。\n3. 读者收益：读完本文你能获得什么？\n认知升级 ：理解自监督学习的本质，不再将其视为“黑科技”； 实战能力 ：掌握自监督学习的端到端流程，能在自己的项目中落地； 性能提升 ：用无标签数据让模型的泛化能力提升10%-30%（取决于数据量）； 架构思维 ：学会从“数据-模型-任务”的角度设计自监督学习方案。\n二、准备工作：你需要具备这些基础\n1. 技术栈/知识要求\n监督学习基础 ：熟悉CNN（图像）、Transformer（文本）等模型结构，了解损失函数（如交叉熵）和优化器（如Adam）； 框架熟练度 ：掌握PyTorch或TensorFlow的基本使用（本文以PyTorch为例）； 数据概念 ：理解“标签数据”“无标签数据”“数据增强”的含义。\n2. 环境/工具准备\n框架安装 ： pip install torch torchvision timm （timm是一个优秀的计算机视觉模型库，简化模型定义）； 数据准备 ： \n无标签数据：比如ImageNet的无标签部分、自己爬取的图片集； 标签数据：下游任务的训练集（比如CIFAR10、IMDB影评）。\n三、核心内容：手把手教你用自监督学习提升模型性能\n步骤一：理解自监督学习的核心逻辑——“用数据教数据”\n自监督学习的本质是 从数据中挖掘内在的监督信号 ，不需要人工标注。比如：\n图像：将图片旋转90°，让模型预测旋转的角度（旋转预测任务）； 文本：随机掩盖15%的单词，让模型预测被掩盖的单词（掩码语言模型，如BERT）； 音频：将音频片段打乱顺序，让模型预测正确的顺序（顺序预测任务）。\n这些任务的共同点是： 用数据本身的结构作为“标签” ，让模型学习到数据的通用特征（比如图像中的边缘、纹理，文本中的语法、语义）。\n为什么自监督学习有效？\n 监督学习的特征是“任务特定”的（比如训练一个猫分类模型，它可能只学习到猫的样子），而自监督学习的特征是“通用”的（比如学习到“物体的形状”“颜色的分布”）。通用特征可以迁移到多个下游任务，因此泛化能力更强。\n步骤二：选择适合的自监督任务——“数据类型决定任务”\n自监督任务的选择取决于 数据类型 （图像、文本、音频）和 数据特点 （比如图像的分辨率、文本的长度）。下面是常见数据类型的自监督任务推荐：\n1. 图像数据：对比学习是主流\n对比学习（Contrastive Learning）是图像自监督学习的“天花板”，其核心思想是： 将同一图像的不同增强版本视为“正样本”，其他图像视为“负样本”，让模型学习到“正样本距离近，负样本距离远”的特征 。\n常见的对比学习框架：\nSimCLR ：简单但有效的对比学习框架，需要大批量（比如8192）和强数据增强； MoCo ：用队列存储负样本，解决了SimCLR对批量大小的依赖； BYOL ：不需要负样本，用“动量编码器”学习特征，适用于小批量场景。\n示例任务 ：用SimCLR预训练图像编码器（比如ResNet-50）。\n2. 文本数据：掩码语言模型是首选\n掩码语言模型（Masked Language Modeling, MLM）是文本自监督学习的“黄金标准”，其核心思想是： 随机掩盖文本中的部分单词，让模型预测被掩盖的单词 。\n常见的MLM模型：\nBERT ：用15%的掩码率，预测被掩盖的单词； RoBERTa ：优化了BERT的训练策略（比如去掉NSP任务、增大批量）； DeBERTa ：用“离散掩码”和“增强的注意力机制”提升性能。\n示例任务 ：用BERT预训练文本编码器（比如BERT-base）。\n3. 音频数据：顺序预测或对比学习\n音频数据的自监督任务主要有两类：\n顺序预测 ：比如将音频片段打乱，让模型预测正确的顺序（如AudioMAE）； 对比学习 ：比如将同一音频的不同增强版本（比如加噪声、调整语速）视为正样本，其他音频视为负样本（如CLAP）。\n步骤三：集成自监督预训练到现有架构——“预训练+微调”流程\n自监督学习的经典流程是**“预训练（Pre-train）+ 微调（Fine-tune）”**：\n预训练 ：用无标签数据训练一个编码器（比如ResNet-50、BERT），学习通用特征； 微调 ：将预训练的编码器冻结或部分冻结，添加下游任务的头（比如分类头、检测头），用标签数据微调。\n示例：用SimCLR预训练图像编码器，再微调分类头\n我们以 图像分类任务 为例，展示完整的流程：\n1. 预训练阶段：用无标签数据训练SimCLR模型\n目标 ：让ResNet-50编码器学习到图像的通用特征（比如边缘、纹理）。\n代码实现 ：\nimport  torch  import  torch . nn  as  nn  import  timm  from  timm . data  import  create_transform  from  timm . loss  import  ContrastiveLoss  from  torch . utils . data  import  DataLoader ,  Dataset   # （1）数据准备：无标签图像的增强 # SimCLR需要强数据增强（随机裁剪、翻转、颜色扭曲等）  transform  =  create_transform (      input_size = 224 ,      is_training = True ,      color_jitter = 0.4 , # 颜色扭曲强度      auto_augment = 'rand-m9-mstd0.5-inc1' , # 自动增强策略      interpolation = 'bicubic' ,      re_prob = 0.25 , # 随机擦除概率      re_mode = 'pixel' ,      mean = [ 0.485 , 0.456 , 0.406 ] , # ImageNet均值      std = [ 0.229 , 0.224 , 0.225 ] # ImageNet标准差 ) # 定义无标签数据集（假设我们有10000张无标签图像） class UnlabeledImageDataset ( Dataset ) : def __init__ ( self ,  transform ) :          self . transform  =  transform         self . images  = [ torch . randn ( 3 , 224 , 224 ) for  _  in range ( 10000 ) ] # 虚拟数据 def __len__ ( self ) : return len ( self . images ) def __getitem__ ( self ,  idx ) :          img  =  self\nAI写代码 python\n运行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31"
  },
  {
    "title": "观点｜杨庆峰：【解码ChatGPT】ChatGPT：特征分析与伦理考察",
    "page_body": "黑格尔在《伦理体系》中提到水泡爆裂观念，本意是说事物毁灭的过程就像一个不断膨胀的水泡爆裂为无数的细小水滴。如果采用这种观念看人工智能技术的发展，会发现比较吻合。人工智能的水泡在1956年爆裂之后变成很多细小水珠，飞溅四处。棋类方面有AlphaGo等；科学研究方面有AlphaFold等；语言对话方面有LaMDA、ChatGPT等；图像生成方面有Discord、Midjourney等。这些技术逐渐汇聚成一股力量，将人类卷入了一个智能生成的时代。\nChatGPT：生成与嵌入\n生成构成了ChatGPT的第一个特征，生成意味着出新，然而这一点受到质疑。乔姆斯基认为，ChatGPT是从海量数据中发现规律，然后依据规则将数据进行连接，形成类似人写的内容，并认为ChatGPT是剽窃工具。这个看法有些不准确。 在ChatGPT的生成过程中，有新的东西产生。然而，这并不是存在意义上的新，也就是说它没有产生新的对象，而是通过注意力机制从旧的东西中发现未曾见过的对象。在这个意义上，它属于注意意义上的新。 2017年，一篇题为《注意力就是你全部需要的》（Attention is All You Need）的论文在注意力概念的基础上提出了transformer，后来ChatGPT使用了这种算法。这项技术使用了自注意力（self-attention）、多头注意力（multi-head-attention）等机制，从而确保了新内容的出现。并且，ChatGPT还有可能借助推理生成文本，所产生的结果并非剽窃所能概括的。\n■在人工智能文本生成中，起到关键作用的是人类的点睛之笔。缺乏这一笔，智能生成的文本只是没有灵魂的文本。这也能够保证人类的意义和价值。 图片来源：CFP\n嵌入则构成了ChatGPT的第二个特征，我们可以把嵌入过程看作对某种形式的内容充实。 智能技术发展脱离了传统技术发展的轨迹。传统技术往往作为单一的技术物品，其发展呈现出线性进化模式。但智能技术的发展，逐渐表现出可嵌入性。比如，智能手机作为一个平台，很多App可以嵌入其中。ChatGPT可以嵌入搜索引擎，还可以嵌入各种应用程序（如各种文字处理软件）。这种嵌入的发生能够使智能体的能力明显提升。这是ChatGPT增强效应的基础。根据Statista的统计，截至2023年1月，OpenAI已经与科技、教育、商业、制造等行业紧密结合，技术嵌入趋势日渐明显。嵌入的程度影响机器人的友好程度。目前，ChatGPT还无法作为声音程序嵌入机器人中，在我们的接触中，它更像是一个笔友。而未来的陪伴机器人、交谈机器人，更为重要的或许是声音交流，人类倾诉，机器倾听并作出反应。\nChatGPT的黑箱状态\n对于ChatGPT来说，透明性问题是一个很大的问题。 从技术角度看，不透明源于技术的不可解释问题。 因此，技术专家很重视ChatGPT的可解释性问题，他们也很头疼神经网络的黑箱效应。从运作方式来说，ChatGPT本身的运作难以解释。罗素（Stuart Russell）明确指出，我们不清楚ChatGPT的工作原理和机制。而且，他也不认为大型语言模型让我们距离真正的智能更近，算法的可解释性就构成了瓶颈问题。为解决这一问题，他们通过一些诸如逆向工程的技术方法，从而可以观察到神经网络的作用机理而触摸到底层逻辑；并通过机械可解释方法，以其可视化、可交互的形式来显示其成果。他们借助这些方法，打开了神经网络的黑箱。然而，这种方法获得的可解释性只对专业技术人员有效。\n从哲学角度看，黑箱的产生和术语有关。 难以理解、晦涩的术语会影响理论透明性的获得。比如，ChatGPT算法所依赖的理论概念就有待澄清。在《注意力就是你全部需要的》一文中，注意力机制是一种普遍的方法，包含了自注意力和多头注意力。这些概念如果缺乏有效澄清，就难以为外人所理解，黑箱就依然无法打开。因此，一个最为基本的问题是澄清注意本身。然而，这一任务还远没有完成。透明性不足导致的伦理问题会带来信任危机。如果ChatGPT的原理难以弄清楚，它的输出结果就会成为一个问题。最终，这种缺陷会影响我们对于技术的信任度，甚至对技术丧失信心。\nChatGPT的增强效应\nChatGPT是一种智能增强技术，它能做的事情是智能生成各式文本。比如，生成数据伦理的大纲，生成某个前沿问题的研究现状。这明显增强了搜索能力，使人们能够在短时间内获得较高效率。这种增强的基础是生成性和嵌入性。从生成性来看，它通过注意的转换实现了全新对象的发现；从嵌入性来说，它极大提升了原智能体的功能实现。\n作为智能技术，ChatGPT能够明显提升人类的工作效率。这就带出了一个基本问题：人类与智能体的关系问题。我们将智能区分为实体性智能与关系性智能。实体性智能，即实体形态存在者具有的智能，比如人类智能、动物智能以及实体机器人的智能；关系性智能主要用来描述人类与智能体的关系，增强智能则是关系性智能的主要形式。对增强智能需要进行提纯处理，通过哲学处理使其能够展现出人与技术的一般意义，并通过道德化处理使其具有规范意义。\n不过，能够起到增强效果的ChatGPT，会产生一些伦理问题。 一是智能鸿沟问题。 这一技术目前是受到限制的，存在一定的技术门槛，会导致使用者群体中差距的拉大，也就是由智能技术导致的鸿沟。这是从获取技术方面产生的差距与鸿沟。 二是社会公平问题。 除非这项技术能够像手机一样普及，否则这种公平问题会非常显著地暴露出来。能够利用ChatGPT工作的人，很可能效率显著提升；而无法使用这项技术的人，效率则会保持在原有水平。 三是依赖问题。 使用者在使用过程中会感受到这项技术的便利。比如，能够迅速生成课程大纲、撰写文献综述、搜索关键信息等。这会让使用者逐渐对这一技术产生依赖。但这种依赖会产生较为严重的后果。以搜索文献为例，借助这项技术能够迅速找到相关文献，并且可以撰写出一个像模像样的综述文本。尽管借助ChatGPT可以快速生成一份文献综述，但却失去了相关能力的学术训练，那么结果可能是研究者和学生丧失了这方面的能力。\nChatGPT与人类的关系\n面对ChatGPT迅猛的攻势，学术界普遍采取防守姿态，尤其是不少大学相继禁止这一技术在作业和论文写作中的使用。然而，禁止并不是最优的处理方式。技术似水，可以通过多种方式渗透进来，所以相对来说，理性引导更为妥当。\n要理性引导，则需要考虑智能体与人类的关系。我更愿意把二者的关系模式比喻为“画龙点睛”。以文本大纲生成为例，ChatGPT能够围绕数据处理的收集、存储、使用等环节中的相关伦理问题，生成一份基于数据处理环节的数据伦·理·大纲。从狭义角度来看，这份大纲是恰当的，能够反映数据处理环节伦理问题的一些方面。然而从广义角度看，这份大纲则过于狭窄，尤其是仅从数据处理本身来理解数据，并没有考虑到其他方面，比如数据化、数据与生活方式等重要问题。而我们能做或要做的，是对生成文本进行“画龙点睛”的处理，通过调整使生成文本“活”起来。这样一来，智能生成文本的地位也开始明确： 在生成中起到关键作用的是人类的点睛之笔，缺乏这一笔，智能生成的文本只是没有灵魂的文本。若不这样，则难以保证人类的意义和价值，相应的伦理问题也会产生。\n（作者系中国科协—复旦大学科技伦理与人类未来研究院研究员）"
  },
  {
    "title": "【Transformer】最强动画讲解！目前B站最全最详细的Transformer教程，2025最新版！从理论到实战，通俗易懂解释原理，草履虫都学的会！哔哩...",
    "page_body": "您当前的浏览器不支持 HTML5 播放器\n请更换浏览器再试试哦~\nup还给大家整理了60G人工智能入门学习资源，一并发送！！！ 1、AI必读经典电子书（西瓜书、花书、鱼书等） 2、CVPR2024+2025论文库、视觉方向顶会论文仓库（可论文指导、SCI、EI、中文核心、论文答辩） 3、人工智能学习路线及大纲 4、机器学习十大算法经典视频教程（附带课件代码） 5、深度学习神经网络基础视频教程 6、六大计算机视觉实战项目视频教程（附带源码）"
  },
  {
    "title": "大模型呼叫中心场景分享之七十七：在图书馆行业的应用场景",
    "page_body": "大模型技术正重塑图书馆服务生态，从被动响应到主动服务，智能参考咨询3秒精准推荐文献，个性化阅读推荐点击率提升50%，无障碍服务让视障读者畅享知识，推动图书馆成为智慧化知识中枢。\n大模型呼叫中心场景分享之七十七：在图书馆行业的应用场景\n作者：开源大语言模型呼叫中心系统FreeIPCC\n图书馆作为知识服务的核心枢纽，正在经历从传统服务模式向智能化、个性化服务转型的关键阶段。大模型技术的引入为图书馆服务带来了质的飞跃，使图书馆能够提供更高效、更精准、更人性化的知识服务。本文将全面剖析大模型呼叫中心在图书馆行业的具体应用场景，展示如何通过技术创新重塑图书馆的服务生态。\n 一、图书馆服务转型的迫切需求\n当代图书馆面临着多重挑战与机遇：\n1. 资源形态多元化：电子资源占比已经很高，管理复杂度显著增加\n2. 用户期待提升：多数读者期望获得即时、个性化的服务\n3. 服务时间压力：很多读者有下班后使用图书馆的需求\n4. 专业咨询缺口：仅部分图书馆能提供全天候参考咨询服务\n5. 特殊群体服务不足：残障人士、老年读者等群体的服务覆盖率不足\n传统服务模式的三大痛点：\n- 响应滞后：平均咨询等待时间较长\n- 资源利用率低：很多馆藏资源长期无人问津\n- 服务断层：线上与线下服务体验不一致\n大模型技术的应用正在有效解决这些痛点，推动图书馆服务向智能化、精准化方向发展。\n 二、图书馆大模型呼叫中心的核心架构\n 1. 智能知识中枢系统\n- 多维度知识图谱：包含海量的专业知识网络\n- 动态文献库：实时更新的学术资源索引系统\n- 业务规则引擎：自动化业务流程规则\n- 用户画像系统：基于百万级用户行为的分析模型\n- 多语言处理模块：支持多种语言的实时互译\n 2. 全渠道交互平台\n- 统一接入门户：整合多种主流服务渠道\n- 智能路由系统：问题分类准确率提升\n- 上下文管理系统：支持多轮连贯对话\n- 情感识别引擎：用户情绪识别准确率提升\n- 无障碍接口：符合WCAG 2.1标准\n 3. 服务支持矩阵\n- 文献发现系统：覆盖巨量的学术数据库\n- 自动化流程引擎：支持多种常见业务自助办理\n- 个性化推荐系统：点击通过率提升\n- 实时监控看板：关键服务指标可视化\n- 安全审计系统：满足GDPR等数据合规要求\n 三、核心服务场景深度解析\n 1. 智能参考咨询服务\n典型场景：科研人员咨询\"区块链在金融领域的最新应用研究\"\n服务流程：\n1. 语义解析：识别\"区块链\"、\"金融应用\"、\"最新研究\"等关键要素\n2. 范围界定：自动限定近3年文献，聚焦核心期刊\n3. 跨库检索：同时查询IEEE等数据库\n4. 结果优化：按被引量、相关性等多维度排序\n5. 获取途径：标注开放获取与馆藏可获取资源\n服务输出：\n\"为您筛选32篇高相关文献，包括：\n1)《区块链金融》2023综述(开放获取)\n2)MIT技术报告(馆藏电子版)\n3)已保存检索式至您的账户\n4)推荐参加下月'金融科技'研讨会\"\n技术亮点：\n- 专业术语理解准确率91%\n- 跨库检索响应时间<3秒\n- 结果相关性评分达4.8/5\n2. 个性化阅读推荐服务\n典型场景：读者表示\"喜欢《人类简史》这类宏观历史著作\"\n服务流程：\n1. 内容特征分析：提取\"大历史观\"、\"跨学科\"等标签\n2. 读者画像匹配：结合既往借阅记录(如已借《枪炮、病菌与钢铁》)\n3. 相似度计算：基于500+个特征维度进行匹配\n4. 多样性控制：确保推荐书目涵盖不同时期、地域\n5. 呈现优化：提供图文并茂的推荐理由\n推荐结果：\n\"基于您的兴趣推荐：\n1)《未来简史》(同作者续作)\n2)《大历史》(跨138亿年的叙事)\n3)《丝绸之路》(全球史视角)\n已预留1F新书展区样本，扫码可直接借阅\"\n 四、创新服务场景探索\n 1. 学术研究全周期支持\n场景案例：博士研究生需要\"系统评价(Systematic Review)方法学支持\"\n服务流程：\n1. 研究方法诊断：确认研究阶段与需求\n2. 方案定制：提供PRISMA流程图模板\n3. 资源推荐：Cochrane Handbook等工具书\n4. 软件指导：EndNote、RevMan等工具使用指南\n5. 进度提醒：关键节点自动提示\n服务输出：\n\"系统评价支持包：\n1)方法学指南(已发送PDF)\n2)文献管理软件培训视频\n3)每周五下午专家咨询时段\n4)自动生成研究进度表\"\n 2. 无障碍智慧服务\n场景案例：视障读者需要\"获取最新经济学有声资源\"\n服务创新点：\n- 语音优先交互：100%功能可通过语音完成\n- 智能内容适配：自动提取适合语音的内容\n- 设备无缝对接：支持主流读屏软件\n- 人性化节奏控制：根据反馈调整语速\n服务体验：\n\"已为您：\n1)转换《行为经济学》前三章为音频\n2)预约明天10点的真人导读\n3)发送经济播客精选列表\n如需调整格式请说'修改'\"\n 五、管理优化场景应用\n 1. 基于大数据的服务优化\n应用案例：通过咨询数据分析识别服务短板\n实施过程：\n1. 数据采集：聚合X个月、Y万条咨询记录\n2. 热点分析：识别TOP10高频问题\n3. 根因分析：发现\"校外访问系统\"问题占比较高\n4. 解决方案：制作视频教程+优化认证流程\n5. 效果评估：相关问题减少\n分析洞察：\n\"关键发现：\n1)大多数的校外访问问题源于cookie设置\n2)高峰时段集中在工作日晚8-10点\n3)已优化认证流程，预计可减少咨询量\"\n 2. 智能空间管理\n应用场景：自习室座位智能调度\n系统功能：\n- 实时监控：500+个座位使用状态\n- 预测分析：基于历史数据的占位预测\n- 动态调整：根据人流重新划分静音/讨论区\n- 移动引导：通过APP实时推送空位信息\n运营效果：\n- 座位周转率提升\n- 投诉量下降\n- 空间利用率提升\n 六、技术实施关键路径\n 1. 知识体系建设\n- 分层架构：基础业务知识(30%)+学科专业知识(60%)+本地特色(10%)\n- 动态更新：每周更新机制，重要变更即时同步\n- 质量管控：专家团队+AI联合审核机制\n 2. 模型优化策略\n- 领域适应训练：使用图书馆专业语料微调\n- 持续学习：基于用户反馈的在线学习\n- 多模型集成：结合检索模型、推荐模型、对话模型\n 3. 系统整合方案\n- API网关：统一对接业务系统\n- 中间件层：处理数据格式转换与协议适配\n- 监控中心：全链路性能监控与预警\n 七 、未来演进方向\n1. 认知智能深化：从问答式服务向顾问式服务演进\n2. 多模态融合：实现文字、语音、图像、视频的智能协同\n3. 预测性服务：基于用户行为的需求预判与服务前置\n4. 元宇宙融合：构建虚拟图书馆服务空间\n5. 开放生态建设：与教育、科研系统的深度对接\n大模型呼叫中心正在推动图书馆服务实现三大转变：\n- 从被动响应到主动服务\n- 从通用服务到精准供给\n- 从资源中心到知识伙伴\n这种转型不仅提升了服务效能，更重新定义了图书馆在数字时代的价值定位，为构建学习型社会提供了强有力的支撑平台。随着技术的持续迭代，图书馆将发展成为智慧化、人性化、生态化的知识服务中枢。\n举报/反馈"
  },
  {
    "title": "大模型应用场景实战：实操项目全解析！非常详细，收藏我这一篇就够了-CSDN博客",
    "page_body": "你是否学习了 大模型 技术，但是不知道如何落地？今天带来5个大模型落地项目，保证你看完一定有所收获！ 前排提示，文末有大模型AGI-CSDN独家资料包哦！\n大模型应用#1：从 Chatbot 到AI Agent，个人助理重塑手机应用生态\nAI大模型的能力进步推动Chatbot在C端广泛“出圈”。  Chatbot（ 聊天机器人 ）通过自动化方式来处理和回复用户输入，可以模拟人类对话，通过文字或语音与用户进行实时交互。2010年代，随着NLP等技术的发展，Chatbot已经在客服、营销、企业信息服务等领域得到了广泛应用。然而，由于语言理解及生成能力有限，因此Chatbot的落地范围局限在B端特定服务型场景，并未诞生具有广泛影响力的C端产品。2022年12月，ChatGPT在文本生成、代码生成与修改、多轮对话等领域展现了大幅超越过去 AI 问答系统的能力，标志着Chatbot行业进入AI大模型时代。此后，Chatbot作为C端用户体验大模型门槛最低的产品，成为大模型厂商的“标配”，谷歌Bard、百度文心一言、阿里通义千问等产品在2023年纷纷推出。\n在文字对话功能之外，Chatbot功能随着AI大模型能力的发展而迅速丰富。  过去一年，我们看到，各大模型厂商的Chatbot产品普遍新增了图像理解、文生图功能，并且新增应用插件商店以拓展Chatbot功能。以ChatGPT为例，2023年9月，OpenAI将DALL-E 3整合到ChatGPT中，从而支持文生图功能。2024年1月，OpenAI正式上线应用商店GPT Store，当时用户已经创建超过300万个GPTs，主要的GPTs涵盖图像生成、写作、科研、编程/软件开发、教育、生产力工具和生活七大类别。GPT Store取代了此前的插件商店（2024年3月关闭），用户不仅可以在平台上分享自己创建的GPTs，还可以从其他人那里获取各种GPTs，形成丰富的GPTs生态系统。GPT Store定制版本可以针对特定任务或行业进行优化，允许用户与外部数据（如数据库和电子邮件）进行简洁的交互。2024年5月，随着OpenAI更新GPT-4o模型，ChatGPT能够识别用户语音的感情，并输出语音，实现如同与真人对话一般的沉浸式体验。\nChatbot逐渐向AI Agent演进。  AI Agent是指大模型赋能的，具备规划、记忆、工具、行动能力的智能体。我们认为Chatbot的演进方向是智能化和自动化程度逐渐提升，需要人类参与的程度逐渐下降，逐渐过渡到人与AI协作的 Copilot ，最终形态是AI Agent，Agent只需要人类的起始指令和结果的反馈，具有自主记忆、推理、规划和执行的全自动能力，执行任务的过程中并不需要人的介入。\n从Chatbot向AI Agent的演进过程中，手机应用生态或将发生改变。  我们认为手机或是向AI Agent演进率先落地的硬件载体，发挥AI个人助理的作用。AI个人助理可以记住生活和工作中的各种信息，如下周的晚餐计划或工作会议的内容，并自动整理和索引这些信息；可以帮助用户完成例如安排约会、预订旅行、点餐、播放音乐、回答问题等各种任务。落地过程中，手机应用生态或将从目前以应用商店+APP的模式转变为Agent Store+Agent的模式，手机厂商可能都会发布自己的Agent Store。\nAI手机：AI大模型驱动软硬件升级\n手机是人们日常生活较高的交互终端，具有普及率高、使用频率高的特点，考虑终端算力、存力以及客户应用需求等因素，手机已经成为AI大模型在C端落地的重要设备。去年底至今，随着三星Galaxy S24、Google Pixel 8等重要产品上市，以及苹果WWDC推出Apple Intelligence，手机AI的功能逐渐清晰。目前 语音助手、修图、写作助手等功能成为主流 。\n以三星今年1月发布的Galaxy S24为例，该机型搭载自研大模型Samsung Gauss，具备实时翻译/圈选搜图/生成式编辑/笔记助手等功能。软件方面，基于OneUI 6.1系统，强化虚拟助手Bixby，为用户提供丰富多样的应用服务。据Techweb，Google有望在10月推出Pixel9系列，预计将搭载基于最新Gemini模型的AI助手，执行复杂的多模态任务。芯片方面，下半年将发布的骁龙8Gen4较上一代产品有望进一步支持AI应用。\n2024年6月举行的苹果WWDC 2024大会推出全新个人化智能系统Apple Intelligence，由苹果端侧大模型、云端大模型、ChatGPT共同组成，算力足够下依赖终端，复杂场景则使用私密云计算或ChatGPT，能够1）增强Siri理解能力，配备多轮对话、总结信息、屏幕内容感知、应用智能交互等能力，2）提供邮件智能回复、通知整理，备忘录和通话录音/撰写/摘要等功能，3）支持图像生成/智能修图等功能，4）ChatGPT4o将融入siri和writing tools，作为云端备选模型。我们看到Apple Intelligence核心能力包括文生文、文生图、跨App交互与个人情境理解，并需要以OpenAI ChatGPT4o作为云端备选模型，配备上了目前已有的大部分AI功能。苹果通过Siri，把AI当作手机不同App之间联系的工具，而不是像此前三星和谷歌的AI应用更侧重于让AI去完成单一特定任务。苹果让Siri在未来成为应用分发入口和流量入口，以超过13亿台用户基数生态去提供好的产品解决方案。\nIDC认为，新一代AI智能手机需拥有至少30 TOPS性能的NPU，能够在手机上运行LLMs，符合标准的SoC包括Apple A17 Pro、MediaTek Dimensity 9300、Qualcomm Snapdragon 8 Gen 3等。此类手机在2023年下半年开始进入市场。\n硬件方面，我们看到：1）SoC：AI引擎升级、NPU算力提升，SoC进一步升级确定性强；2）存储：手机RAM升级至24GB LPDDR5X，相较当前主流的8GB LPDDR4X，成本提升300%；3）电源：电池/电源管理芯片升级，但弹性相对较小；4）光学：AI推动屏下摄像头应用取得突破。软件方面，新一代AI智能手机在系统架构和应用方面更加匹配个性化、场景化服务需求。\n软件方面，与功能机和前代智能机相比，新一代AI智能手机更加注重场景化服务能力。  前代智能机在功能机的基础上增加了手机OS和内嵌语音助手，并针对用户不同需求推出独立APP进行响应。新一代AI手机在大模型和原生化服务组件库的基础上，提供用户可定义的智能体开发平台和专属智能体，实现AI文本/AI图像/Al语音/Al视频等功能，满足用户健康管理/生活服务/角色扮演/高效办公/游戏助手等场景化需求。\n据IDC，全球AI手机2024年出货量有望同比增长233%至1.7亿台。中国AI手机所占份额自2024年以后会迅速增长，预计2024年中国市场AI手机出货量为0.4亿台，2027年将达到1.5亿台，且AI手机渗透率有望在2027年超过50%。我们认为，AI手机以其智能化、个性化的特点，有望吸引更多用户进行换机升级，从而引领新一轮的换机潮。\n根据2024年4月7日发布的《4月手机观察：华为份额继续提升，关注P70等新机发布》，根据IDC数字，苹果2023年销量2.34亿台，华泰预测苹果2024年销量下降8.2%到2.15亿台。根据BankMyCell数字，2024年苹果手机活跃用户14.6亿人，对应目前换机周期6.23年，如果Apple Intelligence能够缩短换机周期3个月，可以带动约1000万台新机销售。\nAR/VR：AI大模型交互能力，看好智能眼镜等轻量级AR发展机遇\nAI大模型有望提升AR/VR交互能力，加速其进入主流市场。  据IDC，2023年， AR /VR产品全球出货量675万台，同比-23%。随着苹果VisionPro发布，AR/VR/MR出货量在2024年有望温和复苏。AI大模型的出现驱动语音助手、物体识别和生活助理等功能赋能AR/VR设备，提升了用户与虚拟环境的互动质量，据VR陀螺（2024/6/5），Meta雷朋智能眼镜出货量已超百万副，AI大模型的出现有望加速AR/VR技术进入主流市场的步伐。\n语音助手、物体识别、生活助理等AI功能已在AR/VR产品中广泛出现。  语音助手功能让AR眼镜能够通过上下文语义理解与用户进行更自然的交流，如李未可Meta Lens S3通过大型语言模型AI系统提供闲聊和建议。物体识别技术使AR眼镜能够识别现实世界中的物体，例如Meta雷朋智能眼镜引入建筑识别和菜单翻译功能。此外，生活助理功能与用户的社交生活深度绑定，提供聊天回复、邮件整理、购物建议等个性化服务。这些AI功能的融合不仅提升了用户体验，还预示着AR/VR产品将更加智能化，为用户提供更便捷和个性化的服务。随着技术的不断进步，预计未来AR/VR设备将实现更复杂的多模态AI应用，进一步增强其作为下一代计算平台的潜力。\n大模型应用#2：生产力工具的AI化有望推动新一轮PC换机周期\n生产力工具、沟通工具及协作工具经历了PC时代、移动互联网时代的演进，正在进入AI时代。  微软、谷歌与金山办公等公司以AI大模型对原有的生产力工具应用进行升级，通常提供文档理解、文字生成、图片生成、数据分析与处理等等功能，提升用户生产力。\n办公：微软、谷歌引领产品矩阵全面AI化\n微软是全球生产力工具的领导企业，围绕企业业务与管理流程，已经形成了布局完整的产品矩阵，目前正主导生产力工具的AI化。  微软的产品矩阵覆盖企业办公、客户关系管理、资源管理、员工管理、低代码开发等业务环节，微软已经围绕这些业务环节，推出相应的Copilot产品，对原有产品进行AI大模型赋能。从Copilot时点来看，微软首先在主力产品Office套件上线Copilot，然后逐步在企业业务与管理流程的Dynamics套件、开发相关的Power Platform条件、员工管理的Viva套件上线Copilot。我们认为Copilot正以“通用助手”为切入点，重塑微软生产力工具矩阵，向数据协同、功能联动的方向发展。目前办公场景Office、企业业务流程场景Dynamics下的Copilot已明确单品收费标准。微软的Copilot产品分为和家庭两大场景。\n工作场景方面：1）面向企业办公场景推出Copilot for Microsoft 365，根据微软FY3Q24（对应日历季度1Q24）业绩会，近60%的财富100强企业正在使用。2）面向企业流程中的财务、销售和客服场景，分别推出Copilot for Finance/Sales/Service；3）面向云运营和管理场景，推出Copilot for Azure；4）面向IT安全场景，推出Copilot for Security；5）此外，微软推出Copilot Studio支持用户自定义Copilot，根据1Q24业绩会，已有3万名用户使用。\n家庭应用方面：1）面向C端用户办公场景推出Copilot Pro；2）面向Win 11和部分Win 10推出Copilot for Windows，支持通过任务栏上或键盘上的Copilot按钮进行快速访问；3）在Bing搜索、Edge浏览器推出Copilot。\n谷歌将Gemini大模型内置在其2B云端办公套件Workspace中。  谷歌将Gemini for Workspace的功能定义为：1）写作，例如生成项目计划、提案、简报等、以及优化文本；2）整理，例如通过简单描述创建项目跟踪表格；3）创建图像；4）联系，例如在视频通话中创建自定义背景，提高声音和视频质量；5）无代码创建应用。\n金山办公WPS已陆续在主要产品上线WPS AI服务。  WPS AI已经覆盖文字、演示、PDF、表格、智能文档、智能表格、智能表单等产品，涵盖了金山办公的主要产品。此外，金山办公发布了WPS AI企业版，推出AI Hub（智能基座）、AI Docs（智能文档库）、Copilot Pro（企业智慧助理）三大功能。\n编程：AI协助编程开发，提高开发效率与质量\nAI编程工具在"
  },
  {
    "title": "教育研究方法专题总结报告-人人文库",
    "page_body": "上传人：1*** IP属地：江苏 上传时间：2024-06-08 格式：DOCX 页数：6 大小：21KB 积分：8\n文档描述\n教育研究方法专题总结报告《教育研究方法专题总结报告》篇一教育研究方法是一门多学科交叉的领域，它涉及到心理学、社会学、人类学、统计学等多个学科的知识。在教育研究中，选择合适的研究方法对于确保研究的效度和信度至关重要。本专题总结报告旨在探讨教育研究中常用的方法，并提供实用的指导和建议。一、定量研究方法定量研究方法主要关注数据收集和分析中的数量化，通过统计分析来推断研究结果的普遍性。常用的定量研究方法包括调查研究、实验研究、准实验研究、描述性研究等。调查研究通常采用问卷和访谈的形式，实验研究则通过控制变量的方式来探究因果关系。在进行定量研究时，研究者需要考虑样本的代表性、数据的可靠性和有效性等问题。二、定性研究方法定性研究方法则更注重于对数据进行质性分析，以获取对现象的深入理解。常见的定性研究方法包括观察研究、访谈研究、个案研究、内容分析等。这些方法强调对数据进行细致的编码和分析，以揭示现象的复杂性和多样性。在定性研究中，研究者需要确保数据的丰富性和深度，以及分析过程的透明度和可靠性。三、混合方法研究混合方法研究是结合了定量和定性研究方法的策略，它允许研究者同时使用两种方法的优势。混合方法研究可以增强研究的信度和效度，提供更全面和深入的洞察。然而，混合方法研究也面临着设计和实施上的挑战，包括如何整合两种方法的数据和分析，以及如何确保研究的一致性和连贯性。四、教育研究的伦理考量在进行教育研究时，研究者必须遵守伦理原则，包括保护参与者的隐私和自主性、避免伤害、获得知情同意等。教育研究中常见的伦理问题包括数据隐私、研究对参与者可能产生的负面影响、以及研究结果的公正和透明报告等。研究者需要对这些问题有清晰的认识，并采取相应的措施来确保研究的伦理合规性。五、教育研究的设计与实施教育研究的设计包括确定研究问题、选择研究方法、制定研究计划等步骤。研究实施则涉及到数据收集、处理和分析的过程。在设计研究时，研究者需要考虑研究的目的、研究对象的背景、研究环境等因素。而在实施研究时，研究者需要确保数据的质量，遵守研究计划和时间表，以及有效地管理和分析数据。六、教育研究中的数据分析数据分析是教育研究中的关键环节，它直接影响到研究结果的可靠性和解释。对于定量研究，研究者通常使用统计软件进行数据分析，而定性研究则更多地依赖于内容分析、主题分析等方法。无论采用何种方法，研究者都需要确保数据的准确性和分析的严谨性，并正确解读研究结果。七、教育研究结果的解释与应用研究结果的解释需要结合研究的设计、数据质量和分析方法来进行。研究者需要谨慎地推断研究结果的意义，并考虑研究的局限性和未来的研究方向。研究结果的应用则需要考虑教育实践的具体情境，确保研究结论能够有效地转化为教育政策和实践。综上所述，教育研究方法的选择和应用是一个复杂的过程，需要研究者具备多方面的知识和技能。通过本专题总结报告，我们希望能够为教育研究者提供一份实用的指南，帮助他们更好地设计和实施教育研究项目。《教育研究方法专题总结报告》篇二教育研究方法专题总结报告教育研究是探索教育现象、揭示教育规律的重要途径，而研究方法的选择与应用则是保证研究质量的关键。本专题总结报告旨在系统梳理教育研究中的常见方法，并对其应用进行深入分析，以期为教育研究者提供有益的指导。一、定量研究方法定量研究方法以其客观性和精确性著称，适用于描述、解释和预测教育现象。常用的定量研究方法包括问卷调查、实验研究、准实验设计、描述性统计分析等。例如，在一项关于在线学习效果的研究中，研究者可以采用问卷调查法收集学生对在线学习平台的满意度数据，并通过实验研究设计来对比不同教学策略对学生成绩的影响。二、定性研究方法与定量研究不同，定性研究更加注重对教育现象的深入理解和解释。观察法、访谈法、案例研究等是常见的定性研究方法。例如，研究者可以通过对一所学校的长期观察，了解其实施素质教育的效果，或者通过深度访谈教师和学生，探究某一教育政策的实际影响。三、混合方法研究混合方法研究结合了定量和定性研究的优点，允许研究者同时收集和分析两种类型的数据。这种方法的灵活性使得研究者能够更加全面地理解教育现象。例如，在一项关于学习风格与学习效果关系的混合方法研究中，研究者可以首先使用问卷调查来大规模地收集学生的学习风格数据，然后通过访谈和观察来深入分析不同学习风格对学生学习成绩的影响。四、行动研究行动研究是一种将研究与实践紧密结合的方法，强调在教育实践中发现问题，并通过研究来解决这些问题。这种方法能够直接促进教育实践的改进。例如，一位教师在发现班级管理中存在问题时，可以通过行动研究来设计并实施新的管理策略，同时记录和分析策略的效果，从而不断优化班级管理。五、教育叙事研究教育叙事研究是通过讲述教育故事来探索教育现象的质性研究方法。它关注的是教育过程中的经历、故事和意义。例如，一位教师可以记录自己在教学过程中的成长故事，分析这些故事背后的教育意义，从而为其他教师提供借鉴和启示。六、政策分析教育政策分析是研究教育政策制定、实施和评估的科学方法。它关注教育政策的合理性、有效性和公平性。例如，研究者可以分析某项教育政策的制定背景、实施过程以及实际效果，从而为政策的优化和完善提供建议。七、教育技术研究随着信息技术的快速发展，教育技术研究成为教育研究的一个重要领域。它关注如何利用信息技术改进教学方法、提升学习效果。例如，研究者可以探究在线学习平台对学生自主学习能力的影响，或者探讨虚拟现实技术在教育中的应用潜力。八、评估研究教育评估研究关注教育项目的效果评价和质量保证。它包括形成性评估、总结性评估和过程评估等多种类型。例如，在一项关于教师专业发展的评估研究中，研究者可以跟踪教师参与培训前后教学效果的变化，以评估培训项目的成效。九、伦理问题在教育研究中，伦理问题是必须高度重视的。研究者应当遵守伦理原则，确保研究对参与者的尊重和保护。例如，在涉及人类受试者的研究中，研究者必须获得他们的知情同意，并对他们的个人信息进行保密。综上所述，教育研究方法的选择应当基于研究目的、研究问题以及研究情境。研究者应当熟练掌握各种研究方法的特点和应用条件，以便在不同的研究项目中灵活运用，从而为教育领域的理论创新和实践改进提供有力的支持。"
  },
  {
    "title": "吴恩达教你如何玩转ChatGPT，限时免费_澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "克雷西 发自 凹非寺\n量子位 | 公众号 QbitAI\nChatGPT催生新职业提示工程师，年薪可高达几十万美元。\n但是，该怎么入门？\n吴恩达面向广大开发者推出ChatGPT提示工程课程，与OpenAI合作出品。\n限时免费，而且对新手友好！\n课程发布还不到十个小时，就有网友表示已经学完了：\n还有网友表示没看够，期待推出更多内容：\n所谓提示工程，简单地说就是向大语言模型（LLM）发布有效的指令。\n在这段时长一个半小时的课程中，吴恩达和OpenAI技术部门员工一起讲解了如何用ChatGPT高效地设计程序。\n课程从LLM的工作方式展开，展示了最优的提示工程策略。\n课程中还介绍了如何利用LLM的API进行总结、推理、改写、扩展。\n此外，课程还介绍了撰写有效提示的两个关键原则，如何系统地设计好的提示。\n甚至还包括如何建立一个定制的聊天机器人。\n其中提到的所有概念都附带了丰富的示例，可以边听边体验。\n课程的门槛也并不高，只需要对Python有最基本的了解。\n不方便看视频或者英语听力不好也没关系，课程配备了脚本和字幕。\n在课程介绍中，吴恩达寄语到：\n生成式人工智能为人工智能工程师提供了许多机会，他们可以在几分钟或几小时内建立强大的应用程序，而这在以前需要几天甚至几周时间。我很高兴能分享这些最佳实践，使更多人能够利用这些革命性的新能力。\n再提醒一下课程是限时免费的，想要一睹为快的读者可要抓紧了！\n传送门：\nhttps://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\n参考链接：\n[1] https://twitter.com/AndrewYNg/status/1651605901781110785\n— 完 —\n科技前沿进展日日相见 ~\n原标题：《吴恩达教你如何玩转ChatGPT，限时免费！》"
  },
  {
    "title": "如何用AI大模型处理数据-CSDN博客",
    "page_body": "用 大模型 处理批量数据，核心是按“数据预处理-任务提交-结果回收”三步流程操作，兼顾效率与准确性，具体方法如下：\n 首先是 数据预处理 ，这是基础前提。需将原始数据整理为大模型支持的格式，主流是UTF-8编码的JSONL文件，每行一个JSON对象，包含唯一 custom_id （用于关联结果）和任务内容，单个文件不超过500MB、5万条请求 。同时要过滤无效数据、去重并移除隐私信息，确保符合模型上下文长度限制，超量数据需分批处理。\n 其次是批量任务提交，可选择两种方式。在线平台（如阿里云百炼）可通过控制台直接上传JSONL文件，选择统一模型和参数后提交，成本仅为实时 推理 的50% ；本地部署场景（如Ollama）可通过Excel公式或代码调用模型，适合离线处理，降低API调用成本。提交后可通过控制台或API查询任务状态，支持取消执行中任务。\n 最后是结果回收与校验。任务完成后，下载结果文件（成功响应）和错误文件（失败详情），通过 custom_id 与原始数据匹配 。对失败数据，根据错误信息修正格式或内容后重新提交；对成功结果，可进一步统计 Token 用量、分析响应质量，确保符合业务需求。\n 整个过程需注意模型一致性，同一任务需使用相同模型及参数，避免结果偏差。无论是在线批量推理还是本地离线处理，都能大幅提升数据处理效率，适配翻译、摘要、分类等多种场景。"
  },
  {
    "title": "职称论文‘研究方法’怎么写？实证vs.理论如何选？-搜狐",
    "page_body": "在撰写职称论文时，研究方法的选择是决定论文质量与学术价值的关键环节。面对实证研究与理论研究的路径分歧，研究者需结合学科特点、研究目标及自身条件进行系统性考量。本文将从方法论本质、适用场景、操作流程及常见误区四个维度展开分析，为学者提供具有实践指导意义的解决方案。\n一、方法论的本质差异与互补性\n实证研究与理论研究构成社会科学研究的两种基本范式。实证研究强调\"用数据说话\"，通过问卷调查、实验设计、案例观察等手段收集可量化的经验证据，采用统计分析方法验证假设，如某高校管理学院对456名企业中层干部的跟踪研究（百度百家号，2023），通过结构方程模型揭示了领导风格与团队绩效的量化关系。其优势在于结论的客观性和可重复性，但存在样本代表性和测量效度等挑战。\n理论研究则侧重概念演绎和逻辑推演，包括文献分析、比较研究、模型构建等方法。知乎专栏《社科研究方法论》（2023）指出，理论研究适用于探索新兴领域或解构复杂概念，如组织行为学中的\"心理契约\"理论发展，通过批判性整合32篇经典文献，建立了新的分析框架。其价值在于思维深度和解释张力，但需警惕陷入\"空对空\"的思辨陷阱。\n两种范式并非对立关系。CSDN技术社区案例（2023）显示，优秀的职称论文往往采用\"理论-实证-理论\"的螺旋结构：先通过文献综述建立理论模型，再用实证数据检验，最后回归理论修正。这种混合研究方法在管理学和经济学领域应用尤为广泛。\n二、学科适配与选题决策矩阵\n选择研究方法需建立三维评估体系：\n1. **学科特性**：实验心理学、临床医学等硬科学通常要求实证设计；哲学、美学等人文学科侧重理论思辨；而教育学、社会学等中间学科则需灵活选择。某核心期刊评审数据显示（百度新闻，2023），经济学领域实证论文录用率比纯理论论文高17%，但理论创新类论文更易获得高引用。\n2. **问题类型**：解释\"是什么\"和\"为什么\"的问题适合理论研究，如《数字化转型的伦理困境》这类选题；探究\"怎么样\"和\"如何做\"的问题需要实证支撑，像《在线教学平台使用效能评估》这类应用研究。\n3. **资源条件**：时间紧张（3个月内）建议选择文献研究或二手数据分析；拥有调研渠道的可采用问卷调查；具备实验条件的可设计对照研究。某省社科基金评审专家透露（知乎回答，2023），约43%被拒稿的实证论文失败于数据采集不足。  决策工具推荐使用\"STEAM模型\"：Significance（意义）、Theoretical space（理论空间）、Empirical feasibility（实证可行性）、Academic basis（学术基础）、Methodological maturity（方法成熟度）。每个维度按1-5分评估，总分≥18分适合实证研究，≤12分建议理论探索。  三、规范操作流程与质量控制  **实证研究实施要点**：  1. 抽样设计需明确总体边界与抽样方法，某高校职称评审要求（2023）特别强调样本量计算公式的呈现；  2. 测量工具应报告信效度检验结果，如Cronbach's α值≥0.7；  3. 数据分析要避免方法滥用，多元回归分析需先检验多重共线性（VIF<10）；  4. 伦理审查不可或缺，涉及人体研究需提供知情同意书。  **理论研究执行规范**：  1. 文献检索应覆盖中英文核心数据库，某C刊要求参考文献中外文比例不低于3:7；  2. 理论框架构建需呈现清晰的逻辑演进图；  3. 观点创新要说明与既有理论的对话点；  4. 论证过程需遵守MECE（相互独立完全穷尽）原则。  质量控制方面，建议建立\"双盲校验\"机制：邀请同行专家对理论逻辑进行证伪测试，安排统计专业人员复核数据分析过程。某学术不端检测报告显示（2023），方法论缺陷导致的退修意见占比达61%。  四、典型误区与高阶技巧  常见陷阱包括：  1. \"方法崇拜症\"：盲目使用复杂模型却忽视问题本质，如用机器学习算法分析仅30个样本的数据；  2. \"数据驱动型\"研究：先收集数据再拼凑理论框架，导致\"削足适履\"；  3. \"文献堆砌\"：理论综述沦为摘要汇编，缺乏批判性整合。  进阶策略建议：  - 理论创新可采用\"沙漏模型\"：从广博的文献综述聚焦到具体问题，再拓展到普遍意义；  - 实证设计可尝试\"三角验证法\"：定量数据+定性访谈+文献证据相互印证；  - 混合方法研究注意\"权重设计\"，如主要采用实证研究时，理论部分占比建议控制在30%以内。  期刊偏好分析显示（2023数据），实证论文在《科研管理》等应用类期刊更受青睐，而《学术月刊》等综合类期刊理论创新权重更高。学者应根据目标期刊特点调整方法侧重，同时保持学术诚信底线。  结语：研究方法的选择本质上是学术价值观的体现。优秀的职称论文应当使方法与问题形成\"榫卯结构\"，无论是实证的精确之美还是理论的思辨之光，最终都要服务于知识创新的根本目的。建议研究者建立个人方法论清单，定期更新技术工具箱，在学术实践中培养\"方法自觉\"意识。  #职称论文#"
  },
  {
    "title": "大模型微调常用术语与知识总结-20250902102413.docx-原创力文档",
    "page_body": "大小 ： 24.96 KB 字数 ： 约5.04千字 发布时间 ： 2025-09-03发布于四川  浏览人气 ： 0 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n大模型微调常用术语与知识总结\n大模型微调是优化预训练语言模型以适应特定任务或领域需求的重要技术。在进行大模型微调的过程中，有一系列常用术语和关键知识需要深入理解。下面将对这些常用术语与知识进行详细总结。\n基础概念与术语\n预训练模型（PretrainedModel）\n预训练模型是在大规模无监督数据上进行训练得到的模型。例如，GPT3、BERT等都是著名的预训练模型。这些模型通过在海量文本数据上学习语言的通用模式和特征，能够捕捉到丰富的语义信息。以BERT为例，它在大规模的维基百科等文本数据上进行了掩码语言模型（MaskedLanguageModel,MLM）和下一句预测（NextSentencePrediction,NSP）任务的训练，从而学习到了上下文相关的词表征。预训练模型为后续的微调提供了一个强大的基础，使得模型在特定任务上能够更快地收敛和达到较好的性能。\n微调（FineTuning）\n微调是指在预训练模型的基础上，使用特定任务的标注数据对模型进行进一步训练的过程。通过微调，模型可以适应新的任务需求，调整其参数以更好地完成特定任务。例如，在情感分析任务中，我们可以在预训练的BERT模型基础上，使用情感标注的文本数据对模型进行微调。微调的过程通常是在预训练模型的最后几层添加特定任务的输出层，然后使用特定任务的数据对整个模型或部分层进行训练。微调的优点在于可以利用预训练模型学习到的通用知识，减少在特定任务上的训练时间和数据需求。\n下游任务（DownstreamTask）\n下游任务是指在预训练模型基础上进行微调后要完成的具体任务。常见的下游任务包括文本分类、命名实体识别、机器翻译、问答系统等。不同的下游任务具有不同的特点和要求。例如，文本分类任务需要将输入的文本划分到不同的类别中，而命名实体识别任务则需要识别文本中的实体，如人名、地名、组织机构名等。在进行微调时，需要根据下游任务的特点对预训练模型进行适当的调整和优化。\n冻结（Freezing）\n冻结是指在微调过程中，固定模型的某些层的参数，使其在训练过程中不发生更新。通常，预训练模型的底层参数包含了更多的通用语言知识，而高层参数则更与特定任务相关。因此，在微调时可以选择冻结底层的一些层，只训练高层的层和特定任务的输出层。这样做的好处是可以减少训练的计算量和内存需求，同时避免在数据量较小的情况下过拟合。例如，在使用BERT进行文本分类任务时，可以冻结前几层的参数，只训练后面几层和分类层。\n解冻（Unfreezing）\n解冻与冻结相反，是指在训练过程中，将之前冻结的层的参数重新允许更新。在微调的初始阶段，为了快速收敛和稳定训练，可能会先冻结部分层。随着训练的进行，当模型的性能达到一定程度后，可以逐步解冻一些层，让模型进一步学习更复杂的特征。例如，在训练的前几个epoch冻结底层层，在后续的epoch中逐渐解冻这些层，以让模型能够更好地适应特定任务。\n数据相关术语与知识\n标注数据（AnnotatedData）\n标注数据是指带有标签的训练数据，用于微调模型以完成特定任务。对于不同的下游任务，标注数据的形式也不同。在文本分类任务中，标注数据是文本及其对应的类别标签；在命名实体识别任务中，标注数据是文本以及每个词对应的实体标签。标注数据的质量和数量对微调的效果有着重要影响。高质量的标注数据可以帮助模型学习到更准确的特征，而足够数量的标注数据可以避免过拟合。获取标注数据通常需要人工标注或使用半自动标注工具。\n数据增强（DataAugmentation）\n数据增强是指通过对原始数据进行变换，生成更多的训练数据的技术。在自然语言处理中，常见的数据增强方法包括同义词替换、插入、删除、回译等。例如，在文本分类任务中，可以将文本中的一些词替换为同义词，或者将文本翻译成另一种语言再翻译回来，从而得到新的训练样本。数据增强可以增加训练数据的多样性，提高模型的泛化能力。特别是在标注数据有限的情况下，数据增强可以有效地缓解数据不足的问题。\n数据划分（DataPartitioning）\n数据划分是指将标注数据划分为训练集、验证集和测试集的过程。训练集用于模型的训练，验证集用于在训练过程中评估模型的性能，选择最优的模型参数，测试集用于最终评估模型的泛化能力。常见的数据划分比例是训练集：验证集：测试集=70%：15%：15%或80%：10%：10%。合理的数据划分可以确保模型在训练过程中不出现过拟合，并且能够准确地评估模型的性能。\n小样本学习（FewShotLearning）\n小样本学习是指在仅有少量标注数据的情况下进行模型训练的技术。在实际应用中，获取大量的标注数据可能是困难和昂贵的，因此小样本学习具有重要的意义。在大模型微调中，小样本学习可以通过利用预训练模型的知识，结合一些特殊的训练策略，如元学习、迁移学习等，在少量标注数据上取得较好的性能。例如，使用预训练模型的特征表示，然后在少量标注数据上进行微调，或者使用元学习算法在不同的小样本任务上进行训练和学习。\n训练相关术语与知识\n学习率（LearningRate）\n学习率是优化算法中的一个重要超参数，它控制着模型参数更新的步长。在微调过程中，合适的学习率非常关键。如果学习率过大，模型的参数更新会过快，可能导致模型无法收敛或在最优解附近震荡；如果学习率过小，模型的训练速度会很慢，需要更多的训练时间才能达到较好的性能。常见的学习率调整策略包括固定学习率、学习率衰减（如按epoch衰减、按验证集性能衰减）等。例如，在训练的前几个epoch使用较大的学习率，随着训练的进行逐渐减小学习率，以让模型在不同阶段都能有效地学习。\n优化器（Optimizer）\n优化器是用于更新模型参数的算法，其目的是最小化损失函数。常见的优化器包括随机梯度下降（StochasticGradientDescent,SGD）、Adagrad、Adadelta、Adam等。不同的优化器具有不同的特点和适用场景。Adam优化器结合了Adagrad和RMSProp的优点，能够自适应地调整每个参数的学习率，在很多情况下表现较好。在大模型微调中，选择合适的优化器可以提高训练效率和模型性能。\n损失函数（LossFunction）\n损失函数用于衡量模型预测结果与真实标签之间的差异。在不同的下游任务中，使用的损失函数也不同。在文本分类任务中，常用的损失函数是交叉熵损失函数；在回归任务中，常用的损失函数是均方误差损失函数。损失函数的选择直接影响模型的训练目标和性能。通过最小化损失函数，模型可以不断调整参数，使其预测结果更接近真实标签。\n过拟合（Overfitting）\n过拟合是指模型在训练集上表现很好，但在测试集或新数据上表现较差的现象。在大模型微调中，过拟合是一个常见的问题。过拟合通常是由于模型过于复杂，而训练数据量不足或模型训练时间过长导致的。为了避免过拟合，可以采用正则化方法（如L1和L2正则化）、早停策略（EarlyStopping）、数据增强等方法。早停策略是指在验证集上的性能不再提升时停止训练，以避免模型在训练集上过度学习。\n欠拟合（Underfitting）\n欠拟合是指模型在训练集和测试集上的表现都较差的现象。欠拟合通常是由于模型过于简单，无法学习到数据中的复杂特征，或者训练时间过短，模型还没有充分学习到数据的特征。为了避免欠拟合，可以增加模型的复杂度，如增加模型的层数或神经元数量，或者增加训练的epoch数，让模型有更多的时间学习。\n模型架构与技术相关知识\n迁移学习（TransferLearning）\n迁移学习是指将在一个任务上学习到的知识迁移到另一个相关任务上的技术。大模型微调就是一种典型的迁移学习方法。通过在大规模无监督数据上预训练模型，学习到通用的语言知识，然后将这些知识迁移到特定的下游任务上。迁移学习可以减少在特定任务上的训练时间和数据需求，提高模型的效率和性能。例如，在图像识别领域，也广泛应用了迁移学习，将在大规模图像数据集上预训练的模型迁移到特定的图像分类任务上。\n多任务学习（MultiTaskLearning）\n多任务学习是指同时在多个相关任务上训练模型的技术。在大模型微调中，多任务学习可以让模型在不同的任务之间共享特征，提高模型的泛化能力和效率。例如，可以同时在文本分类和命名实体识别任务上训练模型，让模型学习到更丰富的语言特征。多任务学习通常通过设计合适的损失函数，将多个任务的"
  },
  {
    "title": "LLM（十三）DeepSeek-R1论文全文翻译",
    "page_body": "论文题目：《DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning》\n论文地址 ：https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf\n以下是论文的翻译内容：\n摘要\n 我们介绍第一代推理模型：DeepSeek-R1-Zero 和 DeepSeek-R1。DeepSeek-R1-Zero 是一个完全通过大规模强化学习（RL）训练而无需监督微调（SFT）作为初步步骤的模型，展示了显著的推理能力。通过RL，DeepSeek-R1-Zero 自然地展现出许多强大且有趣的推理行为。然而，它也遇到了一些挑战，如可读性差和语言混合问题。为了解决这些问题并进一步提高推理性能，我们引入了DeepSeek-R1，它在RL之前引入了多阶段训练和冷启动数据。DeepSeek-R1 在推理任务上的表现与OpenAI-o1-1217相当。为了支持研究社区，我们将DeepSeek-R1-Zero、DeepSeek-R1以及基于Qwen和Llama从DeepSeek-R1提炼出的六个密集模型（1.5B、7B、8B、14B、32B、70B）开源。\n第一章 引言\n 近年来，大型语言模型（LLMs）经历了快速迭代和发展（Anthropic, 2024; Google, 2024; OpenAI, 2024a），逐渐缩小了与人工通用智能（AGI）之间的差距。\n 最近，后训练已经成为完整训练管道的重要组成部分。研究表明，这种方法可以在推理任务上提高准确性，符合社会价值观，并适应用户偏好，同时相对于预训练所需的计算资源相对较少。在推理能力方面，OpenAI的o1系列模型首先通过增加链式思考（Chain-of-Thought, CoT）过程的长度引入了推断时缩放方法。这种方法在各种推理任务中取得了显著进展，例如数学、编程和科学推理。然而，有效测试时缩放仍然是研究界的一个开放问题。先前的工作探索了多种方法，包括基于过程的奖励模型（Lightman et al., 2023; Uesato et al., 2022; Wang et al., 2023）、强化学习（Kumar et al., 2024）以及搜索算法如蒙特卡洛树搜索和束搜索（Feng et al., 2024; Trinh et al., 2024; Xin et al., 2024）。然而，这些方法均未达到与OpenAI的o1系列模型相媲美的普遍推理性能。\n 在本文中，我们首次尝试使用纯强化学习（RL）来改进语言模型的推理能力。我们的目标是探索LLMs在没有任何监督数据的情况下发展推理能力的潜力，专注于其通过纯RL过程的自我进化。具体来说，我们使用DeepSeek-V3-Base作为基础模型，并采用GRPO（Shao et al., 2024）作为RL框架，以提高模型在推理中的表现。在训练过程中，DeepSeek-R1-Zero自然地展现了许多强大且有趣的推理行为。经过数千次RL步骤后，DeepSeek-R1-Zero在推理基准测试中表现出色。例如，在AIME 2024上的pass@1得分从15.6%提高到71.0%，并且通过多数投票，得分进一步提高到86.7%，达到了与OpenAI-o1-0912相当的水平。\n 然而，DeepSeek-R1-Zero面临的问题包括可读性差和语言混合。为了解决这些问题并进一步增强推理性能，我们引入了DeepSeek-R1，它包含少量冷启动数据和多阶段训练管道。具体来说，我们首先收集了数千条冷启动数据对DeepSeek-V3-Base模型进行微调。然后，我们像DeepSeek-R1-Zero一样执行面向推理的RL。接近RL过程收敛时，我们通过拒绝采样创建新的SFT数据，并结合来自DeepSeek-V3领域的监督数据，如写作、事实问答和自我认知，然后重新训练DeepSeek-V3-Base模型。经过新数据的微调后，检查点经历了一个额外的RL过程，考虑到了所有场景的提示。经过这些步骤，我们得到了称为DeepSeek-R1的检查点，在推理基准测试中与OpenAI-o1-1217的表现相当。\n 我们进一步探索了从DeepSeek-R1提炼到较小密集模型的方法。使用Qwen2.5-32B（Qwen, 2024b）作为基础模型，直接从DeepSeek-R1提炼的结果优于在其上应用RL。这表明较大的基础模型发现的推理模式对于提高推理能力至关重要。我们将开源的DeepSeek-R1及其API提供给研究社区，以便将来提炼更好的小型模型。\n1.1 贡献\n后训练：大规模强化学习在基础模型上的应用\n我们直接将RL应用于基础模型，而不依赖于监督微调（SFT）作为初步步骤。这种方法允许模型探索解决复杂问题的链式思考（CoT），从而开发出DeepSeek-R1-Zero。DeepSeek-R1-Zero展示了自我验证、反思和生成长链式思考的能力，标志着研究界的重大里程碑。值得注意的是，这是第一个公开研究，验证了通过RL而非SFT可以激励LLM的推理能力。这一突破为未来的发展铺平了道路。 我们介绍了开发DeepSeek-R1的流程。该流程包含两个旨在发现改进推理模式并与人类偏好保持一致的RL阶段，以及两个作为模型推理和非推理能力种子的SFT阶段。我们相信该流程将有助于行业创造更好的模型。\n知识蒸馏：小型模型也可以很强大\n我们证明了较大模型的推理模式可以被提炼到小型模型中，结果比在小型模型上通过RL发现的推理模式更好。开源的DeepSeek-R1及其API将帮助研究社区在未来提炼出更好的小型模型。 使用由DeepSeek-R1生成的推理数据，我们对研究界广泛使用的多个密集模型进行了微调。评估结果显示，提炼后的较小密集模型在基准测试中表现出色。DeepSeek-R1-Distill-Qwen-7B在AIME 2024上获得了55.5%的成绩，超过了QwQ-32B-Preview。此外，DeepSeek-R1-Distill-Qwen-32B在AIME 2024上得分为72.6%，在MATH-500上得分为94.3%，在LiveCodeBench上得分为57.2%。这些结果显著优于之前的开源模型，并且与o1-mini相当。我们将基于Qwen2.5和Llama3系列的1.5B、7B、8B、14B、32B和70B检查点开源给社区。\n1.2 评估结果总结\n推理任务：\nDeepSeek-R1在AIME 2024上的pass@1得分为79.8%，略高于OpenAI-o1-1217。在MATH-500上，它取得了令人印象深刻的97.3%的得分，表现与OpenAI-o1-1217相当，并显著优于其他模型。 编程相关任务：DeepSeek-R1在编程竞赛任务中展示了专家级水平，在Codeforces上获得了2029的Elo评分，超过了96.3%的人类参赛者。对于工程相关的任务，DeepSeek-R1的表现略优于DeepSeek-V3，这有助于开发人员在实际工作中解决问题。\n知识：\n 基准测试：在MMLU、MMLU-Pro和GPQA Diamond等基准测试中，DeepSeek-R1取得了卓越的成绩，显著优于DeepSeek-V3，分别在MMLU上达到90.8%，在MMLU-Pro上达到84.0%，在GPQA Diamond上达到71.5%。虽然其在这些基准测试中的表现略低于OpenAI-o1-1217，但DeepSeek-R1超越了其他闭源模型，展示了其在教育任务中的竞争力。在事实性基准SimpleQA上，DeepSeek-R1也优于DeepSeek-V3，展示了其处理基于事实查询的能力。类似的趋势也出现在OpenAI-o1上，其在这项基准测试中超过4o。\n其他方面：\n广泛任务：DeepSeek-R1还在各种任务中表现出色，包括创意写作、通用问答、编辑、摘要等。它在AlpacaEval 2.0上的长度控制胜率为87.6%，在ArenaHard上的胜率为92.3%，展示了其智能处理非考试导向查询的强大能力。此外，DeepSeek-R1在需要长上下文理解的任务中表现出色，大幅优于DeepSeek-V3在长上下文基准测试中的表现。\n2. 方法\n2.1 概述\n 之前的工作主要依赖大量的监督数据来提升模型性能。在本研究中，我们展示了通过大规模强化学习（RL），即使没有使用监督微调（SFT）作为冷启动，也可以显著提高推理能力。此外，通过引入少量冷启动数据可以进一步增强性能。在以下部分，我们将介绍：（1）直接应用于基础模型而不使用任何SFT数据的DeepSeek-R1-Zero；（2）从经过数千个长链式思考（CoT）示例微调的检查点开始应用RL的DeepSeek-R1；以及（3）将DeepSeek-R1的推理能力提炼到小型密集模型。\n2.2 DeepSeek-R1-Zero：基于基础模型的强化学习\n 强化学习在推理任务中表现出显著的有效性，如我们之前的工作所示（Shao et al., 2024; Wang et al., 2023）。然而，这些工作严重依赖于监督数据，这些数据收集起来非常耗时。在本节中，我们探索了LLMs在没有任何监督数据的情况下发展推理能力的潜力，专注于其通过纯强化学习过程的自我进化。我们首先简要概述我们的RL算法，然后展示一些令人兴奋的结果，并希望这能为社区提供有价值的见解。\n2.2.1 强化学习算法\n 为了节省RL的训练成本，我们采用了组相对策略优化（GRPO）（Shao et al., 2024），该方法放弃了通常与策略模型相同大小的批评模型，并通过组分数估计基线。具体来说，对于每个问题q，GRPO从旧策略πθold中采样一组输出{o1, o2, · · ·, oG}，然后通过最大化以下目标优化策略模型πθ：\n其中ε和β是超参数，Ai是优势函数，根据每组输出内的奖励{r1, r2,..., rG}计算得出：\n2.2.2 奖励建模\n 奖励是训练信号的来源，决定了RL的优化方向。为了训练DeepSeek-R1-Zero，我们采用了一个基于规则的奖励系统，主要包括两种类型的奖励：\n准确性奖励 ：准确性奖励模型评估响应是否正确。例如，在具有确定结果的数学问题中，要求模型以指定格式（例如，在框内）提供最终答案，从而实现可靠且基于规则的正确性验证。同样地，对于LeetCode问题，可以使用编译器根据预定义的测试用例生成反馈。 格式奖励 ：除了准确性奖励模型外，我们还使用了格式奖励模型，强制模型将其思考过程置于‘<think>’和‘</think>’标签之间。\n 我们没有应用结果或过程神经奖励模型来开发DeepSeek-R1-Zero，因为我们发现大规模强化学习过程中神经奖励模型可能存在奖励黑客问题，重新训练奖励模型需要额外的训练资源，并使整个训练管道复杂化。\n2.2.3 训练模板\n 为了训练DeepSeek-R1-Zero，我们首先设计了一个简单的模板，指导基础模型遵循我们的指定指令。如表1所示，此模板要求DeepSeek-R1-Zero首先生成一个推理过程，然后提供最终答案。我们有意限制这些结构化格式的约束，避免任何特定内容的偏见——例如，要求反思性推理或促进特定的问题解决策略——以确保我们可以准确观察模型在RL过程中自然进展的情况。\n2.2.4 性能、自我进化过程和“啊哈”时刻\nDeepSeek-R1-Zero的性能\n 图2显示了在整个RL训练过程中，DeepSeek-R1-Zero在AIME 2024基准上的性能轨迹。如图所示，随着RL训练的推进，DeepSeek-R1-Zero显示出稳定且一致的性能提升。值得注意的是，AIME 2024上的平均pass@1得分显著增加，从最初的15.6%跃升至令人印象深刻的71.0%，达到了与OpenAI-o1-0912相当的水平。这一显著改进凸显了我们的RL算法在随时间优化模型性能方面的有效性。\n 表2提供了DeepSeek-R1-Zero与OpenAI的o1-0912模型在各种推理相关基准上的比较分析。结果表明，RL使DeepSeek-R1-Zero能够在无需任何监督微调数据的情况下获得强大的推理能力。这是一个值得注意的成就，因为它强调了模型仅通过RL就能有效学习和泛化的强大能力。此外，通过多数投票，DeepSeek-R1-Zero的性能可以进一步增强。例如，在AIME基准上应用多数投票时，DeepSeek-R1-Zero的性能从71.0%提升到86.7%，超过了OpenAI-o1-0912的性能。DeepSeek-R1-Zero能够实现如此竞争性的性能，无论是否使用多数投票，都突显了其在推理任务中的强大基础能力及其进一步发展的潜力。\nDeepSeek-R1-Zero的"
  },
  {
    "title": "留学写作，好论文如何炼成-教育-人民网",
    "page_body": "　　留学期间，论文写作既是重要的学业任务，也是整合知识、输出观点的过程。留学生写作时有哪些可利用的学习资源？如何突破语言障碍？本报记者采访了几名有经验的学生，听听他们的分享。\n 　　\n 　　日常积累素材\n 　　“对我而言，写论文的难点是针对研究问题提出解决方案。”刘涛是就读于美国科罗拉多学院的博士生，一路求学，他积累了不少写论文的经验。刘涛说：“通常一篇论文从研究主题‘是什么’‘为什么’‘怎么办’3个角度展开论述，在‘怎么办’的部分，尤其需要针对研究问题提出创新的解决方法，这是论文的落脚点，也是写作具有挑战的部分。”\n 　　刘涛认为，要想在提出解决方案时有创新的点子，除了充分了解前人研究外，还需要做好日常积累。“我认为在平时的学习中要时刻记录灵感。美国课堂注重学生的阅读和讨论，学生需在课下完成阅读，然后在上课时分享读后感并和同学讨论。我在阅读和讨论时会把与研究内容相关的思考记下来，写作可以从中获得启发。”\n 　　读书破万卷，下笔如有神。几名受访留学生纷纷表示，平时多读文献对论文写作大有裨益。好的阅读并不是“走马观花”、泛泛涉猎，想写出好的论文，先要成为一名好的读者。\n 　　刘人博在韩国延世大学学习对外韩语教育，他分享了自己的阅读技巧。“阅读文献时我会分析论文的内容和语言两个方面，每方面单独整理成文档笔记，帮助我实现‘一篇论文不重读’，从而提高科研效率。”\n 　　刘人博进一步解释说：“看论文内容时我特别关注作者的切入角度、研究对象的选定理由、论文的框架结构、段内句间的逻辑展开方式等，学习作者的思维方式。同时，我也看论文中值得再次引用的部分和参考文献，及时建立相关文档并予以记录，进行归类和总结。对于论文语言表达，我会整理文中好的语言表达、句式、用词等，提升自己的写作能力。”\n 　　利用学校资源\n 　　写作时，中国学生除了参照书籍和文献，还可以通过学校资源获得更多帮助。对此，刘涛有亲身体会。\n 　　“我认为主动联系导师、寻求他的建议相当重要。”刘涛回忆，“我的专业是文艺学，有一次我的论文主题是研究蒋孔阳先生的绘画美学思想。我想找到较好的研究切入视角，便主动与导师探讨。导师提出可以从蒋孔阳先生的中西方绘画美学比较研究切入，我当即受到了启发。这是一条我尚未尝试的写作思路，帮助我挖掘出了更丰富的研究内容。”\n 　　在刘涛看来，论文完成后也要积极请教导师，获取修改建议，这是提高论文写作水平的重要一步。“不仅可以根据老师建议，对论文进行修改和完善，还要学会举一反三，下次写作时避免出现相同问题，写作能力就能逐渐提高。”刘涛说\n 　　记者了解到，不少学校开设了论文写作课程，给予学生指导。杜珂就读于德国慕尼黑大学传媒专业，她说：“学校开设的论文写作课不仅教学生如何确定论文写作的框架、思路，还对具体的语言表达给出指导建议。课程实用，深受同学们喜欢，需要在选课时赶紧‘下手’。”\n 　　“我所就读的韩国延世大学为学生提供丰富的论文指导资源。”刘人博介绍，“学校设有韩语和英语写作服务中心，当学生需要思路指导或语言校正、润色时，可以提前在服务中心系统上预约，会有专门的研究员教授一对一联系学生，提供详细反馈。为提高留学生的写作能力、鼓励大家使用写作服务，学校很多教授要求留学生在期末时上交3份文档，分别是论文初稿、写作服务中心的服务回执单和校正后的论文，以帮助大家在完成论文后进行反思、总结。”\n 　　攻克语言难关\n 　　在国外写作通常需用外语完成，对于如何突破外语障碍、准确表达语言，几名学子分享了自己的看法。\n 　　“论文写作过程中的语言表达问题，可以通过学校提供的写作服务进行改正。”刘人博分享了自己的方法，“每次收到写作服务中心的初稿修改意见时，我都会整理一个‘记错本’，将自己犯过的错误重新梳理一遍，在下次写作的时候尽量避免。与其徒增数次修改初稿的经历，不如对经验和错误进行归纳，提升自身写作实力。”\n 　　刚来美国上学时，刘涛也曾在上课时担心自己的语言表达不够地道，担心会因此赶不上课业进度。“但我后来意识到，观点、内容才是语义传达的核心，中国学生首先要克服非母语表达的那份心中的不自信。”\n 　　刘涛还分享了一些翻译与修改软件，他说：“Deep L和Grammarly是我常用的软件，翻译的准确度较高，还能润色表达、改语法错误，对于论文写作很有用。”\n 　　杜珂认为，相比华丽的辞藻，清楚的表达更为重要，对于非母语论文写作来说更是这样。她说：“论文写作并不需要生僻复杂的词汇，而要把重心放在内容本身。学术论文是学术研究过程和成果的一种呈现方式，想要做到表达清晰，我们除了外语能力，还需具备逻辑思维和谋篇布局能力，这是更全面的写作思维。”\n 　　“提升论文的外语写作能力没有捷径可走。”杜珂说，“首先要有意识地阅读优质论文，学习、总结作者的写作方法。通常好的论文段落很规范，中心句、论据以及之间的逻辑衔接关系一目了然。此外，还需要尽可能多地积累不同的表达句型，让行文表述更丰富。”"
  },
  {
    "title": "Java 机密计算技术全知道：原理详解与代码实践示例",
    "page_body": "机密计算（Confidential Computing）  是一种保护数据在使用过程中（即内存中）的安全技术。它通过硬件支持的可信执行环境（TEE，Trusted Execution Environment）来确保数据在计算过程中不会被未授权的实体访问。Java 作为一种广泛使用的编程语言，也可以与机密计算技术结合，保护敏感数据。\n以下是 Java 机密计算技术的详解及代码示例。\n1. 机密计算的核心概念\n1.1 可信执行环境（TEE）\nTEE 是一个隔离的执行环境，确保代码和数据在运行时不会被外部访问。\n常见的 TEE 技术包括：\nIntel SGX（Software Guard Extensions）\nAMD SEV（Secure Encrypted Virtualization）\nARM TrustZone\n1.2 机密计算的关键特性\n数据加密 ：数据在内存中以加密形式存储。\n代码完整性 ：确保只有经过验证的代码可以在 TEE 中运行。\n远程证明 ：允许外部验证 TEE 环境的真实性。\n2. Java 与机密计算\nJava 可以通过以下方式与机密计算技术结合：\n使用支持 TEE 的硬件 ：如 Intel SGX。\n调用本地库 ：通过 JNI（Java Native Interface）调用 C/C++ 编写的 TEE 代码。\n使用机密计算框架 ：如 Microsoft Open Enclave、Asylo 等。\n3. 使用 Intel SGX  的  Java 机密计算示例\nIntel SGX 是一种广泛使用的 TEE 技术。以下是一个简单的示例，展示如何在 Java 中调用 SGX 的本地代码。\n3.1 环境准备\n硬件 ：确保 CPU 支持 Intel SGX。\n软件 ：\n安装 Intel SGX SDK。\n安装 Java Development Kit (JDK)。\n安装 JNI 工具。\n3.2 编写 SGX 本地代码\n以下是一个简单的 SGX 本地代码示例，用于在 TEE 中执行加法操作。\nC++ 代码（ sgx_enclave.cpp ）\nEnclave 代码（ Enclave.edl ）\nEnclave 实现（ Enclave.cpp ）\n3.3 编写 Java 代码\n通过 JNI 调用 SGX 本地代码。\nJava 代码（ SGXExample.java ）\n3.4 编译和运行\n 1.编译 SGX 代码 ：\n使用 Intel SGX SDK 编译 Enclave 代码。\n生成共享库（如 libsgx_enclave.so ）。\n 2.编译 Java 代码 ：\n使用 javac 编译 Java 代码：\n生成 JNI 头文件：\n 3.运行程序 ：\n确保 SGX 环境已正确配置。\n运行 Java 程序：\n4. 使用机密计算框架\n除了直接使用 SGX，还可以使用机密计算框架（如 Microsoft Open Enclave 或 Asylo ）来简化开发。这些框架提供了跨平台的 TEE 支持，并可以与 Java 集成。\n5. 总结\n机密计算 通过 TEE 技术保护数据在计算过程中的安全。\nJava 可以通过 JNI 调用本地代码，与 TEE 技术（如 Intel SGX）结合。\n使用机密计算框架可以简化开发流程。\n以上示例展示了如何在 Java 中实现机密计算。实际应用中，需要根据具体需求选择合适的 TEE 技术和框架。 #图文创作激励计划#"
  },
  {
    "title": "【英国留学】学术论文写作之方法论",
    "page_body": ""
  },
  {
    "title": "大语言模型在客服领域：AI原生对话系统的架构设计-CSDN博客",
    "page_body": "大语言 模型 在客服领域：AI原生对话系统的架构设计\n关键词：大 语言模型 （LLM）、AI原生客服系统、对话管理、意图识别、多模态交互\n摘要：本文从传统 客服系统 的痛点出发，结合大语言模型（LLM）的技术特性，系统讲解AI原生对话系统的核心架构设计。通过生活类比、技术原理解析和实战代码示例，帮助读者理解如何用LLM重构客服对话系统，涵盖意图识别、多轮对话管理、安全合规等关键模块，并探讨未来发展趋势。\n背景介绍\n目的和范围\n在电商、金融、电信等行业，客服系统是连接企业与用户的关键纽带。传统客服系统依赖规则引擎和关键词匹配，面对复杂问题（如“我上周买的白色连衣裙，物流显示已签收但没收到，能帮我查下吗？”）时，常出现“答非所问”“流程断裂”等问题。本文聚焦“大语言模型（LLM）如何重塑客服系统”，覆盖从架构设计到落地实战的全流程。\n预期读者\n技术人员：想了解如何将LLM应用到客服场景的开发者、架构师 业务人员：企业客服负责人、产品经理（理解技术价值与落地成本） 普通用户：对AI客服背后原理感兴趣的“好奇星人”\n文档结构概述\n本文从“为什么需要AI原生客服”切入，逐步拆解核心模块（ 意图识别 、对话管理、LLM调用），结合代码示例和实际场景，最后展望未来趋势。\n术语表\n术语\n解释（用小学生能懂的话）\n大语言模型（LLM） 像一个“超级知识大脑”，能理解人类语言并生成合理回答（比如ChatGPT就是典型的LLM）\n意图识别 给用户的问题“贴标签”，比如把“退货”“查物流”“投诉”区分开\n多轮对话管理 记住对话历史的“小本本”，比如用户说“我要退货”，系统问“订单号是多少？”，它能记住这是同一件事\n上下文窗口 LLM能“记住”的对话长度（比如能记住最近20轮对话）\n幻觉（Hallucination） LLM“编故事”的情况（比如用户没提过“红色外套”，但系统回答“您的红色外套已退款”）\n核心概念与联系\n故事引入：小明的“崩溃”客服体验\n小明在某电商平台买了一本书，物流显示“已签收”但没收到。他联系客服：\n 小明：“我的书没收到，物流显示签收了，怎么办？”\n 传统客服：“请提供订单号查询物流~”（小明提供后）\n 传统客服：“物流显示已签收，可能是放快递柜了哦~”（小明说没收到快递柜通知）\n 传统客服：“请联系快递员138XXXX1234~”（小明打过去，快递员说没送过）\n 小明崩溃：“我要投诉！”\n 传统客服：“您的问题已记录，3个工作日内处理~”\n而AI原生客服的对话可能是这样的：\n 小明：“我的书没收到，物流显示签收了，怎么办？”\n AI客服：“抱歉给您添麻烦了！已帮您查到订单号12345的物流信息，显示快递员张师傅10:30放到小区快递柜，但您手机没收到取件码。我已联系张师傅确认，并为您申请了优先补发，新包裹预计明天送达，需要帮您备注‘放门口’吗？”\n为什么AI客服更聪明？  因为它能：\n理解“没收到+物流显示签收”的深层问题（可能是快递柜漏发短信）； 记住对话历史（小明没收到通知）； 主动解决问题（联系快递员、申请补发）。\n这背后的核心，就是大语言模型驱动的“AI原生对话系统”。\n核心概念解释（像给小学生讲故事）\n核心概念一：大语言模型（LLM）—— 客服的“超级大脑”\nLLM就像一个“读了全世界所有书”的客服专家。它通过分析海量文本（网页、书籍、对话记录），学会了“理解人类语言”和“生成合理回答”。比如，它知道“没收到快递”可能和“物流信息错误”“快递员漏送”有关，而不仅仅是“用户没查物流”。\n核心概念二：意图识别—— 给问题“分分类”\n意图识别就像超市的“商品分类标签”。用户说“我要退货”，标签是“退货申请”；用户说“物流到哪了”，标签是“物流查询”。系统通过标签快速知道用户需求，避免“用户说退货，系统推荐新品”的尴尬。\n核心概念三：多轮对话管理—— 对话的“记忆小本本”\n多轮对话管理就像玩“你画我猜”时的“提示板”。用户说“我要退昨天买的T恤”，系统问“请问尺码是M还是L？”，这时候需要记住用户是“退T恤”，而不是突然跳到“查物流”。如果没有记忆，用户可能要重复说：“我之前说要退T恤，尺码是M！”\n核心概念之间的关系（用小学生能理解的比喻）\n想象开一家“智能奶茶店”：\nLLM是“万能店员”（能理解“我要少糖、加珍珠的冰奶茶”，还能推荐“最近芒果味很火哦”）； 意图识别是“点单分类器”（区分“点单”“改单”“投诉”）； 多轮对话管理是“点单记录本”（记住用户说“少糖”，后面问“加椰果还是红豆？”时不会忘记）。\n三者关系：\nLLM和意图识别 ：意图识别帮LLM“快速定位问题”（比如先知道用户是“投诉”，LLM就不会用“点单”的语气回答）； 意图识别和对话管理 ：对话管理根据意图“推进流程”（比如“退货”意图需要收集订单号、商品问题，对话管理会一步步问）； LLM和对话管理 ：对话管理把“记忆小本本”（对话历史）交给LLM，LLM就能结合历史生成更自然的回答（比如用户之前说“没收到快递”，LLM会说“关于您之前提到的未收到快递问题，我们已联系快递员”）。\n核心概念原理和架构的文本示意图\nAI原生对话系统的核心架构可分为5层：\n输入层 ：用户输入（文字/语音/图片）→ 预处理（转文字、去噪）； 理解层 ：意图识别（分类）、实体抽取（提取“订单号”“商品名”等关键信息）； 决策层 ：LLM调用（结合对话历史生成回答）、对话状态管理（更新记忆小本本）； 执行层 ：调用外部系统（查物流、改订单）； 输出层 ：生成回答（文字/语音）。\nMermaid 流程图"
  },
  {
    "title": "AI小课堂 大模型技术的三种架构，我用3分钟给大家讲清楚，涉及到计算机科学理论，内容很干！建议先马再看#大模型 #大模型技术架构 #AI #人工智能 #AI小课堂",
    "page_body": ""
  },
  {
    "title": "大模型训练2--Prompt Tuning-->训练可学习提示-知乎",
    "page_body": "近年来，以GPT为代表的大型预训练模型（Pre-trained Language Models, PLMs）在自然语言生成任务中表现出色。为了更好的适配下游任务，传统的全参数微调（Fine-tuning）需要为每个下游任务存储和更新数十亿参数，这对计算资源和存储成本提出了巨大挑战。针对这个问题，GPT3中提出了prompt工程，然而大模型对用户设计的prompt比较敏感，因而也难以保证效果。在此背景下，Prompt Tuning作为一种轻量高效的微调方法备受关注，仅需对每一个任务训练一个提示向量，就可以大大提高大模型在这项任务的表现。\n 一、什么是Prompt Tuning？\n 传统的Fine-tuning通过在预训练模型的基础上添加任务相关层（如分类器）并更新所有参数来适应具体任务。然而，这种方法有两个主要缺陷：\n 参数低效：每个下游任务需独立保存完整模型副本。\n 灾难性遗忘：微调可能覆盖预训练模型中的通用知识。\n 相比之下，Prompt Tuning的核心思想是通过在输入中插入可学习提示（Prompt），以极小的参数调整来适配下游任务。这种方法仅需优化提示相关的参数（通常占总参数的0.1%~1%），而冻结原始模型参数。如Figure1所示，Prompt Tuning所需要训练的参数最小。prompt Design就是Prompt工程，是不可训练的。\n Figure1、不同微调方法所更新的参数\n 二、Prompt Tuning训练过程\n 2.1、设计提示模板\n 在原始输入前添加k 个可学习的提示嵌入（例如[P1][P2][P3][P4]），并拼接模板引导输出。例如：\n [P1][P2][P3][P4] 这部电影很有趣。总体评价是 [MASK] 的。\n 其中，\n [P1]-[P4]：可训练的提示，相当于4个待学习的token。每个P的嵌入维度与文本嵌入的维度一致，比如768。[MASK]：模型需预测的位置，映射到标签（如“好”→“正面”，“差”→“负面”）。对于k的选择，论文中做了实验，20个性价比最高，如Figure3所示。本文中仅以4个作为例子。Figure3\n 2.2、输入编码\n 输入文本被转换为嵌入向量。提示嵌入与原始输入的嵌入向量拼接后输入冻结的预训练模型（如 GPT3）。2.3、计算损失\n 模型预测[MASK]位置的 token 概率（如“好”的概率为 0.8，“差”为 0.2）。根据真实标签（假设是“正面”），计算交叉熵损失：Loss = -log(P(\"好\"))。2.4、反向传播\n 仅更新提示嵌入的参数（[P1]-[P4]嵌入向量）。预训练模型的参数保持冻结。3、预测过程\n Prompt Tuning训练完毕后，可学习提示嵌入的向量就保持不变，对该任务下的所有问题都使用这个提示嵌入。换言之，不管用户输入的问题是什么，只要是同一个任务下的问题，所插入的提示嵌入[P1]-[P4]都是一样的。要适配多任务，就需要为每一个任务训练一个可学习的提示嵌入。\n 3.1、添加训练后的提示\n 新输入特效很棒，但剧情糟糕。与前缀提示拼接：\n [P1][P2][P3][P4] 特效很棒，但剧情糟糕。总体评价是 [MASK] 的。\n 其中，“总体评价是 [MASK] 的”是人工针对这项任务所设计的模板。要注意的是，训练后得到的是P1-P4四个嵌入向量，而不是4个token。需要对输入文本进行embedding后再与学习到的提示嵌入进行拼接。\n 3.2、模型推理\n 冻结的预训练模型处理整个输入序列，预测[MASK]位置的 token 概率（例如“差”的概率为 0.7）。\n 3.3、映射到标签\n 根据[MASK]预测结果（“差”），输出类别为“负面”。\n 4、参考文献\n 【1】The Power of Scale for Parameter-Efficient Prompt Tuning"
  },
  {
    "title": "为什么你的大模型训练这么慢？3个关键并行优化点必须掌握-CSDN博客",
    "page_body": "第一章：大模型训练性能瓶颈的根源分析\n 在大规模语言模型的训练过程中，性能瓶颈往往成为制约迭代效率和成本控制的核心问题。尽管硬件算力持续提升，但实际训练中仍频繁遭遇吞吐量低、收敛缓慢等问题。深入剖析其根源，有助于从系统架构与算法协同设计的角度优化整体训练效率。 \n显存带宽与计算资源的不匹配\n 现代GPU虽具备强大的浮点运算能力，但显存带宽的增长速度远落后于计算能力。这导致大量时间消耗在数据搬运而非实际计算上。例如，在处理千亿参数模型时，激活值和梯度的存储需求极易超出显存容量，引发频繁的CPU-GPU间数据交换。 \n高精度训练（如FP32）加剧显存压力 激活检查点机制虽缓解内存占用，但增加计算开销 张量并行策略若划分不当，会引入额外通信延迟\n分布式训练中的通信开销\n 多卡或多节点训练依赖高效的集合通信（如AllReduce），但在跨节点场景下，网络带宽和延迟显著影响同步速度。特别是在数据并行中，梯度同步成为关键路径。 \n# 所有进程梯度求和并广播回每个进程\n# 若网络带宽不足，此操作可能成为性能瓶颈\n数据加载与预处理延迟\n 模型训练速度提升后，I/O常成为短板。原始文本需经分词、截断、批处理等步骤，若未采用异步加载或缓存机制，GPU将频繁等待数据输入。 \n低效算子、小批量尺寸\n网络拥塞、拓扑不合理\n磁盘读取慢、预处理串行化\n第二章：数据并行与分布式训练优化\n2.1 PyTorch DDP 原理与通信开销解析\n数据并行机制概述\n PyTorch 的 DistributedDataParallel (DDP) 通过在多个进程间复制模型，实现数据并行训练。每个进程处理不同的数据子集，并在反向传播时同步梯度。 \n梯度同步流程\n DDP 使用环形约简（Ring All-Reduce）进行梯度聚合，各 GPU 按拓扑顺序分段通信，降低带宽压力。通信开销主要取决于模型参数量和网络带宽。 \n# 自动触发梯度同步\n 上述代码中， DDP  包装模型后，在  loss.backward()  完成后自动执行跨进程梯度同步，无需手动干预。 \n通信开销影响因素\n参数规模：参数越多，梯度张量越大，通信时间越长 GPU间连接：NCCL后端依赖高速互联（如InfiniBand）提升吞吐 批量大小：大batch增加梯度计算占比，相对降低通信占比\n2.2 多机多卡环境下梯度同步的性能调优\n 在分布式深度学习训练中，多机多卡环境下的梯度同步成为性能瓶颈的关键环节。合理优化通信机制可显著提升整体训练效率。 \n梯度同步策略对比\n 常见的同步方式包括同步SGD、Ring-AllReduce和Hierarchical AllReduce。其中Ring-AllReduce在大规模节点间表现出更优的扩展性。 \n 该函数遍历模型参数，对每个梯度执行全局规约并归一化，确保各节点梯度一致。dist.all_reduce采用环状通信，减少中心节点压力。 \n2.3 使用混合精度训练加速数据并行\n 在大规模模型训练中，混合精度训练结合数据并行可显著提升计算效率。通过使用FP16减少显存占用和带宽需求，同时保留FP32用于稳定梯度更新，实现速度与精度的平衡。 \n混合精度核心机制\n NVIDIA Apex等工具提供便捷的自动混合精度（AMP）支持。启用后，前向传播采用半精度，而关键计算如梯度缩放仍用单精度。 \n 上述代码中， autocast 自动管理张量精度类型， GradScaler 防止FP16梯度下溢，确保训练稳定性。 \n与数据并行的协同优化\n 在DDP场景下，混合精度减少了 all-reduce 通信的数据量，加快梯度同步。每卡独立进行损失缩放，避免跨卡数值不一致问题。 \n2.4 梯度累积与批大小的权衡策略\n 在深度学习训练中，批大小（batch size）直接影响模型收敛性与内存消耗。较大的批大小能提升训练稳定性，但受限于GPU显存容量。梯度累积技术通过模拟大批次训练，允许在小批量迭代中累积梯度，待累积步数完成后统一更新参数。 \n梯度累积实现逻辑\n# 每累积4个小批次执行一次参数更新\nfor  i, (inputs, labels)  in enumerate (dataloader):\n 上述代码将损失除以累积步数，确保梯度尺度合理。反向传播不立即更新参数，而是在累积指定步数后调用  step() ，有效模拟大批次训练。 \n批大小与学习率协同调整\n线性缩放规则：当等效批大小增大时，学习率应成比例提高 学习率预热：在初始阶段逐步增加学习率，避免梯度震荡 梯度裁剪：防止累积过程中梯度爆炸\n2.5 实战：基于 torch.distributed 的可扩展训练框架搭建\n初始化分布式环境\n 在多机多卡训练中，首先需正确初始化分布式通信后端。常用 NCCL 后端支持 GPU 间高效通信。 \n    dist.init_process_group(backend= 'nccl' , init_method= 'env://' )\n 上述代码通过环境变量（如 RANK、WORLD_SIZE）自动获取节点信息，适用于 Kubernetes 或 Slurm 调度场景。 \n数据并行与模型封装\n 使用  DistributedDataParallel  包装模型，实现梯度级别的同步。 \nfrom  torch.nn.parallel  import  DistributedDataParallel  as  DDP\nmodel = DDP(model, device_ids=[local_rank])\n 每个进程独立加载对应子数据集，配合  DistributedSampler  避免样本重复。 \n训练流程协同控制\n所有进程共享同一学习率调度策略 仅主进程保存检查点，避免文件冲突 使用  dist.barrier()  确保全局同步点\n第三章：模型并行的拆分与协同机制\n3.1 层内并行（Tensor Parallelism）在Transformer中的实现\n 层内并行通过将单个张量计算分布到多个设备上来提升大规模Transformer的训练效率，尤其适用于模型参数远超单卡显存容量的场景。 \n张量切分策略\n 在Transformer的自注意力和前馈网络中，大矩阵乘法是性能瓶颈。以隐藏层维度为  d d 、输出维度为  h h  的全连接层为例，权重矩阵  W ∈ R d × h W ∈ R d × h  可沿输出维度切分为  W 1 , W 2 , . . . , W n W 1 , W 2 , . . . , W n ，分别部署于不同GPU。 \n# 假设将输出维度均分至2个设备\noutput_0 = x @ W_tensor_parallel[ 0 ]   # 设备0计算局部结果\noutput_1 = x @ W_tensor_parallel[ 1 ]   # 设备1计算局部结果\n 上述代码展示了权重切分与局部计算过程。每个设备仅需存储部分权重，显著降低显存压力。 \n数据同步机制\n 各设备完成局部矩阵乘法后，需通过  AllReduce  操作聚合结果，确保最终输出一致： \n前向传播：各设备独立计算局部输出，随后执行AllReduce求和 反向传播：梯度已全局同步，可直接更新本地权重分片\n3.2 层间并行（Pipeline Parallelism）的调度与气泡优化\n 在层间并行中，模型被纵向切分为多个阶段，各阶段分布于不同设备上。由于计算与通信无法完全重叠，流水线执行常引入“气泡”（Bubble），即空闲等待周期，降低整体吞吐。 \n调度策略\n 主流调度方式包括： \nNaive Pipeline ：按顺序推进微批次，气泡集中在流水线填满前； 1F1B（One Forward One Backward） ：交错执行前向与反向传播，减少等待时间。\n气泡优化示例\n# 模拟流水线气泡占比计算\ndef calc_bubble_ratio ( num_stages, num_micro_batches ):\n# 四阶段流水线，4个微批次\n 该函数表明，在早期阶段，气泡开销显著。随着微批次增多，利用率提升，凸显调度优化必要性。 \n3.3 实战：使用 FSDP 与模型切分提升显存效率\n 在大规模模型训练中，显存瓶颈是常见挑战。FSDP（Fully Sharded Data Parallel）通过将模型参数、梯度和优化器状态分片，显著降低单卡显存占用。 \n核心实现逻辑\nfrom  torch.distributed.fsdp  import  FullyShardedDataParallel  as  FSDP\n 该代码启用 FSDP， use_orig_params=True  允许使用原生参数格式，提升兼容性与性能。每个进程仅保留当前所需参数分片，其余按需加载。 \n模型切分策略对比\n策略\n显存节省\n通信开销\n FSDP 在显存效率与通信成本之间实现了更优平衡，适合千亿级模型分布式训练场景。 \n第四章：系统级优化与硬件协同加速\n4.1 CUDA内核融合与算子优化技巧\n 在高性能计算中，CUDA内核融合是减少内存带宽瓶颈和提升GPU利用率的关键手段。通过将多个细粒度内核合并为单一复合内核，可显著降低全局内存访问次数和内核启动开销。 \n内核融合示例\n__ global __ void fused_kernel(float *  a, float *  b, float *  c, float *  d, int n) {\n        float temp  =  a[idx]  +  b[idx];      / /  第一步：向量加法\n        d[idx]  =  temp  *  c[idx];            / /  第二步：逐元素乘法\n 上述代码将两个独立操作（加法与乘法）融合为一个内核，避免中间结果写回全局内存，提升数据局部性。 \n优化策略\n减少内存事务：合并读写模式以提高合并访问效率 利用共享内存：在块内重用数据，降低全局内存压力 避免分支发散：确保同一线程束执行相同控制路径\n4.2 显存管理：检查点机制与动态分配策略\n 在深度学习训练中，显存资源往往成为性能瓶颈。为缓解这一问题，现代框架引入了检查点（Checkpointing）机制，通过在前向传播中仅保存部分中间结果，在反向传播时重新计算未缓存的张量，从而显著降低显存占用。 \n检查点机制示例\nfrom  torch.utils.checkpoint  import  checkpoint\n# 使用检查点包装前向过程\n 上述代码通过  checkpoint  函数替代标准前向调用，仅保留输入和最终输出，中间激活值在反向传播时按需重建，节省约40%-60%显存。 \n动态显存分配策略\n GPU显存分配器采用基于内存池的动态管理，避免频繁申请/释放带来的开销。典型策略包括： \n首次适配（First-Fit）：快速分配首个足够大的空闲块 分块合并：回收碎片化空间，提升利用率\n 结合检查点与动态分配，可在有限显存下支持更大模型或批量规模。 \n4.3 NCCL通信后端调优与拓扑感知配置\n 在大规模分布式训练中，NCCL（NVIDIA Collective Communications Library）是实现高效GPU间通信的核心。合理调优其后端参数并启用拓扑感知配置，可显著提升集合通信性能。 \n环境变量调优策略\n 通过设置关键环境变量优化通信行为： \n 其中， NCCL_ALGO 指定使用Ring算法以降低带宽竞争， NCCL_PROTO 选择Simple协议减少小消息延迟， NCCL_TOPO_FILE 引导NCCL加载自定义拓扑描述文件。 \n拓扑感知通信优化\n NCCL通过分析PCIe、NVLink和NUMA拓扑自动构建最优通信路径。可通过以下命令生成物理拓扑图： \n 该文件记录了GPU间的连接带宽与跳数，使NCCL在AllReduce等操作中优先选择NVLink直连路径，避免跨NUMA节点通信瓶颈。 \n4.4 实战：结合PyTorch Profiler定位训练瓶颈\n 在深度学习模型训练过程中，性能瓶颈常隐藏于数据加载、GPU利用率不足或算子执行效率低下中。PyTorch Profiler 提供细粒度的执行时间分析，帮助开发者精准定位问题。 \n启用Profiler进行性能采样\n    on_trac"
  },
  {
    "title": "收藏必备！斯坦福大学Transformer图解教程：大模型架构学习的“圣经“级资源-CSDN博客",
    "page_body": "这篇文章介绍了一份斯坦福大学团队制作的Transformer图解教程，通过高度可视化的方式讲解Transformer架构核心原理、大语言模型的提示微调及应用方法。该教程因其可视化程度高、讲解清晰、学术严谨，被AI学习者誉为\"圣经级\"入门材料，适合初学者理解大语言模型基石技术，也为从业者提供深入探究资源。\n今天给大家一份由斯坦福大学研究人员或课程团队精心制作的深度学习技术教程，旨在以直观、易懂的视觉化方式，深入浅出地讲解Transformer神经网络架构的核心原理。\n涵盖：\nTransformer：自注意力机制、架构、变体、优化技术（如稀疏注意力、低秩注意力、Flash Attention） 大语言模型 (LLM)：提示 (prompting)、微调（SFT、LoRA）、偏好调优、优化技术（混合专家模型、知识蒸馏、量化） 应用：LLM 作为评判者、检索增强生成 (RAG)、智能体、推理模型（来自 DeepSeek-R1 的训练时与测试时缩放技术）\n这份《斯坦福Transformer图解》因其 极高的可视化程度、逻辑清晰的讲解顺序和学术严谨性 ，被全球广大AI学习者、研究者和工程师奉为学习Transformer架构的“圣经级”入门材料。它不仅帮助初学者跨越理解障碍，也为从业者提供了快速回顾和深入探究的宝贵资源。这份图解是理解当今大语言模型（如BERT、GPT系列）基石技术不可或缺的学习资料。\n如何学习大模型 AI ？\n由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。\n但是具体到个人，只能说是：\n“最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。\n这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。\n我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。\n我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。\n这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【 保证100%免费 】\n为什么要学习大模型？\n我国在A大模型领域面临人才短缺,数量与质量均落后于发达国家。2023年，人才缺口已超百万，凸显培养不足。随着AI技术飞速发展，预计到2025年,这一缺口将急剧扩大至400万,严重制约我国AI产业的创新步伐。加强人才培养,优化教育体系,国际合作并进是破解困局、推动AI发展的关键。\n大模型入门到实战全套学习大礼包\n1、大模型系统化学习路线\n作为学习AI大模型技术的新手，方向至关重要。 正确的学习路线可以为你节省时间，少走弯路；方向不对，努力白费。这里我给大家准备了一份 最科学最系统的学习成长路线图和学习规划 ，带你从零基础入门到精通！\n2、大模型学习书籍&文档\n学习AI大模型离不开书籍文档，我精选了一系列大模型技术的书籍和学习文档（电子版），它们由 领域内的顶尖专家撰写 ，内容全面、深入、详尽，为你学习大模型提供坚实的理论基础。\n3、 AI大模型最新行业报告\n2025最新行业报告，针对 不同行业的现状、趋势、问题、机会 等进行系统地调研和评估，以了解哪些行业更适合引入大模型的技术和应用，以及在哪些方面可以发挥大模型的优势。\n4、 大模型项目实战&配套源码\n学以致用 ，在 项目实战中检验和巩固你所学到的知识 ，同时为你找工作就业和职业发展打下坚实的基础。\n5、 大模型大厂面试真题\n面试不仅是技术的较量，更需要充分的准备。在你已经掌握了大模型技术之后，就需要开始准备面试，我精心整理了一份大模型面试题库， 涵盖当前面试中可能遇到的各种技术问题，让你在面试中游刃有余 。\n适用人群\n第一阶段（10天）：初阶应用\n该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨论时发表高级、不跟风、又接地气的见解，别人只会和 AI 聊天，而你能调教 AI，并能用代码将大模型和业务衔接。\n大模型 AI 能干什么？ 大模型是怎样获得「智能」的？ 用好 AI 的核心心法 大模型应用业务架构 大模型应用技术架构 代码示例：向 GPT-3.5 灌入新知识 提示工程的意义和核心思想 Prompt 典型构成 指令调优方法论 思维链和思维树 Prompt 攻击和防范 …\n第二阶段（30天）：高阶应用\n该阶段我们正式进入大模型 AI 进阶实战学习，学会构造私有知识库，扩展 AI 的能力。快速开发一个完整的基于 agent 对话机器人。掌握功能最强的大模型开发框架，抓住最新的技术进展，适合 Python 和 JavaScript 程序员。\n为什么要做 RAG 搭建一个简单的 ChatPDF 检索的基础概念 什么是向量表示（Embeddings） 向量数据库与向量检索 基于向量检索的 RAG 搭建 RAG 系统的扩展知识 混合检索与 RAG-Fusion 简介 向量模型本地部署 …\n第三阶段（30天）：模型训练\n恭喜你，如果学到这里，你基本可以找到一份大模型 AI相关的工作，自己也能训练 GPT 了！通过微调，训练自己的垂直大模型，能独立训练开源多模态大模型，掌握更多技术方案。\n到此为止，大概2个月的时间。你已经成为了一名“AI小子”。那么你还想往下探索吗？\n为什么要做 RAG 什么是模型 什么是模型训练 求解器 & 损失函数简介 小实验2：手写一个简单的神经网络并训练它 什么是训练/预训练/微调/轻量化微调 Transformer结构简介 轻量化微调 实验数据集的构建 …\n第四阶段（20天）：商业闭环\n对全球大模型从性能、吞吐量、成本等方面有一定的认知，可以在云端和本地等多种环境下部署大模型，找到适合自己的项目/创业方向，做一名被 AI 武装的产品经理。\n硬件选型 带你了解全球大模型 使用国产大模型服务 搭建 OpenAI 代理 热身：基于阿里云 PAI 部署 Stable Diffusion 在本地计算机运行大模型 大模型的私有化部署 基于 vLLM 部署大模型 案例：如何优雅地在阿里云私有部署开源大模型 部署一套开源 LLM 项目 内容安全 互联网信息服务算法备案 …\n学习是一个过程，只要学习就会有挑战。天道酬勤，你越努力，就会成为越优秀的自己。\n如果你能在15天内完成所有的任务，那你堪称天才。然而，如果你能完成 60-70% 的内容，你就已经开始具备成为一名大模型 AI 的正确特征了。\n这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【 保证100%免费 】"
  },
  {
    "title": "社区说｜用 TensorFlow 实现 GPT 模型",
    "page_body": ""
  },
  {
    "title": "Transformer模型：核心组件和应用场景",
    "page_body": "Transformer模型在自然语言处理（NLP）领域真的太成功了，从BERT开始，它已经成了文本分类、命名实体识别、情感分析、机器翻译等任务里的常客。\n它的厉害之处，全在它的核心组件上。\n     核心组件一：自注意力机制\n这是Transformer的灵魂。它允许模型在处理序列数据时，对每个位置的输入进行加权求和，得到一个全局的上下文表示。在计算自注意力时，模型首先将输入序列通过线性变换得到Q（查询）、K（键）和V（值）三个向量。然后计算Q和K的点积，并应用softmax函数，得到每个位置的权重。最后，将权重与V向量相乘，得到自注意力的输出。\n     核心组件二：多头注意力\n为了提高模型的表达能力，Transformer模型采用了多头自注意力机制。这意味着模型在同一时间关注来自不同表示子空间的注意力信息。多头自注意力的实现方法是通过多个独立的注意力头，每个头使用不同的权重矩阵对输入序列进行线性变换，生成各自的Q、K、V向量，并计算自注意力。最终，这些自注意力的输出被拼接起来，并通过一个线性层得到最终的输出表示。\n     核心组件三：前馈神经网络\n在计算自注意力和多头自注意力之后，Transformer模型使用前馈神经网络对输入序列进行变换。前馈神经网络由多个全连接层组成，每个全连接层都使用ReLU激活函数。前馈神经网络的作用是对输入序列进行非线性变换，以捕捉更复杂的特征。\n     核心组件四：位置编码\n位置编码是通过在输入序列的每个位置添加一个固定长度的向量来实现的。这个向量包含了该位置在序列中的信息，如位置标识符和相对位置等。\n     应用场景\n文本分类\n文本分类是Transformer模型最常见的应用之一。通过将文本输入到模型中，可以得到每个类别的预测概率分布。常见的文本分类任务包括情感分析、新闻分类、电影评论分类等。例如，BERT等经典模型在情感分析任务上取得了很好的效果，能够准确识别文本中的情感倾向。\n命名实体识别\n命名实体识别是自然语言处理中的一项重要任务，旨在识别文本中的特定实体（如人名、地名、组织名等）。"
  },
  {
    "title": "从实践到课堂 从课堂到实战—全省“十佳精品纪检监察课程”评选工作侧记",
    "page_body": "近日，全省 “十佳精品纪检监察课程”和“优秀纪检监察课程”评选结果揭晓。成都市纪委监委、省纪委监委驻四川银行纪检监察组等16个单位申报的“谈话的策略和方法”等20个课程榜上有名，标志着全省“十佳精品纪检监察课程”评选阶段的工作圆满结束。\n \n7月5日，省纪委监委开展“十佳精品纪检监察课程”现场展示评审，入围的29个课题组同台展示、精彩纷呈。\n广泛参与、深研细磨\n为认真贯彻落实中央纪委、省纪委关于深化干部培训培养和加强纪检监察学科建设有关部署，充分发挥干部培训服务保障办案作用，进一步充实优质培训资源、提升干部培训质效，聚力锻造本领高强的纪检监察干部队伍， 2023年底，省纪委监委部署开展“十佳精品纪检监察课程”评选工作。各地各单位积极响应，共43个地方和单位申报80个选题。经严格审核，65个“精而专”的选题进入课程开发阶段。\n \n各地各单位组建课程组，聚智聚力、精心准备。\n众人拾柴火焰高。眉山市纪委监委、省纪委监委驻体育局纪检监察组等单位，由领导班子成员、主要负责同志牵头，抽调 “精兵强将”集智攻关。省纪委监委法规室等单位“以老带新”共同开发，给业务骨干和年轻干部交任务、压担子，人人能担任课程主讲人，把课程开发过程转化为培训骨干、培养师资的过程。\n \n各课程组采取集中研讨、试讲等方式打磨修改课程讲义。\n“村级监督既是一个实践问题，也是一个理论问题，更是一个关乎江山与人民的问题。”省纪委监委驻川师大纪检监察组副组长张晓宏介绍说，“我们充分发挥纪检监察学科建设优势，与院校专家、基层党政干部一道深入田间地头搞调研，先后调研村（社区）30余个，走访村组党员群众400余人次，收集整理相关资料40余万字，将课程写进乡土里，守正创新、不断精进。”\n雅安市纪委监委案件审理室干部向笛谈到， “为把课程讲深讲透，我们在准备阶段系统梳理市监委查办的258件职务犯罪案件，收集整理18件典型新型隐形受贿问题司法认定情况；形成讲义后，我们课题组又多次集中研讨、反复修改、组织试讲，回想起来历历在目。”\n据悉，各地各单位从选题、研题到起草、试讲，再到初审、复审、现场展示，历时 8个多月，先后近200人参与到课程开发当中，形成课程讲义共计120余万字。\n聚焦中心、突出实务\n纪检监察干部的核心业务能力需要从哪些维度提升？哪些问题长期以来没有讲深讲透？哪些新情况问题需要深入研究？哪些方面有比较成熟的经验可以提炼总结？ ……在“十佳精品纪检监察课程”评选工作筹划阶段，省纪委监委机关专题召开相关业务室参加的会商会，按照“当前最缺什么课程就重点开发什么课程”的思路，梳理形成涵盖信访工作、线索处置、日常监督、审查调查、追责问责、以案促改等纪检监察业务全链条的课题开发参考清单。\n一石激起千层浪。全省纪检监察系统以评选工作为牵引，聚焦纪检监察主责主业开发实务课程，开小口、挖深井，掀起了深度研学纪法、总结提炼经验的热潮，形成了一批质量较高的纪检监察课程。\n \n各课程组代表在现场展示评审环节介绍各自课程。\n“目前专案组运行管理上缺乏统一的规范和标准，开发‘如何带好专案组’这个课程，目的是把我们近几年实践中的一些心得体会做个总结，抛砖引玉，供大家参考。”在现场展示评审环节，自贡市纪委常委、市监委委员李波登台介绍课程开发的初衷。\n“笔录制作是一门实践性比较强的课程。对此，我们将整堂课分为课程导入、案例分析、课堂演练、成果展示、课程总结等5个部分，重点组织案例分析和课堂演练。”在现场展示评审环节，省纪委监委驻四川产业基金纪检监察组黄丽珠详细介绍了课程的教学方法。\n \n各课程组代表在现场展示评审环节介绍各自课程。\n“我们以粮食购销领域腐败问题专项整治有关工作为基础，总结开展专项整治的‘四加’工作法：多管齐下+联动研判、一把手紧盯+紧盯一把手……”在现场展示评审环节，省纪委监委第二纪检监察室宋文远介绍课程的特色亮点。\n7月5日，省纪委监委机关开展现场展示评审。29个进入复审的课程逐一登台亮相，围绕教学目标、教学内容及课程的实践性、创新性和特色亮点等作介绍。\n“这些课程规范性、实践性都比较强，亮点纷呈、特色各异，有不少独到的思考和精辟的提炼，让人印象深刻、深受启发。”担任现场主评委的省纪委常委肖克强在点评讲话中给予充分肯定。\n精心组织、公正公开\n据悉，此次是近年来全省纪检监察系统首次开展课程评选工作，包括选题发布、选题申报、选题审核、课程开发、书面初审、书面复审、现场展示等 7个主要环节。委领导亲自审定方案、高度重视，各级积极参与、广泛关注。\n \n省纪委监委周密组织、有序推进课程评审各环节工作。\n“课程评选专业性强，要广泛听取意见，注重借智借力，切忌闭门造车”。省纪委监委组织部、党风廉政建设研究教育中心认真贯彻委领导指示要求，坚持“开门搞评选”，多次采取召开会商会、点对点征询等方式，征求省纪委监委业务室、课题组、专家评委的意见建议，反复修订有关环节工作方案，凝聚最大“公约数”。\n2024年5月，评选工作进入专家评审环节，20名长期在纪检监察战线工作，实践和理论水平较高的室主任、纪检监察组组长、市（州）纪委副书记和专家学者组成评委会，围绕参评课程的实践性、规范性、创新性，先后开展初审、复审、现场展示等3轮评审。\n \n评委们实事求是、客观公正地开展课程评审工作。\n“初审环节采取‘分类盲评+小组会商’的方式进行，从64个参评课程中遴选29个进入复审。”省纪委监委组织部相关负责同志介绍，“复审采取入围课程拉通盲评的方式进行，得分按60%折算计入总分，现场展示得分按40%折算计入总分，最终按照得分高低确定获奖课程。\n \n评委们对 29个入围课程开展现场展示评审。\n评审工作始终坚持质量为先、优中选优，获奖作品质量过硬，受到广泛认可。\n“这次评选模式新颖、贴近实战、突出实用、注重实效，既是擂台比武、更是认知拓荒，既是创新之举、更是提能之需。我们将借他山之石而内自省，反求诸己而宜自修，不断提高纪检监察工作规范化、法治化、正规化水平。”广元市纪委副书记、市监委副主任夏国茂说。\n“通过这次评选既打造了一批优质课程，又储备一批优秀师资。”参加现场评审观摩的小平干部学院培训部负责人史志伟表示，“获奖课程既可以作为日常实操的教材，也可以作为授课辅导的参考模板，这对我们干部培训基地来讲很有意义。”\n课程评选的目的在于运用。据悉，省纪委监委计划采取编印讲义、录制视频、推荐授课等多种方式，加大获奖课程推送、运用的范围和力度，推动各地各单位结合纪检监察学科建设，进一步总结提炼实践经验，研发优质纪检监察课程，为纪检监察干部队伍建设聚智聚力。"
  },
  {
    "title": "2023首届“粤港澳工商管理案例工作坊及案例论坛”中山大学管理学院",
    "page_body": "改革开放以来，中国经济快速发展，涌现出众多优秀企业。作为改革开放前沿阵地的粤港澳大湾区，已经孕育了丰富的企业实践，急需案例学者进行深入研究和总结，以期为中国特色案例体系建设提供重要补充。\n依据国家印发的《粤港澳大湾区发展规划纲要》指导框架，2023首届“粤港澳工商管理案例工作坊及案例论坛”将于2023年11月23-26日在广州召开，由中山大学管理学院主办、陈瑞球亚太案例开发与研究中心联合专业学位办公室具体承办，加拿大毅伟商学院与中欧国际工商学院共同协办，中山大学工商管理案例研究学会提供会务支持。本次论坛的主题为“立足粤港澳大湾区，讲好中国管理案例故事”，进一步推动中国特色案例库建设和指导粤港澳大湾区工商管理案例的国际化发展。\n本次论坛立足于在全国新发展格局中占据重大战略地位的粤港澳地区，为杰出案例学者分享、案例国际化发展、案例教学与研究、优秀案例展示与讨论、及学界-业界共同探讨前沿理论和实践问题等提供高水平平台，论坛设置了形式多样的分享、交流和参访环节。同时，为了提高中国学者的案例撰写和教学能力，本次活动特邀加拿大毅伟商学院潘兆铭教授（科研与教学都获得前10%毅伟商学院教师奖项，所著案例获得2022-2023年毅伟IVEY出版社全球年度畅销榜单BEST SELLER第二名，多篇论文发表在UTD24顶刊，目前担任UTD24顶刊《生产与运营管理》（POM）的高级编辑），开设一天半的案例工作坊专场，促进案例学者之间的学习与深入探讨。\n一、会议日程\n2023年11月23日\n9:00-17:00\n参会人员注册报到\n19:00-21:00\n粤港澳工商管理案例联盟（筹备）专家委员会以及参会企业成员研讨\n2023年11月24日上午\n7:30-8:00\n论坛签到\n开幕式\n8:00-8:20\n嘉宾致辞：\n李善民 教授，中山大学原党委常委、副校长，现任中山大学经济与管理学部主任；\n王 萍 清华大学，全国MBA教育指导委员会秘书处办公室主任、中国学位与研究生教育学会工商管理工作委员会秘书长；\n钟一彪 党委书记，中山大学管理学院；\n张俊生 教授、副院长，中山大学管理学院\n8:20-8:25\n合影\n案例论坛嘉宾演讲\n8:25-9:10\n演讲嘉宾：王永贵 教授、校长（浙江工商大学）\n演讲主题：案例研究的问题与对策反思\n9:10-9:55\n演讲嘉宾：武常岐 教授、院长（山东大学管理学院） \n演讲主题：一带一路倡议和国际商务中的案例开发\n9:55-10:10\n演讲嘉宾：梁剑平 副教授、主任（中山大学管理学院陈瑞球亚太案例开发与研究中心）\n演讲主题：案例赋能工商管理学科发展-陈瑞球案例中心及粤港澳案例发展介绍\n10:10-10:15\n中场休息和茶歇\n案例论坛嘉宾演讲\n10:15-11:00\n演讲嘉宾：陈世敏 教授、主任（中欧国际工商学院案例中心）\n演讲主题：高质量教学案例的开发：描述与决策型案例\n11:00-11:45\n演讲嘉宾：许晖 教授、主任 （南开大学商学院服务管理研究中心）\n演讲主题：管理案例探索与应用的融合创新模式\n11:45-12:30\n演讲嘉宾：方钰麟 教授、研究所负责人（香港大学数字经济与创新研究所）\n演讲主题：解读电子市场卖家运用平台功能对绩效的影响：基于构型视角\n12:30-14:30\n午餐\n2023年11月24日下午\nIvey Case Workshop\n（毅伟商学院官方认证和授权，中文讲授）\n14:30-17:30\nIvey Case Workshop 毅伟案例工作坊\nProfessor Hubert Pun 潘兆铭教授，加拿大毅伟商学院\n17:30-19:30\n晚餐\n2023年11月24日晚上\n圆桌论坛\n19:30-21:10\n分享环节：新型案例探讨\n分享嘉宾 （按姓氏拼音排序）：\n●陈万思 教授、主任，华东理工大学商学院行为学习案例中心\n分享主题：行动学习+案例：培养知行合一管理者；\n●何波 教授、主任，西南科技大学经管学院案例中心\n分享主题：备以应变——视频案例开发的时与势；\n●刘耿 研究员，中欧国际工商学院案例中心\n分享主题：以简驭繁：一个小型模拟案例开发的心得；\n●赵子倩 研究员、主任，清华大学案例中心\n分享主题：视频案例赏析与经验分享；\n●朱国玮 教授、主任，湖南大学工商管理学院管理案例研究与教学服务中心\n分享主题：ChatGPT与管理案例教学创新\n21:10-21:30\n 互动与问答\n2023年11月25日上午\nIvey Case Workshop\n（毅伟商学院官方认证和授权，中文讲授）\n7:30-8:00\n论坛签到\n8:30-12:30\nIvey Case Workshop 毅伟案例工作坊\nProfessor Hubert Pun 潘兆铭教授，加拿大毅伟商学院\n12:30-14:30\n 午餐\n2023年11月25日下午\nIvey Case Workshop\n（毅伟商学院官方认证和授权，中文讲授）\n14:30-17:30\nIvey Case Workshop 毅伟案例工作坊\nProfessor Hubert Pun 潘兆铭教授，加拿大毅伟商学院\n17:30-19:30\n晚餐\n2023年11月25日晚上\n圆桌论坛\n19:30-21:10\n分享环节：新型案例探讨\n分享嘉宾（按姓氏拼音排序）：\n●刘素 教授、主任，山东财经大学工商管理学院管理案例中心\n分享主题：撰写“又红又专”案例的思考；\n●宋结焱 教授、主任，兰州交通大学经济管理学院农村电商案例研究中心\n分享主题：微案例在农村电商培训中的应用；\n●王崇锋 教授、主任，青岛大学商学院管理案例研究中心\n分享主题：年年有风，风吹年年: 微案例开发反思与探索；\n●徐京悦 教授、主任，中国人民大学商学院案例中心\n分享主题：返璞归真：粗案例的开发与应用；\n●张春依 助理主任，复旦大学管理学院案例中心\n分享主题：科创背景下以终为始的案例开发实践——以复旦大学管理学院案例库平台为例\n21:10-21:30\n互动与问答\n2023年11月26日上午\n7:30-8:00\n论坛签到\n案例论坛嘉宾演讲\n8:00-8:45\n演讲嘉宾：白长虹 教授、院长（南开大学，《南开管理评论》主编）\n演讲主题：幸福企业案例研究\n8:45-9:30\n演讲嘉宾：王淑娟 教授、副主任（大连理工大学中国管理案例共享中心）\n演讲主题：发挥共享优势 推动工商管理案例开发与教学\n9:30-9:55\n演讲嘉宾：苏小恩（AMY SO）教授、助理院长（澳门大学工商管理学院）\n演讲主题：探索商业案例的挑战：澳门的实践与启示\n9:55-10:10\n合影，中场休息和茶歇\n案例论坛嘉宾演讲\n10:10-10:55\n演讲嘉宾：陈玥 教授（澳门科技大学商学院，2022/2023学年“杰出教师”奖）\n演讲主题：案例教学在商学院“沉浸式教学模式”中的整合应用\n10:55-11:40\n演讲嘉宾：卫田 教授、副系主任（复旦大学管理学院企业管理系，Asian Case Research Journal主编）\n演讲主题：案例教学的“入境”与“出境”\n圆桌论坛\n11:40-12:25\n分享环节：高校与企业如何协同赋能案例建设\n分享嘉宾（按姓氏拼音排序）：\n●梁剑平 教授、主任，中山大学管理学院陈瑞球亚太案例开发与研究中心\n分享主题：案例赋能工商管理学科发展—产学协同，案例育人；\n●许雷平 助理主任，中欧国际工商学院案例中心\n分享主题：案例赋能企业，识知激发活力；\n●赵丽缦 案例研究员，中欧国际工商学院案例中心\n分享主题：教学案例开发对案例企业的价值何在？——以深圳四家社会企业案例为例\n12:25-12:35\n 互动与问答\n12:35-12:40\n 闭幕式\n嘉宾致辞：中山大学管理学院李炜文副院长\n12:40-13:50\n 午餐\n2023年11月26日下午\n13:50-14:00\n 企业参访集合，统一安排车辆前往\n14:30-17:30\n参访企业：广药集团\n二 、论坛费用\n早鸟优惠\n（2023年10月31日前）\n线下参会：\n4500元人民币\n线上参会：\n1000元人民币\n常规申请\n（2023年10月31日后，11月10日截止报名）\n线下参会：\n5000元人民币\n线上参会：\n1200元人民币\n本次论坛规模为线下参会80-100人，线上参会200-280人，先报先得，额满即止。欢迎高校教师、学生、企事业单位等各界人士参加。\n注：\n1. 线下参会人员会务费包含毅伟案例工作坊、案例论坛、圆桌论坛、企业参访以及论坛资料费、餐费、企业参访期间的交通费和保险费等，并且可提交一篇案例初稿，组委会安排案例评审，优秀案例可推荐中山大学管理学院（入库奖金税前1万元）、毅伟商学院、中欧商学院等案例中心入库，以及Asian Case Research Journal等发表；参会人员赴广州参会的城市交通费和住宿费自理。线下参会人员可获得线上播放案例论坛和圆桌论坛的链接。\n2. 线上参会人员仅可线上参加案例论坛和圆桌论坛，不包括毅伟案例工作坊、案例评审、企业参访以及用餐等。\n三、缴费 温馨提示：\n1.请截图保存好缴费成功记录，并扫描下方二维码填写参会人员信息；\n2.除不可抗力因素外，费用一经缴纳不予退还，请务必确认参会后缴纳费用，并准确填写开票信息。 发票一经开出不得修改。\n缴纳会议费请点击链接 （建议采取个人缴费方式） ：\nhttps://pay.sysu.edu.cn/app/#/qrcode-pay?range=5351&project=177\n或者扫描如下二维码：\n对公汇款缴费：\n单位通对公汇款方式缴纳会议费，需要在汇款附言写清楚：参会人姓名+单位+会议名称，汇款账户信息如下。\n户名：中山大学\n开户行：中国建设银行广州中山大学支行\n银行账号：44050143004609000001\n联行号：105581010072\n汇款人将以下信息发给会务组，请准确填写， 发票一经开出不作修改 ：\n姓名：\n汇款日期：\n汇款单位：\n汇款金额：\n接收发票的邮箱：\n发票抬头：\n纳税人识别号：\n（若发票还需开具其它内容，可补充填写）\n缴费成功后，请扫描如下二维码填报参会人员信息登记表，以便会务组提前做好相关安排。感谢支持！\n会务组联系咨询方式：\n联系人：程江慧老师\n联系电话：020-84112612\n电子邮箱：casecenter_sysbs@163.com\n四、出席嘉宾名单（按日程先后排序）\n致辞嘉宾\n致辞嘉宾：李善民 中山大学管理学院\n个人简介： 中山大学原党委常委、副校长，现任中山大学经济与管理学部主任、岭南学院院长、教授、博士生导师。主要教学与研究领域为公司金融、科技金融。主编出版《创新理论指导与中国企业管理实践案例精选》，经济科学出版社。\n致辞 嘉宾 ：王萍  清华大学\n个人简介： 全国MBA教育指导委员会秘书处办公室主任，中国学位与研究生教育学会工商管理工作委员会秘书长。\n致辞嘉宾：钟一彪  中山大学管理学院\n个人简介： 中山大学管理学院党委书记，法学博士，研究员。主持教育部人文社科项目等课题10多项，出版著作6部，发表论文40多篇，获评广东省教育系统优秀党务工作者、广东省教育教学成果特等奖等省级以上奖项10余次。\n致辞嘉宾：张俊生  中山大学管理学院\n个人简介： 中山大学管理学院教授、博士生导师，副院长。担任全国会计专业研究生教育指导委员会委员、China Journal of Accounting Research 主编，系财政部全国会计领军人才（学术类）。\n致辞"
  },
  {
    "title": "强推！大模型学习书籍合集推荐|（含PDF地址）最近整理了一批关于大语言模型（LLM）Transformer、BER-掘金",
    "page_body": "最近整理了一批关于大语言模型（LLM）、Transformer、BERT、ChatGPT 等方向的学习资料，涵盖了入门、实战、工具链、理论等多个维度， 非常适合初学者和进阶者收藏阅读     \n      《BERT基础读径：Transformer大模型实战》  深入介绍 BERT 的基本原理及其在 NLP 任务中的实际应用，适合想系统了解 Transformer 架构的朋友。\n      Build a Large Language Model (From Scratch) — Sebastian Raschka Sebastian 老师 2024 年的新书，手把手教你如何从零实现一个大语言模型，理论 + 实战兼备，英文原版但极具价值。\n      HuggingFace自然语言处理详解：基于BERT中文模型的任务实战 基于 HuggingFace 工具链，结合中文任务讲解，适合希望用开源工具快速落地模型的开发者。\n      LLM Cookbook：正在悄悄风靡全球的大模型开发宝典！  从 Prompt 工程到模型微调，涵盖了工程实践技巧，是从业者值得收藏的“开发食谱”。\n      LangChain 入门指南 专为构建 LLM 应用设计的框架介绍，实战性强，适合做问答、搜索、代理等场景。\n      《TensorFlow机器学习实战指南》  老牌深度学习框架 TensorFlow 的实战教材，适合对底层实现感兴趣的技术人员。\n      《动手做AI agent》  面向初学者的智能体入门，轻松有趣，帮助你从「零」构建一个 AI Agent！\n      《自然语言处理：大模型理论与实战（预览版）》  从语言建模到预训练技术，兼顾原理与应用，适合研究生或希望深入 NLP 理论的读者。\n      《大模型应用开发入门：基于 GPT-4 和 ChatGPT_2024》  聚焦 ChatGPT 实战落地，包括问答系统、知识库接入、SaaS 场景，实用性极强。\n      《大模型时代：ChatGPT开启通用人工智能浪潮》  从产业视角解析 AGI 的演进，适合管理层、产品经理及 AI 热衷者快速了解趋势。\n      《大语言模型综述》  梳理当前主流大语言模型结构、训练策略和挑战，是理解大模型技术路线的重要资料。\n      《面向开发者的 LLM 入门课》  语言模型落地项目手册，讲解如何开发和部署轻量级 LLM 应用。\n      《大模型导读：基于GPT-3、ChatGPT、GPT-4等 Transformer 架构的自然语言处理》  一本大模型时代的“说明书”，适合泛读，帮助你快速搭建知识框架。\n      《西瓜书》周志华-机器学习 经典机器学习教材，为理解深度学习与大模型奠定理论基础，强烈推荐！\n建议阅读顺序  新手可从《LLM入门课》《动手做agent》开始 进阶读者推荐《LangChain 入门》《HuggingFace实战》《大模型应用开发入门》 想深入研究理论的同学可阅读《大语言模型综述》《自然语言处理：理论与实战》\n更多AI大模型书籍+开发学习视频籽料， 都在这>> Github <<"
  },
  {
    "title": "突破作业管理 让学习兴趣盎然-北京考试报",
    "page_body": "北京市东城区灯市口小学校长　滕亚杰\n　　“双减”政策出台之后，学校深知“双减”工作事关学生健康成长，事关人民群众切身利益，要努力把“双减”工作抓紧抓好，全面贯彻党的教育方针，落实立德树人根本任务，促进学生全面发展和健康成长。\n　　在推动“双减”政策落地的实践过程中，灯市口小学的思路和实施路径是“一个宗旨”“两个优化”“三个突破”和“万事归一”。\n　　“一个宗旨”，即“双减”工作是新一轮改革，是要构建、完善“五育并举”的高质量育人体系。\n　　“两个优化”，即优化课程体系，优化课堂结构和模式。\n　　“三个突破”，即突破作业管理、突破课后服务、突破家校社协同育人。\n　　“万事归一”，即提升教师队伍质量，才能真正解决“双减”政策落地。\n　　在突破作业管理上，学校严格按照“双减”政策要求，在课堂上解决一部分作业后，一、二年级就没有课后书面作业，高年级则更趋向于综合性作业，逐步探索出作业管理的“四步走”路线。\n　　一是设计分层作业，让作业有梯度可选择。如高年级数学课作业包括“基础练习”“综合运用”“拓展探究”三个层面。教师根据学情给出建议，适时引导，鼓励孩子挑战更高层面的作业。 \n　　二是设计融合性作业，体现多学科联动。如科学作业，尝试“生活中的科技”主题作业，各年级学生根据所学知识，围绕“科技与健康”“科技与安全”“科技与环保”“科技与植物”“科技与天气”等主题进行探究式作业。以班级为单位，以小组活动为形式，通过教师课上讲解、查阅网络和图书馆资料、咨询专业人员等方式，自选小主题再进行深度探究，利用“画一画、做一做、说一说、写一写、拍一拍”等方式将探究作业成果呈现出来，交流展示。\n　　三是设计实践类作业，突出实践性与探究性。这样学生可在真实情境中体验、探究，解决问题、获得真知。如植物栽培主题综合实践作业覆盖一至六年级。学生在教师指导下种植花卉和蔬菜，从播种开始，用图文的方式记录植物的生长过程。不是所有孩子都有成功的经验。六年级学生小苏就说这次种植经历非常难忘。他精心呵护小苗，但有一天下大雨，小苗被雨水砸坏了。他非常懊恼，但也懂得了每个小生命的成长都不容易，要更细心、更用心，留意每个细节。这对于学生而言不仅是一次劳动作业，也是一次生命教育。\n　　再如，学生参与中国美术馆“为新时代人物塑像”作品巡展的讲解员活动，也是美术实践作业的一部分。学生需要提前做大量准备，包括前期调研、搜集资料、撰写文本。这不仅是对学生的爱国主义教育、榜样教育，也锻炼了学生的语言表达、人际交往等综合实践能力。2021年，学校有31名学生获得“中国美术馆小志愿者”荣誉证书，10名学生成为“优秀小志愿者”，31名学生被聘为2022年“中国美术馆在册小志愿者”。这也激励学生继续开展实践类作业，在实践中学习和收获。\n　　四是开展“无作业日”，让学生学会自主管理。学校将每周二定为学生自主日，学校和家长都不留作业，由学生自己制订计划，自主安排。学生的积极性高涨。有给自己留作业的，例如练琴、跳绳、阅读、写日记等，还有做家务、为家人做顿饭的。自主日的灵活性，给学生留下空间，充分调动了其学习积极性和创造力。 \n　　“双减”政策的推出是让学生学得更有兴趣，在轻松活泼的学习氛围中学得更好、学得更多，最终是为了提高育人质量，培养国家的建设者，多出人才，出好人才。\n　　“双减”政策实施以来学校得到很多家长的反馈。有的家长说：“这学期实施‘双减’政策之后，孩子基本能在学校完成作业。尤其是分层作业的设计，让孩子写作业的压力减轻了，兴趣提高了。”还有的家长说：“‘双减’政策是一份‘时代的礼物’，学校老师就是这份礼物的‘派送员’。借助‘双减’政策的东风，家校可以携手帮助孩子养成良好的学习习惯和自我管理能力，让孩子走得更高、更远。”"
  },
  {
    "title": "清华大学 张卫强-中文主页-利用BERT提高语种识别性能",
    "page_body": "本文介绍清华大学语音与音频技术实验室（SATLab）ISCSLP 2022录用论文以及后续IJALP期刊扩展版论文。这篇论文将BERT模型引入到语种识别领域，利用BERT模型的优越性，再结合下游不同的神经网络模型，提升语种识别能力，尤其是在短语音的情况下识别性能有更为明显提升。\nY. Nie, J. Zhao, W.-Q. Zhang, and J. Bai, “BERT-LID: Leveraging BERT to improve spoken language identification,” in  Proc. ISCSLP , 2022, pp. 384–388.  doi: 10.1109/ISCSLP57327.2022.10038152 .\nY. Nie, J. Zhao, Z. Qiu, J. Bai, and W.-Q. Zhang, “Leveraging BERT to Improve Spoken Language Identification of Code-Switching Speech,”  International Journal of Asian Language Processing , vol. 34, Art. no. 2450003, 2024.  doi: 10.1142/S2717554524500036 .\n语种识别\n语种识别是分析处理语音片段以判断其所属的语种。它对智能语音系统中的多语言模块有着深远的影响。目前语种识别技术在中长语音（>3s）上能够实现较高的准确率，但是在短语音（<=1s）上的表现并不能令人满意。由于短语音提供的数据信息较少，因此大大增加了识别难度。\n我们尝试将在自然语言处理中表现甚好的BERT模型应用到语种识别任务中，旨在提升短语音情况下语种识别模型的性能。\nBERT-LID\nBERT的全称是：Bidirectional Encoder Representation from Transformers。该模型通过大规模无标注文本语料训练，获得包含丰富语义信息的表征，BERT具有强大的语义理解能力，是近年来自然语言处理领域公认的里程碑模型。\nBERT示意图（Devlin 2018）\n原始的BERT旨在处理基于文本的表示，而我们这里的输入是语音，因此需要对输入语音进行预处理以适应该模型。\n方法一：提取语音的音素，作为BERT模型的输入。\n方法二：提取语音的后验概率特征，替换原始的Token Embedding结果，作为输入。\n我们通过对整体网络进行训练以获得最佳BERT-LID模型。\n将调整过后的BERT接不同的分类网络模型进行学习\n实验及结论\n我们使用OLR20、TAL_ASR、TIMIT和THCHS30数据集来对BERT模型进行训练。对于音频数据我们使用BUT的开源代码来获得音素序列以及音素后验概率特征。\n其中OLR20来自于2020年东方语种识别竞赛所提供的数据，包含6个语种；TAL_ASR为好未来英语课授课音频，每条音频只有一位说话人，包含中英文混合讲话的情况（对于这种情况，我们使用强制对齐的方法来获得中文与英文的标签信息）；TIMIT为英文数据集；THCHS30为中文数据集。同时我们还对数据进行切分处理来获得时长为1s的短语音数据。数据集的具体情况如下图所示，其中T&T为TIMIT和THCHS30的切分短语音混合使用的情况。\n数据集\n下游神经网络模块，我们选择使用CNN、LSTM、RCNN、DPCNN分别进行实验。首先我们在OLR20和T&T数据上对BERT-LID模型进行测试，然后进行消融实验：a）BERT部分结合线性分类层来得到结果（称之为BERT）；b）去掉BERT模块（称之为LID），直接将数据输入到对应的模型中来得到结果。可以看出，相比于BERT以及LID模块，BERT-LID模型在语种识别任务中准确率整体上有所提升。\n在OLR20和T&T数据集上进行消融实验\n之后，我们在BERT-RCNN、x-vextor、n-gram-svm模型上进行对比实验（TAL_ASR和T&T数据集为短音频数据的集合），其中x-vextor、n-gram-svm为我们的基线系统。可以看出，BERT-LID模型在我们的不同数据集中都能有最优表现，尤其是在短语音情况下，我们所提出的方法有更为明显的提升。\n在不同数据集上进行对比试验"
  },
  {
    "title": "科技论文的学习心得-豆丁网",
    "page_body": "科技论文写作学习心得 软件11C2徐亚群 摘要： 本文结合科技论文写作课程的内容，浅谈了科技论文的学习心得，提高大学生科技论文写作能力的方法以及应考虑投稿的因素，科技论文如何投稿，在以后的科技写作中能够掌握写作规范，提高写作能力，培养创新能力。 关键词： 科技论文特点；学术性；理论性；规范性；学术道德；科技论文投稿； 1引言 科技论文是报道自然科学研究和技术开发创新性工作成果的论说文章,是阐述原始研究结果并公开发表的书面报告。科技论文是以科技新成果为对象，采用科技语言、科学逻辑思维方式，并按照一定的写作格式撰写,经过正规严格的审查后公开发表的论文。写科技论文的目的是报告自己的研究成果，说明自己对某一问题的观点和看法，接受同行的评议和审查，以图在讨论和争论中渐进真理。理解科技论文的定义，有利于科技论文的写作和发表。 科技论文写作的课程内容包括科技论文写作的目的、意义、特点、写作方法以及科技论文需要遵循的各种标准、规范、语言习惯等。该课程是研究生教学的重要组成部分，很多高校已将其列入必修课程，并不断地进行改革，以加强对研究生的培养。课程采用课堂讲授、专家讲座、分析讨论、写作实践等多种方式使研究生掌握科技论文写作的内涵与写作方法，提高科技写作能力，顺利进行科学研究，对学生生的成长发挥着重要的作用。 2科技论文特点 2.1创新性 (1)理论型科技论文是新的科学研究成果或创新见解和知识的科学记录。技术型科技论文是已知原理应用于实际中取得新进展的科学总结。也就是说没有新的观点、见解、结果和结论，就不成其为科技论文。科技论文是科学和技术进步的科学记录和历史性文件，没有新意的论文又怎能体现科技的发展。 (2)创新性是科技论文同其它科技文章的基本区别。如科技报告和综述等具备科学性、学术性等特点，但可不具备创新性特点。创新性或新意是写作与发表每篇科技论文必备的条件，但只有创新性或新意还不够。 (3)科技论文都应是“新”的，但其创新程度有大小之分。“首次提出”等词一般是指具有重大价值的研究成果。 (4)科技论文是报道自己的新研究成果，与他人相重复的研究，基础性知识，具体过程或数学推导，给出参考文献或作简要交代就够。科技论文的写法应避免与教科书、实验报告写法等同. 2.2科学性和准确性 (1)科学性是科技论文同一般议论文以及一切非科技文体的基本区别。科学性主要包括两方面：一方面是指科技论文的内容是科学技术研究的成果。另一方面是指科技论文表达形式的科学性和实事求是的科学精神，即科技论文的结构严谨、思维符合逻辑规律、材料真实、方法准确可靠、观点正确无误。准确性主要是指科技论文的实验过程、实验结果具有可重复性。科技论文中不要用“据估计、据统计、据报道、据观察”等词。 2.3学术性或理论性 科技论文的学术性即理论性。学术性是科技论文同其他科技文章的基本区别。所谓学术是指系统和专门的学问，是指有较深厚的实践基础和一定的理论体系的知识。科技论文学术性是指一篇科技论文应具备一定的学术价值（理论价值）。一篇科技论文的学术价值一般包括两个方面：1.对实验、观察或用其他方式所得到的结果，要从一定的理论高度进行分析和总结，形成一定的科学见解，包括提出并解决一些有科学价值的问题；2.对自己提出的科学见解或问题，要用事实和理论进行符合逻辑的论证与分析或说明，要将实践上升为理论。2.4规范性 科技论文必须按一定格式和要求进行规范写作。如科技论文的参考文献著录应规范，文字表达应规范，语言和技术细节应采用国际或本国法定的名词术语、数字、符号、计量单位等。科技论文要求准确、简明、通顺、条理清楚。 3构建学术道德 当前，研究生学术失范和学术不端行为屡见不鲜，如编造、篡改实验数据，抄袭剽窃他人成果等。这些行为不仅有害于研究生个人的成长，而且是对科研事业的亵渎，造成了极其恶劣的影响。科技论文写作中，要注重培养学术道德。提高对学术道德和基本学术规范的认知能力。科技学术论文，顾名思义，首先是从科学性出发，保证论文写作的真实性，不得带有个人的好恶和偏见，更不得主观臆断，必须切实地从客观实际出发，杜绝在写作过程中的伪造，篡改数据等弄虚作假的行为。其次，要从创造性出发，保证写作的独创性，强调学术论文要突出自己的工作和见解，有创造性 4提高大学生科技论文写作能力的方法 科技论文的写作过程是创造性思维深化的继续，是进行思维训练和素质教育的最佳载体。大学生科技论文写作水平的高低反映了大学生对客观事物本质的把握能力，以及对问题进行辩证分析和客观预见的能力。培养大学生科技论文的写作能力，需要从大学生思想、文化、专业、心理素质等方面进行教育。 （1）编写具有针对性的教材。大学生科技论文写作课，首先应编写具有针对性的教学教材，科学设置写作教学模块，对大学生的写作理论、素养和能力进行系统培训，并正确定位大学写作教学与社会岗位的关系，以专业能力和职业要求来归类设置写作教学课程模块，系统培养大学生的写作综合能力。我校目前有一些专业已经开设了科技论文的选修课，有些课程也包含一些科技论文写作的基础知识，但目前仍存在对科技论文写作课重视不够、师资力量不足、课程结构不合理、与学生专业相脱节等问题。在写作教学中，应淡化学科性，突出专业指导性和未来职业针对性。 （2）制定切实可行的措施，保证论文写作的质量。大学生科技论文写作主要在课程设计和毕业设计两个教学环节，从各院系主管教学的领导、导师到教学秘书都应高度重视科技论文写作，把对论文写作质量的管理当做一项工程来抓，强化监督机制，制定有效的措施，保证这两个教学环节的有序进行。对由于自主择业等问题造成的负面影响，指导教师应该加强管理和督促，使学生从思想和行动上切实重视科技论文的写作。 （3）导师制在提高大学生科技论文写作水平中具有重要作用。在高校连年扩招的影响下，目前高校普遍面临着师生比偏低的严峻情况，很多学校被迫采取大班授课的教育模式。使得学生参加科学研究的机会更少，因此很多学校逐渐开始实施导师制。学生在导师指导下有步骤地进行科学研究，导师可以全面、深入地了解学生的个性和特长，因人而异地制定其学习计划，鼓励和引导学生参加科研活动，使学生在实践过程中，结合所学知识，多进行科技论文写作的实践，从而不断提高科研创新能力。大学生导师制是提高大学生科技论文写作能力的有效探索 5科技论文投稿应考虑的因素 论文定稿后,面临如何选择投稿目标刊。选择原则是根据自己论文水平，在争取发表的同时，获得最大的投稿价值。所谓投稿价值是指论文发表所产生影响的总和。最高的投稿价值可概括为：论文能够以的最快速度发表在能发表的最高级刊物上；并能最大限度地为需要的读者所检索到或看到；能在最大的时空内交流传递。它是投稿追求的最高目标。了解科技论文投稿应考虑的一些因素，并利用目标刊的征稿启事或作者须知，通过浏览目标刊近期已发表论文的目录和内容等获得目标刊的动态和变化情况，有利于选择投稿期刊。 6科技论文投稿 科技论文是科研成果的具体体现,是作者心血的凝结。论文完成写作后,一般都希望及时在相关专业刊物上发表，要提高论文投稿的命中率也有一定的技巧。 （1） 了解所投刊物，了解刊物的性质、宗旨和类别，一个刊物的性质和办刊宗旨可以从以下几方面去了解:一是看刊名。二是看栏目设置。三是研读刊物。这是进一步了解刊物的最好办法。通过研读刊物,能了解刊物的出版周期,是否为核心期刊或统计源期刊,是纯学术期刊、综合性期刊还是科普信息类期刊,了解刊物的特点、特色,以及刊物的作者群和读者对象等。 （2） 关注刊物的年度报道计划和重点　许多刊物在每年年初,会在刊物的适当位置公布当年的报道计划和重点,这是刊物提供给作者的重要信息。只要在该刊的报道计划之内,投稿命中率一般较高,有的论文虽然创新点不多,但因为在刊物报道重点范围之内,编辑部也会在第一时间内优先录用。 （3） 熟悉刊物的“投稿须知”　由于刊物性质、宗旨、类别、特点等的不同,每一份刊物对稿件都有自己独特的要求,包括写作格式、注意事项等,这些要求在“投稿须知”中一般都较为详细地作了规定。熟悉刊物的“投稿须知”,写作时注意与刊物的要求相一致,会大大减少论文退修的概率,缩短论文的录用时间,对提高投稿命中率也有很大的作用。 （4） 及时了解编辑部对稿件的处理进度　每个编辑部都有一套相对固定的稿件处理流程,整个流程有许多环节。有的环节作者不需要了解,但有些环节作者如能了解一二,对于自己的论文何时投寄、何时会有录用意见、何时能出版,能做到心中有数。 （5） 听取编辑对不采用稿件的具体意见。因为论文不被采用的原因很多,大致有:一是专家从思想性、科学性、真实性、实用性等方面审阅后认为不能采用;二是别的刊物已经发表了类似的或更好的论文;三是论文不在刊物的征稿、用稿范围之内;四是由于写作方面的原因不被采用;五是因保密原因不被采用;六是可能编辑部的来稿太多,以“优中选优”的原则筛选淘汰掉的。建议:当论文不被采用时,通过刊物编辑,了解不被采用的具体原因,听取编辑对论文修改的意见和建议,作适当修改后,再投往该刊或者其他刊物。 7结束语 本科技论文是在我的导师的亲切关怀和悉心指导下完成的。他严肃的科学态度，严谨的治学精神，精益求精的工作作风，深深地感染和激励着我。从课题的选择到项目的最终完成，老师都始终给予我细心的指导和不懈的支持。指导我掌握科技论文写作的基本原则及常用方法,加深了我对科技论文写作的认识，同时,也建立起严谨求实,实事求是的科学态度。为我以后的论文创新提供基础。 参考文献 [1] 高明。研究生作者群的形成与科技写作课的设置[J]。沈阳师范大学学报（自然科学版），2006,24(2):238-240。 [2] 王雯姝,杜晶波.当前大学生学术道德缺失现象分析及引导[J].清华大学教育研究.究.2006,27(3):83-89。 [3] 刘庆文.研究生——科技期刊值得关注的作者群[J]。编辑学报，2004，16（1）54-55. [4] 杨继成，陈艳春.研究生论文写作教学改革探索[J]。教学研究，2006, 29（5）：400-403。 [5]郑重,郑忠梅.论研究生学术道德的失范与规范[J].北京理工大学学报(社会科学版) 2006,8(3):115-117。"
  },
  {
    "title": "利用AI大模型优化论文结构、提升写作效率与质量的方法-百家号",
    "page_body": "利用AI大模型优化论文结构、提升写作效率与质量，已成为现代学术写作的重要趋势。通过合理设计提示词（Prompt）、结合多阶段协作流程，并利用AI的逻辑分析、语言生成与知识整合能力，可显著降低写作门槛，同时保证学术严谨性。以下是具体方法与工具推荐：\n一、优化论文结构：从框架设计到逻辑强化\n1.  智能生成论文大纲\n方法 ：输入研究主题、核心问题及目标期刊要求，AI可快速生成符合学术规范的章节框架。例如：\nPrompt示例 ：“请为‘AI在气候变化预测中的应用’撰写论文大纲，要求包含引言、文献综述（分技术路线与数据源）、方法（对比LSTM与Transformer模型）、实验（使用CMIP6数据集）、结果、讨论与结论，并标注每部分字数建议。”\n工具 ：ChatGPT、Claude、Notion AI（支持大纲导出为Markdown）。\n优势 ：避免传统写作中“先写后调”的低效循环，确保结构逻辑自洽。\n2.  逻辑漏洞检测与修正\n方法 ：将论文各章节内容输入AI，要求其分析论证链条的完整性。例如：\nPrompt示例 ：“请检查以下段落是否存在逻辑跳跃：‘AI模型在短期气候预测中表现优异（引用文献A），但长期预测仍需改进（引用文献B）。因此，本研究提出一种混合模型。’需补充：短期与长期预测的关联性分析、混合模型如何解决长期预测问题。”\n工具 ：Elicit（学术逻辑检查）、Grammarly（语法与连贯性分析）。\n案例 ：某研究者通过AI反馈，发现“方法章节”未说明模型参数选择依据，补充后显著提升论文可信度。\n3.  跨学科结构适配\n方法 ：针对不同学科（如人文社科与自然科学）的写作规范，AI可调整章节权重。例如：\nPrompt示例 ：“将以下社会学论文大纲转换为符合APA格式的版本，重点强化‘理论框架’章节，弱化‘实验方法’描述。”\n工具 ：SciSpace（学科模板库）、Typeset（期刊格式自动适配）。\n二、提升写作效率：从素材整合到初稿生成\n1.  自动化文献综述\n方法 ：上传文献包或输入关键词，AI可提取核心观点并生成对比表格。例如：\nPrompt示例 ：“分析以下5篇关于‘AI医疗诊断’的论文，按研究方法（深度学习/传统机器学习）、数据集规模、准确率生成对比表，并标注结论冲突点。”\n工具 ：ResearchRabbit（文献关系图谱）、PaperQA（交互式文献问答）。\n效率提升 ：传统综述需2周，AI辅助可缩短至3天，且避免人工遗漏关键文献。\n2.  段落级内容生成\n方法 ：分步骤输入写作指令，AI逐段输出内容并优化。例如：\n步骤1（背景引入） ：“用3句话解释‘气候模型中的参数不确定性’，引用IPCC报告（2023）。”\n步骤2（方法描述） ：“将以下实验步骤转化为被动语态学术文本：‘我们用Python训练了ResNet模型，输入为卫星图像，输出为温度预测值。’”\n工具 ：Jenni AI（段落生成与改写）、Wordtune（语言风格调整）。\n3.  多语言写作支持\n方法 ：AI可实现中英文论文的互译与本地化修改。例如：\nPrompt示例 ：“将以下中文摘要翻译为英文，并调整句式符合Nature期刊风格：‘本研究提出一种基于Transformer的洪水预测模型，在珠江流域的测试中，F1分数提升15%。’”\n工具 ：DeepL Write（学术翻译）、ChatGPT（风格适配）。\n三、提升写作质量：从语言润色到学术规范\n1.  精准化语言润色\n方法 ：AI可识别冗余表达、学术化用词及句式多样性问题。例如：\nPrompt示例 ：“润色以下句子，使其更符合学术写作规范：‘The AI thing worked pretty well in our tests.’参考修改：‘The proposed AI model demonstrated robust performance in empirical evaluations.’”\n工具 ：QuillBot（同义词替换）、Academic Phrasebank（学术短语库）。\n2.  学术规范检查\n方法 ：AI可检测引用格式、术语一致性及伦理声明缺失问题。例如：\nPrompt示例 ：“检查以下段落是否符合APA格式：（输入段落含未标注引用的数据）需补充：在‘85%的准确率’后添加（Smith et al., 2022）。”\n工具 ：Zotero（引用管理）、Turnitin（查重与格式校验）。\n3.  图表与文本协同优化\n方法 ：AI可生成图表描述文本或根据文本建议图表类型。例如：\nPrompt示例 ：“为以下折线图撰写图注，需包含变量定义、趋势描述及统计显著性：（上传图表显示‘模型准确率随训练轮次变化’）”\n工具 ：DataChant（图表文本生成）、Canva（学术图表设计）。\n四、实践案例：AI辅助完成一篇计算机科学论文\n1.  阶段1：大纲与文献准备（2小时）\n使用ChatGPT生成大纲，并通过ResearchRabbit筛选20篇高引用文献。\nAI输出：5章结构（含子章节标题）+ 文献对比表。\n2.  阶段2：方法与实验写作（5小时）\n输入实验代码与结果数据，AI生成方法描述（含伪代码）及结果分析段落。\n手动补充：模型训练的硬件配置、超参数调优过程。\n3.  阶段3：讨论与润色（3小时）\nAI检测逻辑漏洞（如未对比基线模型），并生成改进建议。\n使用QuillBot润色全文，调整句式多样性。\n4.  成果 ：\n传统需2周的论文，AI辅助下完成初稿仅用10小时，且首次投稿即被接收（修改意见仅涉及格式微调）。\n五、挑战与应对策略\n数据偏差风险\n问题 ：AI可能生成错误引用或过时观点。\n应对 ：要求AI标注信息来源，并手动验证关键文献。\n过度依赖问题\n问题 ：研究者可能丧失批判性思维。\n应对 ：将AI定位为“协作工具”，而非“决策者”，重点审核其输出合理性。\n学科适配性\n问题 ：AI对小众领域（如冷门历史学）支持不足。\n应对 ：结合领域专用数据库（如JSTOR）训练微调模型。\n六、未来趋势：从辅助写作到智能学术生态\n随着GPT-5、Gemini等模型的演进，AI将实现：\n实时协作 ：与研究者对话式修改论文，如“请将这段改写为更简洁的版本，同时保留技术细节”。\n全流程管理 ：从选题到投稿的端到端支持，包括自动匹配目标期刊、生成回复审稿人信函。\n伦理合规性 ：内置学术诚信检测，防止AI生成内容的滥用。\n通过合理应用AI大模型，研究者可聚焦于创新思考，而将重复性劳动（如格式调整、文献筛选）交由机器完成，最终实现“人机协同”的科研写作新范式。\n举报/反馈"
  },
  {
    "title": "本科毕业论文结论范例6篇-中文期刊网",
    "page_body": "前言：中文期刊网精心挑选了本科毕业论文结论范文供你参考和学习，希望我们的参考范文能激发你的文章创作灵感，欢迎阅读。\n本科毕业论文结论范文1\n 【关键词】辅导 毕业论文 三阶段教学法\n 【中图分类号】C41 【文献标识码】A 【文章编号】1009-9646(2008)08(b)-0056-01\n 将要毕业的 本科 生走进实验室参加教师的科研活动,在教师的辅导下进行试验以完成他们的 毕业论文 ,是大学教育中很重要的环节。这一环节对大学生的实践分析能力、开拓创新能力和综合素质的培养都起着重要的作用。本文通过辅导毕业论文的教学实践,提出了三阶段教学法,以期提高本科生的科研素质及创新能力,使以传授知识为主要特征的“教学型”教学向以培养主动探索为主要特征的“创造型”教学转变。\n 1 进入课题教学阶段\n 通过师生相互选择,学生进入教师的研究课题,学生拿到任务书后需进行科研课题调研,若调研思路和方法正确,则可较快进入课题。此时教学重点是引导学生学会如何进行科研课题调研,此阶段的教学可称为“一进一出”,一进:即走进图书馆,图书馆存有大量图书资料和网上资源,学生可通过正确的查阅资料的方法查阅参考资料和相关文献.一出:即走出去与课题合作者交流,进一步了解课题性质、目的和意义,增加感性认识。在深入消化吸收的基础上,撰写文献综述和开题报告。\n 由“一进一出”拓宽了学生思维能力,使学生了解了本专业的前沿课题,将学过的专业知识与生产科研实际相结合,加深了对专业知识的理解,固化了综合性理论知识,提高了学习的主动性、积极性。\n 2 试验教学阶段\n 试验是在人为控制条件下有目的地进行的一种实践活动,试验设计与分析,简称试验统计,是数理统计的一个分支．试验统计的内容一般包括两部分:一是对试验进行周密而审慎的设计、实施而得到数据,二是对数据进行数理统计分析,得到客观而合宜的 结论 。[1]\n 根据试验统计的内容,将此阶段的教学分为两部分试验设计教学和试验分析教学。\n 2.1 试验设计教学\n 学生进行试验前,对试验设计思想是不清楚的,如何使他们迅速理解和掌握试验设计方法是在试验教学阶段中首先要解决的问题。在这一阶段,教学的重点是调动学生的主动性,培养学生自学能力,可通过向学生推荐有关文献的方法,让学生自主的查阅文献,初步建立试验设计的基本思想,理解试验与数理统计分析是相互关联不可分割的一个整体．用数理统计来分析数据,只能在试验数据满足一定条件和假设时才有效．因而在试验前就必须对试验进行周密审慎的设计,使其满足统计方法的要求。好的试验设计可以使研究得到满意的结果;未经审慎设计的试验得到数据多数情况人们不能置信。[1]在学生有了一定基础按照试验设计方法提出自己的试验方案后,再与学生共同探讨,并利用多媒体等教学方式将试验设计方法的精髓展现给学生,重点使学生明确试验设计的目的,要解决的问题是什么,问题的类型是什么、解决问题的途径是什么,选择的试验工具是否与问题的类型相符合。并对学生的设计方案进行点评,鼓励学生发表自己的见解,在学生自学与教师讨论相结合的框架下,学生理解了试验设计法就是“偷工加料法”[2]的真实含义。以固结压缩正交试验设计为例,当主因子A和交互作用B之和大于15时,他们从交互作用B入手,看哪些交互作用可省略？在试验因子不改变的情形下,争取有效地减少试验次数,而达到相同甚至更好的结果。在主因子A和交互作用B之和小于15时,他们巧妙运用直交表,通过决定因子、决定交互作用、将因子与交互作用先绘成点线图、再利用点线图去选择最恰当的直交表等步骤,试验因子可得到增加,试验规模可进一步扩大。这样带有科学性、创新性的试验设计方案就更合理、更完善了。\n 2.2 试验过程教学\n 在试验设计方案通过后,学生按照自己的设计方案进行试验,在试验过程阶段学生已从简单的验证某一原理,在相同的仪器上做相同的试验等传统学习模式提高到进行一定的具有开创性的科学研究工作,为他们未来的创造性工作打下较好的科学研究基础过程。\n 在此阶段学生遇到的问题最多,教学重点是引导学生注重试验策略,在试验中筛选主要因子,找出最佳生产条件,并在试验中证实最佳生产条件有再现性。在试验因子较多的情况下,学生往往会对试验结果没有与自己原来的设想一样而感到困惑,这时启发学生分析各因素的效应及因素间的交互效应,对试验结果进行解释筛选主要因子,使学生明白了判断筛选主要因子是否成功可进行变异数分析,若出现了显著因子且这些显著因子的累积贡献率在70%以上则认为筛选成功。此后学生在采用多水准试验找出最佳生产条件时,会主动进行试验分析,当变异数分析中不出现显著因子时可得出成本低、质量好的最佳生产条件。由于此阶段试验误差由随机因素造成,各因子皆不显著,因此每一因子的各项水准均可使用,即可达到成本低廉且又容易控制的目的。随之再作一批样品看是否为最佳,在试验中证实最佳生产条件有再现性就是较容易的试验阶段。\n 试验结束后,教师与学生一起对试验结果进行讨论分析并总结。教学不再强调是否获得正确的结论,而是强调过程和对结论的解释,尤其是对与预期相反的结果进行探索性分析,以期培养学生严谨的科学思维能力和创新素质,推进科研工作的进一步深入,同时也是教学相长的实践过程。\n 3 论文撰写教学阶段\n 此阶段是培养学生论文写作能力的过程,目的是培养学生逻辑思维能力和书面表达能力。其内容是指导学生建立合理的论文框架,正确应用规范性、科学性学术语言,按照论文标准完成写作。教学中首先由师生互动,在讨论中学生思考了论文的阅读对象是哪些人群？论文的目的及主题是什么？然后要求学生认真考虑论文题目。要明白研究问题和研究方向的区别,学生在对比不同论文题目的过程中,理解了好的论文题目应尽可能的直接点明主题,即应尽可能包括研究问题的主要关键词,又要兼顾简明扼要,避免繁琐。在建立论文体系时,通过论文结构大纲将各个环节的相互联系按顺序排列。在论文内容撰写中要求学生对所做试验内容细化到别人可以按照论文中的方法重做的程度,使试验成果具有可重复性。当学生在论文中提出新发现、新观点、新理论时更要引导他们注重旁征博引,分析论证,注重逻辑思维的严密性和语言表达的准确性。论文结尾部分注重引导学生分析该研究还存在哪些不足和进一步的研究方向,使学生了解科学研究就是前仆后继的过程,前人的研究成果就是后人继续研究的铺垫,这样科学研究才能一步步地进行下去。在论文初稿完成后,指导学生进行反复修改、润色,使达到语言表达准确分析归纳合理,论文细节符合要求。\n 4 结论\n 进入课题试验论文撰写三阶段教学法,有效提高了学生的主观能动性、科学思维创新性,有利于学生理论联系实际,学会全面分析问题和妥善解决问题,掌握科学研究的方法、策略,培养了学生论文写作以及规范科学性学术语言的能力。\n 参考文献\n本科毕业论文结论范文2\n 关键词：本科生导师制;英语专业;毕业论文指导\n 中图分类号：G642.477 文献标志码：A 文章编号：1674-9324（2015）20-0085-02\n 一、高校英语专业毕业论文困境分析\n 本科生毕业论文写作是训练和培养本科生科研素质的重要教学实践环节。然而，当前我国许多高校英语专业毕业论文写作存在抄袭现象严重、同质化现象普遍、写作不规范、选题陈旧、立意不清、质量低下等诸多问题。笔者通过广泛地调研和多年的毕业论文指导教学经验，总结出造成毕业论文工作问题重重的原因主要包括以下三个方面：（1）高校本科生毕业论文工作一般都安排在大三下至大四毕业的三个学期开展，学生撰写毕业论文的时间正是用人单位招聘和学生复习考研的高峰期。大多数学生由于不得不投入大量精力用于找工作和复习备考，因此客观上造成他们没有太多精力去顾及毕业论文的选题和写作，对毕业论文质量的重视程度不够。（2）许多高校鲜有专门针对本科生科研素质培养以及指导学生写作专业论文的课程。本科生在进行毕业论文写作时，由于没有经过专业素养的培训和练习，从而缺乏必要的文献检索能力和学术规范意识，在一定程度上也影响了毕业论文质量的提高。（3）学生和毕业论文指导老师的初次接触大多始于大三下学期的毕业论文选题阶段，彼此间在还不够深入、全面了解的情况下就直接进入了论文选题和撰写环节，缺乏了必要的磨合和适应环节，也为后期指导过程中教师无法高效并因材施教地给学生提供论文写作指导埋下隐患。\n 毕业论文写作教学的重要性和毕业论文现状的不近人意两者间日渐彰显的矛盾张力凸显了当前急需改进英语专业本科毕业论文指导工作的紧迫性。本文倡导将本科生导师制引入至英语专业本科生毕业论文指导当中，让本科生导师兼任论文指导教师的职责，以期为解决当前国内高校英语专业毕业论文指导中的教学困境、提高论文指导成效和提升学生综合科研素质寻找出路。\n 二、本科生导师制与英专毕业论文指导研究概述\n 导师制是书院教育的精髓，其核心理念是因材施教和个性化培养，一直以来都是欧美诸多一流大学培养学生的重要教育形式。导师制最早源于14世纪英国牛津大学，被誉为“牛津皇冠上的宝石”。本科生导师制指在本科教育阶段引入导师制，聘请有经验的专业教师在大学四年的教学过程中对学生进行思想引导、专业辅导和心理疏导，从而促使教学与教育结合、教育与管理挂钩，实现教书和育人的有机结合。本科生导师制以促进“人的全面发展”为核心理念，遵循“因材施教”的教育规律，将单纯的教学活动提升到教育的高度，这是开展素质教育的新途径。在本科生导师制的实施过程中，导师需对学生实施教学和思想的教导、学习方法与技巧的引导，并对学生的疑问提供解答。我国自20世纪90年代开始在高等教育本科教学阶段逐渐引入本科生导师制。当时以北京大学、浙江大学为代表的一大批高校曾在部分院系中尝试本科生导师制并由此掀起研究热潮。但是随后由于高校扩招和师生比的不断攀升，本科生导师制渐渐陷入困境，与此相关的研究也停滞不前。笔者通过中国知网在线搜索发现，国内人文科学类别下以“本科生导师制”为主题的学术论文始自2004年至今总数仅16篇。这些研究多是对本科生导师制内涵、推广意义和实施措施的理论性讨论（孟宪军，2004;靖国安，2005;姜晖，2011;周志高，2012），教学实践性研究还十分欠缺。\n 关于英语专业毕业论文指导的研究现状，目前国内相关文献不仅数量较缺乏，而且该领域研究还存在研究内容比较分散、研究方法较为单一的问题。通过梳理和查阅中国知网、万方、维普等数据库，我们发现现有英"
  },
  {
    "title": "attention is all you need论文解读：深度解析Transformer模型核心-CSDN博客",
    "page_body": "attention is all you need论文解读：深度解析Transformer模型核心\n去发现同类优质开源项目: https://gitcode.com/\n项目介绍\n在 （NLP）领域，\"attention is all you need\" 论文提出了一种革命性的模型——Transformer。该论文由Google Brain团队于2017年发表，成为近年来NLP领域发展的重要里程碑。本文深入解读了该论文的核心思想，帮助读者系统掌握Transformer模型的工作原理和应用。\n项目技术分析\n1. 论文背景及意义\n在论文发表之前，循环神经网络（RNN）和长短时记忆网络（LSTM）是NLP领域的主要模型。然而，这些模型在并行计算和长序列处理上存在局限性。为了解决这些问题，\"attention is all you need\" 论文提出了一种全新的模型——Transformer。\n2. 论文主要观点与创新之处\nTransformer模型的核心思想是“注意力机制”，通过计算序列中各个元素之间的关联程度，来实现对输入序列的加权表示。其主要创新点如下：\n自注意力（Self-Attention）机制 ：通过计算序列内部元素之间的关联程度，实现对输入序列的全面理解。 多头注意力（Multi-Head Attention） ：将输入序列分割为多个头，每个头从不同子空间学习信息，提高模型的表达能力。 位置编码（Positional Encoding） ：引入位置信息，使模型能够理解序列中元素的位置关系。\n3. 论文结构及分析方法\n论文详细介绍了Transformer模型的各个组成部分，包括编码器（Encoder）、解码器（Decoder）和优化方法。同时，通过对比实验，展示了Transformer模型在 等任务上的优越性能。\n项目及技术应用场景\n1. 项目应用场景\nTransformer模型在以下场景中表现出色：\n机器翻译 ：Transformer模型在机器翻译任务上取得了显著的成果，如WMT等国际比赛。 文本分类 ：Transformer模型在文本分类任务上具有很高的准确率，如情感分析、主题分类等。 语音识别 ：Transformer模型在语音识别任务上表现出色，如LibriSpeech等数据集。\n2. 技术应用场景\nTransformer模型的核心技术——注意力机制，在以下场景中具有广泛应用：\n图像处理 ：注意力机制可以用于图像分类、目标检测等任务，提高模型的性能。 推荐系统 ：注意力机制可以用于用户行为分析，提高推荐系统的准确率。 对话系统 ：注意力机制可以用于对话生成、语义理解等任务，提升对话系统的智能化程度。\n项目特点\n高效性 ：Transformer模型采用自注意力机制，计算复杂度较低，可以快速处理长序列。 通用性 ：Transformer模型适用于多种NLP任务，具有较强的泛化能力。 可扩展性 ：Transformer模型可以轻松扩展到多模态任务，如图像-文本融合等。\n通过本文的解读，相信读者对\"attention is all you need\"论文及Transformer模型有了更深入的了解。在实际应用中，可以根据具体场景选择合适的Transformer变种，实现更好的性能。\n去发现同类优质开源项目: https://gitcode.com/"
  },
  {
    "title": "如何缓解大模型训练算力不足问题？院士专家建议可以利用已有超算系统的空余算力_央广网",
    "page_body": "央广网北京5月19日消息（记者吕红桥）据中央广播电视总台经济之声《天下财经》报道，当前，各行各业的人工智能大模型越来越多。在汽车领域，如何发挥大模型的作用？训练和应用汽车大模型有什么难点？2024新能源汽车智能网联创新大赛暨产业智库沙龙日前在安徽宿州举行，中国工程院院士和一些汽车业内专家就此发表了观点。\n活动现场（记者吕红桥 摄）\n以前发生交通事故，当事人都是在现场等待交警和保险公司前来处理，这个过程耗时较长，而且容易造成交通拥堵或者二次事故。后来，轻微车损事故有了“快处快赔”，可以在线快速处理。不过，这种处理方式仍然是人工审核，有出错的可能，有的当事人并不认可。中国工程院院士郑纬民在赛前演讲中表示，大模型在汽车领域具有广泛的应用前景，除自动驾驶大模型外，还可以建立专门的汽车保险大模型，提高事故处理的精准度和效率。\n郑纬民介绍，将大量已有的汽车出事故的照片、录像、文字在基础大模型中再训练，就形成汽车保险大模型。有了汽车保险大模型，一旦有汽车现场出现碰撞，将照片放进大模型里做推理，就可以迅速找到责任人。 \n汽车领域应用潜力最大的是自动驾驶。目前，不少汽车企业都在开展自动驾驶相关研发工作。其中车载算力芯片作为实现自动驾驶的核心硬件，备受汽车企业关注。自动驾驶由于需要实时处理大量多模态数据，所以对车载算力芯片的计算能力提出了很高要求。\n对此，清华大学计算机科学与技术系长聘教授李兆麟建议，发展中央计算平台式算力芯片，同时优先部署和推动存算一体、芯粒集成以及量子计算等前瞻性技术在自动驾驶领域的应用，构建开源开放的软件生态，推动国产算力芯片上车应用，解决汽车智能化对大算力、高并行的计算需求。\n无论训练汽车领域的哪类大模型，都需要规模庞大的智能计算中心来支撑。然而当前进口的训练用大算力芯片一芯难求，国产算力芯片短期内仍存在生态系统短板。如何在短期内解决大模型训练的算力不足问题？\n郑纬民院士建议，在推动智能计算中心建设的同时也可以利用已有超算系统的空余算力。现有的14个国家挂牌的超算系统，每台机器的建设成本都很高，成本在10亿元至20亿元，甚至更高。虽然这些系统已经为我国的国民经济发展、国防事业作出了巨大贡献，但有些系统还有空余算力。这些空余算力也可被用来做大模型训练，且经过优化甚至可降低大模型训练成本。 \n专家认为，从长远来看，我国仍需大力发展面向汽车领域应用的智能算力中心。目前，国家新能源汽车技术创新中心已经在安徽宿州落地了国内领先的智能算力中心，积极推进产业创新落地。\n本届大赛上，智算中心二期也签约落地。国家新能源汽车技术创新中心主任、总经理原诚寅说：“现在汽车比的都是算力，在这个过程中，我们要把在芯片上扎下的底子，和现在正在做的国产工业软件数字化结合起来，形成一个立体化的解决方案，这就是为什么我们集中力量发力智算中心，而智算中心针对专业领域应用，我们对此做出了大量工业软件数字化的SAAS服务。”"
  },
  {
    "title": "博睿数据发布！LLM在可观测性体系建设落地的30大核心技术应用场景-知乎",
    "page_body": "随着数字化转型加速，企业 IT 系统规模与复杂度呈指数级增长，可观测性体系建设正经历着前所未有的变革。LLM作为深度学习领域的重要分支，凭借其跨模态理解能力、复杂上下文推理及自然语言交互优势，正推动可观测性向认知智能跃迁，重塑可观测性实践。\n 本次博睿数据发布的《LLM驱动下的可观测性体系建设变革 ——30 大核心技术应用场景》，深入剖析LLM在可观测性体系建设中落地的 30个核心应用场景，聚焦故障治理、风险防控、知识中枢构建、预测性能力实现，以及垂直场景实践五大关键方向。报告详细阐述了LLM在提升观测效率、强化异常洞察、优化根因定位、赋能智能分析决策等方面的成功应用案例。同时，全面解析了LLM应用的技术演进路径与核心价值，深度洞察其在可观测性体系建设中的发展趋势，旨在为各行业可观测性体系建设提供有力的决策支撑与实践参考。\n 点击下方链接或图片二维码免费获取完整版报告，解锁LLM在可观测性体系建设中落地的30个场景探索，抢占可观测性技术先机！\n LLM驱动下的可观测性体系建设变革--30大核心技术应用场景\n https://host.huiju.cool/p/a3faa (二维码自动识别)\n 我们希望通过本报告，推动LLM技术在可观测性体系建设中的更深入研究和应用，解锁其赋能IT系统深度洞察的无限可能，为可观测性的发展注入新的活力。我们相信，随着LLM技术的不断进步和普及，可观测性能力将迎来更加广阔的发展前景。\n 点击下方，联系我们，免费获取更多行业资料。\n https://host.huiju.cool/p/cc774"
  },
  {
    "title": "专家解读2017年度中国古生物学十大进展—新闻—科学网",
    "page_body": "寄自远古地球的十封信\n 近日，中国古生物学会在南京发布“2017年度中国古生物学十大进展”评选结果。《发现翼龙伊甸园，揭秘翼龙生命史——大量3D翼龙蛋和胚胎首次发现》《中国显生宙腕足动物属志》《中国许昌发现的晚更新世古老型人类头骨化石》等十项研究成果上榜。这十大进展，不仅具有重大科学价值、有助于探究生命起源和演化的奥秘，而且推动了公众对地质历史时期生命演化历程的认识。\n3D化石穿越亿年回到“翼龙伊甸园”\n “当时这一地区是一个大型湖泊，雨量充沛，气候相对温暖，翼龙就生活在大型湖泊边缘，以湖中大量的鱼类为食，把它们的蛋产在湖岸边的沙滩中。”中国科学院古脊椎动物与古人类研究所研究员汪筱林描绘了距今约1.2亿年前的早白垩世，新疆哈密戈壁雅丹地区的“翼龙伊甸园”。\n 汪筱林团队经过10余年连续的野外科考，在新疆哈密发现并抢救性采集了恐龙化石标本，其中有215枚翼龙蛋，其中16枚翼龙蛋含有三维立体（3D）的胚胎化石，这是世界上首次发现3D翼龙胚胎，也是“翼龙研究200年来最令人激动的发现之一”。\n “翼龙不是会飞的恐龙，它们两者关系比较近，有共同的祖先，从距今约2.2亿年前的三叠纪晚期几乎同时在地球上出现，在6500万年前的白垩纪末期同时绝灭，在地球上生存了约1.6亿年。两者占据不同的生态空间，翼龙是飞行动物，空中霸主，以食鱼为主，也有少量类群吃昆虫和植物等。”汪筱林说。\n 此次发现的天山哈密翼龙，胚胎、幼年、亚成年和成年个体都有很多，而且发现大量的雌雄个体，组成一个白垩纪翼龙伊甸园。根据化石推测，哈密翼龙最大翼展可达3.5—4米左右。\n 但是，科研人员发现翼龙小时候“会走不会飞”。通过扫描3D胚胎，可以看出它们的后肢发育速度比前肢快，孵化之后只能走不能飞，牙齿还没有萌出，还不能主动觅食，需要父母照料。\n 据汪筱林推测，这些翼龙遇到突发的风暴，导致湖边的、湖底的物质和岸边湿润沙子里的翼龙蛋等卷在一起，被快速地搬运、沉积和埋藏。而翼龙骨骼分散但完整，则说明它们是带着皮肉被埋藏的。\n30年不离不弃书写中国腕足动物“四库全书”\n 由中科院院士、南古所研究员戎嘉余主编的《中国显生宙腕足动物属志》，也被评为十大进展之一。\n 这本用英文编撰的中国腕足动物化石属志，涉及的化石记录来自显生宙的古生代（寒武纪、奥陶纪、志留纪、泥盆纪、石炭纪和二叠纪）和中生代（三叠纪、侏罗纪和白垩纪）共9个纪的海相地层中，跨越了约4.5亿年的地质历史，涵盖了1883年至2015年间根据中国材料创建的757个腕足动物属。\n 腕足动物是生活在海底的有壳无脊椎动物。它曾经是海洋中个体最丰富、多样性最高、分布最广的优势类群，但目前仅在少数海域才有零星分布。腕足动物群频繁演替的兴衰史，称得上是地球生物宏演化过程的一个缩影。\n “腕足动物生活在古生代海域深约200米以内的海底，基本不动。因此，它能精确反映沉积盆地的演化史，对板块运移布局变化有很强的指示意义。”该书副主编、中科院南京地质古生物研究所副所长詹仁斌说。\n 詹仁斌介绍，中国是腕足动物化石赋存的大国，中华人民共和国成立后，在大规模地质调查中，发表了大批论文，创建了中国很多特有的新属，但由于历史原因，这些科研发现多未与国际同行形成互动，存在重复研究现象，且论文多以中文发表或仅附英文摘要，国外学者也无法了解中国腕足动物的研究成果。\n 为了摸清家底，1986年金玉玕院士提议并开展长达8年的分工写作。但由于种种原因，1995年编写工作被搁置。2008年，戎嘉余院士领衔，沈树忠院士、詹仁斌研究员等一批中青年通力合作再次聚焦该志书的编写，最终于2017年初完成。\n 本着“一个都不能少”的原则，该书将所有依据中国材料建立的757个属级分类单元，全部收录进来，逐个给予编号、按规范记录并展示其模式种的图影。为国内外同行进行全球总结和宏演化研究提供了不可多得的可靠资料。\n10万年前头骨揭示中欧人种曾有基因交流\n 他们不是早期现代人、不是尼安德特人、不是海德堡人，也不是直立人。他们是一种新的古老型人类，目前还无法将其归入任何已知的古老型类群之中。他们是谁？许昌人！\n 中科院古脊椎动物与古人类研究所李占扬、吴秀杰研究员率领的科研团队于2017年3月，在《科学》上发表研究成果：河南许昌发现了新型古人类头骨化石。研究显示，在距今10.5万年至12.5万年前，中国境内生存着一群体质特征非常特殊的古老型人类——许昌人，他们的头骨呈现出更新世晚期人类、东亚中更新世直立人以及欧洲尼安德特人的混合特征。这表明，在当时，中国境内可能并存着多种古人类群体，不同群体之间有杂交或者基因交流产生。\n “许昌人为中国古人类演化的地区连续性以及与欧洲古人类之间的交流提供了一定程度的支持。”中国古生物学会秘书长王永栋研究员说。\n 据介绍，“许昌人”古人类头盖骨化石是在河南省许昌市的灵井旧石器时代遗址发现的。2005年至2016年，河南省文物考古研究院研究员李占扬领导的考古队对灵井遗址展开了连续12年的挖掘，发现了45件人类头骨碎片化石，包括完整的枕骨、部分顶骨、眉脊和颅底骨等，骨骼多数可拼接复原。经过科学家们拼接复原，一共发现了多个许昌人。\n “许昌人头骨在枕圆枕上凹和颞骨内耳迷路半规管的形态上与欧洲的尼安德特人相似，暗示了两个人群之间基因交流的可能性。”王永栋说。"
  },
  {
    "title": "2019 高中议论文写作难点突破：学会阐释材料中的核心概念（福州十一中学 吴叶静）-优酷",
    "page_body": "[9.5.101]很抱歉出现播放错误，错误代码：0502-22503"
  },
  {
    "title": "能自动分辨文章情绪 国产AI大模型“先问”不简单-武汉市人民政府门户网站",
    "page_body": "想要快速了解热点事件传播效果？不用大费心思在网络上搜寻，只需问问“先问”就行。近日，在清博智能武汉分公司，长江日报记者登录内测账号，在输入框中提出“‘神舟十六号发射成功’，近30天在全网的传播情况，以图表形式展示。”下一秒，先问立即生成一份传播效果曲线图，并配上一段300多字的简要报告，其中提到：在全网平台上，微博传播最多，提及量在2023年5月30日达到最高峰。\n工作人员正在利用先问撰写报告\n先问是由清博智能武汉分公司参与研发的AI大模型，前不久刚刚进入内测阶段。相较于市面上其他“竞品”，先问除了能分析事件传播效果、实时生成图表外，还有一项“独门绝技”——分辨文章所蕴含的“喜怒哀乐”情绪，使AI的回答更加精准、人性化。\n“这项独创功能源于我们积累了多年的大数据处理能力。”清博智能技术副总裁王欢说，清博智能武汉分公司拥有300余人的智库团队，承担着行业报告撰写和行业咨询业务，仅2022年就完成了26万份报告。\n“我们的大数据系统已累积了2000亿条数据，这为先问在热点信息聚合、热点议题分析以及内容文案撰写等方面提供有力支撑。”王欢说。\n海量数据的支撑只是先问“诞生”的第一步。想要AI大模型从数据库中“挑选”合适的内容加以改造并反馈，要靠算法来实现，这也是技术团队需要攻克的一大难题。\n先问能分析社会热点时间，实时生成全网传播效果图表\n“对于AI来讲，它无法像人一样分辨其中的感情、态度等信息。”王欢说，技术团队最终采取“结构化数据”算法方案，让先问能够识别文字信息中的人、物等实体，并对信息的传播渠道、发布者以及信息中蕴含的态度、情绪等关键信息打上标签，“一篇几百字的文章就要打上100多个标签”。\n这与其他AI大模型基于搜索引擎、“宽泛式”获取信息的方式截然不同，也是先问的优势所在。\n“比如，当用户想要获取网友关于某件事情的正面、负面或中性评价的信息，先问就能快速、精准地进行反馈。”王欢说，得益于精细处理信息的能力，先问可以实现针对客户的需求进行“定制化”。不仅如此，先问还可以部署在企业或单位的内部服务器上，保障数据安全。\n“目前我们已经推出了融媒体定制版，还有能源、大健康、文旅等领域的20多个合作项目正在推进。”王欢说。\n编辑：熊展平"
  },
  {
    "title": "7 个影响 LLM 生成结果的关键参数，精准解读与应用建议：• Max tokens：生成长度上限。数值过低导致内容截断，过高则浪费计算资源。合理设定避免输出不完整或资源浪费。• Temperatur-什么值得买",
    "page_body": "7 个影响 LLM 生成结果的关键参数，精准解读与应用建议：• Max tokens：生成长度上限。数值过低导致内容截断，过高则浪费计算资源。合理设定避免输出不完整或资源浪费。• Temperatur \n爱可可-爱生活\n微博\n 查看原文 \nAI小值  总结了该内容 \n文章详细介绍了影响大型语言模型（LLM）生成结果的七个关键参数及其应用建议。Max tokens 参数决定了生成文本的长度上限，需要合理设定以避免内容截断或资源浪费。Temperature 参数控制输出的随机性，低值适合问答和客服，而高值则增加创造力和多样性。Top-k 和 Top-p 参数分别限制采样范围和动态采样，以平衡输出的聚焦性和多样性。Frequency penalty 和 Presence penalty 参数分别通过惩罚重复和鼓励新词汇来提升输出质量。Stop 参数定义了终止生成的词汇列表，确保输出的结构清晰。掌握这些参数的调节技巧有助于提升生成文本的质量和控制度，适应不同的输出场景需求。"
  },
  {
    "title": "生物膜的流动镶嵌模型公开课-20230310004704.pptx-原创力文档",
    "page_body": "内容提供方 ： 135****2083 大小 ： 3.81 MB 字数 ： 约3.93千字 发布时间 ： 2023-03-15发布于四川  浏览人气 ： 0 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n问题探究用哪种材料作细胞膜更适于体现细胞膜的功能？塑料袋普通布弹力布选择依据:生命系统的边界---薄控制物质的进出---选择透过性具有一定的弹性---伸缩性第一页，共三十八页。第2节 生物膜的流动镶嵌模型第二页，共三十八页。本节聚焦1.生物膜流动镶嵌模型的基本内容是什么？2.通过分析科学家建立生物膜模型的过程，你对科学的过程和方法有哪些领悟？3.生物膜的结构与功能相适应的观点体现在哪？第三页，共三十八页。一、对生物膜结构的探究历程第四页，共三十八页。[资料一]19世纪末 欧文顿（E.Overton）用500多种物质对植物细胞进行上万次的通透性实验，发现可以溶于脂质的物质，比不能溶于脂质的物质更容易通过细胞膜。 不溶于脂质的物质溶于脂质的物质提出假说：膜是由脂质组成的第五页，共三十八页。资料1.欧文顿的实验脂溶性物质比非脂溶性物质更容易通过细胞膜观察现象　细胞膜的成分是什么？提出问题　细胞膜是由脂质组成的。作出假说　　提取细胞膜进行化学检测设计实验进行实验从细胞膜中提取到大量磷脂。实验结果得出结论　细胞膜是由脂质组成的应用化学手段分析表明：膜的主要成分是脂质和蛋白质,组成膜的脂质中磷脂含量最多第六页，共三十八页。资料1.欧文顿的实验●●●●●●●●不溶于脂质的物质●溶于脂质的物质●细胞膜第七页，共三十八页。[资料二]20世纪初,科学家将细胞膜从哺乳动物的红细胞中分离出来，发现细胞膜不但会被溶解脂质的溶剂溶解，也会被蛋白酶分解。结论：细胞膜主要由脂质和蛋白质组成脂质中主要成分是：磷脂第八页，共三十八页。亲水头部疏水尾部磷脂是一种由甘油，脂肪酸和磷酸所组成的分子，磷酸“头”部是亲水的，脂肪酸“尾”部是疏水的。第九页，共三十八页。 脂质和蛋白质在生物膜上是怎样分布的呢？第十页，共三十八页。[资料三]1925年,荷兰两位科学家从细胞膜中提取脂质，在空气-水界面铺成单分子层，测得单分子层的面积恰好为红细胞表面积的2倍。 结论：细胞膜中的脂质分子必然排列为连续的两层。第十一页，共三十八页。单位膜模型的提出想一想：磷脂分子在空气-水界面上会怎么样铺展？小资料磷脂是组成细胞的主要脂质，是一种由甘油、脂肪酸、和磷酸等所组成的分子。它有一个亲水磷酸“头”部，和一个疏水的脂肪酸的“尾”部。亲水“头部”亲水的“头部”与水接触，疏水的“尾巴”远离水，朝向空气的一面，在水空气界面上铺展成单分子层。疏水“尾部”空气水第十二页，共三十八页。细胞膜的两侧都有水环境存在，同学们尝试着大胆的推测和想象一下在这样的环境中，磷脂分子在细胞膜中可能是怎样排布的呢？推测第十三页，共三十八页。第十四页，共三十八页。水环境水环境第十五页，共三十八页。磷脂双分子层第十六页，共三十八页。[资料四]20世纪40年代，曾经有学者推测脂质两边各覆盖着蛋白质。但直到50年代，电子显微镜的诞生，科学家用它来观察细胞膜。1959年，罗伯特森在电镜下看到了细胞膜清晰的暗—亮—暗三层结构。假设1：脂质—蛋白质—脂质假设2：蛋白质—脂质—蛋白质第十七页，共三十八页。小知识： 电子束照射在分子质量高的物质上，散射度高，较为黑暗；照射在分子质量低的物质上，散射度低，较为亮。第十八页，共三十八页。 罗伯特森结合其他科学家的工作，大胆的提出生物膜的模型：提出假说：生物膜是由“蛋白质—脂质—蛋白质”的三层结构构成的静态统一结构。第十九页，共三十八页。思考：流动镶嵌模型与蛋白质—脂质—蛋白质三层结构模型有何异同？相同点：都认为组成细胞膜的主要物质是脂质和蛋白质。不同点：1、流动镶嵌模型认为蛋白质在膜中的分布是不均匀的。而三层结构模型认为蛋白质均匀分布在脂双层的两侧2、流动镶嵌模型强调组成膜的分子是运动的，而三层结构认为生物膜是静止结构第二十页，共三十八页。变形虫的变形运动变形虫在吞噬草履虫第二十一页，共三十八页。吞噬作用第二十二页，共三十八页。第二十三页，共三十八页。[资料五]人细胞诱导融合40分钟后370C1970年，科学家用发绿色荧光的染料标记小鼠细胞表面的蛋白质分子，用发红色荧光的染料标记小鼠细胞表面的蛋白质分子，荧光标记 膜蛋白鼠细胞结论：细胞膜具有一定的流动性第二十四页，共三十八页。 1972年，桑格和尼克森在新的观察和实验证据的基础上，提出了流动镶嵌模型。第二十五页，共三十八页。[资料六]电镜冰冻蚀刻细胞膜20世纪60年代科学家用扫描电镜技术和冰冻蚀刻技术揭示了细胞膜结构中的蛋白颗粒。第二十六页，共三十八页。 1972年，桑格和尼克森在新的观察和实验证据的基础上，提出了流动镶嵌模型,为多数人所接受。流动镶嵌模型的基本内容： 磷脂双分子层构成了膜的基本支架，这个支架不是静止的。磷脂双分子层是清油般的流体，具有流动性。蛋白质分子有的镶在磷脂双分子层的表面，有的部分或全部嵌入磷脂双分子层中，有的贯穿于整个磷脂双分子层。大多数蛋白质分子也是可以运动的。第二十七页，共三十八页。对生物膜结构的探索历程科学家科学实验假说时间膜是由脂质组成的19世纪末欧文顿两位荷兰科学家1925年生物膜为三层静态统一结构1959年罗伯特森细胞膜具有流动性弗雷和埃迪登1970年桑格和尼克森在新的观察和实验证据基础上1972年第二十八页，共三十八页。二、流动镶嵌模型的基本内容1、磷脂双分子层构成了细胞膜的基本骨架（体现了膜结构内外的不对称性）覆盖在磷脂双分子层外侧2、蛋白质分子镶嵌在磷脂双分子层两侧贯穿磷脂双分子层3、 糖被 糖脂糖蛋白：识别作用（糖类的成分起重要作用）保护和润滑；糖被分布在细胞膜的外侧 4、细胞膜的结构特点 ①特点：具有一定的＿＿＿。 ②原因：组成膜的＿＿＿和＿＿＿大都是运动的。流动性蛋白质脂质5、细胞膜的功能特点：选择透过性第二十九页，共三十八页。流动镶嵌模型基本内容的总结:1、生物膜的组成：主要由蛋白质和脂质组成2、生物膜的基本骨架：磷脂双分子层（亲水性头部朝向两侧，疏水性尾部 朝向内侧）。3、蛋白质分子存在形态：有镶在表面、嵌入、横跨三种，外侧的蛋白质分子与糖类结合形成糖蛋白。体现了生物膜的不对称性。（糖蛋白与细胞识别、胞间信息交流等有密切联系）4、生物膜的结构特点：流动性（磷脂分子和大多数蛋白质分子都是运动的）第三十页，共三十八页。生物膜的结构特性和功能特性1.生物膜的结构特性：流动性结构基础：磷脂分子和大多数蛋白质是运动的。实验验证：变形虫的运动、白细胞的吞噬细胞、胞吞和胞吐现象。2.生物膜的功能特性：选择透过性结构基础：膜上具有载体蛋白。生理意义：控制物质进出。3.流动性和选择透过性的关系区别：流动性是生物膜的结构特点，选择透过性是生物膜的功能特点。联系：流动性是选择透过性的基础，只有膜具有流动性，才能表现住选择透过性。第三十一页，共三十八页。课堂练习1、据研究发现，胆固醇、小分子脂肪酸、维生素D等物质较容易优先通过细胞膜，这是因为（ ）A 细胞膜具有一定流动性B 细胞膜是选择透过性C 细胞膜的结构是以磷脂分子层为基本骨架D 细胞膜上镶嵌有各种蛋白质分子2.下列哪一种膜结构能通过生物大分子（ ）A 细胞膜B核膜C 线粒体膜C叶绿体膜第三十二页，共三十八页。3、一分子CO2从叶肉细胞的线粒体基质中扩散出来，进入一相邻细胞叶叶绿体基质内，共穿过的生物膜层数是（ ）A 5 B 6 C 7 D 84、细胞膜上与细胞识别、免疫反应、信息传递和血型决定有着密切关系的化学物质是（ ）A 糖蛋白B 磷脂C 脂肪D 核酸第三十三页，共三十八页。5、变形虫的任何部位都能伸出伪足，人体某些白细胞能吞噬病菌，这些生理过程的完成都依赖于细胞膜的（ ）A 保护作用B 一定的流动性C 主动运输D 选择透过性6、下列物质中，不能横穿细胞膜进出细胞的是（ ）A 维生素D和性激素B 水和尿素C 氨基酸和葡萄糖D 酶和胰岛素第三十四页，共三十八页。4．在美国梅奥诊所工作的华人科学家陈贤明研究员和他的同事，利用体外胆管上皮细胞感染模型，分析了隐孢子虫的子孢子进入细胞内的全过程。结果发现，隐孢子虫的子孢子侵入宿主细胞膜内时，会诱发大量宿主细胞膜载体及水通道聚集，导致膜局部快速水内流，从而促使局部细胞膜伸展突起。据此回答：（1）上述材料说明细胞膜的结构具有 特性。（2）下列哪些现象与细胞膜伸展突起相关 （ ）A．肿瘤细胞的浸润转移?B．白细胞吞噬异物C．葡萄糖进入小肠上皮细胞 D．抗体的分泌（3）若要进一步证明水的快速内流是细胞膜水通道蛋白开放所致，可另设计一组对照实验，用 对_______进行处理。第三十五页，共三十八页。【解析】（1）从题中所给材料可知，细胞膜受到刺激可使细胞膜伸展突起，说明细胞膜具有一定的流动性。（2）肿瘤细胞的浸润转移，需进行变形运动；白细胞吞食异物，细胞膜要伸出伪足将异物包裹；抗体的分泌，细胞膜要出芽进行胞吐，都与细胞膜伸展突起相关。葡萄糖进入小肠上皮细胞是通过细胞膜上的载体的主动运输进行的，与上皮细胞细胞膜伸展突起无关。（3）要证明水的快速内流是水通道蛋白开放所致，自变量是细胞膜上水通道蛋白开放与否，因变量是否大量进入细胞，因此，用蛋白质抑制剂抑制水通道蛋白的活性作为对照即可。答案：（1）一定的流动性 （2）A、B、D? （3）蛋白质抑制剂 水通道蛋白第三十六页，共三十八页。知识回顾Knowledge Review第三十七页，共三十八页。 放映结束 感谢各位的批评指导！谢 谢！让我们共同进步第三十八页，共三十八页。"
  },
  {
    "title": "transformer架构嵌入层位置编码之Sinusoidal位置编码及简单实现示例-CSDN博客",
    "page_body": "前文，我们已经构建了一个小型的字符级语言模型，是在transformer架构基础上实现的最基本的模型，我们肯定是希望对该模型进行改进和完善的。所以我们的另外一篇文章也从数据预处理、模型架构、训练策略、评估方法、代码结构、错误处理、性能优化等多个方面提出具体的改进点，但是还没有实现以及评估。接下来，我们就 从最核心的模型架构开始，对模型进行改进，其中之一就是嵌入层的位置编码 。\n 然而位置编码有多种方法，其中重要的三种是：Sinusoidal位置编码、RoPE（旋转位置编码）和可学习嵌入，他们各自有什么优缺点，如何比较。接下来我们先了解 Sinusoidal位置编码 。\n 本文是在我前文的基础上讲解的： 从零开始构建一个小型字符级语言模型的详细教程（基于Transformer架构）之一数据准备-CSDN博客\n从零开始构建一个小型字符级语言模型的完整python示例代码-CSDN博客\n1. Sinusoidal位置编码\n Sinusoidal位置编码是Transformer原论文中提出的固定式编码方法，通过正弦和余弦函数的组合生成位置向量，每个位置对应一个独特的编码，这样可以捕捉到序列中各个位置的相对和绝对位置信息。它的 一个关键特点是无需训练参数，直接通过数学公式生成，适合处理长序列 。\n 对于位置 和维度 ，其编码由以下公式生成：\n 其中， 是位置索引（从0开始）， 是维度索引（从0到 ）， 是模型维度（编码向量的总长度）。频率项是 ，每个维度的频率项是 。\n 具体来说，这种编码方式能够捕捉到不同位置之间的相对距离，因为正弦和余弦函数具有周期性，可以表示相对位置的信息。不过，因为是固定的，可能无法适应不同任务或数据的特点。设计意义在于：\n特性\n说明\n维度多样性\n不同维度对应不同频率，避免所有维度编码模式雷同\n外推能力\n频率的几何级数分布使模型能泛化到未见过的长序列\n相对位置建模\n通过波形的相位差自然推导相对位置关系（如PE_pos+k =PE_pos ⋅M(k)）\n2. 完整代码实现\n python代码：\nimport torch\nimport math\ndef sinusoidal_position_encoding(seq_len, d_model):\n\"\" \"\n    生成Sinusoidal位置编码矩阵\n    Args:\n        seq_len (int): 序列最大长度\n        d_model (int): 模型维度\n    Returns:\n        pe (torch.Tensor): 形状为 (seq_len, d_model) 的位置编码矩阵\n    \" \"\"\n    pe  =  torch. zeros (seq_len, d_model)\n    position  =  torch.arange( 0 , seq_len, dtype = torch.float).unsqueeze( 1 )  # (seq_len,  1 )\n    div_term  =  torch.exp(torch.arange( 0 , d_model,  2 ).float()  *  (-math.log( 10000.0 )  /  d_model)\n    pe[:,  0 :: 2 ]  =  torch.sin(position  *  div_term)  # 偶数维度用sin\n    pe[:,  1 :: 2 ]  =  torch.cos(position  *  div_term)  # 奇数维度用cos\nreturn  pe\n# 示例参数\nseq_len  = 5   # 序列长度\nd_model  = 4   # 模型维度\n# 生成位置编码\npe  =  sinusoidal_position_encoding(seq_len, d_model)\nprint( \"位置编码矩阵：\\n\" , pe)\n3. 处理逻辑分步说明\n 接下来我们对以上代码的处理逻辑进行详细说明。\n 步骤1：初始化位置编码矩阵\n python代码：\npe  =  torch. zeros (seq_len, d_model)\n 创建一个形状为 (seq_len, d_model) 的全零矩阵，用于存储所有位置的位置编码。 具体理解就是一共有 seq_len 个位置，每个位置采用 d_model 长度的向量编码 。\n图1 初始化位置编码矩阵\n 示例输出（可以直接在pe之后print(pe)输出）：\ntensor([[ 0 .,  0 .,  0 .,  0 .],\n        [ 0 .,  0 .,  0 .,  0 .],\n        [ 0 .,  0 .,  0 .,  0 .],\n        [ 0 .,  0 .,  0 .,  0 .],\n        [ 0 .,  0 .,  0 .,  0 .]])\n 步骤2：生成位置索引\n 给每一个位置一个索引编号 。\n python代码：\nposition  =  torch.arange( 0 , seq_len, dtype = torch.float).unsqueeze( 1 )\n 生成从0到seq_len-1的位置索引，形状为 (seq_len, 1)。\n图2 位置索引\n 我们再拿前文中的一个例子举例说明。\n图3 位置索引与编码示意图\n 示例输出（seq_len=5时，即序列长度为5个时的位置索引）：\ntensor( [[0.] ,\n[1.] ,\n[2.] ,\n[3.] ,\n[4.] ])\n 步骤3：计算频率项\n Sinusoidal编码是通过不同频率的正弦和余弦函数来为每个位置生成一个独特的编码向量。这样，模型可以捕捉到位置之间的相对关系，比如不同位置之间的距离。所以在Sinusoidal位置编码中， 计算频率项的核心目的是为每个维度分配不同的波长，使得模型能在多尺度上捕捉位置信息 。\n python代码：\ndiv_term  =  torch.exp(torch.arange( 0 , d_model,  2 ).float()  *  (-math.log( 10000.0 )  /  d_model)\n 计算每个维度的频率因子，控制不同维度的波长。\n 分解计算过程 ：\n （1）torch.arange(0, d_model, 2)：生成偶数维度索引（0, 2, 4...）。具体过程是，生成一个从0开始，步长为2的序列，直到d_model。例如，如果d_model是4，那么就是[0,2]。然后，这个序列被转换为浮点数，并乘以(-math.log(10000.0)/d_model)，这是第（2）步。接下来，对这个结果取指数，这是第（3）步。\n （2）-math.log(10000.0)/d_model：归一化因子，调整衰减速率。\n （3）exp(...)：将线性间隔转换为指数间隔的频率。\n 一些解释：根据Sinusoidal的公式，每个维度的频率项是1/(10000^(2i/d_model))，这可以转化为exp(-(2i/d_model)*ln(10000))。这就是代码中为什么会有(-math.log(10000.0)/d_model)的部分，因为ln(10000)是math.log(10000.0)，然后乘以(2i)/d_model，其中i是维度的索引。代码中的arange是从0到d_model，步长2，因此i的值是0,1,...,d_model/2-1。\n 以d_model =4为例讲解计算过程：\n （1）生成维度索引：\n torch.arange(0, 4, 2) → [0, 2]\n （2）计算归一化因子：\n （3）计算频率项：\n （4）应用到位置编码：\n 位置0的编码：[sin(0*1), cos(0*1), sin(0*0.01), cos(0*0.01)] → [0, 1, 0, 1]\n 位置1的编码：[sin(1*1), cos(1*1), sin(1*0.01), cos(1*0.01)] → [0.8415, 0.5403, 0.0099, 0.9999]\n 频率项的作用\n （1）多尺度位置感知：\n 高频（小波长）：捕捉细粒度的局部位置关系（如相邻字符）。\n 低频（大波长）：建模长距离的全局位置依赖（如段落结构）。\n 较高频率（较小的波长）的维度可以捕捉更细粒度的位置变化，而较低频率（较大的波长）的维度则捕捉更大范围的位置变化。\n （2）几何级数波长分布：\n 频率随维度索引i呈指数衰减，确保不同维度的波长覆盖广泛的范围。例如，当 d_model=512时，波长从2π（最小）到2π⋅10000（最大）。\n （3）位置唯一性：\n 不同位置的编码通过不同频率的正弦/余弦波叠加，保证每个位置有唯一编码。\n 步骤4：填充正弦和余弦值\n python代码：\npe[:,  0 :: 2 ]  =  torch.sin(position  *  div_term)  # 偶数维度\npe[:,  1 :: 2 ]  =  torch.cos(position  *  div_term)  # 奇数维度\n 交替填充：偶数列用正弦函数，奇数列用余弦函数。\n position * div_term：将位置索引与频率因子相乘，生成不同频率的正弦/余弦波。\n4. 示例输出\n 当seq_len=5、d_model=4时，输出如下：\n位置编码矩阵：\n tensor([[  0.0000 ,   1.0000 ,   0.0000 ,   1.0000 ],\n        [  0.8415 ,   0.5403 ,   0.0099 ,   0.9999 ],\n        [  0.9093 , - 0.4161 ,   0.0198 ,   0.9998 ],\n        [  0.1411 , - 0.9900 ,   0.0297 ,   0.9996 ],\n        [- 0.7568 , - 0.6536 ,   0.0396 ,   0.9992 ]])\n5. 与输入嵌入的结合\n 将 位置编码直接  加  到输入嵌入（Token Embedding） 中：\n python代码：\nclass Transformer (nn. Module ):\ndef __init__ ( self , d_model, seq_len ):\nsuper ().__init__()\nself .token_embed = nn. Embedding (vocab_size, d_model)\nself .register_buffer( 'pe' , sinusoidal_position_encoding(seq_len, d_model))\ndef forward ( self , x ):\n# x 形状: (batch_size, seq_len)\n        token_embeddings =  self .token_embed(x)   # (batch_size, seq_len, d_model)\nreturn  token_embeddings +  self .pe   # 位置编码广播相加\n6. 关键特性总结\n特性\n说明\n固定性\n无需训练参数，直接通过公式生成\n相对位置感知\n不同位置的编码可通过线性变换关联（如 PE(pos+k) = PE(pos)·M(k)）\n长序列泛化\n周期性设计使其能处理远超训练时序列长度的位置\n维度多样性\n不同维度对应不同频率，捕捉多尺度位置信息\n7. 实际应用注意事项\n（1）序列长度外推：当实际输入长度超过 seq_len 时，可动态计算新位置编码，无需重新训练。\n（2）与可学习嵌入结合：可尝试混合使用：\nFinal_Embedding = Token_Embedding + α * Sinusoidal_PE（α为可学习标量）。\n8.  可视化分析\n python代码（放到前面完整代码的后面即可）：\nimport  matplotlib.pyplot  as  plt\nplt.imshow(pe.numpy(), cmap= 'viridis' )\nplt.xlabel( 'Dimension' )\nplt.ylabel( 'Position' )\nplt.colorbar()\nplt. show ()\n 通过热力图观察不同位置和维度的编码值分布，与数值对照。\n图4 不同位置和维度的编码值分布热力图\n位置编码矩阵：\n tensor([[  0.0000 ,   1.0000 ,   0.0000 ,   1.0000 ],\n        [  0.8415 ,   0.5403 ,   0.0099 ,   0.9999 ],\n        [  0.9093 , - 0.4161 ,   0.0198 ,   0.9998 ],\n        [  0.1411 , - 0.9900 ,   0.0297 ,   0.9996 ],\n        [- 0.7568 , - 0.6536 ,   0.0396 ,   0.9992 ]])\n 得到结果：\n 低纬度（前两维， 前两列 ）变化剧烈（高频），捕捉局部位置。\n 高纬度（后两维， 后两列 ）变化平缓（低频），建模全局结构。\n 通过这种设计，模型不仅能感知绝对位置，还能通过编码的几何关系自然推导相对位置，显著增强对序列结构的理解能力。"
  },
  {
    "title": "如何系统的入门大模型？",
    "page_body": "从ChatGPT诞生至今，我也陆陆续续也写了不少关于大模型的文章，为了方便查看，均梳理了并放置在Github上面:  llm-action\n目前该项目已经超过4500星，感谢大家的支持和喜欢（ 之前发现不少人，拿着这个项目给自己的知识星球引流，大家一定要注意甄别，不要被骗了 ），后面我也会在该项目持续分享大模型相关的知识和经验，欢迎大家关注。\n另外，我创建了大模型学习交流群，供大家一起学习交流大模型相关的最新技术，目前已有5个群，可加我微信进群（加微信请备注来意，如：进大模型学习交流群+知乎）。一定要备注哟，否则不予通过。【点击】 加入大模型技术交流群 。\n项目大体如下所示：\n目录\nLLM训练\nLLM训练实战 LLM参数高效微调技术原理综述 LLM参数高效微调技术实战 LLM分布式训练并行技术 分布式AI框架 分布式训练网络通信\nLLM推理\nLLM推理框架 ✈️  LLM推理优化技术\n♻️  LLM压缩\nLLM量化 LLM剪枝 LLM知识蒸馏 ♑️  低秩分解\n♍️  LLM算法架构 LLM应用开发  ️  LLM国产化适配 AI编译器 AI基础设施 LLMOps LLM生态相关技术 服务器基础环境安装及常用工具\nLLM训练\nLLM训练实战\n下面汇总了我在大模型实践中训练相关的所有教程。从6B到65B，从全量微调到高效微调（LoRA，QLoRA，P-Tuning v2），再到RLHF（基于人工反馈的强化学习）。\nLLM\n预训练/SFT/RLHF...\n参数\n教程\n代码\nAlpaca full fine-turning 7B 从0到1复现斯坦福羊驼（Stanford Alpaca 7B） 配套代码\nAlpaca(LLaMA) LoRA 7B~65B 1.足够惊艳，使用Alpaca-Lora基于LLaMA(7B)二十分钟完成微调，效果比肩斯坦福羊驼\n2. 使用 LoRA 技术对 LLaMA 65B 大模型进行微调及推理 配套代码\nBELLE(LLaMA/Bloom) full fine-turning 7B 1.基于LLaMA-7B/Bloomz-7B1-mt复现开源中文对话大模型BELLE及GPTQ量化 \n 2. BELLE(LLaMA-7B/Bloomz-7B1-mt)大模型使用GPTQ量化后推理性能测试 N/A\nChatGLM LoRA 6B 从0到1基于ChatGLM-6B使用LoRA进行参数高效微调 配套代码\nChatGLM full fine-turning/P-Tuning v2 6B 使用DeepSpeed/P-Tuning v2对ChatGLM-6B进行微调 配套代码\nVicuna(LLaMA) full fine-turning 7B 大模型也内卷，Vicuna训练及推理指南，效果碾压斯坦福羊驼 N/A\nOPT RLHF 0.1B~66B 1.一键式 RLHF 训练 DeepSpeed Chat（一）：理论篇 \n 2. 一键式 RLHF 训练 DeepSpeed Chat（二）：实践篇 配套代码\nMiniGPT-4(LLaMA) full fine-turning 7B 大杀器，多模态大模型MiniGPT-4入坑指南 N/A\nChinese-LLaMA-Alpaca(LLaMA) LoRA（预训练+微调） 7B 中文LLaMA&Alpaca大语言模型词表扩充+预训练+指令精调 配套代码\nLLaMA QLoRA 7B/65B 高效微调技术QLoRA实战，基于LLaMA-65B微调仅需48G显存，真香 配套代码\nLLM微调技术原理\n对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。\n因此，该技术值得我们进行深入分析其背后的机理，本系列大体分七篇文章进行讲解。\n大模型参数高效微调技术原理综述（一）-背景、参数高效微调简介 大模型参数高效微调技术原理综述（二）-BitFit、Prefix Tuning、Prompt Tuning 大模型参数高效微调技术原理综述（三）-P-Tuning、P-Tuning v2 大模型参数高效微调技术原理综述（四）-Adapter Tuning及其变体 大模型参数高效微调技术原理综述（五）-LoRA、AdaLoRA、QLoRA 大模型参数高效微调技术原理综述（六）-MAM Adapter、UniPELT 大模型参数高效微调技术原理综述（七）-最佳实践、总结\nLLM微调实战\n下面给大家分享 大模型参数高效微调技术实战 ，该系列主要针对 HuggingFace PEFT 框架支持的一些高效微调技术进行讲解。\n教程\n代码\n框架\n大模型参数高效微调技术实战（一）-PEFT概述及环境搭建 N/A HuggingFace PEFT\n大模型参数高效微调技术实战（二）-Prompt Tuning 配套代码 HuggingFace PEFT\n大模型参数高效微调技术实战（三）-P-Tuning 配套代码 HuggingFace PEFT\n大模型参数高效微调技术实战（四）-Prefix Tuning / P-Tuning v2 配套代码 HuggingFace PEFT\n大模型参数高效微调技术实战（五）-LoRA 配套代码 HuggingFace PEFT\n大模型参数高效微调技术实战（六）-IA3 配套代码 HuggingFace PEFT\n大模型微调实战（七）-基于LoRA微调多模态大模型 配套代码 HuggingFace PEFT\n大模型微调实战（八）-使用INT8/FP4/NF4微调大模型 配套代码 PEFT、bitsandbytes\n随着ChatGPT的爆火，大语言模型(LLM)得到了空前的关注。模型需要哪些核心技术，有没有代码实践教程？针对这些问题，推荐大家学习深蓝学院的《 生成式预训练语言模型：理论与实战 》课程，课程注重理论思想与代码实践相结合，最终带你从0到1制作自己的mini-ChatGPT。\n生成式预训练语言模型：理论与实战\nLLM分布式训练并行技术\n近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡模式已经无法满足超大模型进行训练的要求。因此，我们需要基于单机多卡、甚至是多机多卡进行分布式大模型的训练。\n而利用AI集群，使深度学习算法更好地从大量数据中高效地训练出性能优良的大模型是分布式机器学习的首要目标。为了实现该目标，一般需要根据硬件资源与数据/模型规模的匹配情况，考虑对计算任务、训练数据和模型进行划分，从而进行分布式训练。因此，分布式训练相关技术值得我们进行深入分析其背后的机理。\n下面主要对大模型进行分布式训练的并行技术进行讲解，本系列大体分九篇文章进行讲解。\n大模型分布式训练并行技术（一）-概述 大模型分布式训练并行技术（二）-数据并行 大模型分布式训练并行技术（三）-流水线并行 大模型分布式训练并行技术（四）-张量并行 大模型分布式训练并行技术（五）-序列并行 大模型分布式训练并行技术（六）-多维混合并行 大模型分布式训练并行技术（七）-自动并行 大模型分布式训练并行技术（八）-MOE并行 大模型分布式训练并行技术（九）-总结\n分布式AI框架\nPyTorch\nPyTorch 单机多卡训练 PyTorch 多机多卡训练\nMegatron-LM\nMegatron-LM 单机多卡训练 Megatron-LM 多机多卡训练 基于Megatron-LM从0到1完成GPT2模型预训练、模型评估及推理\nDeepSpeed\nDeepSpeed 单机多卡训练 DeepSpeed 多机多卡训练\nMegatron-DeepSpeed\n基于 Megatron-DeepSpeed 从 0 到1 完成 LLaMA 预训练 基于 Megatron-DeepSpeed 从 0 到1 完成 Bloom 预训练\n分布式训练网络通信\n待更新...\nLLM推理\nLLM推理框架\n大模型推理框架概述 大模型的好伙伴，浅析推理加速引擎FasterTransformer 模型推理服务化框架Triton保姆式教程（一）：快速入门 模型推理服务化框架Triton保姆式教程（二）：架构解析 模型推理服务化框架Triton保姆式教程（三）：开发实践 TensorRT-LLM保姆级教程（一）-快速入门 TensorRT-LLM保姆级教程（二）-开发实践 TensorRT-LLM保姆级教程（三）-基于Triton完成模型服务化 TensorRT-LLM保姆级教程（四）-新模型适配 TensorRT\nLLM推理优化技术\nLLM推理优化技术概述 PageAttention FlashAttention\nLLM压缩\n近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，从而导致模型变得越来越大，因此，我们需要一些大模型压缩技术来降低模型部署的成本，并提升模型的推理性能。 模型压缩主要分为如下几类：\n剪枝（Pruning） 知识蒸馏（Knowledge Distillation） 量化\nLLM量化\n本系列将针对一些常见大模型量化方案（GPTQ、LLM.int8()、SmoothQuant、AWQ等）进行讲述。\n大模型量化概述 量化感知训练： \n大模型量化感知训练技术原理：LLM-QAT 大模型量化感知微调技术原理：QLoRA PEQA\n训练后量化： \n大模型量化技术原理：GPTQ、LLM.int8() 大模型量化技术原理：SmoothQuant 大模型量化技术原理：AWQ、AutoAWQ 大模型量化技术原理：SpQR 大模型量化技术原理：ZeroQuant系列\n大模型量化技术原理：总结\nLLM剪枝\n结构化剪枝 ：\nLLM-Pruner\n非结构化剪枝 ：\nSparseGPT LoRAPrune Wanda\nLLM知识蒸馏\n大模型知识蒸馏概述\nStandard KD :\n使学生模型学习教师模型(LLM)所拥有的常见知识，如输出分布和特征信息，这种方法类似于传统的KD。\nMINILLM GKD\nEA-based KD :\n不仅仅是将LLM的常见知识转移到学生模型中，还涵盖了蒸馏它们独特的涌现能力。具体来说，EA-based KD又分为了上下文学习（ICL）、思维链（CoT）和指令跟随（IF）。\nIn-Context Learning：\nIn-Context Learning distillation\nChain-of-Thought：\nMT-COT Fine-tune-CoT DISCO SCOTT SOCRATIC CoT\nInstruction Following：\nLion\n低秩分解\n低秩分解旨在通过将给定的权重矩阵分解成两个或多个较小维度的矩阵，从而对其进行近似。低秩分解背后的核心思想是找到一个大的权重矩阵W的分解，得到两个矩阵U和V，使得W≈U V，其中U是一个m×k矩阵，V是一个k×n矩阵，其中k远小于m和n。U和V的乘积近似于原始的权重矩阵，从而大幅减少了参数数量和计算开销。\n在LLM研究的模型压缩领域，研究人员通常将多种技术与低秩分解相结合，包括修剪、量化等。\nZeroQuant-FP（低秩分解+量化） LoRAPrune（低秩分解+剪枝）\nLLM算法架构\n大模型算法演进 ChatGLM / ChatGLM2 / ChatGLM3 大模型解析 Bloom 大模型解析 LLaMA / LLaMA2 大模型解析 百川智能开源大模型baichuan-7B技术剖析 百川智能开源大模型baichuan-13B技术剖析\nLLM应用开发\n大模型是基座，要想让其变成一款产品，我们还需要一些其他相关的技术，比如：向量数据库（Pinecone、Milvus、Vespa、Weaviate），LangChain等。\n云原生向量数据库Milvus（一）-简述、系统架构及应用场景 云原生向量数据库Milvus（二）-数据与索引的处理流程、索引类型及Schema 关于大模型驱动的AI智能体Agent的一些思考\nLLM国产化适配\n随着 ChatGPT 的现象级走红，引领了AI大模型时代的变革，从而导致 AI 算力日益紧缺。与此同时，中美贸易战以及美国对华进行AI芯片相关的制裁导致 AI 算力的国产化适配势在必行。本系列将对一些国产化 AI 加速卡进行讲解。\n大模型国产化适配1-华为昇腾AI全栈软硬件平台总结 大模型国产化适配2-基于昇腾910使用ChatGLM-6B进行模型推理 大模型国产化适配3-基于昇腾910使用ChatGLM-6B进行模型训练 大模型国产化适配4-基于昇腾910使用LLaMA-13B进行多机多卡训练 大模型国产化适配5-百度飞浆PaddleNLP大语言模型工具链总结 大模型国产化适配6-基于昇腾910B快速验证ChatGLM3-6B/BaiChuan2-7B模型推理\nAI编译器\nAI编译器是指将机器学习算法从开发阶段，通过变换和优化算法，使其变成部署状态。\nAI编译器技术剖析（一）-概述 AI编译器技术剖析（二）-"
  },
  {
    "title": "《大模型核心技术与应用（微课视频版）哔哩哔哩_bilibili",
    "page_body": "书号：9787302695776 准备好拥抱大模型时代了吗？本书将手把手带你从入门到精通，解锁智能未来的无限可能！ 本书从大型模型的结构讲起，让读者了解大型模型的内部实现原理，然后讲解如何在特定任务下对大型模型进行预训练、有监督的微调，以及进行强化学习。通过对模型采用不同方法的训练，持续改进模型在特定任务上的性能。最后，本书将与读者一起探讨如何利用大型模型开发大模型时代的智能应用。 本书共9章，第1章讲解大型模型发展的历史及其带来的变革。第2章深入讲解大型模型内部结构的演进。第3章会尝试自己运行一个大模型。第4章介绍大型模型对模型训练和推理过程中带来的技术挑战和解决办法。第5章讲解如何进行大型模型的预训练以获取大模型的基本能力。第6章讲解如何对大模型进行有监督的微调，使大型模型输出与人类意图对齐。第7章讲解如何通过强化学习进一步提升大型模型的表现。第8章讲解如何对大模型进行评估。第9章讲解如何利用大模型构建智能应用。 本书适合有一定深度学习基础的读者，帮助他们从原理到应用，快速了解大型模型的原理、训练方法，并利用大型模型进行智能应用的开发。\n大模型"
  },
  {
    "title": "适合中学生上手使用的deepseek大模型训练",
    "page_body": "以下是专为中学生设计的**「零基础入门大模型训练」手把手教程**，用最通俗的语言和类比，带你一步步理解如何用DeepSeek训练自己的AI模型：\n---\n第一步：认识大模型——它就像一只聪明的“电子小狗”\n1. **什么是大模型？** \n - 想象你养了一只超级聪明的小狗，它需要学习大量指令（数据）才能听懂你的话。大模型就是这样的“电子小狗”，通过“吃”海量文本（比如书籍、网页）学会理解和生成语言。\n2. **为什么用DeepSeek？** \n - DeepSeek就像一家专门培养聪明小狗的宠物学校，提供现成的训练工具和教材（开源代码和模型），让普通人也能轻松训练AI。\n---\n第二步：准备“狗粮”——收集训练数据\n1. **数据是什么？** \n - 数据就是小狗要学习的“知识”。比如你想让AI写古诗，就给它喂《唐诗三百首》；想让它聊天，就喂对话记录。\n2. **中学生友好数据源（免费！）** \n - **古诗数据**：GitHub搜索“Chinese-poetry数据集” \n - **科普问答**：Kaggle平台上的“Science QA”数据集 \n - **漫画对话**：从B站字幕中提取（需家长同意） \n - *小技巧：数据量不用太大，先试试1000条！*\n---\n第三步：选择“训练场地”——用DeepSeek的在线工具\n1. **注册DeepSeek平台** \n - 访问[DeepSeek官网](https://www.deepseek.com/)，点击“免费试用”（需家长协助注册）。\n2. **选择“迷你训练营”模式** \n - 平台会提供预设好的训练模板，就像选择“小狗基础指令课”一样简单：\n - **任务类型**：选“文本生成”（写诗/对话） \n - **模型大小**：选“小模型”（训练更快，适合新手） \n - **上传数据**：把准备好的数据文件拖进去（支持txt/csv）\n---\n第四步：启动训练——点按钮就能开始！\n1. **设置参数（理解成“训练计划”）** \n - **学习次数（Epochs）**：3次（防止小狗学太久“累趴”） \n - **批处理大小（Batch Size）**：16（一次学16条，太快会记不住） \n - **学习率（Learning Rate）**：0.0001（小步慢走更稳妥）\n2. **一键启动** \n - 点击“开始训练”，等待进度条跑完（通常30分钟-2小时）。期间可以看平台提供的**动画教程**，了解背后原理。\n---\n第五步：测试成果——和你的AI玩游戏\n1. **基础测试** \n - 在输入框写下：“床前明月光”，看看AI会不会接“疑是地上霜” \n - 如果它回答“举头望明月”，说明训练成功！\n2. **创意挑战** \n - 让AI用“奥特曼”为主题写一首五言诗，观察是否押韵合理 \n - 如果结果搞笑（比如“怪兽被打倒，光之国有希望”），说明模型有创造力！\n---\n第六步：改进模型——像训练小狗纠正错误\n1. **发现问题** \n - 如果AI把“春风又绿江南岸”接成“可乐炸鸡真好吃”，说明数据中有垃圾食品广告混入。\n2. **清洗数据** \n - 删除无关内容，保留纯古诗文件，重新训练一次。\n3. **进阶技巧（可选）** \n - 在提示词中加入规则：“请严格按照七言绝句格式创作” \n - 使用“奖励机制”：给押韵正确的句子打高分，错误扣分\n---\n **中学生友好工具清单**\n| 工具名称 | 用途 | 使用难度 | \n|----------------|-----------------------|----------| \n| DeepSeek-Playground | 免代码在线训练 | ️ | \n| Google Colab | 运行Python代码（免费）| ️️ | \n| 文心一格 | 生成训练用图片素材 | ️ | \n---\n安全注意事项\n1. 不要上传个人隐私信息（如真实姓名、地址） \n2. 遇到复杂步骤时，优先使用平台预设选项 \n3. 训练失败很正常！多试几次就好，就像教小狗握手需要耐心～\n---\n实战案例：训练“赛博诗人”AI\n1. **目标**：让AI写出带“机甲”元素的五言诗 \n2. **数据准备**： \n - 收集100首《唐诗》+50条科幻小说段落 \n - 手动添加10条示例： \n `\"钢铁铸战甲，激光破夜空。智脑统千军，星际任驰骋。\"` \n3. **训练结果**： \n ``` \n 输入：机甲出征 \n 输出： \n 铁躯映寒光，引擎震九霄。 \n 芯片藏韬略，星海斩巨妖。 \n ``` \n4. **分享成果**：把生成的诗做成动态壁纸，在班级展示！\n---\n通过这个教程，你不仅能理解大模型的基本原理，还能亲手创造出有趣的AI应用。就像养电子宠物一样，训练次数越多，你的模型就会越聪明哦！"
  },
  {
    "title": "所有大学生注意了！专家解读《本科毕业论文（设计）抽检办法（试行）",
    "page_body": "严格学业管理 让学生忙起来\n北京理工大学校长、中国工程院院士 张军\n本科生是高素质专门人才培养的最大群体，本科阶段是学生世界观、价值观、人生观形成的关键阶段，高质量本科教育是提高高等教育质量的重要基础。当前，部分高校依然存在“重科研轻教学”的现象，人才培养中心地位和本科教学基础地位落实不充分，具体表现为教学管理水平不高、教师教学投入不足，以至于部分本科生大学4年里虚度时光、得过且过。\n中共中央、国务院印发的《深化新时代教育评价改革总体方案》，明确提出“严格学业标准。完善各级各类学校学生学业要求，严把出口关”。教育部日前出台的《本科毕业论文（设计）抽检办法（试行）》是切实落实《方案》要求，严把出口关的重要举措，是促进高校本科人才培养全环节提质增效、切实加强学业管理的有效手段，目标是让本科生专注学业、真正忙起来。文件的出台对于全面振兴本科教育、提升人才培养质量具有里程碑式的意义。\n01\n一是严格学业管理标准和制度\n按照《普通高等学校本科专业类教学质量国家标准》要求，改革本科人才培养方案，建立一整套涵盖课堂教学、实习实训等人才培养全环节，符合高校人才培养定位的本科生学业管理标准，提高毕业难度，让学生“有压力”；完善内部质量保障体系，建立一支高水平的教学督导队伍，对学业管理标准执行情况进行全过程监督，及时发现问题，及时整改。\n02\n二是压实教师教书育人责任\n突出人才培养中心地位和本科教学基础地位，提高教学工作在教师职称评聘、聘期考核和年度考核中的比重，明确考核指标，细化考核要求；督促教师严格执行学业管理标准，提高课堂教学、实践教学的授课质量和课业难度，倒逼学生专注学业、潜心学习；提高教师指导本科毕业论文（设计）工作量的考核标准，加大对教师指导过程的监督考核力度。\n03\n三是鞭策学生回归本分、潜心治学\n本科毕业论文（设计）是集中反映学生本科4年专业理论知识和专业实践能力的综合体，学生只有严格按照人才培养方案要求，认真学好每一门课、做好每一项实践，才能打牢完成本科毕业论文（设计）的基础，才能减少出现“问题论文”的可能。学校、教师应以本科毕业论文（设计）抽检工作为契机，做好学生的思想动员和宣传警示工作，引导学生端正学习态度，树立“诚信为本、潜心治学”的学习观念，回归课堂、回归实验室、回归图书馆，认真完成每一门课程的修读，做出高质量本科毕业论文（设计）。\n帮学生扣好学术规范“第一粒扣子”\n天津大学党委书记 李家俊\n2020年10月，中共中央、国务院出台了《深化新时代教育评价改革总体方案》，明确提出要严格学业标准，探索本科毕业论文（设计）抽检试点工作，完善博士、硕士学位论文抽检工作，严肃处理各类学术不端行为。近日，教育部出台《本科毕业论文（设计）抽检办法（试行）》，明确将学术规范作为考察内容，开展学术不端行为检测，突出了监督本科教育教学质量底线的工作定位，在国家层面建立了主动发现、查处学术不端的工作体系，有助于引导本科生刻苦读书、踏实求学，扣好学术规范的“第一粒扣子”。《办法》在很多方面体现了改革和创新，有以下五大亮点：\n01\n一是主动出击提高工作效率\n部分高校已经建立了毕业论文质量管理体系，但缺乏评价其有效性的手段。本科毕业论文抽检对每一篇抽到的论文均进行检测，经专家评审后，将涉嫌存在学术不端的情况反馈有关高校，按程序调查处理，既建立了政府部门对学术不端行为的主动发现机制，又提供了高校发现问题进而改进问题的途径。\n02\n二是全覆盖监督增强威慑力\n本科毕业论文抽检每年进行一次，采取随机抽取的方式抽检上一学年度授予学士学位的论文，覆盖本地区所有本科层次普通高校及其全部本科专业。由此可见，从《办法》实施起，每一篇本科毕业论文都有被抽到的可能，对心存侥幸者形成了强大的威慑。\n03\n三是人技结合保障检测效果\n与单纯依靠查重来判定学术不端不同，本科毕业论文抽检首先基于大数据进行文章重复率检测，再将检测结果提供专家评审参考，做到了将信息技术核查和专家评价有机结合，综合评价更加全面准确。\n04\n四是国家层面建立统一平台\n《办法》提出，由教育部建立全国本科毕业论文抽检信息平台，面向各省开放，提供学术不端行为检测功能，实现了国家和地方的信息共享，形成了发现、查处本科毕业论文作假行为的立体化工作网络。\n05\n五是强化问责多元使用结果\n《办法》对不能保证本科毕业论文质量的学校、教师、学生均提出了问责手段：对于“存在问题毕业论文”较多或比例较高的学校，将采取通报、质量约谈、限期整改等举措，抽检结果还将作为本科教育教学评估、一流本科专业建设、本科专业认证以及专业建设经费投入等教育资源配置的重要参考依据；对于有关教师，要求高校调查其人才培养责任落实情况，依规予以追责；对于查实存在学术不端行为的学生，将依规撤销学位。\n健全抽检体系 保障培养质量\n中国政法大学校长 马怀德\n为贯彻落实中共中央、国务院《深化新时代教育评价改革总体方案》等文件精神，教育部于日前公布了《本科毕业论文（设计）抽检办法（试行）》，决定开展本科毕业论文（设计）抽检试点工作。《办法》有助于构建具有中国特色、体现时代使命和社会责任的论文抽检体系，助推新时代高等教育实现高质量发展。\n0\n1\n一是抽检体系更加完善\n建立论文抽检体系是建设高质量高等教育保障体系的重要组成部分。近年来，国家在研究生教育领域实施的博士硕士学位论文抽检制度，对推动学位授予单位落实第一主体责任，加强内部质量保证体系建设，保证研究生培养基本质量等方面具有巨大推动作用，已成为教育领域质量监督方面的一项品牌工程。开展本科毕业论文抽检，体现了国家从全局着眼，对构建具有中国特色的论文抽检体系加强顶层设计，标志着我国论文抽检体系的总体布局已基本形成，覆盖国家、省和高等学校3个行政层级，涉及博士、硕士、学士3个学位层次，不同学位层次抽检考察各有侧重。\n0\n2\n二是质量导向更加鲜明\n本科生作为高等教育人才培养的最大群体，其培养质量关乎国计民生。教育部在本科教育质量建设方面，已相继推出本科专业国家标准、一流本科“双万计划”、一流课程“双万计划”、基础学科“拔尖计划”等一系列改革举措，不断引领和激励高校提升本科教育质量。在这样的背景下，本科毕业论文抽检是完善高等教育质量保障体系方面的又一重要举措，肩负着新时代推动提高高等教育质量的重大使命，旨在督促高校落实立德树人根本任务，立足本科教育发展规律，以保证本科人才培养基本质量为核心，不断加强培养过程管理，强化质量文化建设，提高学校、教师和学生的质量意识。\n0\n3\n三是底线思维更加凸显\n树立高等教育领域底线思维，有助于大学生社会责任感的养成。本科毕业论文抽检重在考察本科生基本学术规范和基本学术素养，抽检能够反映出本科生在校期间的基本学业情况、思想道德品质和行为习惯，也能暴露出学校在人才培养过程中存在的薄弱环节。立足构建以立德树人、全面发展为导向的高等教育人才培养体系，本科毕业论文抽检将有助于更加清晰地把握本科教育的专业建设底线、课程教学底线、教师教育底线，还有助于增强学生诚信意识，减少学术不端倾向，是高等教育质量底线的“把关人”和“监护人”。\n推进本科毕业论文抽检“四步走”\n河北省教育厅一级巡视员 王廷山\n2017年起，河北省搭建学位论文信息管理平台，开展本科毕业论文抽检试点工作，省级教育主管部门和有关高校合力攻坚，经过几年探索和改进，在论文信息采集、抽检组织实施、格式规范及完善管理过程等方面已初见成效，探索出一条通过本科毕业论文抽检带动高等教育质量提升的有效途径。\n河北从搭建全省学位论文管理信息系统入手，以平台建设推动本科毕业论文抽检工作向纵深发展。整体来看，河北省论文管理平台建设与本科毕业论文抽检工作大体分4个阶段来推进。\n第一阶段搭建平台，实现论文网上采集\n自2017年起，河北着手搭建学位论文管理信息系统，实现论文采集的信息化，明确提出了3个目标：一是全面查找论文存在的质量问题；二是以全部采集论文数据为基础，组建全省高校比对库，作为共享资源供省内高校检测使用；三是适时正式启动本科毕业论文抽检工作。\n第二阶段扩展平台功能，实现论文的网上评阅\n在论文采集的基础上，对论文进行重复率检测，并按专业覆盖面、院校覆盖面等维度设定一定比例进行抽检。在管理系统中有效拓展论文网上评阅功能，专家通过登录管理平台对抽检论文进行评阅。\n第三阶段完善平台建设，强化“平台+过程”管理\n以论文抽检为抓手，推动平台过程管理模块开发，立足对论文的全过程“留痕”管理。印发《河北省本科毕业论文写作指南》指导论文写作程序、内容及规范，并要求各高校着手搭建论文过程管理系统与省级论文管理平台对接，为下一步全面铺开抽检工作奠定了基础。\n第四阶段发挥平台资源优势，为政府决策提供依据\n目前，河北省学位论文信息管理平台已实现了对全省所有普通本科、成人教育本科毕业获得学士学位人员的毕业论文、毕业设计、作品阐述/报告的全覆盖采集。平台提供的数据，可以为了解高校的教学质量和办学水平提供大数据支撑，还能与其他相关行业、部门的数据库对接，实现数据资源共享，为政府决策提供依据。\n2019年河北全省正式开展本科毕业论文抽检工作，采集2018—2019学年度本科毕业论文168637篇。为了横向比较论文质量，了解学校之间论文水平的差异，抽选论文样本覆盖所有高校，各高校抽样比例大体相当，重点抽选了法学、会计学、工商管理等9个专业，全省共抽检4917篇论文，每篇论文分别选聘3位专家进行线上评阅，最终认定“问题论文”114篇。\n（来源：《中国教育报》）\nRECOMMEND\n原标题：《所有大学生注意了！专家解读《本科毕业论文（设计）抽检办法（试行）》》\n阅读原文"
  },
  {
    "title": "4、小语教科研论文 多媒体与课堂教学有效整合的研究-360文档中心",
    "page_body": "基于“雨课堂”的混合式教学模式探析\n基于“雨课堂”的混合式教学模式探析1. 优化课堂教学传统的课堂教学存在着内容单一、互动性不足的问题，学生的学习兴趣和参与度往往不高。\n而基于“雨课堂”的混合式教学模式可以通过将在线课程与课堂教学相结合，有效提高课堂教学效果。\n教师可以在“雨课堂”上发布教学视频、课件、习题等资源，学生可以在课前进行预习，并提前了解要学习的知识点，课堂时间可以更多地用于师生互动和问题解答。\n教师可以在“雨课堂”上进行在线作业布置和批改，对学生的学习情况有一个更加全面的了解。\n2. 个性化学习基于“雨课堂”的混合式教学模式可以更好地满足学生的个性化学习需求。\n学生可以根据自己的学习进度和兴趣，选择适合自己的学习资源进行学习，学习过程更加自主和灵活。\n教师可以通过“雨课堂”平台对学生的学习情况进行跟踪和分析，针对学生的差异化需求进行个性化指导和辅导。\n3. 提高学生学习动力基于“雨课堂”的混合式教学模式可以利用信息技术手段来增强学生的学习动力。\n通过多媒体教学资源的丰富，如视频、动画、图片等，可以更好地激发学生的学习兴趣，提高他们对知识的接受和理解。\n教师可以在“雨课堂”上设置学习任务和竞赛，激发学生的学习积极性，提高学生的学习动力。\n1. 提高教学效果混合式教学模式可以更好地激发学生的学习兴趣和积极性，提高学生对知识的接受和理解。\n教师可以通过“雨课堂”平台更好地了解学生的学习情况，及时调整教学策略，提高教学效果。\n2. 促进师生互动“雨课堂”平台可以为师生之间的互动提供更多便利。\n学生可以在平台上提问、讨论和交流，教师可以及时回答学生的问题，进行教学指导，促进师生之间的良好互动关系。\n1. 教师技能和素质混合式教学模式对教师的信息化素养和教学能力提出了更高的要求。\n教师需要掌握信息技术知识，熟练使用“雨课堂”平台进行教学设计和管理，同时需要具备更强的教学能力和素质，能够有效地指导和引导学生的学习。\n2. 学生学习习惯混合式教学模式需要学生具备一定的自主学习能力和习惯，能够独立进行在线学习和任务完成。\n基于“雨课堂”的混合式教学模式的研究\n基于“雨课堂”的混合式教学模式的研究一、混合式教学模式的概念及特点混合式教学是指将传统面对面教学与在线远程教学相结合的一种教学方式。\n它旨在充分发挥教师的作用，同时利用现代信息技术和多媒体手段，为学生提供更加个性化、多样化的学习机会。\n混合式教学强调教师和学生之间的互动和合作，注重学生自主学习和自主探究的能力培养。\n混合式教学模式的特点主要包括以下几个方面：它突破了传统教学的时间和空间限制，让学生可以随时随地进行学习；它提供了更加丰富多样的学习资源和途径，使得学生可以通过多种方式获取知识；它强调了学生个性化学习和自主探究的重要性，培养了学生的自主学习能力和解决问题的能力。\n二、“雨课堂”混合式教学平台的特点和应用“雨课堂”是一种基于互联网的在线教学平台，它结合了在线直播、录播、实时互动等多种功能，为教学提供了更加多样化和个性化的途径。\n通过“雨课堂”，教师可以进行在线直播授课，学生可以通过电脑、平板或手机随时随地进行学习，还可以在直播过程中和教师进行互动交流，提问和思考。\n“雨课堂”混合式教学平台的特点主要包括以下几个方面：它突破了传统教学的时间和空间限制，使得教学可以更加灵活和自由；它提供了多样化的教学资源和形式，教师可以根据学生的实际需求和兴趣选择不同的教学方式和内容；它强调了教师和学生之间的互动和合作，促进了教师和学生之间的密切联系和联系，提高了教学效果和教学质量。\n近年来，越来越多的教育工作者开始将“雨课堂”引入到自己的教学实践中，探索和研究基于“雨课堂”的混合式教学模式。\n这些实践研究主要包括以下几个方面：1. “雨课堂”在高等教育中的应用研究有些教育工作者在高校教学中引入了“雨课堂”，并进行了一系列的实践探索和研究。\n他们发现，“雨课堂”可以有效地提高教师和学生之间的互动和合作，激发学生的学习积极性和学习兴趣，促进了课堂教学的质量和效果。\n尽管“雨课堂”混合式教学模式取得了一些积极的成果和效果，但也存在一些问题和挑战。\n基于“雨课堂”的高职语文有效性教学策略研究\n基于“雨课堂”的高职语文有效性教学策略研究一、雨课堂在高职语文教学中的应用现状雨课堂是一款以移动互联网技术为基础的在线教学平台，它可以实现课堂互动、课后复习、作业布置等多种教学功能。\n在高职语文教学中，教师可以通过雨课堂来设置课堂问答、课堂测验、课外阅读等教学内容，学生也可以在平台上进行学习、讨论和作业提交。\n相比于传统的教学方式，雨课堂为高职语文教学带来了更多的可能性和便利性。\n目前，在高职语文教学中，越来越多的教师开始尝试使用雨课堂来进行教学。\n他们通过布置作业、设置课堂互动环节、上传课件等方式，使得学生可以通过手机或电脑随时随地进行学习和交流。\n在教学效果方面，雨课堂也得到了一定的肯定，许多教师和学生都感受到了它带来的便利和高效。\n2.1 建立互动式教学环节在高职语文教学中，利用雨课堂建立起互动式的教学环节是非常重要的。\n教师可以通过设置课堂问答、课堂测验、课外阅读等环节，来引导学生对课堂内容进行深入思考和交流。\n这样一来，不仅可以增强学生的学习兴趣，还可以提高他们的学习主动性和参与度。\n学生在参与互动环节的过程中也能够更好地巩固和应用所学知识，从而提升学习效果。\n2.2 引导学生进行线上学习和交流利用雨课堂，教师可以引导学生进行线上学习和交流。\n教师可以在平台上上传课件、发布学习资料、布置作业等，让学生可以通过雨课堂来进行学习和讨论。\n学生也可以在平台上提出问题、参与讨论、提交作业等，加强和教师之间和学生之间的交流与互动。\n这种线上学习和交流的方式，不仅有助于丰富课堂教学内容，还可以为学生提供更多自主学习的机会和平台。\n2.3 创新作业布置和批改方式利用雨课堂，教师可以创新作业布置和批改方式，使得作业可以更加及时、有效地进行。\n教师可以通过平台来布置各种类型的作业，比如选择题、填空题、解答题等，通过设置限时提交、实时批改等功能，可以更好地对学生的作业进行管理和指导。\n这样一来，不仅可以提高作业的质量，还可以让学生更好地掌握所学知识。\n“雨课堂”在教学应用中的问题和思考\n“雨课堂”在教学应用中的问题和思考我们来分析一下“雨课堂”在教学应用中存在的问题。\n二、教学效果问题尽管“雨课堂”在理论上可以提高教学效果，但在实际应用中也存在一些教学效果问题。\n学生在家中参加远程教学时，往往会受到外界环境的干扰，比如家庭成员的影响、家中电视机的声音等，导致学生的注意力无法完全集中在课堂上，从而影响了教学效果。\n由于“雨课堂”是一种全新的教学应用工具，学生和老师对其不够熟悉，导致在使用过程中出现了许多操作问题，进一步影响了教学效果。\n一、技术问题思考针对“雨课堂”在技术方面存在的问题，我们可以提出一些建议。\n对于网络连接不稳定的问题，可以适当地增加带宽和优化网络设备，以提高网络的稳定性和可靠性。\n对于手机设备的差异性问题，可以由学校统一对学生进行手机设备的配备，或者通过其他方式来解决这一问题。\n也可以通过对“雨课堂”进行技术升级和优化，来提高其对于不同手机设备的适配性，从而解决这一问题。\n二、教学效果问题思考针对“雨课堂”在教学效果方面存在的问题，我们可以提出一些建议。\n可以利用一些教学辅助工具，比如通过设置家庭学习专区、提醒学生家人保持安静等方式来提高学生在家中参加远程教学时的注意力和专注度。\n可以通过对学生进行“雨课堂”使用方法的培训和指导，来帮助他们熟悉“雨课堂”的操作，从而提高教学效果。\n也可以通过对“雨课堂”进行教学方式的优化和改进，来提高其对教学效果的促进作用。\n“雨课堂”在教学应用中虽然存在一定的问题，但通过我们的思考和建议，相信这些问题都是可以解决的。\n我们可以通过技术的改进和优化、教学效果的提高和教学方式的优化，来进一步提升“雨课堂”的教学应用效果，为教育教学事业做出更大的贡献。\n希望未来“雨课堂”能够更好地应用于教学中，为教育教学事业带来更大的发展和进步。\n基于“雨课堂”的互动式智慧教学模式改革研究与实践\n基于“雨课堂”的互动式智慧教学模式改革研究与实践一、互动式智慧教学模式的理论基础互动式智慧教学模式是以互联网和信息技术为基础，利用多媒体、网络平台等工具，以促进教师和学生之间的互动与合作，提高教学效果的教学模式。\n在互动式智慧教学模式中，教师不再是传统意义上的知识传授者，更多地是引导者和辅助者。\n学生则在教师的引导下自主学习、合作学习，并通过互动模式获得知识。\n二、雨课堂的特点及应用雨课堂是一款基于互联网技术的在线教学平台，具有以下特点：1.多媒体教学：雨课堂提供了多种多样的教学工具，可以将教学内容以多媒体形式呈现给学生，使学生更加直观地理解知识点。\n2.互动交流：雨课堂提供了强大的互动交流功能，学生可以通过平台进行问题反馈、讨论、作业提交等交流活动，促进教师和学生之间的互动。\n3.自主学习：雨课堂支持学生自主学习，学生可以根据自身的学习需求和进度进行学习，提高学习的积极性和学习效果。\n4.精准评价：雨课堂通过相关数据分析，能够对学生的学习情况进行精准评价，为教师提供针对性的教学建议。\n雨课堂的应用主要包括以下几个方面：1.在线授课：教师可以通过雨课堂进行在线授课，通过多媒体教学工具将课件、视频等教学资源展示给学生，实现信息的传递和知识的学习。\n2.互动讨论：学生可以在雨课堂中与教师以及其他学生进行互动讨论，提出问题、分享经验、解决问题等。\n3.在线作业：教师可以通过雨课堂设置在线作业，通过平台对学生提交的作业进行批改和评价，提供教学反馈。\n4.学习资源共享：教师可以在雨课堂上分享自己的教学资源，供其他教师和学生使用，提高资源的共享和利用效率。\n在雨课堂互动式智慧教学模式的实践中，我们可以采取以下方法进行教学：1.激发学生的主动学习能力：通过设定任务、鼓励学生分享和讨论等方式，激发学生的主动学习能力，提高学生的学习"
  },
  {
    "title": "LLM学习笔记：最好的学习方法是带着问题去寻找答案_腾讯新闻",
    "page_body": "作者：huaxing\n知其然，然后知其所以然。本文主要是对学习赛博活佛Andrej Karpathy 7个小时教学视频的总结和拓展阅读笔记，推荐去看原视频，很精彩，链接在文末。从最常用的聊天应用过程分析开始，引入对话过程原理浅析，再到LLM训练过程；再结合当前主流的应用形式，在得知最新用法的同时，加深对LLM的理解；再谈谈AI的最新重大进展MCP；以及作为JAVAer，在Java领域有哪些前沿能力去整合LLM。\n最后再罗列一下再公司内部一些AI平台、工具。最好的学习方法是带着问题去寻找答案，以费曼学习法为标准，产出可教学的资料。本文是个人所学梳理和所想记录，作为AI的小白，个人知识有限，难免有所错误、疏漏，请及时纠偏、不吝赐教，感谢。\n1 大模型聊天过程分析\n我打开AI聊天窗口https://chat.deepseek.com，发送我的Query：\n1.1 流程浅析\n当我们开始一个LLM聊天对话，输入问题时，实际上大模型托管服务有内置的上下文信息，在我们输入信息，按下发送按钮时，大模型收到的是内置上下文 + 系统服务Prompt + 用户输入信息。\n大模型经过神经网络的概率统计（权重拟合)得到下一个要说的词，通过流式响应逐个词丢回会话窗口，用户就能看到大模型“正在打字”和我们聊天。“打字”的速度就是大模型响应的速度，通常看描述LLM性能的一个指标N token/s。\n1.2 原理浅析\n本质就是从输入的 tokens 推测下一个 token 的出现概率，将可能性较高的作为输出token，再将得到的token添加到输入中，直到满足结束条件（上下文长度限制、结束符以较高概率出现、用户定义的停止条件、概率阈值与采样策略、模型架构的隐式结束符）。所以LLM本质上是一个具有统计概率的知识记忆模糊的知识回顾系统，也可简称概率性复读机。那么这个回顾系统是怎么实现的呢，“zip文件”怎么得来的？构建一个现代的LLM三个步骤：**预训练、后训练（SFT）和强化学习（RL\\RLHF)**。\n1.3 预训练\n在预训练过程中，需要有原始数据和验证数据，所以通常可以将数据集分为两份，例如90%用于训练，10%用于验证（具体比例可能因任务调整）。\n1.3.1 数据集\n数据集生成流程：\n列举主流网站的URL\n有害网站URL过滤，垃圾站点、成人内容等\n从URL网站响应的富文本提取文字内容\n文本语言过滤，如仅针保留英文或者中文内容，在huggingface上数据集语言分布前5如下图：\nGopher 过滤，去除无意义、低信息量或有害内容（如垃圾文本、暴力、偏见等）\nMinHash 去重，用于快速检测并移除数据集中的重复或近似重复的文本片段（如文档、段落或句子）。其核心目的是减少数据冗余，避免模型因重复数据过拟合或偏向高频内容，同时节省计算资源。\nC4 过滤，C4（Colossal Clean Crawled Corpus） 数据集进行清洗和筛选的步骤，旨在从原始网页文本中提取高质量、多样化的语料，同时去除噪声、重复和低效内容。\nCustom Filters（自定义过滤器）目标是针对通用过滤方法（如MinHash去重、C4/Gopher过滤）无法覆盖的领域特殊性问题，进行更精细化的数据质量控制。\nPII Removal（个人身份信息移除） 是指从原始数据中识别并删除或匿名化 个人身份信息（Personally Identifiable Information, PII） 的关键步骤，旨在保护用户隐私、遵守数据保护法规（如GDPR、CCPA），并降低模型泄露敏感信息的风险。\n预训练数据集示例：\n1.3.2 Tokenization\n可以看到OpenAI对数据结构化了，定义了对话角色，增加了<|im_start|>、<|im_sep|>、<|im_end|>这样的标识符用于分割对话，这些标识符都对饮一个token，“You are a helpful assistant”的tokens序列是“3575, 553, 261, 10297, 29186”。\nTokenization（分词/令牌化）是将输入文本拆分为模型可处理的离散单元（Token）的过程，即将文本数据表示为token的一维序列。它是自然语言处理（NLP）中的关键步骤，直接影响模型对文本的理解能力和效率。\n数据集的原始文本数据量非常大，如著名的FineWeb数据集就有15万亿个token，总共44TB大小，需要高效拆分文本窗口，在能表达混合多种语言、复杂字符表达等情况，但不丢失语义。分词实际上就是一层映射包装，过粗、过细的分词都不利于训练和模型性能表现，分词过细（如字符级、字节级别、比特级别）导致长序列，计算开销大，分词过粗（如单词级）则词汇表爆炸，内存占用高。\n采用BPE（Byte-Pair Encoding，如GPT）、WordPiece（如BERT）或SentencePiece，将文本转化为子词（subword）单元。BPE算法（Byte-Pair Encoding）：平衡词汇表大小与序列长度。\n原始文本：\n原始字节\ntokenization：\n对话过程中输入的token越多，越分散注意力，降低模型准确性和性能，节约成本。不丢失信息的情况，越短越好，性能成本都会提升。所以，聊不同的主题应该单独开会话窗口。\n1.3.3 词汇表\n在tokenization过程中，我们发现，在44TB的文本内容里，很多词一起出现的概率较高，如图中49305后面出现17，那么就可以将49305与17合并成4930517，作为一个新的token，重复如此。最后，再将所有词汇压缩到最小映射表，重新编号token，这样就得到了一份可以还原44TB内容的词汇表。如GPT-4词汇表是100277个。主流大语言模型的词汇表大小如下（按数值从小到大排序）：\n原版LLaMA 词汇表大小为  32,000  （32K），但中文token较少（仅几百个）。 中文LLaMA/Alpaca 通过合并中文tokenizer后，词汇表扩展至  49,953  （约50K）。 优化后的实验模型\n部分研究将词汇表从32K扩展至  43,000  （43K），显著提升下游任务性能。 理论预测的Llama2-70B最优词表大小为  216,000  （216K），但尚未实际部署。\n多语言模型（如XLM-R、Bloom） 词汇表普遍较大，约  250,000  （250K）。\n1.3.4 数据分片\n将大规模训练数据集划分为多个逻辑或物理片段（Shard）的技术，目的是实现高效的数据并行处理和分布式训练。\n数据分片的核心作用：\n解决内存与存储限制 ：单个节点无法加载全部数据，分片后每个节点仅处理部分数据。 并行加速训练 ：不同分片由不同计算设备并行处理（如GPU），缩短训练时间。 容错性 ：单个分片损坏或失败时，只需重新处理该分片，而非整个数据集。\n我们知道数据集是一张表，所以数据分片的方式方法和传统结构化数据分片类似，但这里要结合训练过程的实际情况做调整，数据分片常见方法：\n静态分片，预先规划好分片，每个GPU固定处理指定分片，优点实现简单，缺点是实际训练过程中可能导致GPU负载不平衡，因为数据集中的每一行长度是不同的，所以会导致数据倾斜。 动态分片，训练过程中动态分配数据（如通过中央调度器或分布式文件系统），优点：自动平衡负载，适应数据异构性。缺点：实现复杂，需额外协调开销（如Apache Spark或Ray框架）。 分片与数据管道的结合，流水线加载：当一个GPU处理当前分片时，异步预加载下一个分片（隐藏I/O延迟）；格式优化：分片常存储为高效二进制格式（如TFRecord、HDF5），加速读取。\n1.3.5 模型架构选择\n当前主流LLM通常是采用Transformer结构，包含自主力(Self-Attention)和多头注意力(Multi-Head Attention)的注意力层、前馈神经网络(FFN)，注意力层+FFN等模块组成一层，需要确定模型的层数和参数量。\n主流架构 ：Transformer（基于自注意力机制），常见变体：\nDecoder-only （GPT系列）：适合生成任务，单向注意力掩码。 Encoder-decoder （T5、BART）：适合翻译等序列到序列任务。\n规模参数 ：\n层数（L）：12-100+（如GPT-3 davinci版本包含96层） 隐藏层维度（d_model）：768-12,288 注意力头数（h）：12-128\nTransformer结构 ：\n自注意力机制 ：计算输入序列中每个位置的关联权重（如多头注意力）。 前馈网络（FFN） ：每个注意力层后接非线性变换。 层数与参数量 ：例如，GPT-3有1750亿参数，包含96层Transformer块。\n1.3.6 训练任务设计、执行和优化\n预训练任务设计\n自监督学习 ：无需人工标注，通过文本自身生成监督信号。\n因果语言建模（CLM） ：预测下一个Token，目标函数：\n掩码语言建模（MLM） ：随机遮盖部分Token并预测（如BERT），遮盖比例通常15%。\n混合目标 ：如UniLM结合双向和单向预测。\n训练执行\n训练过程\n分布式训练，并行策略执行、通信优化，每一轮训练（单步训练）流程包括：\n数据加载与预处理，可以是分布式数据加载，或动态批次构建。 前向传播（含激活重计算） 反向传播 梯度同步（数据并行） 参数更新（含梯度裁剪）\nTransformer结构的训练通常需要经过上万轮的训练，即上万个训练步数，训练时会充分利用GPU并行的特性，在分布式训练中并行，包括数据并行、模型并行、张量并行、流水线并行，且总GPU数 = 数据并行度 × 模型并行度。\n数据并行（Data Parallelism） ：将批次（Batch）划分为多个子批次（Sub-batch），分配到不同GPU上并行处理。 模型并行（Model Parallelism） ：\n张量并行（Tensor Parallelism） ：将单个矩阵运算拆分到多GPU（如Megatron-LM）。 流水线并行（Pipeline Parallelism） ：将模型层拆分到多GPU（如GPipe）。\n举例GPT-3的预训练情况，加深直观理解：\n参数量：1750亿 训练数据：约3000亿token 训练步数：约94000步（批量大小3.2M tokens/步，3000亿/3.2M 约等于94000） 耗时：数周（使用数千张A100 GPU） 上下文大小：原始上下文长度是2048 Tokens，硬件显存和注意力计算复杂度的权衡结果，Transformer的自注意力机制计算复杂度为 O(n2)（n为序列长度），导致显存和计算成本随序列长度急剧增长。\n这里批量大小和上下文大小的关系是：序列数=批次大小/上下文长度=3.2*10^6/2048≈1562 个序列/步，批次大小是并行训练的序列数量，而上下文长度是单个序列的长度。这里对tokenization后的数据集进行切分为一个个小块（chunk），这个chunk的大小就是上下文窗口长度（context window），chunk的大小是序列长度，批次大小是同时处理的chunk数量，训练批次总token数是两者的乘积。\n单轮训练结果\n在预训练的阶段，每一轮预训练训练的结果是得到一个基础模型（Base Model），这个模型可以预测每一个输入序列tokens的下一个token，可能每个词汇token都会有一个概率，这里是统计性和概率性的结果，是对训练数据集的回放。\n上图得到的next token ID 是19348(\" Direction\")，但是我们期望的是3962（\" Post\"）概率更高一些。所以，在完成一轮训练后，我们会用测试数据集进行测试，计算Lost函数，并将拟合偏离反馈到神经网络的参数调整上，这样下一轮训练后，token ID 3962（\" Post\"）的概率就会更高一些。\n整个训练的过程，我们逐步调整参数权重，这种权重的参数有上亿个，如DeepSeek R1满血版参数量是671B("
  },
  {
    "title": "Transformer的ffn对于所有token参数共享吗?-知乎",
    "page_body": "结论先行：Transformer中的FFN（前馈神经网络）对所有token共享参数，这在标准实现中是一致的。它是1个nn.Linear（实际上是两个线性层组成的FFN），参数在所有8个token上共享，而不是为每个token使用8个不同的nn.Linear。\n Transformer模型中的FFN（前馈神经网络）通常对所有token共享参数。这意味着，无论序列中有多少token（例如8个），FFN都会使用相同的参数来处理每个token，而不是为每个token创建单独的网络。\n 在处理形状为(bs, 8, 768)的特征时，FFN由两个线性层组成，中间有一个激活函数（如ReLU）。这些线性层的参数在整个序列的所有位置上是共享的。在深度学习框架如PyTorch中，当你将张量输入到nn.Linear层时，它会自动对每个token应用相同的线性变换，因此参数是共享的。\n 参数共享的设计允许模型高效地处理变长序列，并且保持了模型的参数数量与序列长度无关。这也是Transformer能够并行处理序列的关键特性之一。\n FFN的参数共享方式与注意力机制类似，查询（queries）、键（keys）和值（values）在计算时也共享参数，这使得Transformer在处理长序列时保持了高效性。\n Transformer模型由Vaswani等人在2017年的论文“Attention is All You Need”中提出，其中FFN被描述为每个编码器和解码器层中的一个组成部分。论文明确指出，FFN是“position-wise”的，即对每个位置（token）单独且相同地应用。这意味着，FFN的线性变换参数在序列的所有位置上是共享的。\n 具体来说，FFN通常由以下形式定义：\n 公式为：[公式] ，其中 [公式] 和 [公式] 是权重矩阵， [公式] 和 [公式] 是偏置项。这些权重在整个序列上共享。\n 在实际实现中，例如在PyTorch或TensorFlow的Transformer模块中，FFN被实现为一个单一的神经网络模块，应用于输入张量的最后一个维度。例如，对于形状为(bs, 8, 768)的输入，nn.Linear(768, d_ff)会自动对每个token（即序列中的8个向量）应用相同的线性变换。这种设计确保了参数的共享性。\n 从计算效率的角度看，参数共享是必要的。如果为每个token使用不同的参数，模型的参数数量会随着序列长度线性增长，这在处理长序列时会变得不可行。例如，对于序列长度为1000的输入，如果不共享参数，参数数量会显著增加，训练和推理成本也会随之上升。\n 综上所述，FFN在Transformer中对所有token共享参数，这不仅符合理论设计，也在实际实现中得到了广泛应用。一个意想不到的细节是，FFN的参数共享方式与注意力机制的共享参数类似，这两者共同构成了Transformer高效处理序列的核心能力。"
  },
  {
    "title": "毕业论文结论范文(精选8).docx-原创力文档",
    "page_body": "内容提供方 ： 180****8306 大小 ： 35.88 KB 字数 ： 约8.71千字 发布时间 ： 浏览人气 ： 4 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n毕业设计（论文）\nPAGE\n1-\n毕业设计（论文）报告\n题目：\n毕业论文结论范文(精选8)\n学号：\n姓名：\n学院：\n专业：\n指导教师：\n起止日期：\n毕业论文结论范文(精选8)\n摘要：本文以……为研究对象，通过对……的研究，分析了……，探讨了……，提出了……，为……提供了有益的参考。本文的研究成果有助于……，对……的发展具有积极意义。本文的研究方法主要包括……，研究数据来源于……，研究结论为……。\n随着……的发展，……问题日益凸显。本文旨在探讨……，以期为……提供理论支持和实践指导。本文的研究背景、研究意义、研究方法、研究内容、研究结论等方面进行了详细的阐述。\n第一章引言\n1.1研究背景\n(1)随着我国经济的快速发展和城市化进程的不断推进，城市交通拥堵问题日益严重。据《中国城市交通报告》显示，截至2020年底，全国城市道路拥堵指数达到6.5，其中一线城市拥堵情况最为严重。以北京市为例，2019年北京市机动车保有量已超过600万辆，而城市道路里程仅为6200公里，道路拥堵成为市民出行的一大难题。这不仅影响了居民的日常生活，也对城市的可持续发展产生了负面影响。\n(2)此外，城市交通拥堵还导致了能源浪费和环境污染。据统计，我国城市交通领域碳排放量占总碳排放量的比例逐年上升，已成为我国碳减排的重要领域。以上海市为例，2018年城市交通领域碳排放量达到1.1亿吨，占上海市总碳排放量的27.5%。此外，交通拥堵还会引发交通事故，增加社会成本。据《中国交通事故统计年鉴》显示，2019年全国共发生交通事故514万起，造成死亡6.4万人，受伤56.5万人。\n(3)针对城市交通拥堵问题，我国政府和社会各界都在积极探索解决方案。近年来，我国大力发展公共交通，推广新能源汽车，优化交通管理，提高道路通行效率。例如，北京市在2019年投入运营的公交专用道达到300公里，有效缓解了公交车辆通行压力。同时，上海市积极推进“互联网+交通”模式，通过智能交通系统优化交通信号灯配时，提高道路通行效率。然而，城市交通拥堵问题仍然严峻，需要进一步研究和探索有效的治理策略。\n1.2研究意义\n(1)研究城市交通拥堵问题对于提高城市交通系统运行效率具有重要意义。随着城市化进程的加快，城市交通拥堵已经成为制约城市发展的重要瓶颈。通过对交通拥堵问题的深入研究，可以揭示其成因和发展趋势，为城市交通规划和治理提供科学依据。同时，优化交通系统设计可以有效降低能源消耗和减少环境污染，推动绿色低碳城市发展。此外，研究城市交通拥堵问题还有助于提升市民出行满意度，促进社会和谐稳定。\n(2)从经济角度看，城市交通拥堵直接影响了城市生产效率和经济发展。拥堵导致的时间延误、车辆损耗以及交通事故等，增加了企业的运营成本，降低了劳动生产率。通过对交通拥堵问题的深入研究，可以提出有效的交通治理策略，提高道路通行效率，降低交通成本，从而为城市经济增长提供动力。同时，合理的交通规划还能够促进城市空间布局优化，吸引投资，推动产业结构调整。\n(3)从社会角度看，城市交通拥堵问题关系到市民的日常生活质量和城市文明程度。拥堵不仅使市民出行时间增加，还可能导致交通事故频发，危及生命财产安全。因此，研究城市交通拥堵问题，有助于提高城市管理水平，保障市民出行安全，提升城市文明程度。同时，通过对交通拥堵问题的研究，可以增强公众对交通问题的认识，提高公众参与城市交通治理的积极性，形成全社会共同参与交通治理的良好氛围。\n1.3研究方法\n(1)本研究采用定性与定量相结合的研究方法。首先，通过文献综述和实地调研，对城市交通拥堵问题的现状、成因和发展趋势进行定性分析。收集国内外相关研究成果，总结城市交通拥堵问题的普遍规律和特殊现象，为后续研究提供理论基础。\n(2)在定量分析方面，本研究主要运用统计学方法对交通数据进行分析。收集城市交通流量、车速、道路状况等数据，运用SPSS、Excel等统计软件进行数据处理和模型构建。通过对数据的统计分析，揭示城市交通拥堵的影响因素和作用机制，为提出有效的治理策略提供数据支持。\n(3)此外，本研究还采用案例分析法，选取具有代表性的城市交通拥堵案例进行深入剖析。通过对案例的深入研究，总结成功经验和失败教训，为其他城市交通拥堵治理提供借鉴。同时，结合实地调研和专家访谈，对案例进行分析和评估，以期为城市交通拥堵治理提供更加全面和深入的见解。\n1.4研究内容\n(1)本研究首先对城市交通拥堵的现状进行分析。以某城市为例，据统计，该城市高峰时段道路拥堵长度平均达到30公里，高峰时段交通延误时间超过20分钟。通过对城市交通拥堵状况的深入分析，揭示了交通拥堵与城市人口、车辆保有量、道路网络布局等因素之间的关系。\n(2)其次，本研究探讨城市交通拥堵的成因。以某城市为例，分析发现，该城市交通拥堵的主要成因包括城市规划不合理、公共交通发展滞后、交通需求管理不足等。通过对这些成因的剖析，本研究提出了相应的对策建议，如优化城市空间布局、发展公共交通、加强交通需求管理等。\n(3)最后，本研究提出城市交通拥堵治理策略。以某城市为例，提出以下治理措施：一是加强交通基础设施建设，提高道路通行能力；二是优化公共交通网络，提高公共交通服务水平；三是实施交通需求管理，引导市民绿色出行；四是采用智能交通技术，提升交通管理效率。通过对这些治理策略的实施效果进行评估，本研究旨在为其他城市提供可借鉴的经验和参考。\n第二章文献综述\n2.1国内外研究现状\n(1)国外关于城市交通拥堵的研究起步较早，主要集中在交通流理论、交通需求管理、交通规划与设计等方面。以美国为例，自20世纪50年代以来，美国学者对城市交通拥堵问题进行了深入研究。其中，交通流理论的研究成果为交通拥堵的预测和控制提供了理论基础。例如，格林希尔茨（Greenhilts）提出的流量-密度关系模型，被广泛应用于交通拥堵预测。同时，美国在交通需求管理方面也取得了显著成果，如实施交通需求管理政策、推广公共交通、鼓励绿色出行等。以洛杉矶为例，通过实施交通需求管理措施，成功降低了城市交通拥堵程度。\n(2)在欧洲，城市交通拥堵问题同样受到广泛关注。以英国为例，英国交通研究实验室（TRL）对城市交通拥堵问题进行了深入研究，提出了交通拥堵指数（CTI）等评估方法。此外，英国政府还通过立法和政策手段，推动城市交通拥堵治理。例如，伦敦实施拥堵收费政策，有效降低了市中心交通拥堵。在欧洲其他城市，如巴黎、柏林等，也采取了类似的措施，如限制私家车进入市中心、发展公共交通等。\n(3)我国城市交通拥堵问题近年来日益突出，引起了学术界和政府的高度重视。国内学者对城市交通拥堵问题的研究主要集中在以下几个方面：一是城市交通拥堵成因分析，如城市规划、交通需求、交通设施等；二是城市交通拥堵治理策略，如交通需求管理、公共交通发展、交通基础设施建设等；三是城市交通拥堵评估方法，如拥堵指数、出行时间等。以某城市为例，该城市通过实施公共交通优先、交通需求管理等措施，有效缓解了交通拥堵问题。然而，我国城市交通拥堵问题仍然严峻，需要进一步深入研究，以期为城市交通拥堵治理提供更加科学、有效的策略。\n2.2相关理论概述\n(1)在城市交通拥堵问题的研究中，交通流理论是一个重要的理论基础。该理论主要研究交通流量、速度、密度等参数之间的关系，以及它们如何影响道路通行效率。交通流理论包括多种模型，如线性理论、流体动力学模型和微观模拟模型等。这些模型有助于预测交通拥堵发生的概率和程度，为交通规划和治理提供科学依据。\n(2)交通需求管理理论是另一个与城市交通拥堵问题密切相关的重要理论。该理论关注如何通过政策、经济手段和宣传教育等手段，引导和调整交通需求，以减少交通拥堵。交通需求管理策略包括限制车辆使用、提高公共交通吸引力、鼓励绿色出行等。这些策略旨在平衡交通供需关系，提高交通系统运行效率。\n(3)城市交通规划理论则是城市交通拥堵问题研究的核心理论之一。该理论涉及城市交通系统的布局、设计和管理，旨在通过合理的城市规划和交通设施建设，优化交通系统，缓解交通拥堵。城市交通规划理论包括交通需求预测、交通系统规划、交通设施布局等。这些理论为城市交通系统的可持续发展提供了指导原则，有助于实现城市交通系统的整体优化。\n2.3研究空白与不足\n(1)在现有关于城市交通拥堵问题的研究中，虽然已经取得了一定的成果，但仍然存在一些研究空白。首先，对于城市交通拥堵成因的深入分析仍有待加强。尽管已有研究指出了城市规划、交通需求、交通设施等因素对交通拥堵的影响，但对于这些因素之间的相互作用和复杂关系，还需进行更为细致的研究。例如，城市规划与交通需求之间的动态关系，以及交通设施建设与交通拥堵之间的滞后效应，这些都是目前研究较少涉及的领域。\n(2)其次，现有研究在交通需求管理策略方面存在不足。虽然交通需求管理被认为是缓解交通拥堵的有效手段，但现有策略的实施效果和可持续性仍有待评估。例如，现有的拥堵收费政策在实际操作中可能存在公平性问题，同时，如何结合不同城市的特点，制定具有针对性的交通需求管理策略，也是当前研究的空白。此外，交通需求管理的长期效果评估机制尚不完善，难以准确评估政策实施对城市交通系统的影响。\n(3)最后，城市交通拥堵问题的研究方法也存在一定的局限性。现有的研究方法多采用定量分析，如统计分析、模型模拟等，而定性研究相对较少。这种研究方法的单一性可能导致对城市交通拥堵问题的全面认识不足。例如，在城市交通拥堵问题的研究中，定性研究可以更深入地了解市民出行需求、出行习惯和出行心理，这些因素对于制定有效的交通拥堵治理策略具有重要意义。因此，未来研究需要结合定量和定性研究方法，以更全面地分析和解决城市交通拥堵问题。\n第三章研究方法与数据\n3.1研究方法\n(1)本研究采用定量分析与定性分析相结合的方法，以期为城市交通拥堵问题提供全面的研究视角。在定量分析方面，本研究收集了某城市近三年的交通流量、车速、道路状况等数据，运用SPSS、Excel等统计软件进行数据处理和分析。通过对数据的统计分析，揭示了城市交通拥堵的时空分"
  },
  {
    "title": "Transformer 学习笔记-CSDN博客",
    "page_body": "一、Transformer 的诞生背景与 优势\n传统序列 模型 （如  RNN /LSTM）受限于循环计算的串行特性，难以并行处理长序列，且长距离依赖问题显著。2017 年，Vaswani 等人在《Attention Is All You Need》中提出 Transformer 架构 ，彻底摒弃循环与 卷积 ，仅依赖注意力机制实现序列建模，成为 自然语言处理 领域的里程碑。\n两大显著优势：\n1.可捕获间隔较长的语义关联。\n2.充分利用分布式GPU进行并行训练，提升模型训练效率。\n二、Transformer 整体架构\nTransformer 总体架构包括四部分：输入、输出、编码器、解码器。\n（一）输入层\n1.词嵌入（Token Embedding）\n对输入的文本以单词为单位进行切分，再对单词序列编码，使用独热向量表达，再将独热向量映射为低维向量，可通过Word2Vec实现。\n2.位置编码（Positional Encoding）\n思路历程：整数位置编码→二进制位置编码→正弦位置编码\n为弥补注意力机制缺乏时序信息的缺陷，通过正弦 / 余弦函数生成位置向量，公式为：\n（二）、编码器（Encoder）\n由多个同样的编码器块组合而成\n1. 多头自注意力层（Multi-Head Self-Attention）\n注意力机制基本思想：“移动”量由 其他 词的意义(值)和其他词与当前词相关度决定。\n自注意力机制：\n（1）由每个编码器的输入向量生成三个向量，即查询向量、键向量和一个值向量。这三个向量是通过词嵌入与三个权重矩阵相乘后创建出来的。将以上所得到的查询向量、键向量、值向量组合起来就可以得到三个向量矩阵Query、Keys、Values。\n（2）计算得分。我们需要拿输入句子中的每个单词对目标单词进行打分。这些分数是通过所有输入句子的单词的键向量与“目标单词”的查询向量相点积来得到的。\n（3）将分数除以8(让梯度更稳定，这里也可以使用其它值),然后进行softmax处理。得到的softmax分数决定了每个单词对编码当下位置单词的贡献。\n（4）将每个值向量乘以对应softmax分数(以此来关注语义上相关的单词，并弱化不相关的单词),最后对加权值向量求和，即得到自注意力层在该位置的输出。\n多头自注意力机制：使用多组矩阵得到多组查询、键、值矩阵，然后每组分别计算得到一个Z矩阵，再得到最终的Z矩阵。这扩展了模型专注于不同位置的能力。\n2.前馈全连接层：Add（ 残差连接 ）、 Norm（层归一化）。\n（三）解码器（Decoder）\n解码器同样由N=6个层堆叠，每层包含三大子层：\n1. 掩码多头自注意力层\n掩码操作(mask)：计算注意力时，每一个新词(query)只能和之前出现的词进行相关运算。\n2. 多头自注意力层  与编码器相同\n3. 前馈 全连接层   与编码器相同\n（四）输出层\n由线性层和Softmax层串联而成。\n线性层：通过对上一步的线性变化得到指定维度的输出，也就是转换维度的作用.\nSoftmax层:使最后一维的向量中的数字缩放到0-1的概率值域内，并满足他们的和为1."
  },
  {
    "title": "关于印发《2016年湖南省“深化考试招生制度改革背景下的教与考”专题研修实施方案》的函-湖南省教育厅",
    "page_body": "湖南省中小学教师发展中心\n湘教师中心函 [2016] 3 号\n关于印发《2016年湖南省“ 深化考试招生制度 改革背景下的教与考”专题研修实施方案》的函\n各市州教育局、教师培训机构：\n为了全面贯彻党的教育方针，进一步落实《国务院关于深化考试招生制度改革的实施意见》精神，及时回应社会关切，解疑析惑，营造良好的考试招生改革氛围，推动基础教育的改革深化，引导教师正确把握高考方向，探索 “ 新高考改革中，基础教育怎么办 ” 这个热门课题，特在全省范围内组织开展 “ 深化考试招生制度改革背景下的教与考 ” 专题研修（研修实施方案见附件）。请 各地根据教师队伍建设的实际情况以及教师的实际需要，认真组织广大高中教师参加该项目的专题研修，建设好研修工作的管理队伍和辅导教师队伍，加强研修过程管理，确保研修质量。\n请各市州教育局和教师培训机构认真研究，做出培训计划，并把计划情况与省 中小学教师发展中心 远程培训与资源建设科衔接。\n联系方式：电话  0731-88607760 ； 邮箱 hnycpx@163.com 。\n附件： 2016 年湖南省“深化考试招生制度改革背景下的教与考”专题研修实施方案\n 2016 年 2 月 24 日\n附件：\n2016 年湖南省“深化考试招生制度改革背景下的  “ 教与考”专题研修实施方案\n为全面贯彻落实《国务院关于深化考试招生制度改革的实施意见》（国发〔 2014 〕 35 号）的文件精神，加大对改革方案和政策的宣传解读力度，及时回应社会关切，解疑释惑、凝聚共识，营造良好的考试招生改革氛围，帮助高中学校和教师掌握高考招生制度改革背景下的新政策，提高教学水平，特此制订本实施方案。\n一、 培训目标\n1. 帮助高中教师和教学管理人员掌握高考招生制度改革背景下的相关政策。 \n2 . 帮助高中学科教师梳理自身在高考改革背景下学科教学中存在的问题，明白高考招生制度改革背景下考什么、教什么及怎么教。\n3. 帮助高中学科教师研读2016年高考考试大纲，解析历届经典高考试题，提高教学水平。\n二、培训对象\n全省高中学科教师及教学管理人员。 参加培训者应具备上网条件和网上交流能力，保证培训期间平均每天不少于1小时的网络研修与交流时间。\n三、研修时间\n各市州、市县区可根据培训需求，任选某个时间阶段组织培训，项目组为高考每个学科提供50课时左右的网络课程资源，通过教师工作坊组织20学时网络校本研修。\n四、研修课程\n本次专题培训课程分为四个模块，具体培训内容见下表：\n课程模块\n课程名称\n课程简介\n课时\n模块一\n深化考试招生制度改革的背景意义及政策解读\n贯彻党的十八届三中全会精神，全面深化教育领域综合改革\n教育部长袁贵仁结合中央决策部署、教育形势变化和热点难点问题，对十八届三中全会精神的基本内涵和深化教育领域综合改革的重点任务做了详细介绍。\n4\n深化教育领域综合改革，推进考试招生制度改革\n主讲人在回顾我国招生考试制度发展与作用的基础上，深入分析了现有考试招生制度改革的动因和面临的挑战，认为改革重心应该放在招生计划、入学考试和录取机制三方面，进而提出了以“遵循规律、试点先行”为核心的五项改革实施路径，以保障教育的公平与公正。\n3\n关于普通高中学业水平考试和综合素质评价两个《意见》的解读说明\n教育部郑富芝司长阐释了两个文件的主要内容和精神实质，并就广大中学师生和家长们集中关心的一些热点问题，如高中学业水平考试怎么考，成绩如何纳入高考；综合素质评价怎么进行，如何确保评价的公平公正等，以及各地需要进一步落实的工作内容为我们做了详尽的解读。\n4\n我国基础教育之改革与治理\n从六个方面对我国基础教育改革与治理问题进行论述：包括基础教育资源配置，基础教育考试招生，基础教育学校制度，基础教育育人过程，基础教育教师队伍建设，基础教育督导监测。\n3\n“十三五”时期基础教育改革发展政策走向\n“十三五”时期是我国基本实现教育现代化的决定性阶段，随着我国经济进入新常态，实施创新驱动发展战略，加快转方式、调结构，要求科学谋划“十三五”时期教育事业发展，进一步加快教育改革发展步伐，加快基本实现教育现代化。本讲重点阐释了基础教育改革发展的政策走向。\n4\n积极稳妥推进考试招生制度改革\n主讲人对考试招生制度改革的政策进行了解读，详细介绍了改革的背景、产生的过程、改革的要点以及对学校的影响。\n4\n落实十八届三中全会精神，推动基础教育改革发展\n主讲人将十八届三中全会关于深化教育领域综合改革的论述归纳为三个要点：把全面贯彻教育方针、全面实施素质教育作为核心要求；把大力促进教育公平、大力提高教育质量作为两大战略重点；把考试招生制度改革、教育治理体系创新作为两个重要抓手。针对每一个要点，主讲人分析了现状，解读了政策，预测了发展趋势。\n4\n模块一\n深化考试招生制度改革的背景意义及政策解读\n新高考改革对中学办学的影响\n从本次改革与30多年来高考改革的关系、对本次改革基本原则和总体目标的理解、“分类考试 多元录取”的理论基础、新高考改革的实践对接、新高考改革后值得关注的问题等五个方面，理论联系实际地研讨了新高考改革的机遇与挑战。\n3\n追求更高水平的招生公平\n主讲人以上海市贯彻35号文件精神而提出的“追求更高水平的公平”为切入点，先是深入阐释了公平的两个基本原则，即“基本权利均等分配，非基本权利按规则分配”、“同等的人同等对待，不同的人区别对待”，然后举例解析了考试招生过程中出现的异地高考、地区差异、城乡差异和阶层差异等热点问题。\n2\n模块二\n深化考试招生制度改革背景下考什么、教什么、如何教\n深化考试招生制度改革背景下考什么？\n在本次访谈中，各学科的权威专家围绕“深化考试招生制度改革背景下考什么”这个热门话题，对35号文件精神进行了深入解读，回应了社会对此次考试招生制度改革的关切点。\n1\n深化考试招生制度改革背景下怎么教？\n本次访谈中，各学科的权威专家围绕“深化考试招生制度改革背景下怎么教”这个热门话题，对35号文件精神进行了深入解读，回应了社会对此次考试招生制度改革的关切点。\n1\n深化考试招生制度改革背景下教什么？\n本次访谈中，各学科的权威专家围绕“深化考试招生制度改革背景下教什么”这个热门话题，对35号文件精神进行了深入解读，回应了社会对此次考试招生制度改革的关切点。\n1\n深化考试招生制度改革背景下\n“教”与“考”系列讲座——数学学科\n本次系列讲座中，主讲人结合历年高考真题，就本轮考试招生制度改革对数学学科的指导思想，为我们梳理了高考数学内容改革的基本思想，深入解读了数学学科高考命题的基本思路，重点给出了数学学科的教学建议，如提高运算能力、培养“直观想象”的数学素养、养成数学思维方法、训练多角度的解题思路、整体把握高中数学等。\n8\n深化考试招生制度改革背景下\n“教”与“考”系列讲座——语文学科\n本次系列讲座中，主讲人结合历年高考真题及自身教学经验，从培养学生的语文素养出发，就本轮考试招生制度改革对语文学科的指导思想，解读了语文学科高考命题中阅读与教学的设计原则及教学对策，无论是阅读教学还是写作教学，都应引导学生探究文字背后的规律，领会文字蕴含的意境，体验到学习的乐趣，以达到自主成长。\n5\n深化考试招生制度改革背景下\n“教”与“考”系列讲座——英语学科\n在本次系列讲座中，主讲人结合历年高考真题，就本轮考试招生制度改革对英语学科的指导思想，解读了英语学科高考命题的设计原则及教学对策，深入阐释了语篇型试题的特点——语境真实、语言地道，并指出了解答语篇型试题的能力培养和方法技巧。\n5\n模块二\n深化考试招生制度改革背景下考什么、教什么、如何教\n深化考试招生制度改革背景下\n“教”与“考”系列讲座——物理学科\n本次系列讲座中，主讲人结合历年高考真题，就本轮考试招生制度改革对物理学科的要求，分析了物理学科高考命题与教学之间的关系，解读了高考试题中的难度、区分度、题量等指标，重点阐释了学习物理学科所应具备的能力要求，对物理学科教学过程中应注意的问题进行了说明。\n6\n深化考试招生制度改革背景下\n“教”与“考”系列讲座——化学学科\n本次系列讲座中，主讲人结合历年高考真题，就本轮考试招生制度改革对化学学科的指导思想，深入解读了化学学科高考命题的基本思路，重点给出了化学学科的教学建议，如重视认知过程、培养学科能力、理解教材原型、提炼分析模型、构建知识网络等。\n5\n深化考试招生制度改革背景下\n“教”与“考”系列讲座——生物学科\n本次系列讲座中，主讲人结合历年高考真题，就本轮考试招生制度改革对生物学科的指导思想，为我们解读了高考内容改革的基本思想和生物学科高考试题的设计理念，分析了生物学科高考命题思路对教学的启示，提出了改进课堂教学、科学备考复习的建议。\n6\n深化考试招生制度改革背景下\n“教”与“考”系列讲座——政治学科\n本次系列讲座中，主讲人结合历年高考真题，就本轮考试招生制度改革对政治学科的指导思想，为我们解析了2015年高考试题的特点与要求，综合近三年全国课标试题的能力要求走向，整体上提出了政治学科教学改进重点，并从经济生活、政治生活、文化生活、哲学生活四个维度，分别提出了具体的教学建议。\n5\n深化考试招生制度改革背景下\n“教”与“考”系列讲座——历史学科\n本次系列讲座中，主讲人结合历年高考真题，就本轮考试招生制度改革对历史学科的要求，精心解读了历史学科高考命题的基本原则、思路和方法，深入阐释了历史学科的知识观、能力观和教学观，进而指出了如何进行历史学科的复习，如何提高历史学科的核心素养，以及如何培养历史学科的解决问题能力。\n6\n深化考试招生制度改革背景下\n“教”与“考”系列讲座——地理学科\n本次系列讲座中，主讲人结合历年高考真题，就本轮考试招生制度改革对地理学科的指导思想，为我们阐述了高考内容改革的基本理念，重点分析了当前命题思路对教育教学的启示，进而提出了深化地理学科教学改革的相关建议。\n6\n模块三\n2016 年高考考试大纲专家研读\n2016 年高考考试大纲专家研读\n——数学\n主要讲解2016年高考数学考试的性质、命题指导思想、试卷结构以及数学考试的知识要求、能力要求和题型示例解析\n5\n2016 年高考考试大纲专家研读\n——语文\n主要讲解2016年高考语"
  },
  {
    "title": "学术交流|武汉大学测绘遥感信息工程国家重点实验室王密教授：大模型赋能智能摄影测量：现状、挑战与…澎湃号·政务_澎湃新闻-The Paper",
    "page_body": "大模型赋能智能摄影测量：现状、挑战与前景\n王密\n,1, 程昫\n,1, 潘俊1, 皮英冬1, 肖晶2\n1.武汉大学测绘遥感信息工程国家重点实验室，湖北 武汉 430079\n2.武汉大学计算机学院，湖北 武汉 430072\n摘要\n大模型从深度学习和迁移学习技术发展而来，依靠大量的训练数据和庞大的参数容量产生规模效应，从而激发了模型的涌现能力，在众多下游任务中展现了强大的泛化性和适应性。以ChatGPT、SAM为代表的大模型标志着通用人工智能时代的到来，为地球空间信息处理的自动化与智能化提供了新的理论与技术。为了进一步探索大模型赋能泛摄影测量领域的方法与途径，本文回顾了摄影测量领域的基本问题和任务内涵，总结了深度学习方法在摄影测量智能处理中的研究成果，分析了面向特定任务的监督预训练方法的优势与局限；阐述了通用人工智能大模型的特点及研究进展，关注大模型在基础视觉任务中的场景泛化性以及三维表征方面的潜力；从训练数据、模型微调策略和异构多模态数据融合处理3个方面，探讨了大模型技术在摄影测量领域当前面临的挑战与发展趋势。\n关键词\n 大模型；智能摄影测量；深度学习；多模态\n作者简介\n第一作者：王密（1974—），男，博士，教授，博士生导师，主要研究方向为高精度智能卫星遥感技术。E-mail：wangmi@whu.edu.cn\n通讯作者: 程昫 E-mail：xucheng@whu.edu.cn\n基金项目\n国家重点研发计划(2022YFB3902804)；国家杰出青年科学基金(62425102)\n本文引用格式\n王密, 程昫, 潘俊, 皮英冬, 肖晶. 大模型赋能智能摄影测量：现状、挑战与前景[J]. 测绘学报, 2024, 53(10): 1955-1966 doi:10.11947/j.AGCS.2024.20240068.\nWANG Mi, CHENG Xu, PAN Jun, PI Yingdong, XIAO Jing. Large models enabling intelligent photogrammetry: status, challenges and prospects[J]. Acta Geodaetica et Cartographica Sinica, 2024, 53(10): 1955-1966 doi:10.11947/j.AGCS.2024.20240068.\n作为测绘科学体系下的分支学科，摄影测量学是通过影像研究信息的获取、处理和成果表达的一门信息科学[1-2]。广义上，摄影测量利用多时相、多尺度、多视角、多模态的天空地一体化综合观测手段[3]，可以提供不同时间分辨率、空间分辨率和波谱分辨率的二维图像和空间三维信息，发展并扩充到遥感范畴，同时结合导航定位、地理信息系统、计算机视觉和人工智能等多门学科的前沿技术，实现地球空间信息的数字化与基础空间数据框架的构建[4]。\n人工智能的概念从20世纪60年代提出至今，在算力、算法方面历经多次革新。ImageNet数据集[5]推动了监督预训练范式下深度学习模型的发展，在图像分类、目标检测和语义分割等基础视觉任务上超越了经典的特征工程与机器学习方法。随着数据和模型规模不断扩大，传统AI逐步迈入AI大模型时代。一些基于超大规模数据集训练的千亿参数大模型，如GPT系列[6]，在自然语言处理任务中表现出强大的性能，并逐步触达视觉及音频处理领域。从技术角度上看，大模型背后的一系列支撑理论如深度神经网络、自监督学习和迁移学习等方法早已具备广泛的研究基础，规模效应催化了大模型的涌现能力[7]。与面向特定任务的中小规模神经网络相比，大模型能够适应多种类型的下游任务，可以在未经明确训练的任务上表现出强大的泛化能力。\n以深度学习为主流的人工智能技术推动了摄影测量智能化发展[8]。尽管经典的摄影测量方法具有严密的数学理论，已广泛运用于近景、航空和卫星场景，从深度学习出发探讨新的解决方法仍具意义。从概念上来看，深度学习方法扩充了原本基于点、线的特征表达，通过引入不同尺度的语义信息改善传统方法的性能，在语义与几何一体化处理方面具有天然优势。然而，现有方法往往无法扩展到数据集之外的场景。大模型则有望为广泛的下游任务提供同质化的基础网络架构，在模型通用性与适应性方面取得突破[9-10]。\n为了进一步探讨AI大模型时代下摄影测量智能处理的新范式，本文首先对摄影测量领域的基本问题和任务内涵进行回顾；其次，总结深度学习方法在摄影测量智能处理中的研究成果，分析面向特定任务的监督预训练方法的优势与局限；然后，阐述通用人工智能大模型的特点及研究进展，关注大模型在基础视觉任务中的场景泛化性以及三维表征方面的潜力；最后，从训练数据、微调策略和异构多模态融合处理3个方面，展望当前阶段摄影测量领域结合大模型能力所面临的挑战与发展趋势。\n1\n摄影测量的基本问题与任务内涵\n1.1 基本问题\n摄影测量的发展历程是技术进步和应用需求相互促进的结果。从模拟摄影测量、解析摄影测量到数字摄影测量，每一阶段都显著提升了数据处理的效率和测量的精度，现今正步入智能摄影测量的时代。从测绘的角度看，摄影测量的基本问题可以归纳为3个方面：解析问题、对应问题和语义问题。\n解析问题，通常指的是从影像等摄影测量数据中解算摄影时刻相机和被摄物体几何信息的一类问题，包含相机标定、相机定向与三维重建等方面的具体内容。成像过程往往根据严格的数学物理模型进行模拟，如共线方程、共面方程、光束法平差，以及计算机视觉领域提出的运动恢复结构和多视角立体等方法，从而保证空间三维坐标的解算精度和效率达到较高水平。在控制信息的约束下，解算后的影像、三维模型、DEM和DSM等对地观测产品被纳入统一坐标系，为新获取的数据及后续分析提供空间基准。\n对应问题，需要确定两个或多个影像中相同物体或特征点的匹配关系，从而建立观测数据的关联性。在立体摄影测量和多视角重建中，特征匹配、密集匹配过程都涉及从不同角度拍摄的影像中寻找同名点的过程。面对弱纹理、重复纹理或因视角和光照变化而导致的地物外观差异等问题，一方面需要构建特征点的可靠描述，另一方面需要剔除异常匹配，进而形成对于特征表征的稳健性与唯一性的两大要求。此外，在多传感器综合观测体系下，不同来源的数据在尺度、光谱特征及成像机理方面的差异，为解决对应性问题带来新的挑战。\n语义问题，关注于理解和解释影像内容的含义，即从影像中识别和分类对象，并理解它们在现实世界中的角色和关系。在摄影测量中，通常包括从航空或卫星图像中识别建筑物、道路、植被等常见要素，以及加入时间维度后的变化监测任务等。然而，语义问题并非仅仅关注识别和分类地物，更需要理解对象在不同语义层次上的关系和作用。解决语义问题的核心，在于将数据驱动与知识驱动的方法相结合，使机器代替人类专家准确高效地获取有意义、可操作性强的信息，支撑后续推理与决策。\n这3个问题共同构成了摄影测量学的核心挑战，解决这些问题需要综合运用数学、物理、计算机科学和地理信息科学的知识和技术。\n1.2 任务内涵\n随着摄影测量技术的不断发展，摄影测量任务的内涵与边界也不断扩充与延伸。早期的摄影测量主要用于地图绘制和简单的地形测绘，这些工作通常依赖于大型模拟摄影测量设备，借助光学或机械交会等物理测图手段避免复杂计算，如使用立体测图仪对比影像中的同名点，手动进行测绘。在解析摄影测量时代，电子计算机根据像点与相应地面点间的数学关系，使用数字投影代替物理投影实时解算被摄物体的空间位置。然而，对应性问题并未很好解答，往往需要大量的人工干预和专业知识，耗时且效率低下。随着数字成像技术的发展，摄影测量开始向数字化转型，减少了对物理照片的依赖，提高了数据处理的速度和精度。数字图像处理、模式识别和计算机视觉领域相关技术的发展极大提高了摄影测量的效率和应用范围，包括使用算法自动识别图像中的特征点，自动完成图像对应和配准。随着无人机技术、航天载荷及遥感技术的进步，摄影测量能够提供实时或近实时的数据采集和处理能力，使得自然资源管理、城市规划、灾害响应等领域变得更加高效和精确。人工智能和深度学习技术的应用极大地增强了摄影测量的能力，特别是在图像识别、分类和语义分析方面，通过自动解释和分析图像内容，提供高度精确的地理信息和决策支持。\n摄影测量的发展历程体现了从传统测绘任务向高效、实时、自动化与智能化信息服务的转变。现代摄影测量系统应当能够集成包括卫星数据、无人机数据和地面观测数据等多种数据源，并结合先进的计算技术、大数据分析和人工智能技术，提供不仅限于地图制作、环境保护、自动驾驶和智慧城市建设等多个领域综合的智能信息服务，以满足不断增长的社会和经济需求。\n2\n深度学习在摄影测量领域的应用\n以深度学习为代表的人工智能技术一方面改善了遥感语义特征提取的完整性和可靠性，另一方面通过与广义控制资料结合，提升了多源遥感影像几何处理的精度和自动化水平，开辟了摄影测量语义与几何信息智能处理的方向。图1展示了深度学习在摄影测量领域的相关应用。\n图1 深度学习在摄影测量领域的相关应用\n深度学习方法扩充了原本基于点、线的特征表达，卷积神经网络能够捕获场景中的高级语义特征，学习到影像之间抽象的共同模式。SuperPoint[11]提出一种端到端的特征提取与描述网络，能够提取更为密集的特征点，并且在立体像对的单应关系上获得更准确的估计。在匹配层面，与传统启发式规则相比，SuperGlue[12]利用基于注意力机制的图神经网络，在端到端架构上同时执行上下文聚合、匹配和过滤等策略并实现GPU实时处理，是深度学习匹配算法的一个里程碑。多源遥感数据时空谱融合方面，深度学习方法对于不同波段、成像模式等带来的非线性辐射差异和大视角变化带来的几何差异具有较好的稳健性[13]。\n深度学习能够自动识别卫星和航空影像中的建筑、道路、水体等各种地物，广泛运用于语义专题图制作[14]、地表常态化与智能化检测[15]等测绘任务，极大提高了从航空和卫星图像中提取信息的速度和准确性。基于MaskRCNN的分割算法代替了超像素分割等传统方法，能够提供包含对象类别信息的精确分割掩膜。在三维语义处理方面，MVCNN[16-17]将多视角影像的分割结果映射到三维目标表面，利用已有的二维分割网络完成三维形状的语义分割任务，但存在三维到二维的信息损失和跨视角语义兼容性等问题。一些研究[18-19]将卷积操作应用于三维体素网格，然而基于体素的方法存在离散采样带来的分辨率下降及三维卷积开销等问题。PointNet[20]、PointNet++[21]为点云处理提供了强大高效的特征提取器，但点云未明确定义邻域及连通性，不利于局部特征的描述。MeshCNN[22]为非结构化三维数据重新设计了卷积和池化操作，实现基于多边形网格的三维表征与拓扑处理。然而，三维语义方面的研究仍然存在训练数据缺乏、模型复杂度较高导致推理速度较慢、计算机内存"
  },
  {
    "title": "数据模型（维度建模）潇湘灬隐者-博客园",
    "page_body": "前言 ：\nmodel对于数仓是最核心的东西，数据模型是数据组织和存储方法，模型的好坏，决定了数仓能支撑企业业务多久。\n为什么大多数企业，数仓都要重建，这不仅仅是业务拓展、发展迅速，很大一部分是因为模型建的很烂。\n01. 基本概念\n维度建模，是数据仓库大师Ralph Kimball提出的，是数据仓库工程领域最流行的数仓建模经典。\n维度建模以分析决策的需求出发构建模型，构建的数据模型为分析需求服务，因此它重点解决用户如何更快速完成分析需求，同时还有较好的大规模复杂查询的响应性能。\n它是面向分析的，为了提高查询性能可以增加数据冗余，反规范化的设计技术。\n1.1 事实表\n事实表产生于业务过程，存储了业务活动或事件提炼出来的性能度量。从最低的粒度级别来看，事实表行对应一个度量事件。\n事实表根据粒度的角色划分不同，可分为事务事实表、周期快照事实表、累积快照事实表。\n（1） 事务事实表 ，用于承载事务数据，通常粒度比较低，它是面向事务的，其粒度是每一行对应一个事务，它是最细粒度的事实表，例如产品交易事务事实、ATM交易事务事实。\n（2） 周期快照事实表 ，按照一定的时间周期间隔(每天，每月)来捕捉业务活动的执行情况，一旦装入事实表就不会再去更新，它是事务事实表的补充。用来记录有规律的、固定时间间隔的业务累计数据，通常粒度比较高，例如账户月平均余额事实表。\n（3） 累积快照事实表 ，用来记录具有时间跨度的业务处理过程的整个过程的信息，每个生命周期一行，通常这类事实表比较少见。\n注意： 这里需要值得注意的是，在事实表的设计时，一定要注意一个事实表只能有一个粒度，不能将不同粒度的事实建立在同一张事实表中。\n1.2 维度表\n维度表，一致性维度，业务过程的发生或分析角度，我们主要关注下退化维度和缓慢变化维。\n（1） 退化维度 （DegenerateDimension）\n在维度类型中，有一种重要的维度称作为退化维度，亦维度退化一说。这种维度指的是直接把一些简单的维度放在事实表中。退化维度是维度建模领域中的一个非常重要的概念，它对理解维度建模有着非常重要的作用，退化维度一般在分析中可以用来做分组使用。\n（2） 缓慢变化维 （Slowly Changing Dimensions）\n维度的属性并不是始终不变的，它会随着时间的流逝发生缓慢的变化，这种随时间发生变化的维度我们一般称之为缓慢变化维（SCD）。\nSCD常用的三种处理方式：\n① TYPE1 直接覆盖原值\n② TYPE2  增加维度行\n在为维度成员增加新行时，需为其分配新的主代理键。 并且，至少需要在维度行再增加三列： 有效日期、截止日期、行标识。 这个地方可联想拉链表设计。\n③  TYPE3 增加属性列 \n④ 混合方式\n可根据实际业务场景，混合或选择使用以上三种方式，以快速方便而又准确的分析历史变化情况。\n1.3 粒度\n用于确定某一事实表中的行表示什么，是业务最小活动单元或不同维度组合，即业务细节程度。\n1.4 维度建模流程\n维度建模步骤：选择业务过程->声明粒度->确定维度->确定事实。旨在重点解决数据粒度、维度设计和事实表设计问题。\n声明粒度，为业务最小活动单元或不同维度组合。以共同粒度从多个组织业务过程合并度量的事实表称为合并事实表，需要注意的是，来自多个业务过程的事实合并到合并事实表时，它们必须具有同样等级的粒度。\n02.建模方法  - - 经典数据仓库模型\n数据仓库建模方法论可分为：维度建模、范式建模、Data Vault模型、Anchor模型。\n2.1 维度模型\n企业中最流行、也是最经典的数仓建模经典，数据仓库大师Ralph Kimball的经典著作《数据仓库工具箱 维度建模权威指南 第三版》一本书进行了论述。从事数据仓库/ETL/BI的同学，强烈建议买一本至少读一遍。\n按数据组织类型划分可分为星型模型、雪花模型、星座模型。\n（1） 星型模型\n星型模型主要是维表和事实表，以事实表为中心，所有维度直接关联在事实表上，呈星型分布。\n（2） 雪花模型\n雪花模型，在星型模型的基础上，维度表上又关联了其他维度表。这种模型维护成本高，性能方面也较差，所以一般不建议使用。尤其是基于hadoop体系构建数仓，减少join就是减少shuffle，性能差距会很大。\n（3） 星座模型\n星座模型，是对星型模型的扩展延伸，多张事实表共享维度表。数仓模型建设后期，大部分维度建模都是星座模型。\n2.2 范式模型\n即 实体关系（ER）模型，数据仓库之父Immon提出的，从全企业的高度设计一个3NF模型，用实体加关系描述的数据模型描述企业业务架构，在范式理论上符合3NF。此建模方法，对建模人员的能力要求非常高。\n2.3 Data Vault模型\nDataVault由Hub（关键核心业务实体）、Link（关系）、Satellite（实体属性） 三部分组成 ，是Dan Linstedt发起创建的一种模型方法论，它是在ER关系模型上的衍生，同时设计的出发点也是为了实现数据的整合，并非为数据决策分析直接使用。\n2.4 Anchor模型\n高度可扩展的模型，所有的扩展只是添加而不是修改，因此它将模型规范到6NF，基本变成了K-V结构模型。企业很少使用，本文不多做介绍。\n03. 建模工具\n建模工具，一般企业以Erwin、powerdesigner、visio，甚至Excel等为主。也有些企业自行研发工具，或使用阿里等成熟套装组件产品。\n3.1 PowerDesigner\n是Sybase的企业建模和设计解决方案，是能进行数据库设计的强大的软件，是一款开发人员常用的数据库建模工具。使用它可以分别从概念数据模型(Conceptual Data Model)和物理数据模型(Physical Data Model)两个层次对数据库进行设计。\n3.2 ERWin \n全称是ERwin Data Modeler，是CA公司的数据建模工具。ERwin提供数据库结构，管理界面的容易简单，图形显示对视觉复杂。\n另附一张 www.erwinchina.com 中文官网首页截图，这几句话很霸气有木有~~\n3.3  Visio\nVisio  是Office  软件系列中的负责绘制流程图和示意图的软件，是一款便于IT和商务人员就复杂信息、系统和流程进行可视化处理、分析和交流的软件。同时它也可以用来数据库建模。\n打开visio 2010,文件—>新建—>数据库—>数据库模型图。建立数据库模型图之后，菜单栏多出一个菜单项\"数据库\"。\n3.4 Excel Mapping\n通过我们最熟悉的Excel进行维护数据模型、血缘关系和元数据管理，话不多说，直接上图：\n04. 结语\n对于数仓而言，模型就是命脉，好与坏直接决定企业数据存储、处理和应用。\n对于维度建模，真正理解了粒度和一致性维度，也就理解了维度建模的魂。\n对于建模工具，没有最好只有更好，适合业务的就是最好的。"
  },
  {
    "title": "人工智能训练师帮助学习模型识别“有用”信息-南昌新闻网",
    "page_body": "　　打开电脑，开启智能训练软件，人工智能训练师杨洪旭开始一天的工作。他最近的任务是训练一个能自主识别银行电汇申请书的人工智能（AI）模型。\n　　杨洪旭供职的达观数据有限公司，位于上海浦东软件园，是一家智能文本处理技术企业。这里研发的AI模型，能读懂合同工单、财务报表、行业报告等各类文本文件，在银行流水识别、合同审核与比对等多场景落地应用。\n　　“在训练AI模型前，训练师首先要阅读大量相关的文件文本，从中提炼和标注出关键信息。”杨洪旭把读文本、做标注的过程比作老师备课，是训练的基础，“我们划重点、做标注，然后将‘有用’信息‘投喂’给AI模型，告诉它们应该提取哪些信息、按照什么格式提取。”人工智能训练师一年需要阅读上万份文档，训练几十个AI模型。\n　　杨洪旭在智能训练软件中打开某银行一张电汇申请书的扫描图像，将“业务种类”“汇款人名称”“账号”“开户银行”“联系地址”等字段信息一一拉框选中，再在旁边打上相应标签，随后点击生成训练模型。\n　　模型生成后，他需要给AI模型出一些练习题，输入字段信息，比对AI模型生成的结果，以此检验学习效果。当发现生成结果与原文本有出入时，杨洪旭会记录并整理成问题列表。“比如文章中有一处图像，它没有读取出来。有一个图像应该是正向的，它读取成了侧向的。”这些问题会统一反馈给AI模型的研发人员，为后续改进作参考。\n　　“AI模型经过训练后，再遇到类似的文本文件，它就能自主抓取、审读这些关键信息，更高效地执行人类指令。”在别人眼中单调、重复、略显枯燥的文档阅读、数据标注、效果测试等工作，杨洪旭却得心应手。他最开心的事就是看到自己训练的模型越来越“聪明”。\n　　1993年出生的杨洪旭，患有先天听力障碍，要戴助听器才能听到外界的声音。2014年，他从上海一所职业技术学院的环境设计专业毕业，先后做过家装设计、会计文员和仓库管理员等工作。\n　　“和客户交流时，因为口齿表达不够清晰流利，经常会有挫败感。”在杨洪旭陷入迷茫之际，上海市浦东新区残联向他推荐了达观数据有限公司的“人工智能训练师”岗位。尽管没有计算机编程技术基础，也对人工智能了解不多，但在听说这份新工作主要和机器打交道后，杨洪旭决定尝试。\n　　招聘杨洪旭入职的运营管理总监袁少杨说，公司首批人工智能训练师主要从事最基础的数据标注工作，重复的工作内容和大批量的标注强度，很考验人的耐心、细心和专注度。\n　　5年下来，踏实、专注、好学的杨洪旭赢得了同事们的交口称赞。在公司的内部培训和自我学习下，他逐渐胜任模型处理、产品测试、接洽客户等多项工作。2022年底，上海发布了首批人工智能训练师（二级）职业技能等级认定通过名单，杨洪旭位列其中。\n　　面对人工智能产业的飞速发展，杨洪旭主动学习AI模型主流的编程语言，编写一些简单代码处理模型出现的问题。“比如，当发现训练的模型有误读问题，我能够编写几行程序代码，做一些初步纠正，而不是把问题直接转给模型研发人员。”杨洪旭说，为了提升自己，眼下，他正在备考信息系统项目管理师职称证书。\n　　人工智能是上海的三大先导产业之一。近年来，上海从算力、语料、模型、测试、应用场景等方面布局人工智能产业，同时加大人才培养力度。2022年，上海启动人工智能训练师职业技能等级认定工作，目前已有450多人获得了“人工智能训练师”证书。\n　　《　人民日报　》（　2024年08月27日　13　版）"
  },
  {
    "title": "AI大模型在代码生成领域的应用现状与未来挑战：2025年深度报告.docx-原创力文档",
    "page_body": "内容提供方 ： 大小 ： 31.81 KB 字数 ： 约9.63千字 ： 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\nAI大模型在代码生成领域的应用现状与未来挑战：2025年深度报告模板\n一、AI大模型在代码生成领域的应用现状\n1.技术特点\n2.应用场景\n3.发展趋势\n二、AI大模型在代码生成领域的具体应用案例\n1.代码自动生成工具\n2.自动化测试与代码审查\n3.教育培训与编程辅助\n4.智能编程助手\n5.代码生成技术的未来发展方向\n三、AI大模型在代码生成领域的挑战与应对策略\n1.模型复杂性与可解释性\n2.数据安全和隐私保护\n3.代码质量和可靠性\n4.模型泛化能力与适应性\n5.伦理和社会影响\n四、AI大模型在代码生成领域的伦理考量与法规遵循\n1.伦理考量\n2.法规遵循\n3.社会责任\n4.伦理法规与行业自律\n五、AI大模型在代码生成领域的国际合作与竞争态势\n1.国际合作模式\n2.竞争格局\n3.合作与竞争的互动关系\n4.未来发展趋势\n六、AI大模型在代码生成领域的未来展望\n1.技术发展趋势\n2.应用场景拓展\n3.伦理与法规挑战\n4.教育与人才培养\n5.国际合作与竞争\n七、AI大模型在代码生成领域的可持续发展策略\n1.技术可持续性\n2.经济可持续性\n3.社会可持续性\n4.环境可持续性\n八、AI大模型在代码生成领域的风险评估与应对\n1.风险评估\n2.应对策略\n3.风险评估与应对的实践案例\n九、AI大模型在代码生成领域的国际合作与竞争态势\n1.国际合作模式\n2.竞争格局\n3.合作与竞争的互动关系\n4.未来发展趋势\n十、AI大模型在代码生成领域的教育与培训\n1.教育与培训现状\n2.教育与培训挑战\n3.未来发展方向\n十一、AI大模型在代码生成领域的监管与合规\n1.监管体系构建\n2.合规挑战\n3.监管趋势\n4.监管与合规的实施\n一、AI大模型在代码生成领域的应用现状\n随着人工智能技术的飞速发展，AI大模型在各个领域的应用日益广泛，尤其在代码生成领域展现出巨大的潜力和应用价值。本章节将探讨AI大模型在代码生成领域的应用现状，分析其技术特点、应用场景和发展趋势。\n1.技术特点\n自动生成代码：AI大模型能够根据用户输入的需求自动生成代码，节省了编程人员的时间和精力。\n跨语言支持：AI大模型具备跨语言能力，可以生成多种编程语言的代码，满足不同用户的需求。\n个性化定制：AI大模型可以根据用户的编程风格和习惯进行个性化定制，提高代码质量和可读性。\n智能纠错：AI大模型可以自动识别和修正代码中的错误，提高代码的可靠性。\n2.应用场景\n软件开发：AI大模型在软件开发领域应用广泛，如自动化测试、代码生成、代码审查等。\n运维管理：AI大模型可以帮助自动化运维任务，如代码部署、系统监控、故障诊断等。\n教育培训：AI大模型可以辅助编程教学，提供个性化学习方案，提高编程学习效果。\n智能编程：AI大模型可以与编程人员协作，提高编程效率和代码质量。\n3.发展趋势\n模型性能不断提升：随着计算能力的提高，AI大模型在代码生成领域的性能将不断优化。\n应用场景不断拓展：AI大模型的应用场景将从单一领域拓展到多个领域，满足不同用户的需求。\n与人类开发者协作：AI大模型将与人类开发者紧密协作，共同完成编程任务。\n代码质量持续提升：AI大模型将不断优化代码生成算法，提高代码质量和可读性。\n二、AI大模型在代码生成领域的具体应用案例\n在深入探讨AI大模型在代码生成领域的应用现状之后，本章节将具体分析一些典型的应用案例，通过这些案例来展示AI大模型在现实世界中的实际效果和价值。\n2.1代码自动生成工具\nGitHubCopilot：GitHubCopilot是GitHub推出的一款基于AI的代码自动生成工具，它能够根据用户的注释和代码片段自动生成补全代码。这种工具极大地提高了编程效率，尤其是在复杂的项目中，它可以减少重复性工作，让开发者能够更加专注于创意和逻辑设计。\nKite：Kite是一个基于AI的代码补全工具，它通过分析用户的代码习惯和项目上下文，提供智能的代码补全建议。Kite的应用场景涵盖了多种编程语言，从Python到JavaScript，都得到了广泛的应用。\n2.2自动化测试与代码审查\nAI辅助的自动化测试：AI大模型在自动化测试中的应用主要体现在测试用例的生成和测试数据的准备上。例如，AI模型可以根据软件的API文档和设计文档，自动生成一系列的测试用例，从而提高测试的全面性和效率。\n代码审查自动化：AI大模型在代码审查中的应用主要在于识别代码中的潜在错误和安全漏洞。例如，通过分析代码的静态结构和执行路径，AI模型可以预测代码的潜在问题，并提出改进建议。\n2.3教育培训与编程辅助\n个性化编程教学：AI大模型可以为学生提供个性化的编程学习方案，根据学生的学习进度和需求，自动调整教学内容和难度。这种个性化的学习体验有助于提高学生的学习兴趣和效率。\n实时编程辅助：在编程过程中，AI大模型可以实时提供代码提示、错误诊断和优化建议，帮助开发者更快地解决问题，提高编程效率。\n2.4智能编程助手\n代码重构与优化：AI大模型可以分析代码的性能瓶颈，并提出重构和优化的建议。这有助于提高代码的执行效率和可维护性。\n跨平台开发支持：AI大模型可以帮助开发者实现跨平台编程，通过自动生成兼容不同平台的代码，降低开发难度和时间成本。\n2.5代码生成技术的未来发展方向\n模型理解能力提升：未来的AI大模型将更加注重对代码逻辑的理解，以提高代码生成的准确性和适用性。\n多模态输入输出：AI大模型将支持更多样化的输入和输出方式，如自然语言、图形界面等，以适应更广泛的应用场景。\n伦理与安全：随着AI大模型在代码生成领域的应用日益广泛，其伦理和安全问题也日益凸显。未来，AI大模型将更加注重保护用户隐私和代码安全。\n三、AI大模型在代码生成领域的挑战与应对策略\n随着AI大模型在代码生成领域的应用不断深化，其面临的挑战也日益增多。本章节将分析这些挑战，并提出相应的应对策略。\n3.1模型复杂性与可解释性\n模型复杂度：AI大模型的复杂度不断提高，这虽然带来了更好的性能，但也使得模型难以理解和解释。在代码生成领域，模型复杂度高可能导致生成的代码出现难以预测的问题。\n可解释性需求：在代码生成中，可解释性对于确保代码质量和安全性至关重要。用户需要理解AI是如何生成代码的，以便在必要时进行干预或优化。\n应对策略：为了提高模型的可解释性，可以采用以下策略：简化模型结构、使用可解释的AI模型（如LIME、SHAP等）、提供代码生成过程的可视化工具。\n3.2数据安全和隐私保护\n数据敏感性：代码生成过程中涉及到的数据可能包含敏感信息，如商业机密、个人隐私等。\n数据泄露风险：AI模型训练和部署过程中，数据泄露的风险较高。\n应对策略：加强数据加密和访问控制、采用联邦学习等技术减少数据泄露风险、确保数据处理的合规性。\n3.3代码质量和可靠性\n代码质量：AI生成的代码可能存在语法错误、逻辑错误或性能问题。\n可靠性：AI生成的代码在复杂或特定场景下可能无法满足可靠性要求。\n应对策略：引入代码质量评估标准、使用代码审查工具、结合专家知识进行代码优化。\n3.4模型泛化能力与适应性\n泛化能力：AI大模型需要具备良好的泛化能力，以适应不断变化的编程需求和场景。\n适应性：模型需要能够快速适应新出现的编程语言、框架和技术。\n应对策略：通过持续学习和自适应算法提高模型的泛化能力，采用迁移学习等技术提高模型的适应性。\n3.5伦理和社会影响\n伦理问题：AI大模型在代码生成中的应用可能引发伦理问题，如算法偏见、自动化失业等。\n社会影响：AI大模型的应用可能对软件开发行业产生深远的社会影响。\n应对策略：制定相应的伦理规范和行业标准，加强对AI大模型的社会影响评估，推动技术向更加负责任的方向发展。\n四、AI大模型在代码生成领域的伦理考量与法规遵循\n随着AI大模型在代码生成领域的广泛应用，其伦理考量与法规遵循成为了一个不可忽视的问题。本章节将探讨AI大模型在代码生成领域的伦理考量，以及如何遵循相关法规，确保技术的健康发展。\n4.1伦理考量\n算法偏见：AI大模型在代码生成过程中可能存在算法偏见，导致生成的代码不公平或歧视某些用户。\n责任归属：当AI大模型生成的代码出现问题时，责任归属不明确，可能引发法律和伦理争议。\n应对策略：建立透明的算法决策过程，确保算法的公平性和无偏见；明确AI大模型的使用者和开发者的责任，建立责任追溯机制。\n4.2法规遵循\n数据保护法规：AI大模型在代码生成过程中涉及大量数据，需遵守相关数据保护法规，如GDPR（通用数据保护条例）。\n知识产权法规：AI大模型生成的代码可能涉及知识产权问题，需遵循相关法规，确保不侵犯他人的知识产权。\n应对策略：建立数据保护合规机制，确保数据处理过程符合法规要求；对AI大模型生成的代码进行版权登记，明确知识产权归属。\n4.3社会责任\n就业影响：AI大模型在代码生成领域的应用可能导致部分编程人员失业，引发社会关注。\n技术普及：AI大模型的技术普及程度不高，可能导致数字鸿沟的扩大。\n应对策略：加强对编程人员的再培训和技能提升，提高AI大模型的技术普及程度，缩小数字鸿沟。\n4.4伦理法规与行业自律\n伦理法规制定：制定针对AI大模型在代码生成领域的伦理法规，规范技术发展。\n行业自律：推动行业自律，建立行业规范和道德准则，引导AI大模型在代码生成领域的健康发展。\n应对策略：加强政府、企业和研究机构的合作，共同推动伦理法规的制定和实施；鼓励企业建立内部伦理审查机制，确保AI大模型的应用符合伦理标准。\n五、AI大模型在代码生成领域的国际合作与竞争态势\n在全球化的背景下，AI大模型在代码生成领域的应用和发展呈现出明显的国际合作与竞争态势。本章节将分析这一领域的国际合作模式、竞争格局以及未来发展趋势。\n5.1国际合作模式\n技术交流与合作：各国研究机构和企业在AI大模型技术方面进行交流与合作，共同推动技术进步。\n标准制定与共享：国际组织如ISO、IEEE等参与AI大模型相关标准的制定，促进全球范围内的技术共享。"
  },
  {
    "title": "基于Transformer的自监督学习在NLP中的前沿应用-稀土掘金",
    "page_body": "1. 引言\n自然语言处理（NLP）领域正经历一场由自监督学习（Self-Supervised Learning, SSL）和Transformer架构共同驱动的革命。自监督学习通过巧妙地利用未标注数据，大大减少了对人工标注的依赖，而Transformer凭借其强大的建模能力，成为实现这一学习范式的理想工具。本文旨在深入探讨基于Transformer的自监督学习在NLP中的前沿应用，为从业者提供全面的技术视角和实践洞见。\n2. 自监督学习与Transformer的结合\n2.1 自监督学习简介\n自监督学习是一种从数据本身自动生成监督信号的学习方法。在NLP中，常见的自监督任务包括：\n掩码语言模型（Masked Language Model, MLM） 下一句预测（Next Sentence Prediction, NSP） 语言模型（Language Model, LM）\n这些任务允许模型从大规模未标注文本中学习语言的结构和语义。\n2.2 Transformer架构的优势\nTransformer架构，最初由Vaswani等人在2017年提出，具有以下关键优势：\n并行计算能力 ：自注意力机制允许并行处理输入序列。 长距离依赖建模 ：克服了RNN难以捕捉长距离依赖的限制。 可扩展性 ：易于扩展到大规模模型和数据集。\n2.3 结合的原因与优势\n将自监督学习与Transformer结合，我们可以：\n充分利用海量未标注数据进行预训练。 学习到通用的语言表示，有利于各种下游任务。 通过微调或少样本学习，快速适应特定任务。\n3. 前沿应用场景\n3.1 预训练语言模型\n预训练语言模型是自监督学习最成功的应用之一。以下是几个代表性模型：\nBERT （Bidirectional Encoder Representations from Transformers）：使用MLM和NSP任务进行预训练。 GPT （Generative Pre-trained Transformer）：使用单向语言模型进行预训练。 RoBERTa ：BERT的改进版本，移除NSP任务，使用更大的批量和更多数据。\n这些模型在各种NLP任务中表现卓越，如文本分类、命名实体识别、问答系统等。\n3.2 句子嵌入与文本相似度计算\n自监督学习产生的高质量句子嵌入可用于多种任务：\n语义检索 ：通过计算句子嵌入的相似度，实现高效的文档检索。 文本聚类 ：基于句子嵌入进行无监督文本聚类。 语义相似度评估 ：评估两个句子的语义相似程度。\n技术实现：可以使用Sentence-BERT等模型，它们在BERT基础上进行了特定的微调，以生成更适合相似度计算的句子嵌入。\n3.3 无监督文本分类\n自监督学习为无监督文本分类提供了新的可能：\n主题模型 ：利用自监督学习改进传统的LDA（Latent Dirichlet Allocation）模型。 聚类分析 ：基于自监督学习得到的文本表示进行聚类。 零样本分类 ：利用预训练模型的语义理解能力，实现无需标注数据的分类。\n实现方法：可以使用BERT等模型的[CLS]token表示作为文档嵌入，然后应用K-means等聚类算法。\n3.4 多模态数据处理\n自监督学习在多模态数据处理中展现出巨大潜力：\nCLIP （Contrastive Language-Image Pre-training）：联合训练图像和文本，实现跨模态检索。 VilBERT ：视觉-语言BERT，用于图像描述、视觉问答等任务。 DALL-E ：基于文本生成图像的模型。\n这些模型通过自监督学习，建立了不同模态数据之间的语义联系。\n3.5 增量学习与持续学习\n自监督学习为增量学习和持续学习提供了新思路：\n动态预训练 ：持续使用新数据进行自监督预训练，更新模型知识。 任务适应 ：通过自监督学习快速适应新任务或领域。 知识蒸馏 ：利用自监督学习进行模型压缩和知识传递。\n实现方法：可以采用渐进式学习策略，逐步增加模型规模和数据复杂度。\n4. 技术实现与挑战\n4.1 数据生成与预处理\n自监督学习的关键在于设计有效的预训练任务。以下是一些常见策略：\n动态掩码 ：RoBERTa中采用的策略，每次前向传播时动态生成掩码。 N-gram掩码 ：掩盖连续的N个词，而不是单个词。 实体掩码 ：优先掩盖命名实体，有助于学习实体相关知识。\n挑战：确保生成的任务能够有效捕捉语言的结构和语义信息。\n4.2 训练策略与优化\n训练大规模Transformer模型面临以下挑战：\n计算资源限制 ：需要大量GPU/TPU资源。 优化困难 ：大模型容易出现梯度消失/爆炸问题。\n解决方案：\n使用混合精度训练 梯度累积 模型并行化 适应性学习率策略（如Transformer-XL中的学习率预热）\n4.3 模型的可扩展性与适应性\n为了提高模型的可扩展性和适应性，可以考虑：\n模型压缩 ：\n知识蒸馏 模型剪枝 量化\n参数高效微调 ：\nAdapter tuning Prompt tuning LoRA (Low-Rank Adaptation)\n这些技术可以在保持模型性能的同时，大幅减少计算和存储需求。\n4.4 评估方法与指标\n评估自监督学习模型的常用方法包括：\n下游任务评估 ：在特定NLP任务上的性能（如GLUE基准）。 探测任务 （Probing tasks）：评估模型学到的语言知识。 生成质量评估 ：使用BLEU、ROUGE等指标评估生成文本的质量。 鲁棒性测试 ：评估模型对对抗样本的抵抗能力。\n4.5 实际应用中的挑战与解决方案\n数据偏见 ： 解决方案：使用多样化的数据源，设计去偏见的预训练任务。\n计算资源限制 ： 解决方案：模型蒸馏、量化、剪枝等技术。\n领域适应性 ： 解决方案：领域自适应预训练，少样本学习技术。\n实时性要求 ： 解决方案：模型压缩、增量更新策略。\n5. 案例研究\n5.1 OpenAI GPT-4\nGPT-4是目前最先进的大规模语言模型之一，展现了自监督学习的巨大潜力：\n规模 ：虽然具体参数量未公开，但估计超过1万亿参数。 训练数据 ：使用了大规模、多样化的互联网文本数据。 应用 ：展现出惊人的跨领域能力，包括自然语言理解、代码生成、多模态任务等。\n技术亮点：\n采用了更先进的自监督学习算法（细节未公开）。 可能使用了稀疏激活技术，如Mixture of Experts (MoE)。 强大的上下文学习能力，能够快速适应新任务。\n5.2 Google BERT\nBERT是自监督学习在NLP中的里程碑式模型：\n架构 ：使用双向Transformer编码器。 预训练任务 ：MLM和NSP。 数据 ：使用BookCorpus和Wikipedia数据。\n技术创新：\n引入了双向上下文建模。 设计了有效的预训练任务（MLM和NSP）。 提出了有效的微调策略。\n5.3 Facebook DINO\nDINO (Self-Distillation with No Labels) 虽然主要用于计算机视觉，但其自监督学习思想对NLP也有重要启发：\n原理 ：使用教师-学生网络架构，通过自蒸馏学习表示。 创新点 ：无需标签，直接从数据中学习有意义的表示。\n对NLP的启示：\n可以探索类似的自蒸馏方法来改进文本表示学习。 启发了跨模态自监督学习的新思路。\n6. 未来发展方向\n6.1 提升模型泛化能力\n大规模预训练 ：继续扩大模型规模和训练数据量。 多任务学习 ：在预训练阶段引入多样化的任务。 元学习 ：探索快速适应新任务的学习算法。\n6.2 增强模型的可解释性\n注意力可视化 ：改进现有的注意力可视化技术。 探测任务 ：设计更精细的探测任务来理解模型的内部表示。 因果推断 ：引入因果推断方法来解释模型决策。\n6.3 改进自监督学习算法\n对比学习 ：探索更有效的对比学习方法，如SimCSE。 生成式对比学习 ：结合生成式模型和对比学习。 自适应预训练 ：根据任务动态调整预训励策略。\n6.4 开放数据集与社区协作\n大规模多语言数据集 ：构建更多样化、高质量的预训练数据集。 标准化评估基准 ：开发更全面的模型评估基准。 开源模型与工具 ：推动大规模预训练模型的开源化。\n6.5 跨领域与多模态融合\n跨模态预训练 ：联合训练处理文本、图像、音频等多模态数据。 领域迁移 ：研究如何有效地将通用预训练模型迁移到特定领域。 多模态理解与生成 ：开发能够理解和生成多模态内容的模型。\n7. 结论\n基于Transformer的自监督学习已经成为NLP领域的核心驱动力，不仅极大地提升了各种NLP任务的性能，还开启了语言理解和生成的新纪元。尽管面临诸多挑战，如计算资源需求、模型可解释性等，但其巨大潜力和广泛应用前景是毋庸置疑的。\n对NLP从业者的建议：\n深入理解自监督学习的原理和最新进展。 掌握Transformer及其变体的实现和优化技巧。 关注多模态和跨领域应用，拓展技术视野。 参与开源项目，贡献于社区发展。 注重模型的伦理和社会影响，推动负责任的AI发展。\n自监督学习与Transformer的结合仍处于快速发展阶段，未来必将带来更多突破性进展。作为NLP从业者，我们应该保持开放和创新的态度，积极探索这一激动人心的研究领域。"
  },
  {
    "title": "论文写作时如何构建合理的框架结构？研究_单车_问题",
    "page_body": "在 论文写作 过程中，一个合理的框架结构如同大厦的基石与梁柱，支撑起整篇论文，确保内容层次分明、逻辑连贯。那么，如何为论文搭建一个合理的框架结构呢？\n首先要明确论文的核心研究问题。以 “城市共享单车的使用现状与发展对策” 为例，此即为贯穿论文的核心议题。围绕这一核心，逐步勾勒出论文的框架轮廓。\n论文开篇，需巧妙引入核心问题。描述城市共享单车随处可见的现象，指出随之出现的诸如乱停乱放、车辆损坏率高以及部分区域投放不合理等问题，强调这些问题对城市环境、交通秩序以及共享单车行业可持续发展的影响，从而引出研究的必要性，让读者迅速理解研究的出发点。\n随后，对该领域已有的研究成果进行梳理。通过广泛查阅资料，汇总其他学者针对共享单车使用现状与发展对策的研究。例如，有的学者研究了用户行为对共享单车使用的影响，有的分析了不同运营模式的优缺点，将这些研究成果系统呈现，使读者了解该领域的研究基础与现状。\n紧接着，详细阐述自己的研究内容。若你的研究聚焦于优化共享单车投放策略，就要说明采用何种方式进行研究。比如，通过收集不同区域的人口密度、出行需求数据，结合共享单车的使用频率与分布情况进行分析，这便是研究方法。同时，阐述在研究过程中的重要发现，如某些商业区域高峰期共享单车供不应求，而部分居民区却存在车辆闲置现象，这些发现构成研究的核心内容。\n基于研究发现，提出切实可行的解决方案。针对共享单车投放不合理的问题，提出依据实时数据动态调整投放量、优化投放区域布局等具体措施，详细说明这些措施如何实施以及预期效果，为解决实际问题提供清晰路径。\n提出解决方案后，阐述研究成果的意义与价值。例如，优化共享单车投放策略能够提高车辆使用效率，减少资源浪费，改善城市交通与环境，促进共享单车行业健康发展，让读者明白研究成果对现实的积极影响。\n论文结尾，对整个研究进行全面总结。回顾开篇提出的共享单车使用现状相关问题，概括研究过程中的主要发现与采取的解决方案，再次强调研究成果的重要性与应用前景，给读者留下清晰、完整的印象。\n论文写作依照引出问题、梳理前人研究、详述自身研究、提出解决方案、阐释成果意义、总结研究的思路，便可构建出合理的框架结构，使论文逻辑清晰、层次分明，便于读者理解与把握。"
  },
  {
    "title": "自监督学习在多模态大模型中的应用：基于对比学习、掩码重建的多模态对齐技术综述-CSDN博客",
    "page_body": "自监督学习与多模态大模型\n理解 自监督三大方法\n基于前置任务 基于对比学习（主流）：\"自己和自己比较\" VS \"自己和他人比较\"，来学习区分性的特征表示\nSimCLR：大样本对比，一张图片的两次增强作为正样本对，同批次大量其他图片作为负样本，让模型学会提取图片的本质特征 MoCo：动量对比学习\n基于掩码重建（主流）：通过上下文预测缺失部分，迫使模型学习数据的内在结构和语义关联\nBEiT：图片随机切分，隐藏一些图块，类似拼音，视觉完形填空\n为什么对比学习、掩码重建是主流？ 对比学习、掩码重建对比分析 与多模态大模型的深度联系\n视觉基础模型\nViT 视觉 Transformer（骨干网络）\nViT 是否抛弃了 CNN 式的特征提取？相比 CNN 有哪些优势？\nMoCo v3 自监督-对比学习的基础框架（骨干网络） DINO 无需标签的自监督学习范式（自蒸馏） MAE 掩码自编码的方式实现自监督学习，只输入均匀分布的 25% 切片，视觉的完形填空 SAM 通用的分割模型，借鉴prompt设计，视觉界的GPT，分割任意物体 LOSAM：视觉大模型SAM + 眼科 TV-SAM 新型零样本医学图像分割算法：GPT-4语言处理 + GLIP视觉理解 + SAM分割技术\n多模态学习方法\nCILP 图文对比学习 GILP 细粒度图文对齐 BLIP BLIP-2\n多模态视觉架构大模型\nMiniGPT-4：采用Adapter架构，通过Q-Former将图片特征对齐到大模型的Input Embedding中，支持多轮对话和逻辑推理能力 Qwen2 VL：阿里巴巴开发的中文开源多模态大模型，能够进行多图多轮对话，识别图中文字并给出物体的准确坐标 Frozen：DeepMind 发布，通过训练视觉编码器来适配LLMs KOSMOS-1：基于 Transformer 框架，采用自回归生成文本，并通过特定的编码策略处理文本和图像数据 Flamingo：DeepMind 发布，在少样本学习中取得了显著成就 LLaVA：Flamingo 简化版，通过两阶段训练实现视觉与语言模态的高效融合 VILA：英伟达开发的多模态大模型，专注于视觉和语言任务的融合 Gemini：谷歌开发的原生多模态大模型，具有无缝跨模态的能力，支持文字与图片输入 BuboGPT：字节跳动开发的多模态大模型，支持文本、图像和音频三种模态，能够实现细粒度的多模态联合理解 WINGS：一种创新的多模态学习架构，通过视觉编码器、投影器、语言学习器等组件提升多模态大模型的表现 紫东太初：中国科学院自动化研究所研发的全球首个千亿参数多模态人工智能大模型，支持图像、文本、语音、视频等多种模态数据间的统一表示与相互生成 混元DiT：腾讯开发的中文原生DiT架构多模态大模型，支持中英文输入和理解，适用于文生图、生视频等多模态视觉生成\n提问\n自监督学习与传统监督学习最本质的区别是什么? 自监督学习类似\"自学成才\"的学生,您如何理解这个比喻?它的局限性在哪里? 为什么自监督学习能够从数据本身学习到有用的特征表示?这种学习机制与人类学习有什么异同? 在三种主要方法(前置任务、对比学习、掩码重建)中,您认为哪种方法最有前景?为什么? 对比学习要求正负样本对,如何定义什么是\"相似\"的数据?这个定义可能带来什么问题? 掩码重建任务中,如何确定最优的掩码比例?这个比例是否会随任务变化? 自监督学习在减少标注数据依赖的同时,是否也带来了新的挑战?这些挑战具体是什么? 为什么自监督学习特别适合多模态大模型?这种结合是否存在潜在问题? 从计算效率的角度看,自监督学习相比传统监督学习有什么优势和劣势? 如何评估一个自监督学习方法的好坏?需要考虑哪些关键指标? 如果让您设计一个新的自监督学习方法,您会如何设计?理由是什么? 自监督学习的发展是否意味着未来可以完全摆脱人工标注?为什么? 在掩码重建方法中，现有的模型通常采用随机掩码策略。如果要设计一种\"智能掩码\"策略，使其能够自适应地选择最具信息量的区域进行掩码，你会如何设计算法？请详细说明技术路线和可能遇到的挑战。 文章提到CLIP使用对比学习实现图文对齐，但在实际应用中可能存在模态间语义差异过大的情况。如何设计更精细的对比学习策略来处理这种\"跨模态语义鸿沟\"问题？ 当前的自监督学习方法主要关注特征学习，但对因果关系的学习较少涉及。如何将因果推理的思想引入自监督学习框架，使模型能够学习到数据中的因果结构？ 在多模态场景下，不同模态的信息量差异很大（如图像通常包含的信息量远大于对应的文本描述）。这种信息不平衡会如何影响自监督学习的效果？有什么解决方案？ 自监督学习在处理长尾分布数据时可能面临样本不平衡的问题。如何设计前置任务或对比学习策略来确保模型能够学习到罕见类别的特征表示？ 在文章提到的三种方法中，如何有效地将它们组合使用？具体来说，如何设计损失函数来平衡不同学习目标，使它们能够互相促进而不是相互干扰？ 自监督学习可能会学习到一些表面的统计相关性而非真正有意义的特征。如何设计机制来区分和过滤这些\"伪相关\"特征？这个问题在多模态学习中尤其重要。 MiniGPT-4采用Adapter架构进行模态对齐，但这种方式可能会带来信息损失。如何评估这种损失，并设计更好的架构来降低信息损失？ 在多轮对话场景下，如何让自监督学习模型保持对话的连贯性和上下文理解能力？现有的掩码策略是否足以处理长程依赖关系？ 自监督学习在处理时序数据时，如何平衡短期和长期依赖的建模？特别是在视频理解任务中，如何设计时序掩码策略来捕获不同时间尺度的特征？\n训练好的视觉大模型 如何 迁移 到医疗领域？\n线性探测：只微调一个新的分类器（Head），替换掉原来的分类器 微调：主干网络（Backbone）+ 分类器（Head）都微调，替换掉 Adapter：在主干网络（Backbone）外面套一层，可以改变的层，只需要微调新层（Adapter） + 分类器（Head）就可以了 视觉 Prompt：新的任务，加一个视觉提示词\n理解\n提出背景：\n类别问题：深度学习中的数据标注问题\n具体问题：人工标注数据成本高昂、耗时长、需要专业知识，且随着模型规模增大，获取足够的标注数据变得越来越困难。\n例如，一个医疗影像分类模型可能需要数十万张由专业医生标注的图像，这在实际中几乎不可能实现。\n概念性质：\n本质是一种无监督学习方法，不需要任何标签 通过数据本身的结构和规律自动生成标签 这种性质源于数据本身包含的丰富信息和内在关联\n正反例对比：\n正例：BERT预训练中预测被遮挡的词，模型能够通过上下文学习语言的语义和语法特征 反例：完全随机遮挡和预测，没有利用数据的内在结构，模型无法学到有意义的特征\n类比理解：\n类比：自监督学习就像是\"自学成才\"的学生 解释：传统监督学习像是老师教学生（需要标注数据），而自监督学习像是学生自己看书学习（从数据本身学习），通过理解书本内容的逻辑关系来掌握知识\n概念介绍与总结：\n 自监督学习是一种机器学习范式，它不依赖外部标注，而是利用数据本身的结构来构建学习目标。通过设计巧妙的学习任务，让模型在完成这些任务的过程中学习到有用的特征表示。\n概念重组：\n \"自监督学习\"可以理解为：通过自身数据进行监督，实现自主学习的过程。\n与上文关联：\n 自监督学习的三种方法（基于前置任务、对比学习、掩码重建）都是自监督学习的具体实现方式。\n规律发现：\n原则：利用数据内在结构 立场：减少人工标注依赖 方法：构建自监督任务 主要矛盾：如何设计有效的自监督任务 次要矛盾：计算资源消耗、模型架构选择等\n功能分析：\n表面形式：预测数据的部分内容 核心功能：学习数据的本质特征表示 最终目标：在下游任务中获得良好效果 定量指标：模型在下游任务上的准确率、召回率等 定性特征：特征表示的泛化能力、迁移能力\n来龙去脉梳理：\n深度学习发展初期主要依赖大量标注数据，这严重限制了其应用范围。\n为解决这一问题，研究者开始探索如何利用未标注数据。\n自监督学习通过巧妙设计预训练任务，让模型从数据本身学习特征，既解决了标注数据不足的问题，又能学到更通用的特征表示。\n这种方法在计算机视觉、自然语言处理等领域取得了巨大成功，为深度学习的发展开辟了新方向。\n自监督三大方法\n基于前置任务（Pretext Tasks）\n核心思想：设计一些辅助任务，让模型在完成这些任务的过程中学习到有用的特征表示 典型例子： \n图像旋转预测：让模型预测图片旋转的角度 图像拼图：打乱图像块的顺序，让模型重新排序 文本预测：预测句子中的下一个词\n与大模型的关系：早期的BERT就使用了预测被遮挡词（Masked Language Modeling）这样的前置任务\n基于对比学习（Contrastive Learning）\n核心思想：让模型学会区分相似和不相似的数据 工作方式： \n对同一数据进行不同的增强/变换，生成正样本对 其他数据作为负样本 让模型学习将正样本对的表示拉近，将负样本的表示推远\n与大模型关系：CLIP就使用了对比学习，让图像和文本的表示在同一空间对齐\n对比学习路线：MoCo v3、DINO 论文\n基于掩码重建（Masked Reconstruction）\n核心思想：遮挡输入数据的一部分，让模型去重建被遮挡的部分 应用例子： \n语言模型中的掩码词预测 图像中的区域重建 视频中的帧预测\n与大模型关系：GPT系列通过预测下一个词来实现自监督学习，而BERT则是预测被遮挡的词\n掩码重建路线： MAE 视觉掩码自编码\n基于前置任务\n基于前置任务就像是在解决主任务之前先做热身运动。\n比如让模型预测图片是否被旋转、预测视频的时间顺序等简单任务, 通过这些前置任务来学习基础特征。\n假设我们最终要训练一个识别猫品种的模型。\n在主任务之前，我们先训练模型完成\"判断图片是否被旋转了90度\"这样的前置任务。\n虽然这个任务看似简单，但要判断图片是否旋转，模型就必须先学会理解基本的视觉特征，比如边缘、纹理等，这些对后续识别猫品种都很有帮助。\nDoersch, C., Gupta, A., Efros, A.A. Unsupervised visual representation learning by context prediction. ICCV, 2015.\n位置预测：\nNoroozi, M., Favaro, P. Unsupervised learning of visual representations by solving jigsaw puzzles. ECCV, 2016.\nGidaris, S., Singh, P., Komodakis, N. Unsupervised representation learning by predicting image rotations. arXiv 2018.\n旋转预测：\nChen, T., Kornblith, S., Norouzi, M., Hinton, G. A simple framework for contrastive learning of visual representations. ICML, 2020.\n上色：\nCaron, M., Bojanowski, P., Joulin, A., Douze, M. Deep clustering for unsupervised learning of visual features. ECCV, 2018.\n聚类预测：\n基于对比学习（主流）：“自己和自己比较” VS “自己和他人比较”，来学习区分性的特征表示\n基于"
  },
  {
    "title": "毕业论文要怎么写，结构怎么安排的？",
    "page_body": ""
  }
]