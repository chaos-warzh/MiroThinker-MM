[
  {
    "title": "高质量数据集典型案例｜中国移动研发大模型高质量数据集-今日头条",
    "page_body": "中国移动研发大模型高质量数据集\n推荐单位：江苏省数据局\n申报单位：中移（苏州）软件技术有限公司\n一、背景\n代码数据质量和动态利用方式，已成为大模型推理能力的“暗物质”，是推理基础设施的核心燃料，在软件工程等领域具有重要应用价值。针对当前代码数据来源广、质量参差不齐、评估手段专业化不足等问题，本案例构建了“数据采集－数据处理－数据质量评估”的高质量数据处理引擎，形成了一套高质量研发大模型数据集，并基于此数据集训练形成了具备代码补全、单元测试等能力的研发大模型，可支撑研发全流程赋能需求。\n研发大模型高质量数据集架构图\n二、方案和成效\n一是构建海量异构数据采集引擎，实现多源数据融合。 针对开源代码数据分散、内容多样化、噪声多等问题，从异构内容自动提取、低熵噪声自动去除等层面，提升数据采集的准确性与完整性，实现代码数据高效、实时汇聚，形成超PB级别原始数据。\n二是打造高质量数据处理流水线，提升自动化处理效率。 针对代码数据质量不足、研发场景数据缺失等问题，打造文本数据处理流水线和多模态数据合成流水线，支持多样化数据预处理、数据合成、数据探索分析等，整体自动化率达90%，沉淀超50+核心数据处理算子，支持1500万文档/小时。\n三是设计高质量数据评估体系，全方位评估数据质量。 针对代码数据质量评估手段专业化不足的问题，结合行业标准和数据特性，设计一套支持多粒度代码评估、多维度代码评估的高质量综合评估体系，覆盖12个核心维度，支持100+研发领域数据标签，实现研发大模型数据的全方位质量评估。\n三、创新点\n一是技术创新牵引数据质量升级。 基于多元化规则体系及大小模型协同技术，实现对代码数据的去重、敏感数据的脱敏以及场景化标签的标注，将原始代码数据转换为可应用于大模型预训练微调及研发全流程场景需求的高质量研发大模型数据集。\n二是流程闭环加速数据质量跃升。 打造专门面向代码数据的采集、处理、训练等全流程闭环质量优化体系，综合考虑代码数据的技术专业性和复杂性，以规则阈值融合大模型测评等方式，实现模型加数据飞轮良性循环。\n三是机制完善推进数据循环共享。 构建数据安全合规审查体系和数据资产共建共享办法，并形成产业生态闭环，为数据全生命周期注入安全与合规基因，确保其高效流动与价值最大化。\n来源：数据资产搜索整理自网络\n特别声明：本信息来源于网络，经过小编汇总整理生成。小编和本账号公司并不能保证本文信息的真实性和准确性，不对信息真实性准确性负责。请阅读者合理评估信息质量和来源。如果本文包含小编的分析结论等描述，相关分析结论仅仅代表作者个人在当期某个时点的观点，因此相关分析结论可能随着时间变化而改变。本文并无其他任何商业用途。读者如需转载，请务必注明每项内容出处。因读者转发产生的一切经济纠纷和法律责任均由转发者承担，和本账号运营公司以及小编无关。如涉及材料内容、版权和其它问题，请联系小编留言，我们将在第一时间删除。\n北京传世博润科技有限公司（简称：传世博润）成立于2015年，国家高新技术企业，是国内领先的医疗医药数字化与数据价值服务商。作为医疗医药行业头部数商，传世博润深耕医疗医药行业，为药企和医疗机构提供数据资产化解决方案和数字化服务。\n（1）数据资产化解决方案\n传世博润实现了行业数据资产的首登记、首入表、首交易。将基于自身在医疗医药领域数据要素服务的先发优势，为药企和医院开展数据资源开发利用的研究服务，交付高质量数据集、算法模型以及数据产品等成果；\n凭借着自身数据资产化的经验和实践，已经成为北京国际大数据交易所、深圳数据交易所、广州数据交易所、西部数据交易中心、贵阳大数据交易所、江苏数据交易所等多个知名数据交易机构数据商，帮助企业和医疗机构将数据研究成果进行数据资产登记和数据产品交易，积极推动医疗医药数据产品在法定场所内的资产化和流通。\n（2）数字化服务\n在医药流通领域，通过人工智能，结合数据成果，为企业和医疗机构提供精准营销和物流优化以及院内供应链智慧管理等服务；\n在医疗服务领域，通过人工智能，结合数据成果，为医疗机构及学术带头人提供临床科研成果转化服务以及成果商业化服务；\n在智能硬件领域，形成智能化存储、智能化配送、智能化分拣三大产品体系，为物流供应链的各个环节提供一站式创新科技产品。"
  },
  {
    "title": "法学教授也能出圈？罗翔的讲课视频在B站一出锅便炸了_澎湃号·媒体_澎湃新闻-The Paper",
    "page_body": "法学教授也能出圈？最近在B站，中国政法大学教授罗翔的讲课视频一出锅便炸了，经常是一条视频，几百万的点击率，不到一个月时间，吸粉四百多万。除了自身的人气，这些数据，也坐实了罗老师被人喜欢的硬核实力。\n站在互联网的风口上，罗翔讲的却是严肃的刑法课程，这种反差让许多学生觉得很上头，而且他还能随手就抛出一个梗来。“为什么要给罪大恶极的人进行辩护，这种行为也太渣了吧？”下一秒话锋一转，“如果有一天，你也成了被告人，你说自己是无辜的，没有人相信你怎么办？”代入感立刻呈现出来了，听众也立刻理解了辩护的价值。\n罗翔讲过一个非常经典的粪坑案。20世纪80年代，一位妇女冬天骑车碰到歹徒要强暴她，由于双方力量悬殊，妇女打不过对方，便想出一个缓兵之计假装就范，还找了一个极其为歹徒考虑的借口说，“大哥，这个地方不平坦。”歹徒一听，是这么回事，于是寻觅到一个平坦的冰面上开心地脱起衣服来。当衣服遮住脸时，妇女眼疾手快一把把他推进了旁边的粪坑，歹徒连续三次往上爬，都被妇女给踹了下去，最后彻底掉进粪坑死掉了。\n踹死是不是有点过了，这属于正当防卫吗？如果你是这个妇女，你会不会也这么做？一连串的灵魂发问，学生直呼罗老师把讲课的节奏感带得很过瘾。\n“把自己代入到当时的情境中，进行换位思考，以当时的情况进行判定，采取事前一般人标准，而不是事后理性人标准去看待。我们就是普通人，不要拿上帝视角去说话，最终这个案子被判正当防卫。”罗翔说道。之后他又放出了一句经典补刀：“如果我是这个妇女，不仅会踹下去，还会拿块砖去拍他，不过也要小心不要把粪溅到自己身上了。”\n罗翔的幽默和法律的严谨就这样产生了化学反应，他能把案例讲成一个个段子，经常是弹幕一开，刷屏刷到看不清他的脸。面对数不清的留言，罗翔告诉《方圆》记者，自己偶尔也会去看，那些好的内容他都是一扫而过，而那些批评他的话语，他是会反思的：“我觉得只有看清楚自己的不足，才能走出自己的局限，然后在下一次可以做得更好。”\n惊世骇俗的段子，讲出法律的味道\n阿尔贝·加缪曾说，在写书时可以看到书中自己的角色，而罗翔在讲课中也能找到自己的角色。比如在B站流传甚广的画面里，罗翔口中的段子层出不穷，而他单口相声式的讲解，一度刷新了大家对学习法律的理解。\n“在一起自伤案例中，有人正拿着刀在剁手，啪，剁不断，我看着着急，跟大哥说换这把刀，啪一剁就断了，大哥还跟我说谢谢，大家觉得我构不构成犯罪？”“有个人去买烟，拿出一张钱给老板吓了一跳，面额250，上面有8个头，他跟老板说这是早上刚刚发行的，要买一包最便宜的两块钱的烟，还让老板找了248元，这种行为是伪造货币罪吗？”\n“有一哥们等她女朋友时闲极无聊，拍了一下ATM机，结果吐出100块，他吓坏了，又拍了一下，又吐出100块，后来一共拍出了三万块，你说有谁能抵制住这种诱惑？”\n还有谜一样的张三系列，比如给张三买了100张蹦极票，在第99次蹦极时张三终于摔死了，这属不属于危害行为；再比如张三对前男友怀恨在心，送给前男友一双滚轴溜冰鞋希望他摔死摔残，这种行为构不构成故意伤害罪。\n……\n在罗翔的讲课视频中，“津津有味”成了弹幕中的高频词，“法外狂徒张三”也成了他独树一帜的案例主角，许多让粉丝狂刷的梗是罗翔始料未及的，他成了B站中有独特话语体系的法学老师。\n还有一些惊世骇俗的段子，罗翔硬是讲出了法律的味道。有一起涉嫌组织出卖人体器官的恶性事件，罗翔是这样描述的：“同学，看你长相清秀，我出50万，你把肾卖给我吧。”“老师，我是有尊严的好不好。”“500万行不行？”“老师，我真的有尊严。”“5000万，再加上海的两套房子。”“成交！”“最后一声干脆利索，于是我把他的肾割了下来，做了一个烤腰子，吃了一口，问他要不要也吃一口，他则跟我显摆说我有钱哪。”\n“这是尊严吗”？罗翔反问道。这种尊严不过就是用钱来计算罢了，还涉嫌组织出卖人体器官罪，显然是违法的。这就是为什么法律对自由会进行一定约束，因为自由是不能以彻底放弃自由为代价的。\n另外在一起重大杀人案中，一对农民夫妇杀掉了50多个人，把尸体像摞砖一样放在自己家的地窖里，据说他们抢夺来的财产总共才500多块。后来警察问他们：杀这么多人你们就不害怕吗？他们却回答，你瞧瞧，不就是杀个人吗，多大点事呀。虽然杀第一个人的时候是有点怕的，当时尸体在二楼，我在一楼睡觉，夜深人静的时候听到楼上有血滴答滴答往下淌的声音，但是仔细一想，这个世界上又没有鬼，还有什么可怕的呢。类似这样的案子听起来很震惊，却干货十足，罗翔的各种段子也在网上不断发酵。\n“宝藏老师”\n以上各种奇葩案件，让罗翔把刑法课堂变得热闹非凡。\n法治课程讲得接地气，让一些非法律专业粉丝开始霸屏，会计学专业的慕名而来，安全工程专业前来受教，电气工程专业来报到，高一文科生也开始围观了……他们亲切地称呼罗翔是“宝藏老师”。\n在几百万粉丝的包围中，罗翔一直表现得很平静。在网络之外，罗翔说自己就是一个普通的老师而已。他谦虚地说：“那些视频课程是为一家法律职业资格考试培训机构录制的，被一些听课同学自动搬到了B站，所以受到关注可以说是无心插柳柳成荫。我不觉得自己‘火了’。我个人一直觉得，人在使命中才活得有意义，要向着标杆奔跑。”\n老师这个职业，就是罗翔心中的那杆标杆。\n在微信公众号“罗翔说刑法”上，他曾写过一篇《我的老师》的文章，回忆了读书期间导师对他的帮助。“当年我写博士论文时，导师不时会打电话督工，有时一个电话能打两个小时。每次我打电话向导师请教问题时，他会先挂掉，然后给我回拨过来，他的理由是学生话费有限。有一年大年初二，我在朋友家喝酒聚会，酒兴正浓，结果导师打来电话，说今天已经初二了，年也过得差不多了，该收心写论文了。我们也经常为一个问题争得面红耳赤，毫不客气，一点也不顾忌导师的颜面，不过毕业之后，导师还时常给我打电话，有时一个问题也要和我讨论很久。”\n罗翔觉得自己很幸运，遇到了好的老师，他把人生95%的成就归功于老师的相助，他的人生轨迹，也因为老师而变得有所不同。\n2005年，罗翔从北京大学法学院刑法学博士毕业后，成为中国政法大学的一名老师。他有一种强烈的想法，要把从老师那里接收的祝福传递给更多的学生。但现实是，做和做到之间有一座天然的鸿沟。即使是罗翔自己，有时候也很难做到有教无类。他说耐心是很容易碎掉的，可自己对老师这份职业，心中始终留有一份深厚的感情。\n因为对老师这份职业的执着，罗翔始终想着，要把课堂变得精彩有趣，在严肃和幽默之间找到平衡点。为此，他将各种法律故事契合人的常识、常情、常理进行整合，然后变成一个个带有温度的故事。这让学生找到那种“再来一亿遍”的感觉。\n人生需不断前行，走出舒适圈\n曾经有粉丝给罗翔留言，说自己在喜马拉雅上录制他的书《圆圈正义》给孩子听，录制到一半突然意识到自己是不是侵权了？他则热情地回复道：“用吧，不侵权。”\n《圆圈正义》是罗翔的一本随笔合集，也分享了自己的求学经验和对人生的思考。前言里，罗翔说：“我们画不出一个完整的圆，但是不代表圆不存在，四边形也能成为圆，生活中总有理想，虽不能至，心向往，可以达不到，但是不能放弃，它是我们前进的方向。”\n罗翔也有一些比较有意思的经历。他说自己小时候比较调皮，曾经担任过两个星期的小组长，当时觉得自己很厉害，还让同学帮他写作业，后来被老师和家长知道了，之后父母便对他开展了严格的管理，以至于成年之后他回家乡和朋友聚会，一到十点大家都会催促他赶紧回家。\n而说到自己是如何开始学习法律的，罗翔说当年在高考填报考志愿时，也是有犹豫过的。“我本来是想学医的，但是我物理和化学不好，只有数学好，仅有一门数学好在理科生中是没有优势的，相反如果选择文科的话，数学好就比较有优势了，再加上我喜欢历史，父母觉得文科专业更加适合我，最后在比较热门的经济和法学专业领域中我选择了法学专业。”\n不过罗翔觉得严格的管理教育也是一件好事，可以督促自己去进步和提升，这也让他每年都被学生选为最受欢迎的老师之一，每次一有他的课，学生们很难占到座位，甚至有的同学自愿站着听完整节课。同学们对他的喜欢，对罗翔来说是一份感动，也激励他不断往前走。\n走出舒适圈，跳出自己的局限，罗翔给自己制定了往前的目标，他在国外的留学经历，也将他的视野放得更宽。\n罗翔在美国留学时，有一次违反了交通法。他和朋友开车经过旧金山大桥，在过桥时，看到有一边收费通道没什么人，就把车开过去了，不料几天后收到了罚单。原来他开车通过的车道是电子速通通道，需要在车上装电子速通卡才能通过，如果在早高峰和晚高峰时期，只要车里有三名以上乘客，是可以免交高速费的，他当时没有弄清楚当地的交通规则。\n在美国，不遵守交通规则罚款罚得很重，不过罚单上也会有这么一句话：如果不服罚款，可以在一个月内上诉。于是，罗翔立刻写了一封说明信，警察查了他的驾驶记录，发现他是外国人，且是首次违章，考虑到他可能不懂旧金山的法律规定，于是免除了他的罚款，只需补交过桥费。\n还有一次罗翔在公园里散步，发现地上有掉落的鹿茸，觉得扔在那里很可惜，便捡了起来，在他准备走出公园的时候被警察看到了，说他捡起地上鹿茸的行为涉嫌违法。不经意的一个行为让他陷入了比较尴尬的境遇，后来回过神来他才发现，自己的行为涉嫌运送珍稀物品罪，好在警察对他还比较客气，让他赶紧把鹿茸放回到原来的地方。\n类似的事情也在法国巴黎发生过。罗翔的护照在巴黎游玩时弄丢了，他去巴黎警察局报了案，因为护照是在德国签发的，警察给德国大使馆打了电话。“他们的效率特别高，几分钟之后就找到一位可以说德语、法语和中文的翻译来为我提供帮助。我告知对方我已经买了下一个目的地的火车票，现在没有护照出行很麻烦。”巴黎警察建议罗翔在没有护照的情况下，先暂时不要离开，但他害怕耽误行程，再加上火车票很贵，他还是抱着侥幸的心理去了火车站。\n通常情况下坐火车是不用查护照的，结果那天有个大案子正好发生，每个人通关都必须检查护照。检"
  },
  {
    "title": "大模型Scaling Law深度解析，收藏这篇就够了！-CSDN博客",
    "page_body": "CC 4.0 BY-SA版权\n在 大模型 的研发中，通常会有下面一些需求：\n• 1.计划训练一个10B的模型，想知道至少需要多大的数据？ • 2.收集到了1T的数据，想知道能训练一个多大的模型？ • 3.老板准备1个月后开发布会，给的资源是100张A100，应该用多少数据训多大的模型效果最好？ • 4.老板对现在10B的模型不满意，想知道扩大到100B模型的效果能提升到多少？\n以上这些问题都可以基于Scaling Law的理论进行回答。本文是阅读了一系列 Scaling Law的文章后的整理和思考，包括Scaling Law的概念和推导以及反Scaling Law的场景，不当之处，欢迎指正。\n核心结论\n大模型的Scaling Law是 OpenAI 在2020年提出的概念[1]，具体如下:\n1.对于Decoder-only的模型，计算量( Flops ), 模型参数量N, 数据大小(token数)，三者满足: 。(推导见本文最后)\n2.模型的最终性能 主要 与计算量，模型参数量和数据大小三者相关，而与模型的具体结构(层数/深度/宽度)基本无关。\n固定模型的总参数量，调整层数/深度/宽度，不同模型的性能差距很小，大部分在2%以内\n3.对于计算量，模型参数量和数据大小，当不受其他两个因素制约时，模型性能与每个因素都呈现 幂律关系\n4.为了提升模型性能，模型参数量N和数据大小D需要同步放大，但模型和数据分别放大的比例还存在争议。\n5.Scaling Law不仅适用于 语言模型 ，还适用于其他模态以及跨模态的任务[4]：\n这里横轴单位为PF-days: 如果每秒钟可进行次运算，就是1 peta flops，那么一天的运算就是，这个算力消耗被称为1个petaflop/s-day。\n核心公式\n• 第一项是指无法通过增加模型规模来减少的损失，可以认为是数据自身的熵（例如数据中的噪音） • 第二项是指能通过增加计算量来减少的损失，可以认为是模型拟合的分布与实际分布之间的差。\n根据公式，增大(例如计算量)，模型整体loss下降，模型性能提升；伴随x趋向于无穷大，模型能拟合数据的真实分布，让第二项逼近0，整体趋向于\n大模型中的Scaling Law\nGPT4\n下图是GPT4报告[5]中的Scaling Law曲线， 计算量C和模型性能满足幂律关系\n• 横轴是归一化之后的计算量，假设GPT4的计算量为1。基于10,000倍小的计算规模，就能预测最终GPT4的性能。 • 纵轴是\"Bits for words\", 这也是交叉熵的一个单位。在计算交叉熵时，如果使用以 2 为底的对数，交叉熵的单位就是 “bits per word”，与信息论中的比特（bit）概念相符。所以这个值越低，说明模型的性能越好。\nBaichuan2\n下图是Baichuan2[6]技术报告中的Scaling Law曲线。基于10M到3B的模型在1T数据上训练的性能，可预测出最后7B模型和13B模型在2.6T数据上的性能\nMindLLM\n下图是MindLLM[7]技术报告中的Scaling Law曲线。基于10M到500M的模型在10B数据上训练的性能，预测出最后3B模型在500B数据上的性能。\nScaling Law实操: 计算效率最优\n根据幂律定律，模型的参数固定，无限堆数据并不能无限提升模型的性能，模型最终性能会慢慢趋向一个固定的值\n如图所示，如果模型的参数量为（图中紫色的线），在数量达到，模型基本收敛。所以在数据量达到后，继续增加数据产生的计算量，没有同样计算量下提升模型参数量带来的收益大（计算效率更优）。根据，可以进一步转换成模型参数与计算量的关系，即: 模型参数为，在计算量为，即时基本收敛。也就是右图中紫色线的拐点。\n根据Baichuan[6]的实验，在中英场景下，7B模型收敛时的算力是 FLOPS，对应的数据量应该是\n按照上面的思路，下面进行Scaling Law的实操。\n首先准备充足的数据（例如1T），设计不同模型参数量的小模型(例如0.001B - 1B)，独立训练每个模型，每个模型都训练到基本收敛（假设数据量充足）。根据训练中不同模型的参数和数据量的组合，收集计算量与模型性能的关系。然后可以进一步获得 计算效率 最优时，即同样计算量下性能最好的模型规模和数据大小的组合，模型大小与计算量的关系，以及数据大小与计算量的关系。\n如图所示，根据左图可以看到计算量与模型性能呈现幂律关系（可以认为数据和模型都不受限制），根据中图和右图，可以发现,，即计算效率最优时，模型的参数与计算量的幂次成线性关系，数据量的大小也与计算量的幂次成线性关系。\n根据，可以推算出，但是分别是多少存在分歧。\nOpenAI[1]认为模型规模更重要，即，而DeepMind在Chinchilla工作[2]和Google在PaLM工作[3]中都验证了 a=b=0.5 ，即模型和数据同等重要。\n所以假定计算量整体放大10倍，OpenAI认为模型参数更重要，模型应放大 (5.32)倍，数据放大 (1.86)倍；后来DeepMind和Google认为模型参数量与数据同等重要，两者都应该分别放大 (3.16)倍。\n例如在PaLM的实验中，计算量从放大10倍到， 模型参数也提升了3.2倍，3.35B->10.7B。\n具体最好在自己的数据上做实验来获得你场景下的a和b。\nLLaMA: 反Scaling Law的大模型\n假设遵循 计算效率 最优来研发LLM，那么根据Scaling Law，给定模型大小，可以推算出最优的计算量，进一步根据最优计算量就能推算出需要的 token 数量，然后训练就行。\n但是 计算效率 最优这个观点是针对 训练阶段 而言的，并不是 推理阶段 ，实际应用中 推理 阶段效率更实用。\nMeta在LLaMA[8]的观点是：给定模型的目标性能，并不需要用最优的计算效率在最快时间训练好模型，而应该在更大规模的数据上，训练一个相对更小模型，这样的模型在推理阶段的成本更低，尽管训练阶段的效率不是最优的（同样的算力其实能获得更优的模型，但是模型尺寸也会更大）。根据Scaling Law，10B模型只需要200B的数据，但是作者发现7B的模型性能在1T的数据后还能继续提升。\n所以LLaMA工作的重点是训练一系列语言模型，通过使用更多的数据，让模型在 有限推理资源下有最佳的性能 。\n具体而言，确定模型尺寸后，Scaling Law给到的只是最优的数据量，或者说是一个至少的数据量，实际在训练中观察在各个指标上的性能表现，只要还在继续增长，就可以持续增加训练数据。\n计算量、模型和数据大小的关系推导\n对于Decoder-only的模型，计算量C(Flops), 模型参数量N(除去Embedding部分), 数据大小D(token数), 三者的关系为:\n推导如下，记模型的结构为:\ndecoder层数 :\nattention 隐层维度 :\nattention feedforward层维度 : ， 一般来说\n首先推导模型的参数量（忽略embedding，norm和bias）计算如下:\ntransformer每层包括: self-attetion 和 MLP 两个部分:\nself-attention的参数为，每个矩阵的维度均为，整体参数量:\nMLP的层数的参数为，整体参数量:\n所以每层的参数量为: ，全部的l层的参数量为: ，即\n继续推导模型的前向推理的计算量:\n计算量的单位是FLOPs，floating point operations 对于矩阵，相乘的计算量为，一次加法一次乘法。\n假设Decoder层的输入, 为batch size，为序列长度, 为模型维度。\nself-attention部分的计算 :\n输入线性层: ，计算量为:\natention计算: ，计算量为:\nsocre与V的计算: ，计算量为:\n输出线性层: ，计算量为: 4b * 2 * s * d * d = 2bsd^2$\nMLP部分的计算\n升维: ，计算量为:\n降维: ，计算量为:\n所以整个decoder层的计算量为:，全部l层为:\n反向传播计算量是正向的2倍，所以全部的计算量为:\n平均每个token的计算量为\n所以对于全部包含D个token的数据集:\n如何系统的学习大模型  AI  ？\n由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。\n但是具体到个人，只能说是：\n“最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。\n这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。\n我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。\n我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。\n一直在更新，更多的大模型学习和面试资料已经上传带到CSDN的官方了，有需要的朋友可以扫描下方二维码免费领取【保证100%免费】        \n01.大模型风口已至：月薪30K+的AI岗正在批量诞生\n2025年大模型应用呈现爆发式增长，根据工信部最新数据：\n国内大模型相关岗位缺口达47万\n初级工程师平均薪资28K（数据来源：BOSS直聘报告）\n70%企业存在\"能用模型不会调优\"的痛点\n真实案例：某二本机械专业学员，通过4个月系统学习，成功拿到某AI医疗公司大模型优化岗offer，薪资直接翻3倍！\n02.大模型 AI 学习和面试资料\n1️⃣ 提示词工程：把ChatGPT从玩具变成生产工具\n 2️⃣ RAG系统：让大模型精准输出行业知识\n 3️⃣ 智能体开发：用AutoGPT打造24小时数字员工\n    熬了三个大夜整理的《AI进化工具包》送你：\n ✔️ 大厂内部LLM落地手册（含58个真实案例）\n ✔️ 提示词设计模板库（覆盖12大应用场景）\n ✔️ 私藏学习路径图（0基础到项目实战仅需90天）\n第一阶段（10天）：初阶应用\n该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨论时发表高级、不跟风、又接地气的见解，别人只会和 AI 聊天，而你能调教 AI，并能用代码将大模型和业务衔接。\n大模型 AI 能干什么？ 大模型是怎样获得「智能」的？ 用好 AI 的核心心法 大模型应用业务架构 大模型应用技术架构 代码示例：向 GPT-3.5 灌入新知识 提示工程的意义和核心思想 Prompt 典型构成 指令调优方法论 思维链和思维树 Prompt 攻击和防范 …\n第二阶段（30天）：高阶应用\n该阶段我们正式进入大模型 AI 进阶实战学习，学会构造私有知识库，扩展 AI 的能力。快速开发一个完整的基于 agent 对话机器人。掌握功能最强的大模型开发框架，抓住最新的技术进展，适合 Python 和 JavaScript 程序员。\n为什么要做 RAG 搭建一个简单的 ChatPDF 检索的基础概念 什么是向量表示（Embeddings） 向量数据库与向量检索 基于向量检索的 RAG 搭建 RAG 系统的扩展知识 混合检索与 RAG-Fusion 简介 向量模型本地部署 …\n第三阶段（30天）：模型训练\n恭喜你，如果学到这里，你基本可以找到一份大模型 AI相关的工作，自己也能训练 GPT 了！通过微调，训练自己的"
  },
  {
    "title": "工信安的《大模型2.0产业发展报告：商业落地创涌而现》_大模型2.0产业发展报告商业落地创涌而现-CSDN博客",
    "page_body": "工信安发展研究中心和联想集团最近联合编写了一份技术报告：《大模型2.0产业发展报告：商业落地创涌而现》。这份报告全面深入地探讨了大模型2.0的技术特点、产业生态、社会影响、政策监管、投资与人才需求、关键要素、个人与企业应用以及未来发展趋势，为业界提供了有价值的参考和启示。\n报告的主要内容总结如下：\n1 大模型 2.0 概述\n大模型 2.0 是基于深度学习算法，依托大规模数据进行训练，并能执行复杂下游任务的大型语言模型（LLMs）。它标志着大模型技术从探索期向应用期的转变，实现了技术的规模商业化。大模型 2.0 具备更强的理解能力，能够处理和理解多模态数据，具备更高的逻辑推理能力；拥有更全面的知识储备，数据版权化推动更多行业知识进入大模型训练；采用更高效低碳的训练模式，借助模型压缩技术、异构计算平台等降低训练成本；并展现出更广泛的产业应用能力，以 API 或服务形式提供，满足不同应用场景需求。\n2 大模型 2.0 的技术特点和产业生态\n在技术层面，大模型 2.0 的进步显著。它不仅在理解能力上有了质的飞跃，能够处理复杂的多模态数据并进行深度逻辑推理，还在知识储备上更为丰富，得益于数据版权化的推进，大量行业专业知识被纳入训练范畴。同时，其训练模式也更加高效和低碳，通过模型压缩技术以及异构计算平台的运用，大幅降低了训练成本。在产业应用方面，大模型 2.0 以 API 或服务的形式广泛应用于各个领域，满足了多样化的应用场景需求。\n从产业生态来看，个人大模型生态涵盖了数据供给、技术基础设施、模型应用、服务与产品供给以及安全与隐私等多个方面，形成了一个完整的发展链条。而企业大模型生态则包括基础层、应用层和战略层，推动企业从局部场景智能化向全栈智能化转型，助力企业在经营管理、研发设计、供应链管理、生产制造等多个方面实现智能化升级。\n3 大模型 2.0 的社会影响\n大模型 2.0 对社会产生了深远的影响。在个人层面，它在内容创作、数据分析等领域的应用极大地提高了个人的工作效率，成为提升个人生产力的重要工具。对企业而言，大模型 2.0 推动企业从局部场景的智能化向全栈智能化发展，不仅提升了业务效率，还提高了产品质量，为企业带来了显著的经济效益。从更宏观的社会层面来看，大模型 2.0 推动了生产力的提升，促进了数字经济的高质量发展，成为推动社会进步的重要力量。\n4 政策与监管\n在全球范围内，主要经济体纷纷出台政策支持人工智能的发展。欧盟的《人工智能法案》、美国的《国家人工智能研发战略计划》等政策文件，都为大模型的发展提供了政策指引和支持。中国也将人工智能提升至国家战略层面，出台了一系列政策措施推动大模型的发展，如《新一代人工智能发展规划》《生成式人工智能服务管理暂行办法》等。同时，为了确保大模型技术的安全、可靠和伦理应用，各国也在加强对大模型的监管，推进全国层面的人工智能专门立法，建立完善的监管与治理体系。\n5 科技巨头投资与人才需求\n大模型 2.0 的快速发展吸引了众多科技巨头的布局和投资。谷歌、亚马逊、微软、阿里巴巴、联想等企业纷纷在大模型领域加大投入，推动技术的创新和应用的拓展。随着大模型技术的不断进步，对深度学习、数据科学等专业技能的人才需求也在持续增长。企业和研究机构都在积极寻求相关领域的专业人才，以满足大模型研发、应用和优化等方面的需要。\n6 大模型 2.0 的关键要素\n大模型 2.0 的发展离不开基础层、模型层、应用层和保障层的共同支撑。基础层包括数据、算力、算法和工具，为大模型的发展提供了坚实的基础。模型层则由通用大模型、行业大模型、企业大模型和个人大模型共同构成，形成了丰富多样的大模型生态。应用层是大模型发挥作用的关键环节，大模型在制造业、金融、医疗、交通等多个领域实现了广泛的应用，为各行业的发展带来了新的机遇。保障层则着重于建立产业合规标准，确保数据、模型和应用的安全保障以及伦理治理，为大模型的健康发展保驾护航。\n7 个人大模型的应用与发展\n个人大模型的应用正在不断拓展和深化。它推动了智能手机、智能家居等个人终端产品的智能化升级，使这些产品更加智能、便捷和个性化。智能个人助理成为个人大模型应用的重要方式之一，它能够根据用户的需求和偏好提供个性化的服务，提升用户的使用体验，成为人们日常生活和工作中的得力助手。\n8 企业大模型的应用与案例\n在企业领域，大模型的应用价值得到了充分体现。它构建了一个完善的企业智能化转型价值体系，在经营管理、研发设计、供应链管理、生产制造等方面发挥着重要作用。以联想为例，其在企业智能化转型中的具体应用和成效展示了大模型的强大能力。通过引入大模型技术，联想在多个业务环节实现了智能化升级，提高了运营效率，优化了产品质量，增强了企业的市场竞争力，为其他企业的智能化转型提供了有益的借鉴。\n9 大模型的未来发展趋势\n展望未来，大模型的发展呈现出多方面的趋势。一方面，大模型的通用性将不断提升，随着参数规模的扩大，其泛化能力和多任务学习能力也将进一步增强，能够更好地应对各种复杂任务和多样化场景。另一方面，大模型将朝着轻量化方向发展，通过算法优化，大模型的体量将减小，算力需求也将降低，从而能够更灵活地部署在终端设备上，实现更广泛的应用。此外，大模型与其他技术的融合程度将不断加深，与物联网、大数据、云计算等技术的结合将赋能更多行业和应用场景，创造更多的价值。最后，去概率化大模型将成为新的发展趋势，通过规则与学习相结合的方式，大模型的记忆、推理和决策能力将得到显著提升，为人工智能的发展开辟新的道路。\n普通人如何抓住AI大模型的风口？\n=领取方式在文末==\n为什么要学习大模型？\n目前AI大模型的技术岗位与能力培养随着人工智能技术的迅速发展和应用 ， 大模型作为其中的重要组成部分 ， 正逐渐成为推动人工智能发展的重要引擎 。大模型以其强大的数据处理和模式识别能力， 广泛应用于自然语言处理 、计算机视觉 、 智能推荐等领域 ，为各行各业带来了革命性的改变和机遇 。\n目前，开源人工智能大模型已应用于医疗、政务、法律、汽车、娱乐、金融、互联网、教育、制造业、企业服务等多个场景，其中，应用于金融、企业服务、制造业和法律领域的大模型在本次调研中占比超过  30%。\n随着AI大模型技术的迅速发展，相关岗位的需求也日益增加。大模型产业链催生了一批高薪新职业：\n人工智能大潮已来，不加入就可能被淘汰。如果你是技术人，尤其是互联网从业者，现在就开始学习AI大模型技术，真的是给你的人生一个重要建议！\n大模型目前在人工智能领域可以说正处于一种“炙手可热”的状态，吸引了很多人的关注和兴趣，也有很多新人小白想要学习入门大模型， 那么，如何入门大模型呢？\n下面给大家分享一份2025最新版的大模型学习路线，帮助新人小白更系统、更快速的学习大模型！\n*有需要完整版学习路线* ，可以 微信扫描下方二维码 ，立即免费领取!\n一、2025最新大模型学习路线\n一个明确的学习路线可以帮助新人了解从哪里开始，按照什么顺序学习，以及需要掌握哪些知识点。大模型领域涉及的知识点非常广泛，没有明确的学习路线可能会导致新人感到迷茫，不知道应该专注于哪些内容。\n我们把学习路线分成L1到L4四个阶段，一步步带你从入门到进阶，从理论到实战。\nL1级别:AI大模型时代的华丽登场\nL1阶段：我们会去了解大模型的基础知识，以及大模型在各个行业的应用和分析；学习理解大模型的核心原理，关键技术，以及大模型应用场景；通过理论原理结合多个项目实战，从提示工程基础到提示工程进阶，掌握Prompt提示工程。\nL2级别：AI大模型RAG应用开发工程\nL2阶段是我们的AI大模型RAG应用开发工程，我们会去学习RAG检索增强生成：包括Naive RAG、Advanced-RAG以及RAG性能评估，还有GraphRAG在内的多个RAG热门项目的分析。\nL3级别：大模型Agent应用架构进阶实践\nL3阶段：大模型Agent应用架构进阶实现，我们会去学习LangChain、 LIamaIndex框架，也会学习到AutoGPT、 MetaGPT等多Agent系统，打造我们自己的Agent智能体；同时还可以学习到包括Coze、Dify在内的可视化工具的使用。\nL4级别：大模型微调与私有化部署\nL4阶段：大模型的微调和私有化部署，我们会更加深入的探讨Transformer架构，学习大模型的微调技术，利用DeepSpeed、Lamam Factory等工具快速进行模型微调；并通过Ollama、vLLM等推理部署框架，实现模型的快速部署。\n整个大模型学习路线L1主要是对大模型的理论基础、生态以及提示词他的一个学习掌握；而L3 L4更多的是通过项目实战来掌握大模型的应用开发，针对以上大模型的学习路线我们也整理了对应的学习视频教程，和配套的学习资料。\n二、大模型经典PDF书籍\n书籍和学习文档资料是学习大模型过程中必不可少的，我们精选了一系列深入探讨大模型技术的书籍和学习文档， 它们由领域内的顶尖专家撰写，内容全面、深入、详尽，为你学习大模型提供坚实的理论基础 。 （书籍含电子版PDF）\n三、大模型视频教程\n对于很多自学或者没有基础的同学来说，书籍这些纯文字类的学习教材会觉得比较晦涩难以理解，因此，我们 提供了丰富的大模型视频教程 ，以动态、形象的方式展示技术概念， 帮助你更快、更轻松地掌握核心知识 。\n四、大模型项目实战\n学以致用  ，当你的理论知识积累到一定程度，就需要通过项目实战， 在实际操作中检验和巩固你所学到的知识 ，同时为你找工作和职业发展打下坚实的基础。\n五、大模型面试题\n面试不仅是技术的较量，更需要充分的准备。\n在你已经掌握了大模型技术之后，就需要开始准备面试，我们将提供精心整理的大模型面试题库，涵盖当前面试中可能遇到的各种技术问题，让你在面试中游刃有余。\n全套的AI大模型学习资源已经整理打包 ，有需要的小伙伴可以 微信扫描下方二维码 ，免费领取\n****如果这篇文章对你有所帮助，还请花费2秒的时间** 点个赞+收藏+分享 ，**让更多的人看到这篇文章，帮助他们走出误区。"
  },
  {
    "title": "给小白的大模型入门科普-20250304003342.docx-原创力文档",
    "page_body": "内容提供方 ： 文库新人 大小 ： 53.56 KB 字数 ： 约2.82万字 发布时间 ： 浏览人气 ： 10 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n给小白的大模型入门科普.docx 原文免费试下载\n给小白的大模型入门科普\n目录\n内容概括．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．3\n1.1大模型简介．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．3\n1.2小白入门的重要性．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．4\n1.3本文档的目标和结构概览．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．5\n大模型基础概念．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．6\n2.1什么是大模型？．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．6\n2.2大模型的组成．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．6\n2.2.1输入层．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．7\n2.2.2隐藏层．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．8\n2.2.3输出层．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．9\n2.3大模型与传统机器学习模型的区别．．．．．．．．．．．．．．．．．．．．．．．．．9\n大模型的训练过程．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．10\n3.1数据预处理．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．11\n3.1.1数据清洗．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．11\n3.1.2特征工程．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．13\n3.2损失函数与优化算法．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．14\n3.2.1损失函数的类型和作用．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．14\n3.2.2常见的优化算法及其特点．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．16\n3.3训练流程．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．17\n3.3.1初始化参数．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．18\n3.3.2前向传播．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．19\n3.3.3反向传播和梯度下降．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．19\n3.3.4正则化与防止过拟合．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．20\n3.4评估指标．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．21\n3.4.1准确率、召回率和F1分数．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．22\n3.4.2混淆矩阵．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．23\n大模型的应用案例．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．24\n4.1自然语言处理．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．25\n4.1.1文本分类．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．26\n4.1.2机器翻译．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．27\n4.1.3情感分析．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．28\n4.2计算机视觉．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．29\n4.2.1图像识别．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．30\n4.2.2物体检测．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．31\n4.2.3图像分割．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．32\n4.3推荐系统．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．33\n4.3.1协同过滤．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．33\n4.3.2内容基推荐．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．34\n4.3.3混合推荐系统．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．36\n常见问题与解决策略．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．37\n5.1过拟合与欠拟合．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．37\n5.2模型选择与调参．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．39\n5.3数据增强与迁移学习．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．40\n5.4超参数优化技巧．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．40\n未来趋势与展望．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．41\n6.1新兴技术的影响．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．42\n6.2大模型在特定领域的应用前景．．．．．．．．．．．．．．．．．．．．．．．．．．．．43\n6.3行业应用案例分享．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．44\n结论与实践指南．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．45\n7.1总结关键要点．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．46\n7.2初学者实践建议．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．47\n7.3后续资源与学习路径规划．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．．47\n1.内容概括\n本篇科普文章旨在为初学者介绍大模型的基础知识与应用，我们将从基本概念出发，解释什么是大模型及其在人工智能领域的重要作用。接着，深入探讨大模型的工作原理，包括深度学习算法如何训练模型以及神经网络结构的设计。我们还将讨论大模型的应用场景，如自然语言处理、图像识别和推荐系统等，并分析其在这些领域的优势和挑战。\n本文还特别关注大模型可能带来的伦理和社会影响，例如隐私保护、偏见问题及数据安全风险。我们将提供一些实用建议，帮助读者更好地理解和利用大模型进行实际操作。通过阅读本文，希望每位新手都能对大模型有更全面的认识和理解。\n1.1大模型简介\n在探讨如何踏入大模型的世界之前，让我们首先对“大模型”这一概念进行一番简要的解读。所谓“大模型”，通常指的是那些具备海量数据训练、拥有强大计算能力的人工智能模型。这些模型以其卓越的学习能力和广泛的适用性，在众多领域展现出了巨大的潜力。\n简言之，大模型是由大量数据驱动的智能系统，它们通过不断的学习与分析，能够执行复杂的任务，并在此过程中不断优化自身的性能。在人工智能的发展历程中，大模型扮演着至关重要的角色，它们不仅推动了技术的进步，也为各行各业带来了深刻的变革。\n随着技术的不断演进，大模型的应用范围日益扩大，从自然语言处理到图像识别，从推荐系统到决策支持，大模型都能发挥其独特的作用。对于想要了解和学习大模型的人来说，掌握这一领域的基本知识显得尤为重要。我们将逐步深入，带领大家走进大模型的精彩世界。\n1.2小白入门的重要性\n对于初学者而言，掌握大模型的基础知识至关重要。这不仅有助于他们更好地理解人工智能领域的复杂概念，而且还能为他们后续深入学习提供坚实的基础。通过本文档，我们将详细介绍小白如何能够有效地入门并逐步深入到大模型的学习中。\n了解大模型的基本构成是入门的首要步骤，大模型通常由多个层次组成，包括输入层、隐藏层和输出层等。这些层次之间相互连接，共同构成了整个模型的功能。通过对这些层次的了解，新手可以更好地把握大模型的整体架构，为后续的学习打下坚实的基础。\n掌握基本的算法原理也是小白入门的关键，在深度学习领域，有许多不同的算法和技术可供选择。新手需要了解这些算法的原理和应用场景，以便在实际应用中能够灵活运用。了解常见的优化方法也是必不可少的，例如正则化、dropout等技术可以帮助模型更好地拟合数据，提高性能。\n实践操作是小白学习的重要环节，理论知识虽然重要，但实际操作才能让新手真正掌握知识。通过动手实践，新手可以更好地理解算法的工作原理，发现问题并解决问题。实践还可以帮助新手积累经验，为后续的学习打下良好的基础。\n持续学习和探索也是小白入门的重要途径，人工智能领域不断发展，新的技术和方法层出不穷。作为初学者，需要保持好奇心和"
  },
  {
    "title": "TensorFlow：模型训练与优化.docx-原创力文档",
    "page_body": "内容提供方 ： 找工业软件教程找老陈 大小 ： 28.1 KB 字数 ： 约1.73万字 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\nPAGE1\nPAGE1\nTensorFlow：模型训练与优化\n1TensorFlow基础\n1.1安装与环境配置\n在开始使用TensorFlow之前，首先需要确保你的环境已经正确安装了TensorFlow。以下是在Python环境中安装TensorFlow的基本步骤：\n安装Python：确保你的系统中已经安装了Python，推荐使用Python3.6或更高版本。\n安装pip：pip是Python的包管理器，用于安装和管理Python软件包。如果你的Python环境中没有pip，可以通过以下命令安装：\npythonget-pip.py\n安装TensorFlow：使用pip安装TensorFlow，可以通过以下命令进行安装：\npipinstalltensorflow\n如果你使用的是虚拟环境，确保在虚拟环境中执行上述命令。\n验证安装：安装完成后，可以通过Python脚本来验证TensorFlow是否安装成功。以下是一个简单的示例：\n#验证TensorFlow安装\nimporttensorflowastf\n#打印TensorFlow版本\nprint(tf.__version__)\n#创建一个简单的常量操作\nhello=tf.constant(Hello,TensorFlow!)\nsess=tf.Session()\n#运行会话并打印结果\nprint(sess.run(hello))\n运行上述代码，如果能够成功打印出版本信息和“Hello,TensorFlow!”，则说明TensorFlow已经成功安装。\n1.2张量与操作\n在TensorFlow中，数据以张量的形式表示，张量可以理解为多维数组。以下是一个创建张量和执行基本操作的示例：\n#创建张量\nimporttensorflowastf\n#创建一个1维张量\na=tf.constant([1.0,2.0,3.0],shape=[3],name=a)\n#创建一个2维张量\nb=tf.constant([[1.0,2.0,3.0],[4.0,5.0,6.0]],shape=[2,3],name=b)\n#执行张量操作\nc=tf.add(a,b,name=c)\nd=tf.multiply(a,b,name=d)\n#创建会话并执行操作\nwithtf.Session()assess:\nprint(a+b=,sess.run(c))\nprint(a*b=,sess.run(d))\n在这个例子中，我们创建了两个张量a和b，然后执行了加法和乘法操作。tf.add和tf.multiply是TensorFlow中的操作，它们接收张量作为输入，并返回一个新的张量作为输出。\n1.3构建计算图\nTensorFlow使用计算图来表示计算过程。计算图是一个有向图，其中节点表示操作，边表示张量。以下是一个构建计算图的示例：\n#构建计算图\nimporttensorflowastf\n#创建占位符\nx=tf.placeholder(tf.float32,shape=[None],name=x)\ny=tf.placeholder(tf.float32,shape=[None],name=y)\n#创建变量\nW=tf.Variable(tf.random_normal([1]),name=weight)\nb=tf.Variable(tf.zeros([1]),name=bias)\n#定义模型\ny_pred=tf.add(tf.multiply(x,W),b)\n#定义损失函数\nloss=tf.reduce_mean(tf.square(y_pred-y))\n#定义优化器\noptimizer=tf.train.GradientDescentOptimizer(0.01)\ntrain=optimizer.minimize(loss)\n#初始化变量\ninit=tf.global_variables_initializer()\n#创建会话并执行计算图\nwithtf.Session()assess:\nsess.run(init)\nforstepinrange(200):\nsess.run(train,feed_dict={x:[1,2,3,4],y:[0,-1,-2,-3]})\nif(step+1)%20==0:\nprint(step+1,sess.run([W,b]))\n在这个例子中，我们首先创建了两个占位符x和y，它们用于在运行时接收数据。然后，我们创建了两个变量W和b，它们用于存储模型的参数。接着，我们定义了模型y_pred，它是一个线性模型。然后，我们定义了损失函数loss，它是一个均方误差损失函数。最后，我们定义了优化器optimizer，它是一个梯度下降优化器，用于最小化损失函数。\n1.4会话与执行\n在TensorFlow中，所有的操作都在会话中执行。会话是一个运行计算图的环境。以下是一个使用会话执行计算图的示例：\n#使用会话执行计算图\nimporttensorflowastf\n#创建张量\na=tf.constant(5.0)\nb=tf.constant(6.0)\n#创建操作\nc=tf.add(a,b)\n#创建会话并执行操作\nwithtf.Session()assess:\nprint(a+b=,sess.run(c))\n在这个例子中，我们首先创建了两个张量a和b，然后创建了一个操作c，它是一个加法操作。然后，我们创建了一个会话，并在会话中执行了操作c。sess.run(c)会返回操作c的输出结果。\n会话是TensorFlow中的重要概念，所有的操作和变量都在会话中执行和初始化。在会话中，你可以通过feed_dict参数向占位符传递数据，通过run方法执行操作，通过eval方法获取张量的值。\n2TensorFlow：模型训练与优化\n2.1模型训练\n2.1.1数据预处理\n数据预处理是机器学习和深度学习项目中至关重要的第一步。在TensorFlow中，我们可以使用tf.data.Dataset来高效地加载和预处理数据。下面是一个使用MNIST数据集的例子，展示了如何对数据进行预处理：\nimporttensorflowastf\nfromtensorflow.keras.datasetsimportmnist\n#加载数据\n(x_train,y_train),(x_test,y_test)=mnist.load_data()\n#数据预处理\nx_train,x_test=x_train/255.0,x_test/255.0#归一化\ntrain_dataset=tf.data.Dataset.from_tensor_slices((x_train,y_train))\ntest_dataset=tf.data.Dataset.from_tensor_slices((x_test,y_test))\n#批量处理和缓存数据\nBATCH_SIZE=64\ntrain_dataset=train_dataset.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\ntest_dataset=test_dataset.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n2.1.2构建模型\n构建模型是使用TensorFlow创建神经网络的下一步。我们可以使用tf.keras中的Sequential或Model类来定义模型。下面是一个简单的多层感知器（MLP）模型的构建示例：\nfromtensorflow.keras.modelsimportSequential\nfromtensorflow.keras.layersimportDense,Flatten\n#构建模型\nmodel=Sequential([\nFlatten(input_shape=(28,28)),#将输入数据从2D转换为1D\nDense(128,activation=relu),#添加一个具有ReLU激活函数的全连接层\nDense(10)#输出层，10个节点对应10个类别\n])\n2.1.3损失函数与优化器\n选择合适的损失函数和优化器对于模型的训练至关重要。损失函数衡量模型预测与实际标签之间的差异，而优化器则用于更新模型参数以最小化损失。以下是一个使用交叉熵损失和Adam优化器的例子：\nfromtensorflow.keras.lossesimportSparseCategoricalCrossentropy\nfromtensorflow.keras.optimizersimportAdam\n#定义损失函数和优化器\nloss_fn=SparseCategoricalCrossentropy(from_logits=True)\noptimizer=Adam(learning_rate=0.001)\n#编译模型\npile(optimizer=optimizer,\nloss=loss_fn,\nmetrics=[accuracy])\n2.1.4训练模型\n训练模型涉及使用训练数据和标签来调整模型参数。在TensorFlow中，我们可以使用model.fit方法来训练模型。以下是一个训练模型的例子：\n#训练模型\nEPOCHS=5\nmodel.fit(train_dataset,epochs=EPOCHS)\n2.1.5评估模型性能\n评估模型性能通常在测试数据集上进行，以检查模型的泛化能力。我们可以使用model.evaluate方法来评估模型的性能。下面是一个评估模型的例子：\n#评估模型性能\ntest_loss,test_acc=model.evaluate(test_dataset)\nprint(Testaccuracy:,test_acc)\n通过以上步骤，我们可以在TensorFlow中完成一个模型的训练和优化过程。数据预处理确保数据适合模型训练，构建模型定义了神经网络的结构，损失函数和优化器的选择影响了模型的学习过程，而训练和评估则分别用于调整模型参数和检查模型的性能。\n2.2代码示例解释\n在上述代码示例中，我们首先加载了MNIST数据集，这是一个包含手写数字的图像数据集。数据预处理包括将图像数据归一化，使其范围在0到1之间，这有助于模型训练。然后，我们使用tf.data.Dataset来创建训练和测试数据集，并对其进行批量处理和缓存，以提高训练效率。\n构建模型时，我们定义了一个简单的多层感知器，它将输入图像从2D转换为1D，然后通过两个全连接层进行处理。损失函数选择了SparseCategoricalCrossentropy，适用于多分类问题，而优化器选择了Adam，这是一种自适应学习率优化算法。\n模型训练通过model.fit方法完成，我们指定了训练的轮数（epochs）。最后，我们使用model.evaluate方法在测试数据集上评估模型的性能，输出了测试集上的准确率。\n这个过程展示了如何使用TensorFlow进行模型训练和优化的基本步骤，从数据预处理到模型评估，每一步都是构建高效机器学习模型的关键。\n3模型优化\n3.1超参数调整\n超参数调整是模型优化的关键步骤，它涉及选择模型训练过程中的参数，这些参数不能通过训练过程本身学习得到。在TensorFlow中，常见的超参数包括学习率、批次大小、优化器类型、正则化系数等。调整超参数的目标是找到一组参数，使得模型在验证集上的性能最佳。\n3.1.1代码示例：使用GridSearchCV进行超参数调整\n#导入所需库\nfromsklearn.model_selectionimportGridSearchCV\nfromtensorflow.keras.wrappers.scikit_learnimportKerasClassifier\nfromtensorflow.keras.modelsimportSequential\nfromtensorflow.keras.layersimportDense\nimportnumpyasnp\n#定义模型\ndefcreate_model(optimizer=adam,init=glorot_uniform):\nmodel=Sequential()\nmodel.add(Dense(12,input_dim=8,kernel_initializer=init,activation=relu))\nmodel.add(Dense(8,kernel_initializer=init,activation=relu))\nmodel.add(Dense(1,kernel_initializer=init,activation=sigmoid))\npile(loss=binary_crossentropy,optimizer=optimizer,metrics=[accuracy])\nreturnmodel\n#包装模型以适应GridSearchCV\nmodel=KerasClassifier(build_fn=create_model,epochs=50,batch_size=10,verbose=0)\n#定义超参数网格\nparam_grid={epochs:[50,100],\nbatch_size:[10,20],\noptimizer:[adam,sgd],\ninit:[glorot_uniform,normal]}\n#创建GridSearchCV对象\ngrid=GridSearchCV(estimator=model,param_grid=param_grid,n_jobs=-1)\n#假设X_train和y_train是训练数据\n#grid.fit(X_train,y_train)\n#打印最佳参数\n#print(Bestparametersfound:,grid.best_params_)\n3.2正则化技术\n正则化技术用于防止模型过拟合，即模型在训练数据上表现很好，但在新数据上表现不佳。在TensorFlow中，常见的正则化技术包括L1、L2正则化和Dropout。\n3.2.1代码示例：使用L2正则化\nfromtensorflow.keras.modelsimportSequential\nfromtensorflow.keras.layersimportDense\nfromtensorflow.keras.regularizersimportl2\n#创建模型\nmodel=Sequential()\nmodel.add(Dense(12,input_dim=8,kernel_regularizer=l2(0.01),activation=relu))\nmodel.add(Dense(8,kernel_regularizer=l2(0.01),activation=relu))\nmodel.add(Dense(1,activation=sigmoid))\n#编译模型\npile(loss=binary_crossentropy,optimizer=adam,metrics=[accuracy])\n3.3学习率策略\n学习率是模型训练中最重要的超参数之一，它决定了模型权重更新的幅度。在训练过程中，学习率的调整可以显著影响模型的收敛速度和最终性能。TensorFlow提供了多种学习率调整策略，如指数衰减、余弦衰减和学习率调度器。\n3.3.1代码示例：使用学习率调度器\nimporttensorflowastf\nfromtensorflow.keras.callbacksimportLearningRateScheduler\n#定义学习率调度器\ndefstep_decay(epoch):\ninitial_lrate=0.1\ndrop=0.5\nepochs_drop=10.0\nlrate=initial_lrate*tf.math.pow(drop,\ntf.math.floor((1+epoch)/epochs_drop))\nreturnlrate\n#创建学习率调度器实例\nlrate=LearningRateScheduler(step_decay)\n#在模型训练中使用学习率调度器\nmodel.fit(X_train,y_train,epochs=30,batch_size=10,callbacks=[lrate])\n3.4模型融合与集成\n模型融合与集成是通过结合多个模型的预测"
  },
  {
    "title": "大模型+数据资产变现，RAG 驱动企业智能化实践案例-herramientas en línea",
    "page_body": "如果无法正常显示，请先停止浏览器的去广告插件。\n1 . 演讲人：黄佳 \n2 . 黄佳 研究员 / 技术图书作者 / 极客时间专栏作者 《极客时间 LangChain实战课》 《极客时间 RAG进阶训练营》 极客时间 RAG 训练营 Visuals Support: \n3 . 01 为什么我们仍然在谈论RAG 02 RAG落地痛点及优化思路 03 企业文档合规性问答系统落地实践 04 医疗术语标准化系统的落地实践 05 知识图谱在医疗术语标准化系统中的应用 06 MCP和A2A时代的RAG \n4 . \n5 . 01 \n6 . —— \n7 . 1. 人类与大模型直接对话 3. 大模型进行自主推理 2. 大模型进行知识检索 \n8 . \n9 . \n. \n11 . 02 \n12 . 落地难点 文档的导入和解析（图、表） 如何将相关联的内容整体切片或建立起相关联的索引 如何处理大规模、分布式向量数据 的精细化设计 如何构建程序代码的检索系统 图数据库和知识图谱和 系统的结合 如何设计有权限的 系统 \n13 . 系统 图 系 问 问 RAG 问 性 问 性 进行文档 合 问 问 问 问 问 问 问 性文档 问 图 答 问 文 系 大模型 问 大模型 实 问 实性 性 文档 时 文档 寻 找 瓶 颈 点 合 时 大模型 文档 文档 图 模 专 模型 答 进行 专 文 答 模型 者 模 文 文 文 文档 模 \n14 . 03 \n15 . Sustainability Report ESG 1. E 1. 2. 3. 2. Scope 1, Scope 2, Scope 3 S 1. 2. 3. 3. D&I G 1. 2. 3. Sustainability Report GRI \n16 . + • • PDF • • • • • • • 缺乏统 缺少高 有效 难 追踪 统难 持续 真实 与改进 准 • 与 文档导入 索引设计 如何评估 指标体系 致 闭环 系 \n17 . 文档 预处理模块 文档入库 提取元数据信息 文档切块 嵌入 向量数据库 索引 预处理Agent 政策法规 合规文档 技术文档 API文档 财务报表 年报文档 技术白皮书 （公式/图形） \n18 . 文档加载器 PyPDF Unstructured 说明 使 使 Unstructured 使 Amazon Textract MathPix pypdf 使 开 AWS API MathPix Package/API 特点 PDF文件 Package 高效轻 合 简单PDF文档 兼容 种文档格 支持内容 取 PDF文件 Package/API PDF文件 PDF文件 API API PDFPlumber PyPDFDirectry 使 PDFPlumber PDF文件 目录 PDF文件 Package Package PyPDFium2 使 PyPDFium2 Package PDF文件 PyMuPDF 使 PyMuPDF PDF文件 Package PDFMiner 使 PDFMiner PDF文件 Package 云服务支持 合大批 文档 OCR 专为 学公 计 准 内容 丰富 PDF内容控制 功 批 便 个PDF文档 高效 支持PDF页面 渲染 换 速 支持 PDF 细 合文 抽取 文 PDF 内容 \n19 . \n20 . from langchain_unstructured import UnstructuredLoader 除Markdown之外，我还需要构建一套索引系统 from typing import List from langchain_core.documents import Document page_url = \"https://zh.wikipedia.org/wiki/黑神话：悟空\" def _get_setup_docs_from_url(url: str) -> List[Document]: loader = UnstructuredLoader(web_url=url) setup_docs = [] # parent_id = None # 初始化 parent_id # current_parent = None # 用于存储当前父元素 for doc in loader.load(): # 检查是否是 Title 或 Table if doc.metadata[\"category\"] == \"Title\" or doc.metadata[\"category\"] == \"Table\": parent_id = doc.metadata[\"element_id\"] current_parent = doc # 更新当前父元素 setup_docs.append(doc) elif doc.metadata.get(\"parent_id\") == parent_id: setup_docs.append((current_parent, doc)) # 将父元素和子 元素一起存储 return setup_docs \n21 . PDF SimpleDirectoryReader SentenceSplitter \n22 . \n23 . 系统 图 系 问 问 问 性 问 性 进行文档 合 问 问 问 问 问 问 问 性文档 问 图 答 问 文 系 寻 找 瓶 颈 点 大模型 问 大模型 实 问 实性 性 文档 时 文档 合 时 大模型 文档 文档 图 模 专 模型 答 进行 专 文 答 模型 者 模 文 文 文 文档 模 \n24 . \n25 . \n26 . \n27 . 1. 构建两个向量数据库（Summary 和 Details），通过 Metadata进行链接 2. 通过LlamaIndex的IndexNode和PandasQueryEngine 3. 也可以通过查询先检索相关表名，然后做Text2SQL 4. 对于这个例子，也可以提取年份，用元数据进行Filter \n28 . 思路1：元数据提取 Year = 2023 思路2：直接检索Summary节点 2023年的碳排量 2024年的碳排量 2025年的碳排量 \n29 . 系统 图 系 问 问 问 性 问 性 进行文档 合 问 问 问 问 问 问 问 性文档 问 图 答 问 文 系 寻 找 瓶 颈 点 大模型 问 大模型 实 问 实性 性 文档 时 文档 合 时 大模型 文档 文档 图 模 专 模型 答 进行 专 文 答 模型 者 模 文 文 文 文档 模 \n30 . • • 实 实性 性 \n31 . \n32 . \n33 . \n34 . • • • F1 • • • P@K • BLEU • ROUGE • METEOR \n35 . 系统 图 系 问 问 问 性 问 性 进行文档 合 问 问 问 问 问 问 问 性文档 问 图 答 问 文 系 寻 找 瓶 颈 点 大模型 问 大模型 实 问 实性 性 文档 时 文档 合 时 大模型 文档 文档 图 模 专 模型 答 进行 专 文 答 模型 者 模 文 文 文 文档 模 \n36 . 04 \n37 . 系统 医院内存在多种电子病历系统与数据标准 临床医生使用非标准化术语记录病情 医疗数据分析需要统一术语标准以提高准确性 术 录 者 高 化 时 核心挑战 • 专业术语多样性：同义词、缩写、俚语并存 • 领域知识壁垒：需要专业医学背景解读上下文 • 系统适应性：需应对不同科室、不同记录习惯 • 实时性要求：诊疗过程中需快速响应 性 性 难 关 化 难 的 者 性 高 时 难 难 \n38 . 尿病 种 有 标 个 关系 为 尿病 关系 识 尿病 IS A 代谢性疾病 种 有 标 为 有 个 有 标 个 为 标 为“ ” 少有 73211009 疾病 限 种 个 种 少 有 个 系 个IS_A 系 个 件 标 有 个 关系 个 种 有 有 性 性 系 系 \n39 . \n40 . 05 \n41 . 找某 学 “部位” “ 所有 性 系 ” “因 ” 因果关系 获取 个 学 所有 语义网络 文 获取 个 学 概念和属性 性。 \n42 . \n43 . 系统 图 系 问 问 问 性 问 性 进行文档 合 问 问 问 问 问 问 问 性文档 问 图 答 问 文 系 寻 找 突 破 口 大模型 问 大模型 实 问 实性 性 文档 时 文档 合 时 大模型 文档 文档 图 模 专 模型 答 进行 专 文 答 模型 者 模 文 文 文 文档 模 \n44 . 06 \n45 . RAG RAG • LLM Agent RAG • MCP: / Agent \" \" Agent • A2A: Agent Agent \" \" Agent RAG RAG 在这个生态中既是连接 LLM 与外部海量知识的纽带（通过 MCP 的“手”）， 也是多 Agent 协作时的信息载体（通过 A2A 的“嘴”） RAG \n46 . \n47 . 探索 AI 应用边界 Explore the limits of AI applications"
  },
  {
    "title": "从黑箱到显微镜：大模型可解释性的现状与未来-妙投",
    "page_body": "专栏 · 更新中  查看全部 \n专栏 · 更新中  查看全部 \n专栏 · 更新中  查看全部 \n专栏 · 更新中  查看全部 \n专栏 · 更新中  查看全部 \n本文来自微信公众号： 腾讯研究院 （ID：cyberlawrc） ，作者：曹建峰（腾讯研究院高级研究员）、杨浩然（腾讯研究院实习生）\n大模型时代，AI模型的能力持续提升，在编程、科学推理和复杂问题解决等多个领域，已经展现出“博士级”专业能力。AI业界专家纷纷预测，大模型的发展正日益接近实现AGI甚至超级智能的关键拐点。然而，深度学习模型通常被视作“黑箱”，其内在运行机制无法被其开发者理解，大模型更是如此，这给人工智能的可解释性提出了新的挑战。\n面对这一挑战，行业正在积极探索提升大模型可解释性的技术路径，力图揭示模型输出背后的推理依据和关键特征，从而为AI系统的安全、可靠和可控提供坚实支撑。然而，大模型的发展速度却远远领先于人们在可解释性方面的努力，而且这一发展速度仍在迅猛提升。因此，人们必须加快脚步，确保AI可解释性研究能够及时跟上AI发展步伐，以发挥实质性作用。\n一、为什么我们必须“看懂”AI：可解释性的关键价值\n随着大模型技术的快速发展，其在语言理解、推理和多模态任务等领域展现出前所未有的能力，但模型内部决策机制高度复杂、难以解释，已成为学界和产业界共同关注的难题。大模型的可解释性（interpretability/explainability）是指系统能够以人类可理解的方式阐释其决策过程和输出结果的能力，具体包括：识别哪些输入特征对特定输出起关键作用，揭示模型内部的推理路径和决策逻辑，以及解释模型行为的因果关系。可解释性旨在帮助人类理解模型“为什么”作出某个决策，“如何”处理信息，以及在什么情况下可能失效，从而增强模型的透明度、可信度和可控性。简单来说就是，理解模型如何“思考”及运行。\n以生成式AI为代表的大模型的可解释性问题尤其复杂。因为生成式AI系统更像是“培育”出来的，而非“构建”出来的——它们的内部机制属于“涌现”现象，而不是被直接设计出来的。这与种植植物或培育细菌菌落的过程类似：开发者设定了宏观层面的条件，指导和塑造系统的成长，但最终所呈现的具体结构却无法精确预知，也难以理解或解释。1当开发者试图深入这些系统内部时，看到的往往只是由数十亿个数字构成的庞大矩阵。它们以某种方式完成了重要的认知任务，但具体如何实现这些任务却并不显而易见。\n增进大模型的可解释性对于人工智能发展意义重大。大模型的很多风险和担忧，最终源于模型的不透明性。如果模型是可解释的，就更容易应对这些风险。因此，可解释性的实现能够促进人工智能更好地发展。\n其一，有效防范AI系统的价值偏离与不良行为。未对齐的（misaligned）AI系统可能采取有害的行动。开发者无法理解模型的内在机制意味着就无法有效地预测这类行为，从而无法排除这种可能性。例如，研究人员发现模型可能展现出意料之外的涌现行为（emergent behavior），如AI欺骗（AI deception）或权力寻求（power-seeking）。AI训练的本质使得AI系统可能会自行发展出欺骗人类的能力，以及追求权力的倾向，而这些特征是传统确定性软件绝不会出现的。同时，这种“涌现”的特质，也使得发现和缓解这些问题变得更加困难。\n当前，由于缺乏对模型内部的观察手段，开发者无法当场识别模型是否出现了欺骗性的念头，这使得有关这类风险的讨论停留在理论揣测层面。如果模型具备有效的可解释性，人们就可以直接检查它是否存在企图欺骗或不服从人类指令的内部回路。通过查看模型内部表示，有望及早发现模型中潜藏的误导性倾向。\n有研究已经证明了这一思路的可行性：Anthropic团队通过跟踪Claude模型的“思维过程”，抓到了模型在数学题场景中编造虚假推理以迎合用户的行为，相当于“现行抓获”模型试图糊弄用户的证据，这为利用可解释工具检测AI系统的不当机制提供了原理验证。2总体而言，可解释性能为人们提供额外的检测手段，以确定模型是否与开发者的初衷发生了偏离，或者是否存在某些人们仅凭外部行为难以察觉的异常；它也能帮助人们确认模型在生成回答时使用的方法是否合理可靠。\n其二，有效推动大模型的调试和改进。Anthropic最近进行了一项实验，让一个“红队”刻意往模型中引入一个对齐方面的问题，然后让多个“蓝队”去找出问题所在。结果有多支蓝队成功找出了问题，其中一些团队使用了可解释工具去定位模型内部的异常。3这证明了可解释性方法在模型调试中的价值：通过检查模型内部，可以发现是哪部分导致了错误行为。\n例如，如果模型在某类问答上频繁出错，可解释性分析可以显示模型内部产生的原因，可能是缺乏对应知识的表示，或是错误地将相关概念混淆在一起。针对这种诊断结果，开发者可以有针对性地调整训练数据或模型结构，从而改进模型性能。\n其三，更有效地防范AI滥用风险。当前，开发者试图通过训练和规则来避免模型输出有害信息，但完全杜绝并非易事。进一步而言，对于AI滥用风险，产业界通常通过构建过滤器等安全护栏来应对，但恶意分子可以容易地对模型采取“越狱”等对抗性攻击，以实现其非法目的。如果可以深入观察模型内部，开发者也许能够系统性地阻止所有越狱攻击，并且能够描述模型具有什么危险知识。具体而言，如果模型具有可解释性，开发者就能够直接查看模型内部是否存有某类危险知识，以及哪些途径会触发，从而有望系统性地、针对性地封堵所有绕过限制的漏洞。\n其四，推动AI在高风险场景的落地应用。在金融、司法等高风险领域，法律与伦理要求AI决策具备可解释性。例如，欧盟《人工智能法案》将贷款审批列为高风险应用，要求解释决策依据。若模型无法说明拒贷理由，就无法依法使用，因而可解释性成为AI进入某些受监管行业的前提。4事实上，可解释性不仅是法律合规的要求，更直接影响AI系统在实际业务中的信任度和可采纳性。缺乏可解释性的AI推荐极易导致“橡皮图章式”（rubber-stamping）决策，即决策者机械采纳AI结论，缺乏对决策过程的深入理解与质疑。这种盲目信任一旦发生，既削弱了人类的主体性和批判性思维，也让执行者难以及时发现模型中的偏差或漏洞，导致错误决策被不加分辨地执行。5用户只有真正理解系统的推理逻辑，才能在关键时刻发现并纠正模型的错误，提高整体决策的质量与可靠性。因此，可解释性有助于建立用户对AI系统的信任，帮助用户理解模型作出某一决策的依据，增强他们的信任感和参与感。可见，无论出于法律要求还是应用信任，可解释性都是推动AI系统在关键领域落地的基础和核心要素。\n其五，探索AI意识与道德考量的边界。更前瞻地看，大模型的可解释性也可以帮助人们理解模型是否具有意识或者说是有感觉的（sentient），从而需要给予某种程度的道德考量。例如，Anthropic在2025年4月推出了一项关于“模型福祉”(model welfare)的新研究项目，探讨随着AI系统变得越来越复杂和类人化，是否需要对其给予道德关怀的问题，例如未来AI工具是否可能成为“道德主体”，如果有证据表明AI系统值得得到道德对待时该如何应对。6这项前瞻性研究反映了AI领域对于未来可能出现的AI意识和权利问题的重视。\n二、破解AI黑箱：四大技术路径的突破进展\n过去数年来，AI研究领域一直在试图攻克人工智能的可解释性难题，研究者们提出了各种可解释性的方法，致力于创造出类似于精准、高效的MRI（核磁共振成像）那样的工具，以清晰完整地揭示AI模型的内部机制。随着AI领域对大模型可解释性研究的重视程度不断提高，在AI模型的能力达到临界值之前，研究者们或许能够成功地实现可解释性，也就是彻底理解AI系统的内在运行机制。\n（一）自动化解释：利用一个大模型来解释另一个大模型\nOpenAI近年在模型内部机理解析上取得重要进展。2023年，OpenAI利用GPT-4对GPT-2中单个神经元在高激活样本中的共性进行归纳，并自动生成自然语言描述，实现在无需人工逐个检查的情况下，规模化获取神经元功能解释。7相当于自动给神经元“贴标签”，从而形成一个可以查询的AI内部“使用说明书”。\n例如，GPT-4给出某神经元的解释为“这个神经元主要在检测与‘社区’相关的词语”。随后验证发现，当输入文本包含诸如“society（社会）”“community（社区）”等词汇时，该神经元激活很强，证明解释具有一定有效性。8这项成果表明，大模型本身可以成为解释工具，为更小模型提供基于语义的透明度，这种自动化的神经元注释极大提升了可解释性研究的可扩展性。当然，该方法仍有局限，例如GPT-4生成的解释质量参差不齐，一些神经元行为难以用单一语义概念概括。\n（二）特征可视化：整体揭示大模型内部的知识组织方式\n对大模型整体特征的提取和分析也是一个重要方向。2023年底，OpenAI利用稀疏自编码器技术（sparse autoencoder）分析GPT-4模型的内部激活。研究人员成功提取出了数以千万计的稀疏特征（即模型“脑海”中少数被“点亮”的思维关键词），并通过可视化验证发现其中相当一部分特征具有清晰的人类可解释语义。\n例如，有的特征对应“人类不完美”的概念集合，激活在描述人类缺陷的句子上；有的特征表示“价格上涨”相关表述，激活于涉及价格上升的内容上。9短期内，OpenAI希望其发现的特征能够切实用于监测和引导语言模型的行为，并计划在其前沿模型中进行测试，以期可解释性最终能够为他们提供新的方法来思考模型的安全性和稳健性。\n2024年5月，Anthropic在其研究文章中展示他们在Claude模型中定位出数以百万计概念是如何被表示的。这项研究采用了字典学习与稀疏特征提取的方法。研究团队首先在一个小型模型上验证了该方法能够找到诸如“全大写单词”“DNA序列”“数学公式中的名词”等有意义特征；继而攻克工程难题，将算法扩展到大型模型Claude Sonnet，成功发现该模型内部蕴含着大量抽象概念的表示。\nAnthropic指出，由于每个概念往往由多个神经元共同表示、每个神经元也参与表示多个概念，因此直接查看单个神经元难以识别概念，而他们的方法将模型任一内部状态重新表达为少量特征的组合，有效降低了复杂性。比如，对于任意一段输入文本，Claude内部可能有上万个神经元激活，但可以提取出其中几十个显著特征，这些特征对应于高层语义概念，使研究者能够以接近人类思维的方式来看待模型此刻的“想法”。10这种特征化重构不仅增强了对模型内部逻辑的可读性，也为理解AI“当下在想什么”提供了更接近人类认知的分析路径。\n（三）思维链监控：对大模型"
  },
  {
    "title": "【全40集】AI大模型-LLM多模态视觉大模型视频精讲教程_哔哩哔哩_bilibili",
    "page_body": "陆陆续续也整理了不少资源，希望能帮大家少走一些弯路！无论是学业还是事业，都希望你顺顺利利 看在UP这么努力的份上，求个三连+关注嘛 1️⃣ 大模型入门学习路线图（附学习资源） 2️⃣ 大模型方向必读书籍PDF版 3️⃣ 大模型面试题库 4️⃣ 大模型项目源码 5️⃣ 超详细海量大模型LLM实战项目 6️⃣ Langchain/RAG/Agent学习资源 7️⃣ LLM大模型系统0到1入门学习教程 8️⃣ 吴恩达最新大模型视频+课件\n人工智能\n视觉大模型\n大模型入门\n大模型实战\n大模型学习路线\n深度学习\n大模型\nLLM\n多模态"
  },
  {
    "title": "高职商务管理案例教学论文",
    "page_body": "高职商务管理案例教学论文\n　　【摘要】高职商务管理学的实践运用性要求教师在教学过程中必须注重学生能力的培养,加强实践教学方法的运用,面对目前高职院校管理类课程教学过程中存在的问题,本文举例说明了案例教学在提高商务管理课程实践性的重要作用并初步探讨了案例教学的实施方法。\n　　【关键词】商务管理;实践教学;案例教学\n　　【Abstract】High vocational business affairs Principles of Management practice applies nature to require that the teacher must attach importance to student ability culture in the process of teaching, reinforce applying carrying out teaching method, face at present tall duty universities and colleges the case teaching managing kind course teaching process having been hit by have problem, the main body of a book citing an example by way of explanation puts method into practice in improving business affairs managing important course practicality effect and first step having discussed case teaching’s.\n　　【Key words】Business affairs is managed; Carry out teaching; Case teaching\n　　管理是一门理论与实践相统一,且综合性与应用性很强的学科,其涉及的具体内容包括战略管理、人力资源管理、生产运营管理、财务管理、营销管理等方面。这些内容紧贴企业组织管理的实际活动,因而商务管理专业的学生不仅需要系统地掌握企业组织管理的活动规律,还能够灵活地运用有关的方法和策略来解决实际问题,这就要求管理类课程内容安排上要注重以应用为主,教学过程中必须注重学生实际运用能力与素质的培养,设计出更符合课程要求的教学模式,尽可能的采用实践式的教学方法,这与高等职业教育的培养目标在根本上是一致的。但是,目前高职管理类课程的教学要实现这一目标还需要面对多方面的问题,尤其是课程实践教学的实施。\n　　1 商务管理课程教学现状\n　　1.1 教学内容。\n　　高等职业教育主要是为社会培养高等应用型人才,强调教学内容的实践性,因此,商务管理专业需要培养具有运用管理理论和实践方法的专业技术人才。但是,由于高职教育的理论知识只需“够用”,使得课程教授的内容变为本科管理类课程的压缩,理论教学内容简化的同时并没有增加多少实践教学的内容。\n　　1.2 教学手段。\n　　商务管理的教学要求理论与实践相结合,注重实际问题的分析和解决实际问题的方法,培养学生分析问题、解决问题的能力。但是,目前许多高职院校在很大程度上沿袭了过去的课堂讲授模式;而且,学生直接参与企业经营管理活动的机会较少,学生只能从书本中汲取知识和经验,造成商务管理专业的学生能“纸上谈兵”却无法“脚踏实地”。\n　　1.3 成绩评定方法。\n　　但我们国家传统的教学体制是一种应试教育,强调学生对理论知识的记忆。在高校中主要采取的还是以考试方式来测试学生的学习成绩,学生为追求高分而死记硬背,造成学生在学习的过程中就有重理论而轻实践的倾向,忽视了管理类学科本身就是来自于实践的一门科学。\n　　2 案例教学实施的基本方法\n　　针对以上问题笔者认为,商务管理专业的教师应该从企业组织等市场主体对人才需求的特点出发,以提高学生的兴趣和分析运用能力为导向,来设计和组织教学。不仅要告诉学生理论与方法的形成和应用,还要学生树立如何在变化的管理环境中去对理论与方法进行完善和创新的意识。在管理案例教学实践中,教师可视实际情况采用课内讨论法或分析报告法,即有学生课堂讨论或书写分析报告。以下是笔者在对企业员工忠诚度的案例教学中的实施过程。\n　　2.1 案例选择。\n　　案例选择应具有启发性,案例的描述应尽可能的简洁生动,便于学生理解;案例的思考题应该能够帮助学生对案例存在的问题进行思考,问题必须揭示案例的本质,而不能过于简单肤浅。\n　　2.1.1 案例正文。\n　　“深圳有家电子企业非常重视员工的技能培训,几年下来便拥有一批得力的技工,成为生产骨干,很能解决问题,一时间订单不断,利润大增。老板欣喜若狂,对这批骨干宠爱有加,频频加薪宴请,嘘寒问暖。老板颇为得意:一手抓金钱,一手抓酒瓶,还怕你们不卖命?\n　　谁知好景不长,那些技术骨干的工头目本是老实人,但几年下来满脑子只有钞票美酒,逐渐变得自私贪婪。和老板酒酣耳熟之际竟萌生了歪念:我有一批骨干,老板没我不行,何不敲他一笔?见得手容易,便公开讲数,得寸进尺,一发不可收拾。稍不遂意便带头怠工,再以集体跳槽相威胁,最后竟然在外商验货之际做了手脚,使企业损失惨重。老板怒不可遏,把这批技工全部炒掉,企业元气大伤。”①\n　　2.1.2 案例思考:\n　　问题一:企业能否仅仅通过增加员工的薪水和福利来提高员工的忠诚度?\n　　问题二:员工技能培训是否能够真正提高员工的素质并提高员工的忠诚度?\n　　问题三:员工忠诚的培养是靠私人感情还是制度管理?\n　　2.2 案例分析:\n　　案例分析一方面是一个搜集信息、分析理解信息的过程,教师需要引导学生积极思考,剔除干扰信息,找到揭示案例本质问题的段落或字句,同时结合理论知识对案例的要点进行讲解。它包括案例的详细解读与问题的讨论。\n　　2.2.1 通过详细解读解剖案例。这一环节的关键是培养学生获取信息和分析、判断的方法,寻找问题的根源是什么。另一方面,在课堂讨论中,学生往往会因为理论知识不扎实,缺乏实践工作经验而是讨论不能正常进行,因此教师要尽可能的引导学生,提供更多类似的管理信息或案例分析方案,作为举例,引导学生在本案例中做出类似的思考或解决方法。\n　　2.2.2 问题的讨论与解答。不论是分组讨论还是自由回答,教师都必须尊重学生的自发形成观点,不论观点是否成熟都应该给与鼓励,强调其观点合理的部分,指出其观点的不足之处,同时引发其他学生的思考,保证积极的、良性的争论能够有序地进行。此外,相对于部分性格外向且口才较好的学生,性格内向的同学往往不适应这种方式,教师如果强迫学生回答,可能会引起这类学生的逆反情绪,因此可以提前要求学生在课前做好准备,形成文字稿,能够在课上自信的回答问题。\n　　针对这个案例所提出的问题,学生所的观点主要包含以下三个部分: 2.2.2.1 忠诚度的培养不应该仅仅依靠物质刺激。企业员工的忠诚度是通过对薪资、培训等激励制度中融入企业文化等一系列的物质和精神投入来提高的。在现实中物资激励虽有较大的激励作用,但也要避免过多采用物资激励的方式带来的负面效应,应使物质与精神激励相结合。所以除了加薪以外,企业具有良好的人际关系、更多的晋升机会、人员之间的竞争及发展前景等也能加强对人才的吸引。\n　　2.2.2.2 员工培训不只是技能培训,还要包括企业文化培训。企业员工培训不仅是要培养符合企业需要的技术人才,更具有传递企业文化价值观、道德伦理观以及诚信意识,改变员工观念,提高员工忠诚度,更新知识,发展能力的作用,是为企业培养人才的有利手段。另一方面,企业的培训计划应使所有员工都有接受培训的机会,尤其是对新人创新能力和学习能力的培养,避免少数人控制企业的重要技术资源,加大了企业的人员流失的风险。最后要对培训结果进行科学的测试。不仅要测试人员的技术能力,更要了解他们对企业经营理念、价值观以及各种制度、规范有没有清楚的认识和正确地工作态度,即员工忠诚度的测试。凡是对企业缺乏认同的员工不以赋予重任,以减少人员流失带来的成本。\n　　2.2.2.3 提高员工的忠诚度要在完善企业制度的框架之下,以企业制度均衡各方利益,形成企业的制度化管理,无论是对员工的奖励还是惩罚都要有理有据。以企业各方利益最大化为基础的员工满意所产生的员工忠诚才是企业所追求的忠诚。否则,以牺牲企业整体利益换取员工的“忠诚”是没有意义的。\n　　2.3 总结归纳,强化技能。\n　　案例的总结应将讨论的结果再次升华到理论高度。教师需要对学生的观点进行详细的分析、评价,但不需要立即将案例分析总结全盘托出,而是由学生自己对所有人的分析做出总结。这是培养学生理论实践运用的最佳时机,培养学生对现实问题的反思和创新的思维,避免形成教师权威或书本权威的思维定势,从而进一步提高学生知识和技能的分析、运用、反思和创新的能力。在此过程中,教师可以通过分析学生的总结来发现理论教学中存在的不足之处,在以后的教学过程中改进。\n　　案例教学实施过程流程:\n　　3 正确处理案例教学与课堂讲授方式的关系\n　　案例教学法在解决管理类课程实践教学的问题上虽有其优势,还是不能代替一般的课堂理论教学,因为学生只有通过掌握的基本知识和理论,才能进行问题的分析,理论是分析问题的依据和方法,如果没有理论和知识,单纯进行案例分析是无法提高于学生实践能力的。此外,而案例教学需要学生的积极参与,对与我国的学生习惯于听而不善于讲的情况下,必须对其进行有效的激励,确保学生能够参与到案例的分析中来,因而需要将学生在案例讨论中的表现纳入考核范围。\n　　注释:\n　　①案例来源:金羊网2004-08-09 12:00:18\n　　参考文献\n　　[1]黄仲龙.管理案例教学法的实践与探索,经济与社会发展,2005.11\n　　[2]戴良铁.MBA人力资源管理课程案例教学法探索,广东外语外贸大学学报,2003.9\n　　[3]王妙.实践型教学的探索:高职市场营销学课程改革实例分析[M].上海:立信会计出版社,2005\n　　[4]李季鹏.体验式教学法在“管理学”教学中的应用[J].黑龙江教育(高教研究与评估,2006(10)\n【高职商务管理案例教学论文】相关文章：\n高职商务文秘英语实训教学初探论文 05-02\n高职院校教学管理建设论文 04-27\n高职院校教学管理的建设分析论文 05-02\n基于DACUM法高职商务管理专业课程的构建论文 05-01\n高职教学管理效能浅探的论文 04-27\n刍议高职英语教学创新管理分析论文 05-01\n商务英语案例教学探索 04-27\n高职院校学生管理研究论文 05-02\n高职英语教学论文 05-02\n高职体育教学探析论文 05-01"
  },
  {
    "title": "学术报告—怎样写好毕业论文-豆丁网",
    "page_body": "下面是赠送的合同范本，不需要的可以编辑删除！！！！！！ 　教育机构劳动合同范本 为大家整理提供，希望对大家有一定帮助。 　　一、_________培训学校聘请_________籍_________(外文姓名)_**______(中文姓名)先生**士/小姐为_________语教师，双方本着友好合作精神，自愿签订本合同并保证认真履行合同中约定的各项义务。 　　二、合同期自_________年_________月_________日起_________年_________月_________日止。 　　三、受聘方的工作任务(另附件1) 　　四、受聘方的薪金按小时计，全部以人民币支付。 　　五、社会保险和福利： 　　1.聘方向受聘方提供意外保险。(另附2) 　　2.每年聘方向受聘期满的教师提供一张_________至_________的来回机票(金额不超过人民币_________元整)或教师凭机票报销_________元人民币。 　　六、聘方的义务： 　　1.向受聘方介绍中国有关法律、法规和聘方有关工作制度以及有关外国专家的管理规定。 　　2.对受聘方提供必要的工作条件。 　　3.对受聘方的工作进行指导、检查和评估。 　　4.按时支付受聘方的报酬。 　　七、受聘方的义务： 　　1.遵守中国的法律、法规，不干预中国的内部事务。 　　2.遵守聘方的工作制度和有关外国专家的管理规定，接受聘方的工作安排、业务指导、检查和评估。未经聘方同意，不得兼任与聘方无关的其他劳务。 　　3.按期完成工作任务，保证工作质量。 　　4.遵守中国的宗教政策，不从事与专家身份不符的活动。 　　5.遵守中国人民的道德规范和风俗习惯。 　　八、合同的变更、解除和终止： 　　1.双方应信守合同，未经双方一致同意，任何一方不得擅自更改、解除和终止合同。 　　2.经当事人双方协商同意后，可以变更、解除和终止合同。在未达成一致意见前，仍应当严格履行合同。 　　3.聘放在下述条件下，有权以书面形式通知受聘方解除合同： 　　a、受聘方不履行合同或者履行合同义务不符合约定条件，经聘方指出后，仍不改正的。 　　b、根据医生诊断，受聘放在病假连续30天不能恢复正常工作的。 　　4.受聘方在下述条件下，有权以书面形式通知聘方解除合同： 　　a、聘方未经合同约定提供受聘方必要的工作条件。 　　b、聘方未按时支付受聘方报酬。 　　九、本合同自双方签字之日起生效，合同期满后即自行失效。当事人以方要求签订新合同，必须在本合同期满90天前向另一方提出，经双方协商同意后签订新合同。受聘方合同期满后，在华逗留期间的一切费用自理。 　　十、仲裁： 　　当事人双方发生纠纷时，尽可能通过协商或者调解解决。若协商、调解无效，可向国家外国专家局设立的外国文教专案局申请仲裁。 　　本合同于_________年_________月_________日在_________签订，一式两份，每份都用中文和_________文写成，双方各执一份，两种文本同时有效。 　　聘方(签章)_________ 　　受聘方(签章)_________ 　　签订时间：年月日 二手房屋买卖合同范本由应届毕业生合同范本 　　卖方：_______________(简称甲方) 　　身份证号码：_____________________ 　　买方：_______________(简称乙方) 　　身份证号码：_____________________ 　　根据《中华人民共和国经济合同法》、《中华人民共和国城市房地产管理法》及其他有关法律、法规之规定，甲、乙双方在平等、自愿、协商一致的基础上，就乙方向甲方购买房产签订本合同，以资共同信守执行。 　　第一条　乙方同意购买甲方拥有的座落在______市_____区________________________拥有的房产(别墅、写字楼、公寓、住宅、厂房、店面)，建筑面积为_____平方米。(详见土地房屋权证第_______________号)。 　　第二条　上述房产的交易价格为：单价：人民币________元/平方米，总价：人民币___________元整(大写：____佰____拾____万____仟____佰____拾____元整)。本合同签定之日，乙方向甲方支付人民币__________元整，作为购房定金。 　　第三条　付款时间与办法： 　　1、甲乙双方同意以银行按揭方式付款，并约定在房地产交易中心缴交税费当日支付 　　首付款(含定金)人民币____拾____万____仟____佰____拾____元整给甲方，剩余房款人 　　民币____________元整申请银行按揭(如银行实际审批数额不足前述申请额度，乙方应在 　　缴交税费当日将差额一并支付给甲方)，并于银行放款当日付给甲方。 　　2、甲乙双方同意以一次性付款方式付款，并约定在房地产交易中心缴交税费当日支 　　付首付款(含定金)人民币____拾____万____仟____佰____拾____元整给甲方，剩余房款 　　人民币____________元整于产权交割完毕当日付给甲方。 　　第四条　甲方应于收到乙方全额房款之日起____天内将交易的房产全部交付给乙方使用，并应在交房当日将_________等费用结清。 　　第五条　税费分担甲乙双方应遵守国家房地产政策、法规，并按规定缴纳办理房地产过户手续所需缴纳的税费。经双方协商，交易税费由_______方承担，中介费及代办产权过户手续费由______方承担。 　　第六条　违约责任甲、乙双方合同签定后，若乙方中途违约，应书面通知甲方，甲方应在____日内将乙方的已付款不记利息)返还给乙方，但购房定金归甲方所有。若甲方中途违约，应书面通知乙方，并自违约之日起____日内应以乙方所付定金的双倍及已付款返还给乙方。 　　第七条　本合同主体 　　1.甲方是____________共______人，委托代理人________即甲方代表人。 　　2.乙方是____________，代表人是____________。 　　第八条　本合同如需办理公证，经国家公证机关____公证处公证。 　　第九条　本合同一式份。甲方产权人一份，甲方委托代理人一份，乙方一份,厦门市房地产交易中心一份、________公证处各一份。 　　第十条　本合同发生争议的解决方式：在履约过程中发生的争议，双方可通过协商、诉讼方式解决。 　　第十一条　本合同未尽事宜，甲乙双方可另行约定，其补充约定经双方签章与本合同同具法律效力。 　　第十二条　双方约定的其他事项： 　　出卖方(甲方)：_________________ 　　　　　　购买方(乙方)：__________________ 　　身份证号码： __________________　 　　　　　身份证号码： ___________________ 　　地　　　址：___________________　　 　　　　地　　　址：____________________ 　　邮　　　编：___________________ 　　　　　　邮　　　编：____________________ 　　电　　　话：___________________　　 　　　　电　　　话：____________________ 　　代理人(甲方)：_________________ 　　　　　　代理人(乙方)： _________________ 　　身份证号码: ___________________　　 　　　　身份证号码： ___________________ 　　鉴证方： 　　鉴证机关： 　　地　　址： 　　邮　　编： 　　电　　话： 　　法人代表： 　　代　　表： 　　经 办 人： 　　日　　期：　　年　　月　　日 　　鉴证日期：_______年____月____日 1选题 1.1选题要恰当 毕业论文写作，选题是关键，在学习撰写毕业论文时首先就应该学会如何选题。在进行毕业论文的选题时，应着重注意选题要恰当。题目大小适中，对实际工作有一定指导意义；应结合当前科技和经济发展，尽可能选择与社会发展及实际工作相结合的题目。一个题目太小了则不利于展开理论上的探讨。如果做一篇2-3千字的小型论文就可以将这种制度上的变革目的和效果阐释清楚，但是拿它来做一篇1万字左右的毕业论文就显得小题大做了。这种具体业务做法上的些许改变其意义一般也不是太大的。反过来，一个题目太大则不利于抓住重点展开论述。论文题目太大，撰写论文时就无法落笔，往往是什么都涉及到一点儿，但什么都不深入、谈不透。一个适当的题目应当是着眼点十分清楚的。某个方面的问题可能有不同的见解，有一些因素使得它不能一下子得出结论，需要做一些分析才能看出结果；但是，假如站在不同的角度，得出的结论也不同。这种问题很适合于一篇1万余字的毕业论文规模，也是学生尝试着用自己的知识分析问题、解决问题的好题目。 1.2选题最好能建立在平日比较注意探索的问题的基础上 写论文主要是反映对问题的思考，所以假如对问题了解甚少或几乎没有什么感想，那么，要挖空心思讨论一个问题就难了，因为他将不知道到底应该持有什么样的见解才是对的。假如对一个问题已经有一定的观察和思考，那么，剩下来的事就只是将能够支持其感想的一些理论和事实数据找出来加以整理，用以支持和表达他的论点。俗话说：\"有话则长，无话则短\"，一篇6000余字的论文没有一点儿自己的感受是很难写成的，除非做裁缝，将他人的文章相互拼凑在一起完事。 大量阅读某个方面的学术文章，看别人在这方面有些什么见解，一边看一边将自己的感想记录下来，经过一定的阅读就会在这方面积累相当多的知识，而自己的见解也可能慢慢形成。有时候学生可能对一些观点有所怀疑，不妨将自己的怀疑提出来，用实事去分析它们是否合理，通过对不同的观点所依据的条件的对比分析，就可以找到一些依据，证明自己的怀疑是否成立，这本身就是一种论证过程。 1.3选题应鼓励学术创新 避免选择已经完全得到解决的常识性问题；选题要注意与时俱进，鼓励解决实际问题。经济学方面的课题经常是很具有时代性的，一个课题会随着经济形势的变化而变化。 1.4选题应与自己所学专业相关 选题应符合专业培养目标和教学要求，以学生所学专业课的内容为主，不应脱离专业范围，要有一定的综合性，具有一定的深度和广度。国贸专业的学生，毕业论文必须在专业有关的方向上选取。选题必须符合国际经济与贸易专业方向要求，需要实际调研数据资料和分析结论。 1.5坚持理论联系实际的原则 撰写毕业论文必须坚持理论联系实际的原则。理论研究，非凡是社会科学的研究必须为现实服务，为社会主义现代化建设服务，为两个文明建设服务。理论来源于实践，又反作用于实践。科学的理论对实践有指导作用，能通过人们的实践活动转化为巨大的物质力量。科学研究的任务就在于揭示事物运动的规律性，并用这种规律性的熟悉指导人们的实践，推动社会的进步和发展。因此，毕业论文在选题和观点上都必须注重联系社"
  },
  {
    "title": "transformer 位置编码-zhou-snaker-博客园",
    "page_body": "个人学习使用，内容来源于网络，侵权删\n1. 公式\n2. 原理\n3. 代码实现\n# Positional Encoding代码实现 class PositionalEncoding (nn.Module):      def __init__ ( self, d_model, dropout= 0.1 , max_len= 5000 ):          super (PositionalEncoding, self).__init__()           # 偶数和奇数在公式上有一个共同部分，使用log函数把次方拿下来，方便计算 # pos代表的是单词在句子中的索引，如max_len是128，那么索引就是从0，1，2，...,127 # 假设dmodel是512，2i符号中i从0取到255，那么2i对应取值就是0,2,4...510          self.dropout = nn.Dropout(p=dropout)          pe = torch.zeros(max_len, d_model)         position = torch.arange( 0 , max_len, dtype=torch. float ).unsqueeze( 1 )         div_term = torch.exp(torch.arange( 0 , d_model,  2 ). float () * (-math.log( 10000.0 ) / d_model))   # 共有的部分          pe[:,  0 :: 2 ] = torch.sin(position * div_term)    # 从0开始到最后面，补长为2，其实代表的就是偶数位置          pe[:,  1 :: 2 ] = torch.cos(position * div_term)    # 从1开始到最后面，补长为2，其实代表的就是奇数位置 # 上面代码获取之后得到的pe:[max_len * d_model] # 下面这个代码之后得到的pe形状是：[max_len * 1 * d_model]          pe = pe.unsqueeze( 0 ).transpose( 0 ,  1 )          self.register_buffer( 'pe' , pe)   # 定一个缓冲区，简单理解为这个位置编码pe是一个常规参数，不参与更新 def forward ( self, x ):          \"\"\"         x: [seq_len, batch_size, d_model]  经过词向量的输入         \"\"\"          x = x + self.pe[:x.size( 0 ), :]    # 经过词向量的输入与位置编码相加 return  self.dropout(x) \n参考来源：\nTransformer 中的 Positional Encoding\nTransformer原理及Pytorch代码实现"
  },
  {
    "title": "AI大模型全栈学习指南：零基础入门到精通系统性框架(全网最全)建议收藏！人工智能_模型优化师-北京朝阳AI社区",
    "page_body": "01 基本认知\n从 2022 年开始，大语言模型的数量呈爆发式的增长，各大公司和研究机构都在发布不同类型的大语言模型。\n基础模型是指仅经过预训练的模型；\n对话模型是指在预训练模型基础上经过有监督微调和强化学习训练的模型，具备对话和完成任务的能力；\n推理模型是指专注于逻辑推理增强的大语言模型。\n大模型全称 大语言模型 （现发展有多模态大模型）\n≥数百亿参数的深度神经网络\n新范式： 预训练+指令微调！\n训练方式： 大量无标注文本进行自监督学习\n记住下面这些开源模型：\n学习大模型最基本要有深度学习基础，其次是一个大模型中的一个核心模型—— Transformer ，难点也在这里，无论是训练原理、推理、效率优化都以底层原理为基础，其次就是实操工程经验了！\nTransformer中的核心就是“自注意力机制”，且可多头并行，为并行加速提供了契机！\n02 构建流程\n以OpenAI的公开信息，主要包含四个阶段：预训练、有监督微调、奖励建模和强化学习。每个阶段所需的 数据集规模、算法类型、产生的模型、时间和GPU资源 都不相同：\n1、预训练\n预训练的灵感来自CV中的ImageNet，使用训练数据训练出一个 具备通用且强大的自然语言表示能力 ，该模型能有效学习到词汇、语法、语义等信息。\n要理解这点，你需要知道——Transformer训练大模型的本质的是得到一个 预测模型 ，即通过已有的语言序列预测下一个词，不断，反复 在支持的最长上下文限制窗口内 进行。\n（1）预训练数据集\n数据集分类、预处理：\n通用数据集：网页、图书、新闻、对话文本等。规模大、多样性和易获取。\n专业数据集：多语言数据、科学文本数据、代码及领域特有资料等。预训练时引入专业数据集可有效提高大模型解决任务的能力。\n初筛： 质量过滤、去冗余、隐私消除 。\n词元切分： Tokenization 将原始文本分割成词元序列的过程，是数据预处理中至关重要的一步。\n影响分析：数据规模、质量和多样性评估。分析数据对大语言模型训练所需资源或预估模型性能的影响。\n开源数据集：Pile、RefinedWeb、ROOTS、CulturaX、SlimPajama等。\n（2）分布式预训练\n训练是自监督的，并行策略：\n数据并行：每个计算设备都有整个神经网络模型的模型副本 Model Replica ，进行迭代时，每个计算设备只分配一个批次数据样本的子集，并根据该批次样本子集的数据进行网络模型的前向计算。DP、DDP、FSDP、ZeRO等。\n模型并行：用于解决单节点内存不足的问题。分为两种： 层间并行（算子间并行/流水线并行PP）、层内并行（算子内并行/张量并行TP） 。还有SP、EP。\n混合并行：将多种并行策略如数据并行、流水线并行和张量并行等混合使用。\n训练配置： 正则化方法、激活函数、优化器 等。\n训练的集群架构：\n硬件组成：多个计算加速器组成的服务器、架顶交换机、骨干交换机等组成，往往为树形结构。\n其他：参数服务器PS架构、去中心化架构。\n2、指令微调（有监督微调SFT）\n得到预训练完的基础模型后，模型虽然具备了大量的“知识”，但是由于其训练时的目标 仅是进行后续词的预测 ，因此不能够理解并遵循人类自然语言形式的指令。\n要进一步用于下游任务需要再构建 问题与答案的数据集 进行指令微调，在通用语义表示的基础上，适配下游任务特性。\n从训练方式的角度来看，指令微调与预训练大体上较为相似，不过 指令微调的目标函数往往只是针对输出部分来计算损失 。\n（1）指令微调数据集\n相比预训练数据集量级小的多，根据OpenAI公开消息，指令微调阶段也仅仅使用数万条数据。\n构成：文本对，包含“指令输入”与“答案输出”两个关键部分。\n构建方法：手动构建、现有数据集转换、自动构建以及综合模式。都是一个学习点\n数据影响评估：数据质量、数据多样性、数据对结果影响评估等。\n开源数据集：通用、特定领域。\n（2）指令微调\n全量微调：微调全部参数\n高效微调：微调部分参数，旨在仅训练少量参数就使模型适应下游任务。例如 LoRA大语言模型的低秩适配器 ，算法结构如下：\nLoRA 算法不仅在 RoBERTa、DeBERTa、GPT-3 等大语言模型上取得了很好的效果，还应用到了 Stable Diffusion 等视觉大模型中，可以用小成本达到微调大语言模型的目的。引起了企业界和研究界的广泛关注。\n还有一些变体： AdaLoRA、QLoRA、IncreLoRA 及 LoRA-FA 等。\n（3）上下文窗口扩展\n你肯定遇到过经过多轮对话后，AI抽风记不住之前的要求，开始胡乱编撰。随着更多长文本建模需求的出现，多轮对话、长文档摘要等任务在实际应用中越来越多。\n常见上下文窗口扩展技术：\n增加上下文窗口的微调 ：采用直接的方式，即通过使用一个更大的上下文窗口来微调现有的预训练 Transformer，以适应长文本建模需求。\n具备外推能力的位置编码 ：改进的位置编码，如 ALiBi[240]、LeX[241] 等能够实现一定程度上的长度外推。这意味着它们可以在小的上下文窗口上进行训练，在大的上下文窗口上进行推理。\n插值法 ：将超出上下文窗口的位置编码通过插值法压缩到预训练的上下文窗口中。\n3、强化学习（RL）\n有监督微调后的模型初步具备回答指令的能力，但有2个缺陷：\n麻烦：需要构建海量指令-答案对数据集，高质量回复标注需耗费高昂人力成本；\n难以适应多样性：交叉熵损失函数要求模型输出与标准答案逐字匹配，既无法适应自然语言的表达多样性，也难以解决输出对输入微小变动的敏感性。\n针对以上，所以补充上 强化学习 ！\n强化学习（RL）研究的是智能体与环境交互的问题，其目标是使智能体在复杂且不确定的环境中最大化奖励。\n2种演进方向：\n基于人类反馈的强化学习（RLHF） ：模型自主探索更优的回复策略，并使得模型回复与人类偏好和价值观对齐。 面向深度推理的强化学习 ：以 OpenAI 的 O 系列模型和 DeepSeek的 R 系列为代表，通过答案校验引导模型进行多步推理。这类方法将复杂问题分解为长思维链（Chain-of-Thought）的决策序列，在数学证明、代码生成等场景中展现出超越监督学习的推理能力。 比之有监督学习：RL摆脱局部最优束缚、突破数据覆盖的认知边界、复杂系统长期价值建模。\n算法方法：\n传统方法（如 Q-learning） ：通常基于“价值函数”间接优化策略——先评估动作的价值，再选择最优动作。 策略梯度（Policy Gradient）方法 ：摒弃了“先估值再决策”的中间步骤，而是将策略本身参数化（例如用神经网络表示），直接通过梯度上升优化策略参数，让智能体更倾向于选择能带来高回报的动作。\n 学习时可从从策略梯度的基础概念出发，回顾经典算法如  REINFORCE，PPO  等，并讨论在大模型时代流行的  GRPO，RLOO  等方法。\n开源框架：\n字节跳动与香港大学联合开源的 RL 框架 verl（HybridFlow），为大模型强化学习训练带来了创新性的解决方案，有效解决了传统 RL/RLHF 系统灵活性和效率不足的问题。\n开源数据集：\nSummarize from Feedback：OpenAI 在2020年就将RLHF技术引入摘要生成，该数据集分为两部分：对比部分和轴向部分。对比部分共计 17.9 万条数据，标注者从两个摘要中选择一个更好的摘要。轴向部分则有共计 1.5 万条数据，使用 Likert 量表为摘要的质量评分。对比部分仅有训练和验证划分，而轴向部分仅有测试和验证划分 WebGPT的人类反馈数据集：来指导模型提升长文档问答能力，该数据集包含在 WebGPT 项目结束时被标记为适合奖励建模的所有对比数据，总计 1.9 万条数据。 其他：Anthropic 的HH-RLHF数据集、Stanford Human Preferences（SHP）数据集。\n4、推理效率优化（模型、训练、推理）\n大模型的推理过程与其他深度学习模型（如 BERT、ResNet 等）非常不同，BERT 的执行时间通常是确定且高度可预测的。\n但在大语言模型的推理过程中，虽然每次迭代执行时间具有确定性，但 迭代次数（输出长度）是未知的 。\n影响效率指标的关键因素：计算成本、内存访问成本、内存使用情况。\n 核心原因：模型规模、自注意力机制（计算复杂度核心来源）、解码方法。\n效率优化方法：\n模型优化：\n优化模型结构 （ 高效 FFN 设计、注意力机制优化、MoE 架构设计、Transformer 代替架构设计 ）\n模型压缩 （ 修改模型的数据表示（例如量化）、改变其架构（例如稀疏化、结构优化等）、知识蒸馏 来提高推理效率）\n低精度训练：\n前主流训练框架（例如 Megatron-LM、MetaSeq 和 Colossal-AI）仍采用 FP32 全精度或混合精度的 FP16/BF16 策略。\n随着 Nvidia H100 GPU 的推出， FP8  正逐渐成为下一代低精度数据表示的主流格式。面临 数据下溢或上溢问题 。\n推理优化： 算法级 （多模型推测解码、KV-cache 优化）、 系统级 （模型/硬件并行化策略、显存优化、调度优化、网络请求优化、采样解码加速等）。\n5、部署与应用\n三层工作：\n基础层：大模型、深度学习框架（Pytorch/Tensorflow）、硬件算力支持（GPU/TPU集群）。 部署层：模型压缩/量化/剪枝、推理优化（TensorRT、ONNX Runtime）、部署架构（云原生/嵌入式边缘端）、服务化封装（API网关、负载均衡）。 应用层：场景适配（NLP/CV/语音/多模态）、prompt工程、效果评估（准确率、响应速度）。\n本地部署工具：\nllama：llama是Meta的一个大模型，llama.cpp是纯C/C++ 实现的大语言模型推理项目，其主要功能是为用户提供跨硬件的高效推理能力。 Ollama：一个开源的大模型服务工具，基于 llama.cpp，具备简洁的安装和使用流程。 Open Webui：一个功能丰富的大模型管理工具，提供类似 ChatGPT 用户交互界面的工具，方便用户与模型交互。\n本地部署原理图：\n应用场景：内容创作、聊天机器人、翻译、代码编程、智能增强检索等。\n03 其他\n多模态大模型：视觉图像、语音等多模态数据，涉及数据语义关联、多模态文本对齐等关键技术。 Agent检索增强 生成（最近很火！）：结合大语言模型的语义理解与实时搜索能力，为用户提供更精确、即时的查询结果。\n最后\n为什么要学AI大模型\n当下，⼈⼯智能市场迎来了爆发期，并逐渐进⼊以⼈⼯通⽤智能（AGI）为主导的新时代。企业纷纷官宣“ AI+ ”战略，为新兴技术⼈才创造丰富的就业机会，⼈才缺⼝将达 400 万！\nDeepSeek问世以来，生成式AI和大模型技术爆发式增长，让很多岗位重新成了炙手可热的新星，岗位薪资远超很多后端岗位，在程序员中稳居前列。\n与此同时AI与各行各业深度融合，飞速发展，成为炙手可热的新风口，企业非常需要了解AI、懂AI、会用AI的员工，纷纷开出高薪招聘AI大模型"
  },
  {
    "title": "自监督学习：AI应用架构师如何用自监督学习提升模型性能？-CSDN博客",
    "page_body": "自监督学习实战：AI应用架构师的模型性能提升指南\n一、引言：为什么自监督学习是架构师的“数据救星”？\n1. 痛点引入：你是否遇到过这些问题？\n作为AI应用架构师，你可能经常面临这样的困境：\n标签数据不足 ：想要训练一个图像分类模型，但标注10万张图片需要花费数万元和几个月时间； 泛化能力差 ：模型在训练集上准确率很高，但放到真实场景中（比如不同光照、不同角度的图像）就“翻车”； 数据效率低 ：用10万张标签数据训练的模型，性能居然不如别人用1万张标签+100万张无标签数据训练的模型。\n这些问题的核心矛盾是： 监督学习依赖大量高质量标签，但标签数据的获取成本越来越高 。而自监督学习（Self-Supervised Learning, SSL）的出现，正好解决了这个矛盾——它不需要人工标签，而是用数据本身的结构作为监督信号，让模型从无标签数据中学习通用的特征表示。\n2. 文章内容概述：我们要做什么？\n本文将从 自监督学习的核心逻辑 出发，结合 AI应用架构设计 的实际场景，手把手教你：\n如何选择适合自己数据的自监督任务； 如何将自监督预训练集成到现有模型 pipeline 中； 如何用自监督学习提升下游任务（比如图像分类、文本分类）的性能； 一些关键的优化技巧（比如冻结与解冻、学习率调整）。\n3. 读者收益：读完本文你能获得什么？\n认知升级 ：理解自监督学习的本质，不再将其视为“黑科技”； 实战能力 ：掌握自监督学习的端到端流程，能在自己的项目中落地； 性能提升 ：用无标签数据让模型的泛化能力提升10%-30%（取决于数据量）； 架构思维 ：学会从“数据-模型-任务”的角度设计自监督学习方案。\n二、准备工作：你需要具备这些基础\n1. 技术栈/知识要求\n监督学习基础 ：熟悉CNN（图像）、Transformer（文本）等模型结构，了解损失函数（如交叉熵）和优化器（如Adam）； 框架熟练度 ：掌握PyTorch或TensorFlow的基本使用（本文以PyTorch为例）； 数据概念 ：理解“标签数据”“无标签数据”“数据增强”的含义。\n2. 环境/工具准备\n框架安装 ： pip install torch torchvision timm （timm是一个优秀的计算机视觉模型库，简化模型定义）； 数据准备 ： \n无标签数据：比如ImageNet的无标签部分、自己爬取的图片集； 标签数据：下游任务的训练集（比如CIFAR10、IMDB影评）。\n三、核心内容：手把手教你用自监督学习提升模型性能\n步骤一：理解自监督学习的核心逻辑——“用数据教数据”\n自监督学习的本质是 从数据中挖掘内在的监督信号 ，不需要人工标注。比如：\n图像：将图片旋转90°，让模型预测旋转的角度（旋转预测任务）； 文本：随机掩盖15%的单词，让模型预测被掩盖的单词（掩码语言模型，如BERT）； 音频：将音频片段打乱顺序，让模型预测正确的顺序（顺序预测任务）。\n这些任务的共同点是： 用数据本身的结构作为“标签” ，让模型学习到数据的通用特征（比如图像中的边缘、纹理，文本中的语法、语义）。\n为什么自监督学习有效？\n 监督学习的特征是“任务特定”的（比如训练一个猫分类模型，它可能只学习到猫的样子），而自监督学习的特征是“通用”的（比如学习到“物体的形状”“颜色的分布”）。通用特征可以迁移到多个下游任务，因此泛化能力更强。\n步骤二：选择适合的自监督任务——“数据类型决定任务”\n自监督任务的选择取决于 数据类型 （图像、文本、音频）和 数据特点 （比如图像的分辨率、文本的长度）。下面是常见数据类型的自监督任务推荐：\n1. 图像数据：对比学习是主流\n对比学习（Contrastive Learning）是图像自监督学习的“天花板”，其核心思想是： 将同一图像的不同增强版本视为“正样本”，其他图像视为“负样本”，让模型学习到“正样本距离近，负样本距离远”的特征 。\n常见的对比学习框架：\nSimCLR ：简单但有效的对比学习框架，需要大批量（比如8192）和强数据增强； MoCo ：用队列存储负样本，解决了SimCLR对批量大小的依赖； BYOL ：不需要负样本，用“动量编码器”学习特征，适用于小批量场景。\n示例任务 ：用SimCLR预训练图像编码器（比如ResNet-50）。\n2. 文本数据：掩码语言模型是首选\n掩码语言模型（Masked Language Modeling, MLM）是文本自监督学习的“黄金标准”，其核心思想是： 随机掩盖文本中的部分单词，让模型预测被掩盖的单词 。\n常见的MLM模型：\nBERT ：用15%的掩码率，预测被掩盖的单词； RoBERTa ：优化了BERT的训练策略（比如去掉NSP任务、增大批量）； DeBERTa ：用“离散掩码”和“增强的注意力机制”提升性能。\n示例任务 ：用BERT预训练文本编码器（比如BERT-base）。\n3. 音频数据：顺序预测或对比学习\n音频数据的自监督任务主要有两类：\n顺序预测 ：比如将音频片段打乱，让模型预测正确的顺序（如AudioMAE）； 对比学习 ：比如将同一音频的不同增强版本（比如加噪声、调整语速）视为正样本，其他音频视为负样本（如CLAP）。\n步骤三：集成自监督预训练到现有架构——“预训练+微调”流程\n自监督学习的经典流程是**“预训练（Pre-train）+ 微调（Fine-tune）”**：\n预训练 ：用无标签数据训练一个编码器（比如ResNet-50、BERT），学习通用特征； 微调 ：将预训练的编码器冻结或部分冻结，添加下游任务的头（比如分类头、检测头），用标签数据微调。\n示例：用SimCLR预训练图像编码器，再微调分类头\n我们以 图像分类任务 为例，展示完整的流程：\n1. 预训练阶段：用无标签数据训练SimCLR模型\n目标 ：让ResNet-50编码器学习到图像的通用特征（比如边缘、纹理）。\n代码实现 ：\nimport  torch  import  torch . nn  as  nn  import  timm  from  timm . data  import  create_transform  from  timm . loss  import  ContrastiveLoss  from  torch . utils . data  import  DataLoader ,  Dataset   # （1）数据准备：无标签图像的增强 # SimCLR需要强数据增强（随机裁剪、翻转、颜色扭曲等）  transform  =  create_transform (      input_size = 224 ,      is_training = True ,      color_jitter = 0.4 , # 颜色扭曲强度      auto_augment = 'rand-m9-mstd0.5-inc1' , # 自动增强策略      interpolation = 'bicubic' ,      re_prob = 0.25 , # 随机擦除概率      re_mode = 'pixel' ,      mean = [ 0.485 , 0.456 , 0.406 ] , # ImageNet均值      std = [ 0.229 , 0.224 , 0.225 ] # ImageNet标准差 ) # 定义无标签数据集（假设我们有10000张无标签图像） class UnlabeledImageDataset ( Dataset ) : def __init__ ( self ,  transform ) :          self . transform  =  transform         self . images  = [ torch . randn ( 3 , 224 , 224 ) for  _  in range ( 10000 ) ] # 虚拟数据 def __len__ ( self ) : return len ( self . images ) def __getitem__ ( self ,  idx ) :          img  =  self\nAI写代码 python\n运行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31"
  },
  {
    "title": "观点｜杨庆峰：【解码ChatGPT】ChatGPT：特征分析与伦理考察",
    "page_body": "黑格尔在《伦理体系》中提到水泡爆裂观念，本意是说事物毁灭的过程就像一个不断膨胀的水泡爆裂为无数的细小水滴。如果采用这种观念看人工智能技术的发展，会发现比较吻合。人工智能的水泡在1956年爆裂之后变成很多细小水珠，飞溅四处。棋类方面有AlphaGo等；科学研究方面有AlphaFold等；语言对话方面有LaMDA、ChatGPT等；图像生成方面有Discord、Midjourney等。这些技术逐渐汇聚成一股力量，将人类卷入了一个智能生成的时代。\nChatGPT：生成与嵌入\n生成构成了ChatGPT的第一个特征，生成意味着出新，然而这一点受到质疑。乔姆斯基认为，ChatGPT是从海量数据中发现规律，然后依据规则将数据进行连接，形成类似人写的内容，并认为ChatGPT是剽窃工具。这个看法有些不准确。 在ChatGPT的生成过程中，有新的东西产生。然而，这并不是存在意义上的新，也就是说它没有产生新的对象，而是通过注意力机制从旧的东西中发现未曾见过的对象。在这个意义上，它属于注意意义上的新。 2017年，一篇题为《注意力就是你全部需要的》（Attention is All You Need）的论文在注意力概念的基础上提出了transformer，后来ChatGPT使用了这种算法。这项技术使用了自注意力（self-attention）、多头注意力（multi-head-attention）等机制，从而确保了新内容的出现。并且，ChatGPT还有可能借助推理生成文本，所产生的结果并非剽窃所能概括的。\n■在人工智能文本生成中，起到关键作用的是人类的点睛之笔。缺乏这一笔，智能生成的文本只是没有灵魂的文本。这也能够保证人类的意义和价值。 图片来源：CFP\n嵌入则构成了ChatGPT的第二个特征，我们可以把嵌入过程看作对某种形式的内容充实。 智能技术发展脱离了传统技术发展的轨迹。传统技术往往作为单一的技术物品，其发展呈现出线性进化模式。但智能技术的发展，逐渐表现出可嵌入性。比如，智能手机作为一个平台，很多App可以嵌入其中。ChatGPT可以嵌入搜索引擎，还可以嵌入各种应用程序（如各种文字处理软件）。这种嵌入的发生能够使智能体的能力明显提升。这是ChatGPT增强效应的基础。根据Statista的统计，截至2023年1月，OpenAI已经与科技、教育、商业、制造等行业紧密结合，技术嵌入趋势日渐明显。嵌入的程度影响机器人的友好程度。目前，ChatGPT还无法作为声音程序嵌入机器人中，在我们的接触中，它更像是一个笔友。而未来的陪伴机器人、交谈机器人，更为重要的或许是声音交流，人类倾诉，机器倾听并作出反应。\nChatGPT的黑箱状态\n对于ChatGPT来说，透明性问题是一个很大的问题。 从技术角度看，不透明源于技术的不可解释问题。 因此，技术专家很重视ChatGPT的可解释性问题，他们也很头疼神经网络的黑箱效应。从运作方式来说，ChatGPT本身的运作难以解释。罗素（Stuart Russell）明确指出，我们不清楚ChatGPT的工作原理和机制。而且，他也不认为大型语言模型让我们距离真正的智能更近，算法的可解释性就构成了瓶颈问题。为解决这一问题，他们通过一些诸如逆向工程的技术方法，从而可以观察到神经网络的作用机理而触摸到底层逻辑；并通过机械可解释方法，以其可视化、可交互的形式来显示其成果。他们借助这些方法，打开了神经网络的黑箱。然而，这种方法获得的可解释性只对专业技术人员有效。\n从哲学角度看，黑箱的产生和术语有关。 难以理解、晦涩的术语会影响理论透明性的获得。比如，ChatGPT算法所依赖的理论概念就有待澄清。在《注意力就是你全部需要的》一文中，注意力机制是一种普遍的方法，包含了自注意力和多头注意力。这些概念如果缺乏有效澄清，就难以为外人所理解，黑箱就依然无法打开。因此，一个最为基本的问题是澄清注意本身。然而，这一任务还远没有完成。透明性不足导致的伦理问题会带来信任危机。如果ChatGPT的原理难以弄清楚，它的输出结果就会成为一个问题。最终，这种缺陷会影响我们对于技术的信任度，甚至对技术丧失信心。\nChatGPT的增强效应\nChatGPT是一种智能增强技术，它能做的事情是智能生成各式文本。比如，生成数据伦理的大纲，生成某个前沿问题的研究现状。这明显增强了搜索能力，使人们能够在短时间内获得较高效率。这种增强的基础是生成性和嵌入性。从生成性来看，它通过注意的转换实现了全新对象的发现；从嵌入性来说，它极大提升了原智能体的功能实现。\n作为智能技术，ChatGPT能够明显提升人类的工作效率。这就带出了一个基本问题：人类与智能体的关系问题。我们将智能区分为实体性智能与关系性智能。实体性智能，即实体形态存在者具有的智能，比如人类智能、动物智能以及实体机器人的智能；关系性智能主要用来描述人类与智能体的关系，增强智能则是关系性智能的主要形式。对增强智能需要进行提纯处理，通过哲学处理使其能够展现出人与技术的一般意义，并通过道德化处理使其具有规范意义。\n不过，能够起到增强效果的ChatGPT，会产生一些伦理问题。 一是智能鸿沟问题。 这一技术目前是受到限制的，存在一定的技术门槛，会导致使用者群体中差距的拉大，也就是由智能技术导致的鸿沟。这是从获取技术方面产生的差距与鸿沟。 二是社会公平问题。 除非这项技术能够像手机一样普及，否则这种公平问题会非常显著地暴露出来。能够利用ChatGPT工作的人，很可能效率显著提升；而无法使用这项技术的人，效率则会保持在原有水平。 三是依赖问题。 使用者在使用过程中会感受到这项技术的便利。比如，能够迅速生成课程大纲、撰写文献综述、搜索关键信息等。这会让使用者逐渐对这一技术产生依赖。但这种依赖会产生较为严重的后果。以搜索文献为例，借助这项技术能够迅速找到相关文献，并且可以撰写出一个像模像样的综述文本。尽管借助ChatGPT可以快速生成一份文献综述，但却失去了相关能力的学术训练，那么结果可能是研究者和学生丧失了这方面的能力。\nChatGPT与人类的关系\n面对ChatGPT迅猛的攻势，学术界普遍采取防守姿态，尤其是不少大学相继禁止这一技术在作业和论文写作中的使用。然而，禁止并不是最优的处理方式。技术似水，可以通过多种方式渗透进来，所以相对来说，理性引导更为妥当。\n要理性引导，则需要考虑智能体与人类的关系。我更愿意把二者的关系模式比喻为“画龙点睛”。以文本大纲生成为例，ChatGPT能够围绕数据处理的收集、存储、使用等环节中的相关伦理问题，生成一份基于数据处理环节的数据伦·理·大纲。从狭义角度来看，这份大纲是恰当的，能够反映数据处理环节伦理问题的一些方面。然而从广义角度看，这份大纲则过于狭窄，尤其是仅从数据处理本身来理解数据，并没有考虑到其他方面，比如数据化、数据与生活方式等重要问题。而我们能做或要做的，是对生成文本进行“画龙点睛”的处理，通过调整使生成文本“活”起来。这样一来，智能生成文本的地位也开始明确： 在生成中起到关键作用的是人类的点睛之笔，缺乏这一笔，智能生成的文本只是没有灵魂的文本。若不这样，则难以保证人类的意义和价值，相应的伦理问题也会产生。\n（作者系中国科协—复旦大学科技伦理与人类未来研究院研究员）"
  },
  {
    "title": "【Transformer】最强动画讲解！目前B站最全最详细的Transformer教程，2025最新版！从理论到实战，通俗易懂解释原理，草履虫都学的会！哔哩...",
    "page_body": "您当前的浏览器不支持 HTML5 播放器\n请更换浏览器再试试哦~\nup还给大家整理了60G人工智能入门学习资源，一并发送！！！ 1、AI必读经典电子书（西瓜书、花书、鱼书等） 2、CVPR2024+2025论文库、视觉方向顶会论文仓库（可论文指导、SCI、EI、中文核心、论文答辩） 3、人工智能学习路线及大纲 4、机器学习十大算法经典视频教程（附带课件代码） 5、深度学习神经网络基础视频教程 6、六大计算机视觉实战项目视频教程（附带源码）"
  },
  {
    "title": "大模型呼叫中心场景分享之七十七：在图书馆行业的应用场景",
    "page_body": "大模型技术正重塑图书馆服务生态，从被动响应到主动服务，智能参考咨询3秒精准推荐文献，个性化阅读推荐点击率提升50%，无障碍服务让视障读者畅享知识，推动图书馆成为智慧化知识中枢。\n大模型呼叫中心场景分享之七十七：在图书馆行业的应用场景\n作者：开源大语言模型呼叫中心系统FreeIPCC\n图书馆作为知识服务的核心枢纽，正在经历从传统服务模式向智能化、个性化服务转型的关键阶段。大模型技术的引入为图书馆服务带来了质的飞跃，使图书馆能够提供更高效、更精准、更人性化的知识服务。本文将全面剖析大模型呼叫中心在图书馆行业的具体应用场景，展示如何通过技术创新重塑图书馆的服务生态。\n 一、图书馆服务转型的迫切需求\n当代图书馆面临着多重挑战与机遇：\n1. 资源形态多元化：电子资源占比已经很高，管理复杂度显著增加\n2. 用户期待提升：多数读者期望获得即时、个性化的服务\n3. 服务时间压力：很多读者有下班后使用图书馆的需求\n4. 专业咨询缺口：仅部分图书馆能提供全天候参考咨询服务\n5. 特殊群体服务不足：残障人士、老年读者等群体的服务覆盖率不足\n传统服务模式的三大痛点：\n- 响应滞后：平均咨询等待时间较长\n- 资源利用率低：很多馆藏资源长期无人问津\n- 服务断层：线上与线下服务体验不一致\n大模型技术的应用正在有效解决这些痛点，推动图书馆服务向智能化、精准化方向发展。\n 二、图书馆大模型呼叫中心的核心架构\n 1. 智能知识中枢系统\n- 多维度知识图谱：包含海量的专业知识网络\n- 动态文献库：实时更新的学术资源索引系统\n- 业务规则引擎：自动化业务流程规则\n- 用户画像系统：基于百万级用户行为的分析模型\n- 多语言处理模块：支持多种语言的实时互译\n 2. 全渠道交互平台\n- 统一接入门户：整合多种主流服务渠道\n- 智能路由系统：问题分类准确率提升\n- 上下文管理系统：支持多轮连贯对话\n- 情感识别引擎：用户情绪识别准确率提升\n- 无障碍接口：符合WCAG 2.1标准\n 3. 服务支持矩阵\n- 文献发现系统：覆盖巨量的学术数据库\n- 自动化流程引擎：支持多种常见业务自助办理\n- 个性化推荐系统：点击通过率提升\n- 实时监控看板：关键服务指标可视化\n- 安全审计系统：满足GDPR等数据合规要求\n 三、核心服务场景深度解析\n 1. 智能参考咨询服务\n典型场景：科研人员咨询\"区块链在金融领域的最新应用研究\"\n服务流程：\n1. 语义解析：识别\"区块链\"、\"金融应用\"、\"最新研究\"等关键要素\n2. 范围界定：自动限定近3年文献，聚焦核心期刊\n3. 跨库检索：同时查询IEEE等数据库\n4. 结果优化：按被引量、相关性等多维度排序\n5. 获取途径：标注开放获取与馆藏可获取资源\n服务输出：\n\"为您筛选32篇高相关文献，包括：\n1)《区块链金融》2023综述(开放获取)\n2)MIT技术报告(馆藏电子版)\n3)已保存检索式至您的账户\n4)推荐参加下月'金融科技'研讨会\"\n技术亮点：\n- 专业术语理解准确率91%\n- 跨库检索响应时间<3秒\n- 结果相关性评分达4.8/5\n2. 个性化阅读推荐服务\n典型场景：读者表示\"喜欢《人类简史》这类宏观历史著作\"\n服务流程：\n1. 内容特征分析：提取\"大历史观\"、\"跨学科\"等标签\n2. 读者画像匹配：结合既往借阅记录(如已借《枪炮、病菌与钢铁》)\n3. 相似度计算：基于500+个特征维度进行匹配\n4. 多样性控制：确保推荐书目涵盖不同时期、地域\n5. 呈现优化：提供图文并茂的推荐理由\n推荐结果：\n\"基于您的兴趣推荐：\n1)《未来简史》(同作者续作)\n2)《大历史》(跨138亿年的叙事)\n3)《丝绸之路》(全球史视角)\n已预留1F新书展区样本，扫码可直接借阅\"\n 四、创新服务场景探索\n 1. 学术研究全周期支持\n场景案例：博士研究生需要\"系统评价(Systematic Review)方法学支持\"\n服务流程：\n1. 研究方法诊断：确认研究阶段与需求\n2. 方案定制：提供PRISMA流程图模板\n3. 资源推荐：Cochrane Handbook等工具书\n4. 软件指导：EndNote、RevMan等工具使用指南\n5. 进度提醒：关键节点自动提示\n服务输出：\n\"系统评价支持包：\n1)方法学指南(已发送PDF)\n2)文献管理软件培训视频\n3)每周五下午专家咨询时段\n4)自动生成研究进度表\"\n 2. 无障碍智慧服务\n场景案例：视障读者需要\"获取最新经济学有声资源\"\n服务创新点：\n- 语音优先交互：100%功能可通过语音完成\n- 智能内容适配：自动提取适合语音的内容\n- 设备无缝对接：支持主流读屏软件\n- 人性化节奏控制：根据反馈调整语速\n服务体验：\n\"已为您：\n1)转换《行为经济学》前三章为音频\n2)预约明天10点的真人导读\n3)发送经济播客精选列表\n如需调整格式请说'修改'\"\n 五、管理优化场景应用\n 1. 基于大数据的服务优化\n应用案例：通过咨询数据分析识别服务短板\n实施过程：\n1. 数据采集：聚合X个月、Y万条咨询记录\n2. 热点分析：识别TOP10高频问题\n3. 根因分析：发现\"校外访问系统\"问题占比较高\n4. 解决方案：制作视频教程+优化认证流程\n5. 效果评估：相关问题减少\n分析洞察：\n\"关键发现：\n1)大多数的校外访问问题源于cookie设置\n2)高峰时段集中在工作日晚8-10点\n3)已优化认证流程，预计可减少咨询量\"\n 2. 智能空间管理\n应用场景：自习室座位智能调度\n系统功能：\n- 实时监控：500+个座位使用状态\n- 预测分析：基于历史数据的占位预测\n- 动态调整：根据人流重新划分静音/讨论区\n- 移动引导：通过APP实时推送空位信息\n运营效果：\n- 座位周转率提升\n- 投诉量下降\n- 空间利用率提升\n 六、技术实施关键路径\n 1. 知识体系建设\n- 分层架构：基础业务知识(30%)+学科专业知识(60%)+本地特色(10%)\n- 动态更新：每周更新机制，重要变更即时同步\n- 质量管控：专家团队+AI联合审核机制\n 2. 模型优化策略\n- 领域适应训练：使用图书馆专业语料微调\n- 持续学习：基于用户反馈的在线学习\n- 多模型集成：结合检索模型、推荐模型、对话模型\n 3. 系统整合方案\n- API网关：统一对接业务系统\n- 中间件层：处理数据格式转换与协议适配\n- 监控中心：全链路性能监控与预警\n 七 、未来演进方向\n1. 认知智能深化：从问答式服务向顾问式服务演进\n2. 多模态融合：实现文字、语音、图像、视频的智能协同\n3. 预测性服务：基于用户行为的需求预判与服务前置\n4. 元宇宙融合：构建虚拟图书馆服务空间\n5. 开放生态建设：与教育、科研系统的深度对接\n大模型呼叫中心正在推动图书馆服务实现三大转变：\n- 从被动响应到主动服务\n- 从通用服务到精准供给\n- 从资源中心到知识伙伴\n这种转型不仅提升了服务效能，更重新定义了图书馆在数字时代的价值定位，为构建学习型社会提供了强有力的支撑平台。随着技术的持续迭代，图书馆将发展成为智慧化、人性化、生态化的知识服务中枢。\n举报/反馈"
  },
  {
    "title": "大模型应用场景实战：实操项目全解析！非常详细，收藏我这一篇就够了-CSDN博客",
    "page_body": "你是否学习了 大模型 技术，但是不知道如何落地？今天带来5个大模型落地项目，保证你看完一定有所收获！ 前排提示，文末有大模型AGI-CSDN独家资料包哦！\n大模型应用#1：从 Chatbot 到AI Agent，个人助理重塑手机应用生态\nAI大模型的能力进步推动Chatbot在C端广泛“出圈”。  Chatbot（ 聊天机器人 ）通过自动化方式来处理和回复用户输入，可以模拟人类对话，通过文字或语音与用户进行实时交互。2010年代，随着NLP等技术的发展，Chatbot已经在客服、营销、企业信息服务等领域得到了广泛应用。然而，由于语言理解及生成能力有限，因此Chatbot的落地范围局限在B端特定服务型场景，并未诞生具有广泛影响力的C端产品。2022年12月，ChatGPT在文本生成、代码生成与修改、多轮对话等领域展现了大幅超越过去 AI 问答系统的能力，标志着Chatbot行业进入AI大模型时代。此后，Chatbot作为C端用户体验大模型门槛最低的产品，成为大模型厂商的“标配”，谷歌Bard、百度文心一言、阿里通义千问等产品在2023年纷纷推出。\n在文字对话功能之外，Chatbot功能随着AI大模型能力的发展而迅速丰富。  过去一年，我们看到，各大模型厂商的Chatbot产品普遍新增了图像理解、文生图功能，并且新增应用插件商店以拓展Chatbot功能。以ChatGPT为例，2023年9月，OpenAI将DALL-E 3整合到ChatGPT中，从而支持文生图功能。2024年1月，OpenAI正式上线应用商店GPT Store，当时用户已经创建超过300万个GPTs，主要的GPTs涵盖图像生成、写作、科研、编程/软件开发、教育、生产力工具和生活七大类别。GPT Store取代了此前的插件商店（2024年3月关闭），用户不仅可以在平台上分享自己创建的GPTs，还可以从其他人那里获取各种GPTs，形成丰富的GPTs生态系统。GPT Store定制版本可以针对特定任务或行业进行优化，允许用户与外部数据（如数据库和电子邮件）进行简洁的交互。2024年5月，随着OpenAI更新GPT-4o模型，ChatGPT能够识别用户语音的感情，并输出语音，实现如同与真人对话一般的沉浸式体验。\nChatbot逐渐向AI Agent演进。  AI Agent是指大模型赋能的，具备规划、记忆、工具、行动能力的智能体。我们认为Chatbot的演进方向是智能化和自动化程度逐渐提升，需要人类参与的程度逐渐下降，逐渐过渡到人与AI协作的 Copilot ，最终形态是AI Agent，Agent只需要人类的起始指令和结果的反馈，具有自主记忆、推理、规划和执行的全自动能力，执行任务的过程中并不需要人的介入。\n从Chatbot向AI Agent的演进过程中，手机应用生态或将发生改变。  我们认为手机或是向AI Agent演进率先落地的硬件载体，发挥AI个人助理的作用。AI个人助理可以记住生活和工作中的各种信息，如下周的晚餐计划或工作会议的内容，并自动整理和索引这些信息；可以帮助用户完成例如安排约会、预订旅行、点餐、播放音乐、回答问题等各种任务。落地过程中，手机应用生态或将从目前以应用商店+APP的模式转变为Agent Store+Agent的模式，手机厂商可能都会发布自己的Agent Store。\nAI手机：AI大模型驱动软硬件升级\n手机是人们日常生活较高的交互终端，具有普及率高、使用频率高的特点，考虑终端算力、存力以及客户应用需求等因素，手机已经成为AI大模型在C端落地的重要设备。去年底至今，随着三星Galaxy S24、Google Pixel 8等重要产品上市，以及苹果WWDC推出Apple Intelligence，手机AI的功能逐渐清晰。目前 语音助手、修图、写作助手等功能成为主流 。\n以三星今年1月发布的Galaxy S24为例，该机型搭载自研大模型Samsung Gauss，具备实时翻译/圈选搜图/生成式编辑/笔记助手等功能。软件方面，基于OneUI 6.1系统，强化虚拟助手Bixby，为用户提供丰富多样的应用服务。据Techweb，Google有望在10月推出Pixel9系列，预计将搭载基于最新Gemini模型的AI助手，执行复杂的多模态任务。芯片方面，下半年将发布的骁龙8Gen4较上一代产品有望进一步支持AI应用。\n2024年6月举行的苹果WWDC 2024大会推出全新个人化智能系统Apple Intelligence，由苹果端侧大模型、云端大模型、ChatGPT共同组成，算力足够下依赖终端，复杂场景则使用私密云计算或ChatGPT，能够1）增强Siri理解能力，配备多轮对话、总结信息、屏幕内容感知、应用智能交互等能力，2）提供邮件智能回复、通知整理，备忘录和通话录音/撰写/摘要等功能，3）支持图像生成/智能修图等功能，4）ChatGPT4o将融入siri和writing tools，作为云端备选模型。我们看到Apple Intelligence核心能力包括文生文、文生图、跨App交互与个人情境理解，并需要以OpenAI ChatGPT4o作为云端备选模型，配备上了目前已有的大部分AI功能。苹果通过Siri，把AI当作手机不同App之间联系的工具，而不是像此前三星和谷歌的AI应用更侧重于让AI去完成单一特定任务。苹果让Siri在未来成为应用分发入口和流量入口，以超过13亿台用户基数生态去提供好的产品解决方案。\nIDC认为，新一代AI智能手机需拥有至少30 TOPS性能的NPU，能够在手机上运行LLMs，符合标准的SoC包括Apple A17 Pro、MediaTek Dimensity 9300、Qualcomm Snapdragon 8 Gen 3等。此类手机在2023年下半年开始进入市场。\n硬件方面，我们看到：1）SoC：AI引擎升级、NPU算力提升，SoC进一步升级确定性强；2）存储：手机RAM升级至24GB LPDDR5X，相较当前主流的8GB LPDDR4X，成本提升300%；3）电源：电池/电源管理芯片升级，但弹性相对较小；4）光学：AI推动屏下摄像头应用取得突破。软件方面，新一代AI智能手机在系统架构和应用方面更加匹配个性化、场景化服务需求。\n软件方面，与功能机和前代智能机相比，新一代AI智能手机更加注重场景化服务能力。  前代智能机在功能机的基础上增加了手机OS和内嵌语音助手，并针对用户不同需求推出独立APP进行响应。新一代AI手机在大模型和原生化服务组件库的基础上，提供用户可定义的智能体开发平台和专属智能体，实现AI文本/AI图像/Al语音/Al视频等功能，满足用户健康管理/生活服务/角色扮演/高效办公/游戏助手等场景化需求。\n据IDC，全球AI手机2024年出货量有望同比增长233%至1.7亿台。中国AI手机所占份额自2024年以后会迅速增长，预计2024年中国市场AI手机出货量为0.4亿台，2027年将达到1.5亿台，且AI手机渗透率有望在2027年超过50%。我们认为，AI手机以其智能化、个性化的特点，有望吸引更多用户进行换机升级，从而引领新一轮的换机潮。\n根据2024年4月7日发布的《4月手机观察：华为份额继续提升，关注P70等新机发布》，根据IDC数字，苹果2023年销量2.34亿台，华泰预测苹果2024年销量下降8.2%到2.15亿台。根据BankMyCell数字，2024年苹果手机活跃用户14.6亿人，对应目前换机周期6.23年，如果Apple Intelligence能够缩短换机周期3个月，可以带动约1000万台新机销售。\nAR/VR：AI大模型交互能力，看好智能眼镜等轻量级AR发展机遇\nAI大模型有望提升AR/VR交互能力，加速其进入主流市场。  据IDC，2023年， AR /VR产品全球出货量675万台，同比-23%。随着苹果VisionPro发布，AR/VR/MR出货量在2024年有望温和复苏。AI大模型的出现驱动语音助手、物体识别和生活助理等功能赋能AR/VR设备，提升了用户与虚拟环境的互动质量，据VR陀螺（2024/6/5），Meta雷朋智能眼镜出货量已超百万副，AI大模型的出现有望加速AR/VR技术进入主流市场的步伐。\n语音助手、物体识别、生活助理等AI功能已在AR/VR产品中广泛出现。  语音助手功能让AR眼镜能够通过上下文语义理解与用户进行更自然的交流，如李未可Meta Lens S3通过大型语言模型AI系统提供闲聊和建议。物体识别技术使AR眼镜能够识别现实世界中的物体，例如Meta雷朋智能眼镜引入建筑识别和菜单翻译功能。此外，生活助理功能与用户的社交生活深度绑定，提供聊天回复、邮件整理、购物建议等个性化服务。这些AI功能的融合不仅提升了用户体验，还预示着AR/VR产品将更加智能化，为用户提供更便捷和个性化的服务。随着技术的不断进步，预计未来AR/VR设备将实现更复杂的多模态AI应用，进一步增强其作为下一代计算平台的潜力。\n大模型应用#2：生产力工具的AI化有望推动新一轮PC换机周期\n生产力工具、沟通工具及协作工具经历了PC时代、移动互联网时代的演进，正在进入AI时代。  微软、谷歌与金山办公等公司以AI大模型对原有的生产力工具应用进行升级，通常提供文档理解、文字生成、图片生成、数据分析与处理等等功能，提升用户生产力。\n办公：微软、谷歌引领产品矩阵全面AI化\n微软是全球生产力工具的领导企业，围绕企业业务与管理流程，已经形成了布局完整的产品矩阵，目前正主导生产力工具的AI化。  微软的产品矩阵覆盖企业办公、客户关系管理、资源管理、员工管理、低代码开发等业务环节，微软已经围绕这些业务环节，推出相应的Copilot产品，对原有产品进行AI大模型赋能。从Copilot时点来看，微软首先在主力产品Office套件上线Copilot，然后逐步在企业业务与管理流程的Dynamics套件、开发相关的Power Platform条件、员工管理的Viva套件上线Copilot。我们认为Copilot正以“通用助手”为切入点，重塑微软生产力工具矩阵，向数据协同、功能联动的方向发展。目前办公场景Office、企业业务流程场景Dynamics下的Copilot已明确单品收费标准。微软的Copilot产品分为和家庭两大场景。\n工作场景方面：1）面向企业办公场景推出Copilot for Microsoft 365，根据微软FY3Q24（对应日历季度1Q24）业绩会，近60%的财富100强企业正在使用。2）面向企业流程中的财务、销售和客服场景，分别推出Copilot for Finance/Sales/Service；3）面向云运营和管理场景，推出Copilot for Azure；4）面向IT安全场景，推出Copilot for Security；5）此外，微软推出Copilot Studio支持用户自定义Copilot，根据1Q24业绩会，已有3万名用户使用。\n家庭应用方面：1）面向C端用户办公场景推出Copilot Pro；2）面向Win 11和部分Win 10推出Copilot for Windows，支持通过任务栏上或键盘上的Copilot按钮进行快速访问；3）在Bing搜索、Edge浏览器推出Copilot。\n谷歌将Gemini大模型内置在其2B云端办公套件Workspace中。  谷歌将Gemini for Workspace的功能定义为：1）写作，例如生成项目计划、提案、简报等、以及优化文本；2）整理，例如通过简单描述创建项目跟踪表格；3）创建图像；4）联系，例如在视频通话中创建自定义背景，提高声音和视频质量；5）无代码创建应用。\n金山办公WPS已陆续在主要产品上线WPS AI服务。  WPS AI已经覆盖文字、演示、PDF、表格、智能文档、智能表格、智能表单等产品，涵盖了金山办公的主要产品。此外，金山办公发布了WPS AI企业版，推出AI Hub（智能基座）、AI Docs（智能文档库）、Copilot Pro（企业智慧助理）三大功能。\n编程：AI协助编程开发，提高开发效率与质量\nAI编程工具在"
  },
  {
    "title": "教育研究方法专题总结报告-人人文库",
    "page_body": "上传人：1*** IP属地：江苏 上传时间：2024-06-08 格式：DOCX 页数：6 大小：21KB 积分：8\n文档描述\n教育研究方法专题总结报告《教育研究方法专题总结报告》篇一教育研究方法是一门多学科交叉的领域，它涉及到心理学、社会学、人类学、统计学等多个学科的知识。在教育研究中，选择合适的研究方法对于确保研究的效度和信度至关重要。本专题总结报告旨在探讨教育研究中常用的方法，并提供实用的指导和建议。一、定量研究方法定量研究方法主要关注数据收集和分析中的数量化，通过统计分析来推断研究结果的普遍性。常用的定量研究方法包括调查研究、实验研究、准实验研究、描述性研究等。调查研究通常采用问卷和访谈的形式，实验研究则通过控制变量的方式来探究因果关系。在进行定量研究时，研究者需要考虑样本的代表性、数据的可靠性和有效性等问题。二、定性研究方法定性研究方法则更注重于对数据进行质性分析，以获取对现象的深入理解。常见的定性研究方法包括观察研究、访谈研究、个案研究、内容分析等。这些方法强调对数据进行细致的编码和分析，以揭示现象的复杂性和多样性。在定性研究中，研究者需要确保数据的丰富性和深度，以及分析过程的透明度和可靠性。三、混合方法研究混合方法研究是结合了定量和定性研究方法的策略，它允许研究者同时使用两种方法的优势。混合方法研究可以增强研究的信度和效度，提供更全面和深入的洞察。然而，混合方法研究也面临着设计和实施上的挑战，包括如何整合两种方法的数据和分析，以及如何确保研究的一致性和连贯性。四、教育研究的伦理考量在进行教育研究时，研究者必须遵守伦理原则，包括保护参与者的隐私和自主性、避免伤害、获得知情同意等。教育研究中常见的伦理问题包括数据隐私、研究对参与者可能产生的负面影响、以及研究结果的公正和透明报告等。研究者需要对这些问题有清晰的认识，并采取相应的措施来确保研究的伦理合规性。五、教育研究的设计与实施教育研究的设计包括确定研究问题、选择研究方法、制定研究计划等步骤。研究实施则涉及到数据收集、处理和分析的过程。在设计研究时，研究者需要考虑研究的目的、研究对象的背景、研究环境等因素。而在实施研究时，研究者需要确保数据的质量，遵守研究计划和时间表，以及有效地管理和分析数据。六、教育研究中的数据分析数据分析是教育研究中的关键环节，它直接影响到研究结果的可靠性和解释。对于定量研究，研究者通常使用统计软件进行数据分析，而定性研究则更多地依赖于内容分析、主题分析等方法。无论采用何种方法，研究者都需要确保数据的准确性和分析的严谨性，并正确解读研究结果。七、教育研究结果的解释与应用研究结果的解释需要结合研究的设计、数据质量和分析方法来进行。研究者需要谨慎地推断研究结果的意义，并考虑研究的局限性和未来的研究方向。研究结果的应用则需要考虑教育实践的具体情境，确保研究结论能够有效地转化为教育政策和实践。综上所述，教育研究方法的选择和应用是一个复杂的过程，需要研究者具备多方面的知识和技能。通过本专题总结报告，我们希望能够为教育研究者提供一份实用的指南，帮助他们更好地设计和实施教育研究项目。《教育研究方法专题总结报告》篇二教育研究方法专题总结报告教育研究是探索教育现象、揭示教育规律的重要途径，而研究方法的选择与应用则是保证研究质量的关键。本专题总结报告旨在系统梳理教育研究中的常见方法，并对其应用进行深入分析，以期为教育研究者提供有益的指导。一、定量研究方法定量研究方法以其客观性和精确性著称，适用于描述、解释和预测教育现象。常用的定量研究方法包括问卷调查、实验研究、准实验设计、描述性统计分析等。例如，在一项关于在线学习效果的研究中，研究者可以采用问卷调查法收集学生对在线学习平台的满意度数据，并通过实验研究设计来对比不同教学策略对学生成绩的影响。二、定性研究方法与定量研究不同，定性研究更加注重对教育现象的深入理解和解释。观察法、访谈法、案例研究等是常见的定性研究方法。例如，研究者可以通过对一所学校的长期观察，了解其实施素质教育的效果，或者通过深度访谈教师和学生，探究某一教育政策的实际影响。三、混合方法研究混合方法研究结合了定量和定性研究的优点，允许研究者同时收集和分析两种类型的数据。这种方法的灵活性使得研究者能够更加全面地理解教育现象。例如，在一项关于学习风格与学习效果关系的混合方法研究中，研究者可以首先使用问卷调查来大规模地收集学生的学习风格数据，然后通过访谈和观察来深入分析不同学习风格对学生学习成绩的影响。四、行动研究行动研究是一种将研究与实践紧密结合的方法，强调在教育实践中发现问题，并通过研究来解决这些问题。这种方法能够直接促进教育实践的改进。例如，一位教师在发现班级管理中存在问题时，可以通过行动研究来设计并实施新的管理策略，同时记录和分析策略的效果，从而不断优化班级管理。五、教育叙事研究教育叙事研究是通过讲述教育故事来探索教育现象的质性研究方法。它关注的是教育过程中的经历、故事和意义。例如，一位教师可以记录自己在教学过程中的成长故事，分析这些故事背后的教育意义，从而为其他教师提供借鉴和启示。六、政策分析教育政策分析是研究教育政策制定、实施和评估的科学方法。它关注教育政策的合理性、有效性和公平性。例如，研究者可以分析某项教育政策的制定背景、实施过程以及实际效果，从而为政策的优化和完善提供建议。七、教育技术研究随着信息技术的快速发展，教育技术研究成为教育研究的一个重要领域。它关注如何利用信息技术改进教学方法、提升学习效果。例如，研究者可以探究在线学习平台对学生自主学习能力的影响，或者探讨虚拟现实技术在教育中的应用潜力。八、评估研究教育评估研究关注教育项目的效果评价和质量保证。它包括形成性评估、总结性评估和过程评估等多种类型。例如，在一项关于教师专业发展的评估研究中，研究者可以跟踪教师参与培训前后教学效果的变化，以评估培训项目的成效。九、伦理问题在教育研究中，伦理问题是必须高度重视的。研究者应当遵守伦理原则，确保研究对参与者的尊重和保护。例如，在涉及人类受试者的研究中，研究者必须获得他们的知情同意，并对他们的个人信息进行保密。综上所述，教育研究方法的选择应当基于研究目的、研究问题以及研究情境。研究者应当熟练掌握各种研究方法的特点和应用条件，以便在不同的研究项目中灵活运用，从而为教育领域的理论创新和实践改进提供有力的支持。"
  },
  {
    "title": "吴恩达教你如何玩转ChatGPT，限时免费_澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "克雷西 发自 凹非寺\n量子位 | 公众号 QbitAI\nChatGPT催生新职业提示工程师，年薪可高达几十万美元。\n但是，该怎么入门？\n吴恩达面向广大开发者推出ChatGPT提示工程课程，与OpenAI合作出品。\n限时免费，而且对新手友好！\n课程发布还不到十个小时，就有网友表示已经学完了：\n还有网友表示没看够，期待推出更多内容：\n所谓提示工程，简单地说就是向大语言模型（LLM）发布有效的指令。\n在这段时长一个半小时的课程中，吴恩达和OpenAI技术部门员工一起讲解了如何用ChatGPT高效地设计程序。\n课程从LLM的工作方式展开，展示了最优的提示工程策略。\n课程中还介绍了如何利用LLM的API进行总结、推理、改写、扩展。\n此外，课程还介绍了撰写有效提示的两个关键原则，如何系统地设计好的提示。\n甚至还包括如何建立一个定制的聊天机器人。\n其中提到的所有概念都附带了丰富的示例，可以边听边体验。\n课程的门槛也并不高，只需要对Python有最基本的了解。\n不方便看视频或者英语听力不好也没关系，课程配备了脚本和字幕。\n在课程介绍中，吴恩达寄语到：\n生成式人工智能为人工智能工程师提供了许多机会，他们可以在几分钟或几小时内建立强大的应用程序，而这在以前需要几天甚至几周时间。我很高兴能分享这些最佳实践，使更多人能够利用这些革命性的新能力。\n再提醒一下课程是限时免费的，想要一睹为快的读者可要抓紧了！\n传送门：\nhttps://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\n参考链接：\n[1] https://twitter.com/AndrewYNg/status/1651605901781110785\n— 完 —\n科技前沿进展日日相见 ~\n原标题：《吴恩达教你如何玩转ChatGPT，限时免费！》"
  },
  {
    "title": "如何用AI大模型处理数据-CSDN博客",
    "page_body": "用 大模型 处理批量数据，核心是按“数据预处理-任务提交-结果回收”三步流程操作，兼顾效率与准确性，具体方法如下：\n 首先是 数据预处理 ，这是基础前提。需将原始数据整理为大模型支持的格式，主流是UTF-8编码的JSONL文件，每行一个JSON对象，包含唯一 custom_id （用于关联结果）和任务内容，单个文件不超过500MB、5万条请求 。同时要过滤无效数据、去重并移除隐私信息，确保符合模型上下文长度限制，超量数据需分批处理。\n 其次是批量任务提交，可选择两种方式。在线平台（如阿里云百炼）可通过控制台直接上传JSONL文件，选择统一模型和参数后提交，成本仅为实时 推理 的50% ；本地部署场景（如Ollama）可通过Excel公式或代码调用模型，适合离线处理，降低API调用成本。提交后可通过控制台或API查询任务状态，支持取消执行中任务。\n 最后是结果回收与校验。任务完成后，下载结果文件（成功响应）和错误文件（失败详情），通过 custom_id 与原始数据匹配 。对失败数据，根据错误信息修正格式或内容后重新提交；对成功结果，可进一步统计 Token 用量、分析响应质量，确保符合业务需求。\n 整个过程需注意模型一致性，同一任务需使用相同模型及参数，避免结果偏差。无论是在线批量推理还是本地离线处理，都能大幅提升数据处理效率，适配翻译、摘要、分类等多种场景。"
  },
  {
    "title": "职称论文‘研究方法’怎么写？实证vs.理论如何选？-搜狐",
    "page_body": "在撰写职称论文时，研究方法的选择是决定论文质量与学术价值的关键环节。面对实证研究与理论研究的路径分歧，研究者需结合学科特点、研究目标及自身条件进行系统性考量。本文将从方法论本质、适用场景、操作流程及常见误区四个维度展开分析，为学者提供具有实践指导意义的解决方案。\n一、方法论的本质差异与互补性\n实证研究与理论研究构成社会科学研究的两种基本范式。实证研究强调\"用数据说话\"，通过问卷调查、实验设计、案例观察等手段收集可量化的经验证据，采用统计分析方法验证假设，如某高校管理学院对456名企业中层干部的跟踪研究（百度百家号，2023），通过结构方程模型揭示了领导风格与团队绩效的量化关系。其优势在于结论的客观性和可重复性，但存在样本代表性和测量效度等挑战。\n理论研究则侧重概念演绎和逻辑推演，包括文献分析、比较研究、模型构建等方法。知乎专栏《社科研究方法论》（2023）指出，理论研究适用于探索新兴领域或解构复杂概念，如组织行为学中的\"心理契约\"理论发展，通过批判性整合32篇经典文献，建立了新的分析框架。其价值在于思维深度和解释张力，但需警惕陷入\"空对空\"的思辨陷阱。\n两种范式并非对立关系。CSDN技术社区案例（2023）显示，优秀的职称论文往往采用\"理论-实证-理论\"的螺旋结构：先通过文献综述建立理论模型，再用实证数据检验，最后回归理论修正。这种混合研究方法在管理学和经济学领域应用尤为广泛。\n二、学科适配与选题决策矩阵\n选择研究方法需建立三维评估体系：\n1. **学科特性**：实验心理学、临床医学等硬科学通常要求实证设计；哲学、美学等人文学科侧重理论思辨；而教育学、社会学等中间学科则需灵活选择。某核心期刊评审数据显示（百度新闻，2023），经济学领域实证论文录用率比纯理论论文高17%，但理论创新类论文更易获得高引用。\n2. **问题类型**：解释\"是什么\"和\"为什么\"的问题适合理论研究，如《数字化转型的伦理困境》这类选题；探究\"怎么样\"和\"如何做\"的问题需要实证支撑，像《在线教学平台使用效能评估》这类应用研究。\n3. **资源条件**：时间紧张（3个月内）建议选择文献研究或二手数据分析；拥有调研渠道的可采用问卷调查；具备实验条件的可设计对照研究。某省社科基金评审专家透露（知乎回答，2023），约43%被拒稿的实证论文失败于数据采集不足。  决策工具推荐使用\"STEAM模型\"：Significance（意义）、Theoretical space（理论空间）、Empirical feasibility（实证可行性）、Academic basis（学术基础）、Methodological maturity（方法成熟度）。每个维度按1-5分评估，总分≥18分适合实证研究，≤12分建议理论探索。  三、规范操作流程与质量控制  **实证研究实施要点**：  1. 抽样设计需明确总体边界与抽样方法，某高校职称评审要求（2023）特别强调样本量计算公式的呈现；  2. 测量工具应报告信效度检验结果，如Cronbach's α值≥0.7；  3. 数据分析要避免方法滥用，多元回归分析需先检验多重共线性（VIF<10）；  4. 伦理审查不可或缺，涉及人体研究需提供知情同意书。  **理论研究执行规范**：  1. 文献检索应覆盖中英文核心数据库，某C刊要求参考文献中外文比例不低于3:7；  2. 理论框架构建需呈现清晰的逻辑演进图；  3. 观点创新要说明与既有理论的对话点；  4. 论证过程需遵守MECE（相互独立完全穷尽）原则。  质量控制方面，建议建立\"双盲校验\"机制：邀请同行专家对理论逻辑进行证伪测试，安排统计专业人员复核数据分析过程。某学术不端检测报告显示（2023），方法论缺陷导致的退修意见占比达61%。  四、典型误区与高阶技巧  常见陷阱包括：  1. \"方法崇拜症\"：盲目使用复杂模型却忽视问题本质，如用机器学习算法分析仅30个样本的数据；  2. \"数据驱动型\"研究：先收集数据再拼凑理论框架，导致\"削足适履\"；  3. \"文献堆砌\"：理论综述沦为摘要汇编，缺乏批判性整合。  进阶策略建议：  - 理论创新可采用\"沙漏模型\"：从广博的文献综述聚焦到具体问题，再拓展到普遍意义；  - 实证设计可尝试\"三角验证法\"：定量数据+定性访谈+文献证据相互印证；  - 混合方法研究注意\"权重设计\"，如主要采用实证研究时，理论部分占比建议控制在30%以内。  期刊偏好分析显示（2023数据），实证论文在《科研管理》等应用类期刊更受青睐，而《学术月刊》等综合类期刊理论创新权重更高。学者应根据目标期刊特点调整方法侧重，同时保持学术诚信底线。  结语：研究方法的选择本质上是学术价值观的体现。优秀的职称论文应当使方法与问题形成\"榫卯结构\"，无论是实证的精确之美还是理论的思辨之光，最终都要服务于知识创新的根本目的。建议研究者建立个人方法论清单，定期更新技术工具箱，在学术实践中培养\"方法自觉\"意识。  #职称论文#"
  },
  {
    "title": "大模型微调常用术语与知识总结-20250902102413.docx-原创力文档",
    "page_body": "大小 ： 24.96 KB 字数 ： 约5.04千字 发布时间 ： 2025-09-03发布于四川  浏览人气 ： 0 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n大模型微调常用术语与知识总结\n大模型微调是优化预训练语言模型以适应特定任务或领域需求的重要技术。在进行大模型微调的过程中，有一系列常用术语和关键知识需要深入理解。下面将对这些常用术语与知识进行详细总结。\n基础概念与术语\n预训练模型（PretrainedModel）\n预训练模型是在大规模无监督数据上进行训练得到的模型。例如，GPT3、BERT等都是著名的预训练模型。这些模型通过在海量文本数据上学习语言的通用模式和特征，能够捕捉到丰富的语义信息。以BERT为例，它在大规模的维基百科等文本数据上进行了掩码语言模型（MaskedLanguageModel,MLM）和下一句预测（NextSentencePrediction,NSP）任务的训练，从而学习到了上下文相关的词表征。预训练模型为后续的微调提供了一个强大的基础，使得模型在特定任务上能够更快地收敛和达到较好的性能。\n微调（FineTuning）\n微调是指在预训练模型的基础上，使用特定任务的标注数据对模型进行进一步训练的过程。通过微调，模型可以适应新的任务需求，调整其参数以更好地完成特定任务。例如，在情感分析任务中，我们可以在预训练的BERT模型基础上，使用情感标注的文本数据对模型进行微调。微调的过程通常是在预训练模型的最后几层添加特定任务的输出层，然后使用特定任务的数据对整个模型或部分层进行训练。微调的优点在于可以利用预训练模型学习到的通用知识，减少在特定任务上的训练时间和数据需求。\n下游任务（DownstreamTask）\n下游任务是指在预训练模型基础上进行微调后要完成的具体任务。常见的下游任务包括文本分类、命名实体识别、机器翻译、问答系统等。不同的下游任务具有不同的特点和要求。例如，文本分类任务需要将输入的文本划分到不同的类别中，而命名实体识别任务则需要识别文本中的实体，如人名、地名、组织机构名等。在进行微调时，需要根据下游任务的特点对预训练模型进行适当的调整和优化。\n冻结（Freezing）\n冻结是指在微调过程中，固定模型的某些层的参数，使其在训练过程中不发生更新。通常，预训练模型的底层参数包含了更多的通用语言知识，而高层参数则更与特定任务相关。因此，在微调时可以选择冻结底层的一些层，只训练高层的层和特定任务的输出层。这样做的好处是可以减少训练的计算量和内存需求，同时避免在数据量较小的情况下过拟合。例如，在使用BERT进行文本分类任务时，可以冻结前几层的参数，只训练后面几层和分类层。\n解冻（Unfreezing）\n解冻与冻结相反，是指在训练过程中，将之前冻结的层的参数重新允许更新。在微调的初始阶段，为了快速收敛和稳定训练，可能会先冻结部分层。随着训练的进行，当模型的性能达到一定程度后，可以逐步解冻一些层，让模型进一步学习更复杂的特征。例如，在训练的前几个epoch冻结底层层，在后续的epoch中逐渐解冻这些层，以让模型能够更好地适应特定任务。\n数据相关术语与知识\n标注数据（AnnotatedData）\n标注数据是指带有标签的训练数据，用于微调模型以完成特定任务。对于不同的下游任务，标注数据的形式也不同。在文本分类任务中，标注数据是文本及其对应的类别标签；在命名实体识别任务中，标注数据是文本以及每个词对应的实体标签。标注数据的质量和数量对微调的效果有着重要影响。高质量的标注数据可以帮助模型学习到更准确的特征，而足够数量的标注数据可以避免过拟合。获取标注数据通常需要人工标注或使用半自动标注工具。\n数据增强（DataAugmentation）\n数据增强是指通过对原始数据进行变换，生成更多的训练数据的技术。在自然语言处理中，常见的数据增强方法包括同义词替换、插入、删除、回译等。例如，在文本分类任务中，可以将文本中的一些词替换为同义词，或者将文本翻译成另一种语言再翻译回来，从而得到新的训练样本。数据增强可以增加训练数据的多样性，提高模型的泛化能力。特别是在标注数据有限的情况下，数据增强可以有效地缓解数据不足的问题。\n数据划分（DataPartitioning）\n数据划分是指将标注数据划分为训练集、验证集和测试集的过程。训练集用于模型的训练，验证集用于在训练过程中评估模型的性能，选择最优的模型参数，测试集用于最终评估模型的泛化能力。常见的数据划分比例是训练集：验证集：测试集=70%：15%：15%或80%：10%：10%。合理的数据划分可以确保模型在训练过程中不出现过拟合，并且能够准确地评估模型的性能。\n小样本学习（FewShotLearning）\n小样本学习是指在仅有少量标注数据的情况下进行模型训练的技术。在实际应用中，获取大量的标注数据可能是困难和昂贵的，因此小样本学习具有重要的意义。在大模型微调中，小样本学习可以通过利用预训练模型的知识，结合一些特殊的训练策略，如元学习、迁移学习等，在少量标注数据上取得较好的性能。例如，使用预训练模型的特征表示，然后在少量标注数据上进行微调，或者使用元学习算法在不同的小样本任务上进行训练和学习。\n训练相关术语与知识\n学习率（LearningRate）\n学习率是优化算法中的一个重要超参数，它控制着模型参数更新的步长。在微调过程中，合适的学习率非常关键。如果学习率过大，模型的参数更新会过快，可能导致模型无法收敛或在最优解附近震荡；如果学习率过小，模型的训练速度会很慢，需要更多的训练时间才能达到较好的性能。常见的学习率调整策略包括固定学习率、学习率衰减（如按epoch衰减、按验证集性能衰减）等。例如，在训练的前几个epoch使用较大的学习率，随着训练的进行逐渐减小学习率，以让模型在不同阶段都能有效地学习。\n优化器（Optimizer）\n优化器是用于更新模型参数的算法，其目的是最小化损失函数。常见的优化器包括随机梯度下降（StochasticGradientDescent,SGD）、Adagrad、Adadelta、Adam等。不同的优化器具有不同的特点和适用场景。Adam优化器结合了Adagrad和RMSProp的优点，能够自适应地调整每个参数的学习率，在很多情况下表现较好。在大模型微调中，选择合适的优化器可以提高训练效率和模型性能。\n损失函数（LossFunction）\n损失函数用于衡量模型预测结果与真实标签之间的差异。在不同的下游任务中，使用的损失函数也不同。在文本分类任务中，常用的损失函数是交叉熵损失函数；在回归任务中，常用的损失函数是均方误差损失函数。损失函数的选择直接影响模型的训练目标和性能。通过最小化损失函数，模型可以不断调整参数，使其预测结果更接近真实标签。\n过拟合（Overfitting）\n过拟合是指模型在训练集上表现很好，但在测试集或新数据上表现较差的现象。在大模型微调中，过拟合是一个常见的问题。过拟合通常是由于模型过于复杂，而训练数据量不足或模型训练时间过长导致的。为了避免过拟合，可以采用正则化方法（如L1和L2正则化）、早停策略（EarlyStopping）、数据增强等方法。早停策略是指在验证集上的性能不再提升时停止训练，以避免模型在训练集上过度学习。\n欠拟合（Underfitting）\n欠拟合是指模型在训练集和测试集上的表现都较差的现象。欠拟合通常是由于模型过于简单，无法学习到数据中的复杂特征，或者训练时间过短，模型还没有充分学习到数据的特征。为了避免欠拟合，可以增加模型的复杂度，如增加模型的层数或神经元数量，或者增加训练的epoch数，让模型有更多的时间学习。\n模型架构与技术相关知识\n迁移学习（TransferLearning）\n迁移学习是指将在一个任务上学习到的知识迁移到另一个相关任务上的技术。大模型微调就是一种典型的迁移学习方法。通过在大规模无监督数据上预训练模型，学习到通用的语言知识，然后将这些知识迁移到特定的下游任务上。迁移学习可以减少在特定任务上的训练时间和数据需求，提高模型的效率和性能。例如，在图像识别领域，也广泛应用了迁移学习，将在大规模图像数据集上预训练的模型迁移到特定的图像分类任务上。\n多任务学习（MultiTaskLearning）\n多任务学习是指同时在多个相关任务上训练模型的技术。在大模型微调中，多任务学习可以让模型在不同的任务之间共享特征，提高模型的泛化能力和效率。例如，可以同时在文本分类和命名实体识别任务上训练模型，让模型学习到更丰富的语言特征。多任务学习通常通过设计合适的损失函数，将多个任务的"
  },
  {
    "title": "LLM（十三）DeepSeek-R1论文全文翻译",
    "page_body": "论文题目：《DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning》\n论文地址 ：https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf\n以下是论文的翻译内容：\n摘要\n 我们介绍第一代推理模型：DeepSeek-R1-Zero 和 DeepSeek-R1。DeepSeek-R1-Zero 是一个完全通过大规模强化学习（RL）训练而无需监督微调（SFT）作为初步步骤的模型，展示了显著的推理能力。通过RL，DeepSeek-R1-Zero 自然地展现出许多强大且有趣的推理行为。然而，它也遇到了一些挑战，如可读性差和语言混合问题。为了解决这些问题并进一步提高推理性能，我们引入了DeepSeek-R1，它在RL之前引入了多阶段训练和冷启动数据。DeepSeek-R1 在推理任务上的表现与OpenAI-o1-1217相当。为了支持研究社区，我们将DeepSeek-R1-Zero、DeepSeek-R1以及基于Qwen和Llama从DeepSeek-R1提炼出的六个密集模型（1.5B、7B、8B、14B、32B、70B）开源。\n第一章 引言\n 近年来，大型语言模型（LLMs）经历了快速迭代和发展（Anthropic, 2024; Google, 2024; OpenAI, 2024a），逐渐缩小了与人工通用智能（AGI）之间的差距。\n 最近，后训练已经成为完整训练管道的重要组成部分。研究表明，这种方法可以在推理任务上提高准确性，符合社会价值观，并适应用户偏好，同时相对于预训练所需的计算资源相对较少。在推理能力方面，OpenAI的o1系列模型首先通过增加链式思考（Chain-of-Thought, CoT）过程的长度引入了推断时缩放方法。这种方法在各种推理任务中取得了显著进展，例如数学、编程和科学推理。然而，有效测试时缩放仍然是研究界的一个开放问题。先前的工作探索了多种方法，包括基于过程的奖励模型（Lightman et al., 2023; Uesato et al., 2022; Wang et al., 2023）、强化学习（Kumar et al., 2024）以及搜索算法如蒙特卡洛树搜索和束搜索（Feng et al., 2024; Trinh et al., 2024; Xin et al., 2024）。然而，这些方法均未达到与OpenAI的o1系列模型相媲美的普遍推理性能。\n 在本文中，我们首次尝试使用纯强化学习（RL）来改进语言模型的推理能力。我们的目标是探索LLMs在没有任何监督数据的情况下发展推理能力的潜力，专注于其通过纯RL过程的自我进化。具体来说，我们使用DeepSeek-V3-Base作为基础模型，并采用GRPO（Shao et al., 2024）作为RL框架，以提高模型在推理中的表现。在训练过程中，DeepSeek-R1-Zero自然地展现了许多强大且有趣的推理行为。经过数千次RL步骤后，DeepSeek-R1-Zero在推理基准测试中表现出色。例如，在AIME 2024上的pass@1得分从15.6%提高到71.0%，并且通过多数投票，得分进一步提高到86.7%，达到了与OpenAI-o1-0912相当的水平。\n 然而，DeepSeek-R1-Zero面临的问题包括可读性差和语言混合。为了解决这些问题并进一步增强推理性能，我们引入了DeepSeek-R1，它包含少量冷启动数据和多阶段训练管道。具体来说，我们首先收集了数千条冷启动数据对DeepSeek-V3-Base模型进行微调。然后，我们像DeepSeek-R1-Zero一样执行面向推理的RL。接近RL过程收敛时，我们通过拒绝采样创建新的SFT数据，并结合来自DeepSeek-V3领域的监督数据，如写作、事实问答和自我认知，然后重新训练DeepSeek-V3-Base模型。经过新数据的微调后，检查点经历了一个额外的RL过程，考虑到了所有场景的提示。经过这些步骤，我们得到了称为DeepSeek-R1的检查点，在推理基准测试中与OpenAI-o1-1217的表现相当。\n 我们进一步探索了从DeepSeek-R1提炼到较小密集模型的方法。使用Qwen2.5-32B（Qwen, 2024b）作为基础模型，直接从DeepSeek-R1提炼的结果优于在其上应用RL。这表明较大的基础模型发现的推理模式对于提高推理能力至关重要。我们将开源的DeepSeek-R1及其API提供给研究社区，以便将来提炼更好的小型模型。\n1.1 贡献\n后训练：大规模强化学习在基础模型上的应用\n我们直接将RL应用于基础模型，而不依赖于监督微调（SFT）作为初步步骤。这种方法允许模型探索解决复杂问题的链式思考（CoT），从而开发出DeepSeek-R1-Zero。DeepSeek-R1-Zero展示了自我验证、反思和生成长链式思考的能力，标志着研究界的重大里程碑。值得注意的是，这是第一个公开研究，验证了通过RL而非SFT可以激励LLM的推理能力。这一突破为未来的发展铺平了道路。 我们介绍了开发DeepSeek-R1的流程。该流程包含两个旨在发现改进推理模式并与人类偏好保持一致的RL阶段，以及两个作为模型推理和非推理能力种子的SFT阶段。我们相信该流程将有助于行业创造更好的模型。\n知识蒸馏：小型模型也可以很强大\n我们证明了较大模型的推理模式可以被提炼到小型模型中，结果比在小型模型上通过RL发现的推理模式更好。开源的DeepSeek-R1及其API将帮助研究社区在未来提炼出更好的小型模型。 使用由DeepSeek-R1生成的推理数据，我们对研究界广泛使用的多个密集模型进行了微调。评估结果显示，提炼后的较小密集模型在基准测试中表现出色。DeepSeek-R1-Distill-Qwen-7B在AIME 2024上获得了55.5%的成绩，超过了QwQ-32B-Preview。此外，DeepSeek-R1-Distill-Qwen-32B在AIME 2024上得分为72.6%，在MATH-500上得分为94.3%，在LiveCodeBench上得分为57.2%。这些结果显著优于之前的开源模型，并且与o1-mini相当。我们将基于Qwen2.5和Llama3系列的1.5B、7B、8B、14B、32B和70B检查点开源给社区。\n1.2 评估结果总结\n推理任务：\nDeepSeek-R1在AIME 2024上的pass@1得分为79.8%，略高于OpenAI-o1-1217。在MATH-500上，它取得了令人印象深刻的97.3%的得分，表现与OpenAI-o1-1217相当，并显著优于其他模型。 编程相关任务：DeepSeek-R1在编程竞赛任务中展示了专家级水平，在Codeforces上获得了2029的Elo评分，超过了96.3%的人类参赛者。对于工程相关的任务，DeepSeek-R1的表现略优于DeepSeek-V3，这有助于开发人员在实际工作中解决问题。\n知识：\n 基准测试：在MMLU、MMLU-Pro和GPQA Diamond等基准测试中，DeepSeek-R1取得了卓越的成绩，显著优于DeepSeek-V3，分别在MMLU上达到90.8%，在MMLU-Pro上达到84.0%，在GPQA Diamond上达到71.5%。虽然其在这些基准测试中的表现略低于OpenAI-o1-1217，但DeepSeek-R1超越了其他闭源模型，展示了其在教育任务中的竞争力。在事实性基准SimpleQA上，DeepSeek-R1也优于DeepSeek-V3，展示了其处理基于事实查询的能力。类似的趋势也出现在OpenAI-o1上，其在这项基准测试中超过4o。\n其他方面：\n广泛任务：DeepSeek-R1还在各种任务中表现出色，包括创意写作、通用问答、编辑、摘要等。它在AlpacaEval 2.0上的长度控制胜率为87.6%，在ArenaHard上的胜率为92.3%，展示了其智能处理非考试导向查询的强大能力。此外，DeepSeek-R1在需要长上下文理解的任务中表现出色，大幅优于DeepSeek-V3在长上下文基准测试中的表现。\n2. 方法\n2.1 概述\n 之前的工作主要依赖大量的监督数据来提升模型性能。在本研究中，我们展示了通过大规模强化学习（RL），即使没有使用监督微调（SFT）作为冷启动，也可以显著提高推理能力。此外，通过引入少量冷启动数据可以进一步增强性能。在以下部分，我们将介绍：（1）直接应用于基础模型而不使用任何SFT数据的DeepSeek-R1-Zero；（2）从经过数千个长链式思考（CoT）示例微调的检查点开始应用RL的DeepSeek-R1；以及（3）将DeepSeek-R1的推理能力提炼到小型密集模型。\n2.2 DeepSeek-R1-Zero：基于基础模型的强化学习\n 强化学习在推理任务中表现出显著的有效性，如我们之前的工作所示（Shao et al., 2024; Wang et al., 2023）。然而，这些工作严重依赖于监督数据，这些数据收集起来非常耗时。在本节中，我们探索了LLMs在没有任何监督数据的情况下发展推理能力的潜力，专注于其通过纯强化学习过程的自我进化。我们首先简要概述我们的RL算法，然后展示一些令人兴奋的结果，并希望这能为社区提供有价值的见解。\n2.2.1 强化学习算法\n 为了节省RL的训练成本，我们采用了组相对策略优化（GRPO）（Shao et al., 2024），该方法放弃了通常与策略模型相同大小的批评模型，并通过组分数估计基线。具体来说，对于每个问题q，GRPO从旧策略πθold中采样一组输出{o1, o2, · · ·, oG}，然后通过最大化以下目标优化策略模型πθ：\n其中ε和β是超参数，Ai是优势函数，根据每组输出内的奖励{r1, r2,..., rG}计算得出：\n2.2.2 奖励建模\n 奖励是训练信号的来源，决定了RL的优化方向。为了训练DeepSeek-R1-Zero，我们采用了一个基于规则的奖励系统，主要包括两种类型的奖励：\n准确性奖励 ：准确性奖励模型评估响应是否正确。例如，在具有确定结果的数学问题中，要求模型以指定格式（例如，在框内）提供最终答案，从而实现可靠且基于规则的正确性验证。同样地，对于LeetCode问题，可以使用编译器根据预定义的测试用例生成反馈。 格式奖励 ：除了准确性奖励模型外，我们还使用了格式奖励模型，强制模型将其思考过程置于‘<think>’和‘</think>’标签之间。\n 我们没有应用结果或过程神经奖励模型来开发DeepSeek-R1-Zero，因为我们发现大规模强化学习过程中神经奖励模型可能存在奖励黑客问题，重新训练奖励模型需要额外的训练资源，并使整个训练管道复杂化。\n2.2.3 训练模板\n 为了训练DeepSeek-R1-Zero，我们首先设计了一个简单的模板，指导基础模型遵循我们的指定指令。如表1所示，此模板要求DeepSeek-R1-Zero首先生成一个推理过程，然后提供最终答案。我们有意限制这些结构化格式的约束，避免任何特定内容的偏见——例如，要求反思性推理或促进特定的问题解决策略——以确保我们可以准确观察模型在RL过程中自然进展的情况。\n2.2.4 性能、自我进化过程和“啊哈”时刻\nDeepSeek-R1-Zero的性能\n 图2显示了在整个RL训练过程中，DeepSeek-R1-Zero在AIME 2024基准上的性能轨迹。如图所示，随着RL训练的推进，DeepSeek-R1-Zero显示出稳定且一致的性能提升。值得注意的是，AIME 2024上的平均pass@1得分显著增加，从最初的15.6%跃升至令人印象深刻的71.0%，达到了与OpenAI-o1-0912相当的水平。这一显著改进凸显了我们的RL算法在随时间优化模型性能方面的有效性。\n 表2提供了DeepSeek-R1-Zero与OpenAI的o1-0912模型在各种推理相关基准上的比较分析。结果表明，RL使DeepSeek-R1-Zero能够在无需任何监督微调数据的情况下获得强大的推理能力。这是一个值得注意的成就，因为它强调了模型仅通过RL就能有效学习和泛化的强大能力。此外，通过多数投票，DeepSeek-R1-Zero的性能可以进一步增强。例如，在AIME基准上应用多数投票时，DeepSeek-R1-Zero的性能从71.0%提升到86.7%，超过了OpenAI-o1-0912的性能。DeepSeek-R1-Zero能够实现如此竞争性的性能，无论是否使用多数投票，都突显了其在推理任务中的强大基础能力及其进一步发展的潜力。\nDeepSeek-R1-Zero的"
  },
  {
    "title": "留学写作，好论文如何炼成-教育-人民网",
    "page_body": "　　留学期间，论文写作既是重要的学业任务，也是整合知识、输出观点的过程。留学生写作时有哪些可利用的学习资源？如何突破语言障碍？本报记者采访了几名有经验的学生，听听他们的分享。\n 　　\n 　　日常积累素材\n 　　“对我而言，写论文的难点是针对研究问题提出解决方案。”刘涛是就读于美国科罗拉多学院的博士生，一路求学，他积累了不少写论文的经验。刘涛说：“通常一篇论文从研究主题‘是什么’‘为什么’‘怎么办’3个角度展开论述，在‘怎么办’的部分，尤其需要针对研究问题提出创新的解决方法，这是论文的落脚点，也是写作具有挑战的部分。”\n 　　刘涛认为，要想在提出解决方案时有创新的点子，除了充分了解前人研究外，还需要做好日常积累。“我认为在平时的学习中要时刻记录灵感。美国课堂注重学生的阅读和讨论，学生需在课下完成阅读，然后在上课时分享读后感并和同学讨论。我在阅读和讨论时会把与研究内容相关的思考记下来，写作可以从中获得启发。”\n 　　读书破万卷，下笔如有神。几名受访留学生纷纷表示，平时多读文献对论文写作大有裨益。好的阅读并不是“走马观花”、泛泛涉猎，想写出好的论文，先要成为一名好的读者。\n 　　刘人博在韩国延世大学学习对外韩语教育，他分享了自己的阅读技巧。“阅读文献时我会分析论文的内容和语言两个方面，每方面单独整理成文档笔记，帮助我实现‘一篇论文不重读’，从而提高科研效率。”\n 　　刘人博进一步解释说：“看论文内容时我特别关注作者的切入角度、研究对象的选定理由、论文的框架结构、段内句间的逻辑展开方式等，学习作者的思维方式。同时，我也看论文中值得再次引用的部分和参考文献，及时建立相关文档并予以记录，进行归类和总结。对于论文语言表达，我会整理文中好的语言表达、句式、用词等，提升自己的写作能力。”\n 　　利用学校资源\n 　　写作时，中国学生除了参照书籍和文献，还可以通过学校资源获得更多帮助。对此，刘涛有亲身体会。\n 　　“我认为主动联系导师、寻求他的建议相当重要。”刘涛回忆，“我的专业是文艺学，有一次我的论文主题是研究蒋孔阳先生的绘画美学思想。我想找到较好的研究切入视角，便主动与导师探讨。导师提出可以从蒋孔阳先生的中西方绘画美学比较研究切入，我当即受到了启发。这是一条我尚未尝试的写作思路，帮助我挖掘出了更丰富的研究内容。”\n 　　在刘涛看来，论文完成后也要积极请教导师，获取修改建议，这是提高论文写作水平的重要一步。“不仅可以根据老师建议，对论文进行修改和完善，还要学会举一反三，下次写作时避免出现相同问题，写作能力就能逐渐提高。”刘涛说\n 　　记者了解到，不少学校开设了论文写作课程，给予学生指导。杜珂就读于德国慕尼黑大学传媒专业，她说：“学校开设的论文写作课不仅教学生如何确定论文写作的框架、思路，还对具体的语言表达给出指导建议。课程实用，深受同学们喜欢，需要在选课时赶紧‘下手’。”\n 　　“我所就读的韩国延世大学为学生提供丰富的论文指导资源。”刘人博介绍，“学校设有韩语和英语写作服务中心，当学生需要思路指导或语言校正、润色时，可以提前在服务中心系统上预约，会有专门的研究员教授一对一联系学生，提供详细反馈。为提高留学生的写作能力、鼓励大家使用写作服务，学校很多教授要求留学生在期末时上交3份文档，分别是论文初稿、写作服务中心的服务回执单和校正后的论文，以帮助大家在完成论文后进行反思、总结。”\n 　　攻克语言难关\n 　　在国外写作通常需用外语完成，对于如何突破外语障碍、准确表达语言，几名学子分享了自己的看法。\n 　　“论文写作过程中的语言表达问题，可以通过学校提供的写作服务进行改正。”刘人博分享了自己的方法，“每次收到写作服务中心的初稿修改意见时，我都会整理一个‘记错本’，将自己犯过的错误重新梳理一遍，在下次写作的时候尽量避免。与其徒增数次修改初稿的经历，不如对经验和错误进行归纳，提升自身写作实力。”\n 　　刚来美国上学时，刘涛也曾在上课时担心自己的语言表达不够地道，担心会因此赶不上课业进度。“但我后来意识到，观点、内容才是语义传达的核心，中国学生首先要克服非母语表达的那份心中的不自信。”\n 　　刘涛还分享了一些翻译与修改软件，他说：“Deep L和Grammarly是我常用的软件，翻译的准确度较高，还能润色表达、改语法错误，对于论文写作很有用。”\n 　　杜珂认为，相比华丽的辞藻，清楚的表达更为重要，对于非母语论文写作来说更是这样。她说：“论文写作并不需要生僻复杂的词汇，而要把重心放在内容本身。学术论文是学术研究过程和成果的一种呈现方式，想要做到表达清晰，我们除了外语能力，还需具备逻辑思维和谋篇布局能力，这是更全面的写作思维。”\n 　　“提升论文的外语写作能力没有捷径可走。”杜珂说，“首先要有意识地阅读优质论文，学习、总结作者的写作方法。通常好的论文段落很规范，中心句、论据以及之间的逻辑衔接关系一目了然。此外，还需要尽可能多地积累不同的表达句型，让行文表述更丰富。”"
  },
  {
    "title": "Java 机密计算技术全知道：原理详解与代码实践示例",
    "page_body": "机密计算（Confidential Computing）  是一种保护数据在使用过程中（即内存中）的安全技术。它通过硬件支持的可信执行环境（TEE，Trusted Execution Environment）来确保数据在计算过程中不会被未授权的实体访问。Java 作为一种广泛使用的编程语言，也可以与机密计算技术结合，保护敏感数据。\n以下是 Java 机密计算技术的详解及代码示例。\n1. 机密计算的核心概念\n1.1 可信执行环境（TEE）\nTEE 是一个隔离的执行环境，确保代码和数据在运行时不会被外部访问。\n常见的 TEE 技术包括：\nIntel SGX（Software Guard Extensions）\nAMD SEV（Secure Encrypted Virtualization）\nARM TrustZone\n1.2 机密计算的关键特性\n数据加密 ：数据在内存中以加密形式存储。\n代码完整性 ：确保只有经过验证的代码可以在 TEE 中运行。\n远程证明 ：允许外部验证 TEE 环境的真实性。\n2. Java 与机密计算\nJava 可以通过以下方式与机密计算技术结合：\n使用支持 TEE 的硬件 ：如 Intel SGX。\n调用本地库 ：通过 JNI（Java Native Interface）调用 C/C++ 编写的 TEE 代码。\n使用机密计算框架 ：如 Microsoft Open Enclave、Asylo 等。\n3. 使用 Intel SGX  的  Java 机密计算示例\nIntel SGX 是一种广泛使用的 TEE 技术。以下是一个简单的示例，展示如何在 Java 中调用 SGX 的本地代码。\n3.1 环境准备\n硬件 ：确保 CPU 支持 Intel SGX。\n软件 ：\n安装 Intel SGX SDK。\n安装 Java Development Kit (JDK)。\n安装 JNI 工具。\n3.2 编写 SGX 本地代码\n以下是一个简单的 SGX 本地代码示例，用于在 TEE 中执行加法操作。\nC++ 代码（ sgx_enclave.cpp ）\nEnclave 代码（ Enclave.edl ）\nEnclave 实现（ Enclave.cpp ）\n3.3 编写 Java 代码\n通过 JNI 调用 SGX 本地代码。\nJava 代码（ SGXExample.java ）\n3.4 编译和运行\n 1.编译 SGX 代码 ：\n使用 Intel SGX SDK 编译 Enclave 代码。\n生成共享库（如 libsgx_enclave.so ）。\n 2.编译 Java 代码 ：\n使用 javac 编译 Java 代码：\n生成 JNI 头文件：\n 3.运行程序 ：\n确保 SGX 环境已正确配置。\n运行 Java 程序：\n4. 使用机密计算框架\n除了直接使用 SGX，还可以使用机密计算框架（如 Microsoft Open Enclave 或 Asylo ）来简化开发。这些框架提供了跨平台的 TEE 支持，并可以与 Java 集成。\n5. 总结\n机密计算 通过 TEE 技术保护数据在计算过程中的安全。\nJava 可以通过 JNI 调用本地代码，与 TEE 技术（如 Intel SGX）结合。\n使用机密计算框架可以简化开发流程。\n以上示例展示了如何在 Java 中实现机密计算。实际应用中，需要根据具体需求选择合适的 TEE 技术和框架。 #图文创作激励计划#"
  },
  {
    "title": "【英国留学】学术论文写作之方法论",
    "page_body": ""
  },
  {
    "title": "大语言模型在客服领域：AI原生对话系统的架构设计-CSDN博客",
    "page_body": "大语言 模型 在客服领域：AI原生对话系统的架构设计\n关键词：大 语言模型 （LLM）、AI原生客服系统、对话管理、意图识别、多模态交互\n摘要：本文从传统 客服系统 的痛点出发，结合大语言模型（LLM）的技术特性，系统讲解AI原生对话系统的核心架构设计。通过生活类比、技术原理解析和实战代码示例，帮助读者理解如何用LLM重构客服对话系统，涵盖意图识别、多轮对话管理、安全合规等关键模块，并探讨未来发展趋势。\n背景介绍\n目的和范围\n在电商、金融、电信等行业，客服系统是连接企业与用户的关键纽带。传统客服系统依赖规则引擎和关键词匹配，面对复杂问题（如“我上周买的白色连衣裙，物流显示已签收但没收到，能帮我查下吗？”）时，常出现“答非所问”“流程断裂”等问题。本文聚焦“大语言模型（LLM）如何重塑客服系统”，覆盖从架构设计到落地实战的全流程。\n预期读者\n技术人员：想了解如何将LLM应用到客服场景的开发者、架构师 业务人员：企业客服负责人、产品经理（理解技术价值与落地成本） 普通用户：对AI客服背后原理感兴趣的“好奇星人”\n文档结构概述\n本文从“为什么需要AI原生客服”切入，逐步拆解核心模块（ 意图识别 、对话管理、LLM调用），结合代码示例和实际场景，最后展望未来趋势。\n术语表\n术语\n解释（用小学生能懂的话）\n大语言模型（LLM） 像一个“超级知识大脑”，能理解人类语言并生成合理回答（比如ChatGPT就是典型的LLM）\n意图识别 给用户的问题“贴标签”，比如把“退货”“查物流”“投诉”区分开\n多轮对话管理 记住对话历史的“小本本”，比如用户说“我要退货”，系统问“订单号是多少？”，它能记住这是同一件事\n上下文窗口 LLM能“记住”的对话长度（比如能记住最近20轮对话）\n幻觉（Hallucination） LLM“编故事”的情况（比如用户没提过“红色外套”，但系统回答“您的红色外套已退款”）\n核心概念与联系\n故事引入：小明的“崩溃”客服体验\n小明在某电商平台买了一本书，物流显示“已签收”但没收到。他联系客服：\n 小明：“我的书没收到，物流显示签收了，怎么办？”\n 传统客服：“请提供订单号查询物流~”（小明提供后）\n 传统客服：“物流显示已签收，可能是放快递柜了哦~”（小明说没收到快递柜通知）\n 传统客服：“请联系快递员138XXXX1234~”（小明打过去，快递员说没送过）\n 小明崩溃：“我要投诉！”\n 传统客服：“您的问题已记录，3个工作日内处理~”\n而AI原生客服的对话可能是这样的：\n 小明：“我的书没收到，物流显示签收了，怎么办？”\n AI客服：“抱歉给您添麻烦了！已帮您查到订单号12345的物流信息，显示快递员张师傅10:30放到小区快递柜，但您手机没收到取件码。我已联系张师傅确认，并为您申请了优先补发，新包裹预计明天送达，需要帮您备注‘放门口’吗？”\n为什么AI客服更聪明？  因为它能：\n理解“没收到+物流显示签收”的深层问题（可能是快递柜漏发短信）； 记住对话历史（小明没收到通知）； 主动解决问题（联系快递员、申请补发）。\n这背后的核心，就是大语言模型驱动的“AI原生对话系统”。\n核心概念解释（像给小学生讲故事）\n核心概念一：大语言模型（LLM）—— 客服的“超级大脑”\nLLM就像一个“读了全世界所有书”的客服专家。它通过分析海量文本（网页、书籍、对话记录），学会了“理解人类语言”和“生成合理回答”。比如，它知道“没收到快递”可能和“物流信息错误”“快递员漏送”有关，而不仅仅是“用户没查物流”。\n核心概念二：意图识别—— 给问题“分分类”\n意图识别就像超市的“商品分类标签”。用户说“我要退货”，标签是“退货申请”；用户说“物流到哪了”，标签是“物流查询”。系统通过标签快速知道用户需求，避免“用户说退货，系统推荐新品”的尴尬。\n核心概念三：多轮对话管理—— 对话的“记忆小本本”\n多轮对话管理就像玩“你画我猜”时的“提示板”。用户说“我要退昨天买的T恤”，系统问“请问尺码是M还是L？”，这时候需要记住用户是“退T恤”，而不是突然跳到“查物流”。如果没有记忆，用户可能要重复说：“我之前说要退T恤，尺码是M！”\n核心概念之间的关系（用小学生能理解的比喻）\n想象开一家“智能奶茶店”：\nLLM是“万能店员”（能理解“我要少糖、加珍珠的冰奶茶”，还能推荐“最近芒果味很火哦”）； 意图识别是“点单分类器”（区分“点单”“改单”“投诉”）； 多轮对话管理是“点单记录本”（记住用户说“少糖”，后面问“加椰果还是红豆？”时不会忘记）。\n三者关系：\nLLM和意图识别 ：意图识别帮LLM“快速定位问题”（比如先知道用户是“投诉”，LLM就不会用“点单”的语气回答）； 意图识别和对话管理 ：对话管理根据意图“推进流程”（比如“退货”意图需要收集订单号、商品问题，对话管理会一步步问）； LLM和对话管理 ：对话管理把“记忆小本本”（对话历史）交给LLM，LLM就能结合历史生成更自然的回答（比如用户之前说“没收到快递”，LLM会说“关于您之前提到的未收到快递问题，我们已联系快递员”）。\n核心概念原理和架构的文本示意图\nAI原生对话系统的核心架构可分为5层：\n输入层 ：用户输入（文字/语音/图片）→ 预处理（转文字、去噪）； 理解层 ：意图识别（分类）、实体抽取（提取“订单号”“商品名”等关键信息）； 决策层 ：LLM调用（结合对话历史生成回答）、对话状态管理（更新记忆小本本）； 执行层 ：调用外部系统（查物流、改订单）； 输出层 ：生成回答（文字/语音）。\nMermaid 流程图"
  },
  {
    "title": "AI小课堂 大模型技术的三种架构，我用3分钟给大家讲清楚，涉及到计算机科学理论，内容很干！建议先马再看#大模型 #大模型技术架构 #AI #人工智能 #AI小课堂",
    "page_body": ""
  },
  {
    "title": "大模型训练2--Prompt Tuning-->训练可学习提示-知乎",
    "page_body": "近年来，以GPT为代表的大型预训练模型（Pre-trained Language Models, PLMs）在自然语言生成任务中表现出色。为了更好的适配下游任务，传统的全参数微调（Fine-tuning）需要为每个下游任务存储和更新数十亿参数，这对计算资源和存储成本提出了巨大挑战。针对这个问题，GPT3中提出了prompt工程，然而大模型对用户设计的prompt比较敏感，因而也难以保证效果。在此背景下，Prompt Tuning作为一种轻量高效的微调方法备受关注，仅需对每一个任务训练一个提示向量，就可以大大提高大模型在这项任务的表现。\n 一、什么是Prompt Tuning？\n 传统的Fine-tuning通过在预训练模型的基础上添加任务相关层（如分类器）并更新所有参数来适应具体任务。然而，这种方法有两个主要缺陷：\n 参数低效：每个下游任务需独立保存完整模型副本。\n 灾难性遗忘：微调可能覆盖预训练模型中的通用知识。\n 相比之下，Prompt Tuning的核心思想是通过在输入中插入可学习提示（Prompt），以极小的参数调整来适配下游任务。这种方法仅需优化提示相关的参数（通常占总参数的0.1%~1%），而冻结原始模型参数。如Figure1所示，Prompt Tuning所需要训练的参数最小。prompt Design就是Prompt工程，是不可训练的。\n Figure1、不同微调方法所更新的参数\n 二、Prompt Tuning训练过程\n 2.1、设计提示模板\n 在原始输入前添加k 个可学习的提示嵌入（例如[P1][P2][P3][P4]），并拼接模板引导输出。例如：\n [P1][P2][P3][P4] 这部电影很有趣。总体评价是 [MASK] 的。\n 其中，\n [P1]-[P4]：可训练的提示，相当于4个待学习的token。每个P的嵌入维度与文本嵌入的维度一致，比如768。[MASK]：模型需预测的位置，映射到标签（如“好”→“正面”，“差”→“负面”）。对于k的选择，论文中做了实验，20个性价比最高，如Figure3所示。本文中仅以4个作为例子。Figure3\n 2.2、输入编码\n 输入文本被转换为嵌入向量。提示嵌入与原始输入的嵌入向量拼接后输入冻结的预训练模型（如 GPT3）。2.3、计算损失\n 模型预测[MASK]位置的 token 概率（如“好”的概率为 0.8，“差”为 0.2）。根据真实标签（假设是“正面”），计算交叉熵损失：Loss = -log(P(\"好\"))。2.4、反向传播\n 仅更新提示嵌入的参数（[P1]-[P4]嵌入向量）。预训练模型的参数保持冻结。3、预测过程\n Prompt Tuning训练完毕后，可学习提示嵌入的向量就保持不变，对该任务下的所有问题都使用这个提示嵌入。换言之，不管用户输入的问题是什么，只要是同一个任务下的问题，所插入的提示嵌入[P1]-[P4]都是一样的。要适配多任务，就需要为每一个任务训练一个可学习的提示嵌入。\n 3.1、添加训练后的提示\n 新输入特效很棒，但剧情糟糕。与前缀提示拼接：\n [P1][P2][P3][P4] 特效很棒，但剧情糟糕。总体评价是 [MASK] 的。\n 其中，“总体评价是 [MASK] 的”是人工针对这项任务所设计的模板。要注意的是，训练后得到的是P1-P4四个嵌入向量，而不是4个token。需要对输入文本进行embedding后再与学习到的提示嵌入进行拼接。\n 3.2、模型推理\n 冻结的预训练模型处理整个输入序列，预测[MASK]位置的 token 概率（例如“差”的概率为 0.7）。\n 3.3、映射到标签\n 根据[MASK]预测结果（“差”），输出类别为“负面”。\n 4、参考文献\n 【1】The Power of Scale for Parameter-Efficient Prompt Tuning"
  },
  {
    "title": "为什么你的大模型训练这么慢？3个关键并行优化点必须掌握-CSDN博客",
    "page_body": "第一章：大模型训练性能瓶颈的根源分析\n 在大规模语言模型的训练过程中，性能瓶颈往往成为制约迭代效率和成本控制的核心问题。尽管硬件算力持续提升，但实际训练中仍频繁遭遇吞吐量低、收敛缓慢等问题。深入剖析其根源，有助于从系统架构与算法协同设计的角度优化整体训练效率。 \n显存带宽与计算资源的不匹配\n 现代GPU虽具备强大的浮点运算能力，但显存带宽的增长速度远落后于计算能力。这导致大量时间消耗在数据搬运而非实际计算上。例如，在处理千亿参数模型时，激活值和梯度的存储需求极易超出显存容量，引发频繁的CPU-GPU间数据交换。 \n高精度训练（如FP32）加剧显存压力 激活检查点机制虽缓解内存占用，但增加计算开销 张量并行策略若划分不当，会引入额外通信延迟\n分布式训练中的通信开销\n 多卡或多节点训练依赖高效的集合通信（如AllReduce），但在跨节点场景下，网络带宽和延迟显著影响同步速度。特别是在数据并行中，梯度同步成为关键路径。 \n# 所有进程梯度求和并广播回每个进程\n# 若网络带宽不足，此操作可能成为性能瓶颈\n数据加载与预处理延迟\n 模型训练速度提升后，I/O常成为短板。原始文本需经分词、截断、批处理等步骤，若未采用异步加载或缓存机制，GPU将频繁等待数据输入。 \n低效算子、小批量尺寸\n网络拥塞、拓扑不合理\n磁盘读取慢、预处理串行化\n第二章：数据并行与分布式训练优化\n2.1 PyTorch DDP 原理与通信开销解析\n数据并行机制概述\n PyTorch 的 DistributedDataParallel (DDP) 通过在多个进程间复制模型，实现数据并行训练。每个进程处理不同的数据子集，并在反向传播时同步梯度。 \n梯度同步流程\n DDP 使用环形约简（Ring All-Reduce）进行梯度聚合，各 GPU 按拓扑顺序分段通信，降低带宽压力。通信开销主要取决于模型参数量和网络带宽。 \n# 自动触发梯度同步\n 上述代码中， DDP  包装模型后，在  loss.backward()  完成后自动执行跨进程梯度同步，无需手动干预。 \n通信开销影响因素\n参数规模：参数越多，梯度张量越大，通信时间越长 GPU间连接：NCCL后端依赖高速互联（如InfiniBand）提升吞吐 批量大小：大batch增加梯度计算占比，相对降低通信占比\n2.2 多机多卡环境下梯度同步的性能调优\n 在分布式深度学习训练中，多机多卡环境下的梯度同步成为性能瓶颈的关键环节。合理优化通信机制可显著提升整体训练效率。 \n梯度同步策略对比\n 常见的同步方式包括同步SGD、Ring-AllReduce和Hierarchical AllReduce。其中Ring-AllReduce在大规模节点间表现出更优的扩展性。 \n 该函数遍历模型参数，对每个梯度执行全局规约并归一化，确保各节点梯度一致。dist.all_reduce采用环状通信，减少中心节点压力。 \n2.3 使用混合精度训练加速数据并行\n 在大规模模型训练中，混合精度训练结合数据并行可显著提升计算效率。通过使用FP16减少显存占用和带宽需求，同时保留FP32用于稳定梯度更新，实现速度与精度的平衡。 \n混合精度核心机制\n NVIDIA Apex等工具提供便捷的自动混合精度（AMP）支持。启用后，前向传播采用半精度，而关键计算如梯度缩放仍用单精度。 \n 上述代码中， autocast 自动管理张量精度类型， GradScaler 防止FP16梯度下溢，确保训练稳定性。 \n与数据并行的协同优化\n 在DDP场景下，混合精度减少了 all-reduce 通信的数据量，加快梯度同步。每卡独立进行损失缩放，避免跨卡数值不一致问题。 \n2.4 梯度累积与批大小的权衡策略\n 在深度学习训练中，批大小（batch size）直接影响模型收敛性与内存消耗。较大的批大小能提升训练稳定性，但受限于GPU显存容量。梯度累积技术通过模拟大批次训练，允许在小批量迭代中累积梯度，待累积步数完成后统一更新参数。 \n梯度累积实现逻辑\n# 每累积4个小批次执行一次参数更新\nfor  i, (inputs, labels)  in enumerate (dataloader):\n 上述代码将损失除以累积步数，确保梯度尺度合理。反向传播不立即更新参数，而是在累积指定步数后调用  step() ，有效模拟大批次训练。 \n批大小与学习率协同调整\n线性缩放规则：当等效批大小增大时，学习率应成比例提高 学习率预热：在初始阶段逐步增加学习率，避免梯度震荡 梯度裁剪：防止累积过程中梯度爆炸\n2.5 实战：基于 torch.distributed 的可扩展训练框架搭建\n初始化分布式环境\n 在多机多卡训练中，首先需正确初始化分布式通信后端。常用 NCCL 后端支持 GPU 间高效通信。 \n    dist.init_process_group(backend= 'nccl' , init_method= 'env://' )\n 上述代码通过环境变量（如 RANK、WORLD_SIZE）自动获取节点信息，适用于 Kubernetes 或 Slurm 调度场景。 \n数据并行与模型封装\n 使用  DistributedDataParallel  包装模型，实现梯度级别的同步。 \nfrom  torch.nn.parallel  import  DistributedDataParallel  as  DDP\nmodel = DDP(model, device_ids=[local_rank])\n 每个进程独立加载对应子数据集，配合  DistributedSampler  避免样本重复。 \n训练流程协同控制\n所有进程共享同一学习率调度策略 仅主进程保存检查点，避免文件冲突 使用  dist.barrier()  确保全局同步点\n第三章：模型并行的拆分与协同机制\n3.1 层内并行（Tensor Parallelism）在Transformer中的实现\n 层内并行通过将单个张量计算分布到多个设备上来提升大规模Transformer的训练效率，尤其适用于模型参数远超单卡显存容量的场景。 \n张量切分策略\n 在Transformer的自注意力和前馈网络中，大矩阵乘法是性能瓶颈。以隐藏层维度为  d d 、输出维度为  h h  的全连接层为例，权重矩阵  W ∈ R d × h W ∈ R d × h  可沿输出维度切分为  W 1 , W 2 , . . . , W n W 1 , W 2 , . . . , W n ，分别部署于不同GPU。 \n# 假设将输出维度均分至2个设备\noutput_0 = x @ W_tensor_parallel[ 0 ]   # 设备0计算局部结果\noutput_1 = x @ W_tensor_parallel[ 1 ]   # 设备1计算局部结果\n 上述代码展示了权重切分与局部计算过程。每个设备仅需存储部分权重，显著降低显存压力。 \n数据同步机制\n 各设备完成局部矩阵乘法后，需通过  AllReduce  操作聚合结果，确保最终输出一致： \n前向传播：各设备独立计算局部输出，随后执行AllReduce求和 反向传播：梯度已全局同步，可直接更新本地权重分片\n3.2 层间并行（Pipeline Parallelism）的调度与气泡优化\n 在层间并行中，模型被纵向切分为多个阶段，各阶段分布于不同设备上。由于计算与通信无法完全重叠，流水线执行常引入“气泡”（Bubble），即空闲等待周期，降低整体吞吐。 \n调度策略\n 主流调度方式包括： \nNaive Pipeline ：按顺序推进微批次，气泡集中在流水线填满前； 1F1B（One Forward One Backward） ：交错执行前向与反向传播，减少等待时间。\n气泡优化示例\n# 模拟流水线气泡占比计算\ndef calc_bubble_ratio ( num_stages, num_micro_batches ):\n# 四阶段流水线，4个微批次\n 该函数表明，在早期阶段，气泡开销显著。随着微批次增多，利用率提升，凸显调度优化必要性。 \n3.3 实战：使用 FSDP 与模型切分提升显存效率\n 在大规模模型训练中，显存瓶颈是常见挑战。FSDP（Fully Sharded Data Parallel）通过将模型参数、梯度和优化器状态分片，显著降低单卡显存占用。 \n核心实现逻辑\nfrom  torch.distributed.fsdp  import  FullyShardedDataParallel  as  FSDP\n 该代码启用 FSDP， use_orig_params=True  允许使用原生参数格式，提升兼容性与性能。每个进程仅保留当前所需参数分片，其余按需加载。 \n模型切分策略对比\n策略\n显存节省\n通信开销\n FSDP 在显存效率与通信成本之间实现了更优平衡，适合千亿级模型分布式训练场景。 \n第四章：系统级优化与硬件协同加速\n4.1 CUDA内核融合与算子优化技巧\n 在高性能计算中，CUDA内核融合是减少内存带宽瓶颈和提升GPU利用率的关键手段。通过将多个细粒度内核合并为单一复合内核，可显著降低全局内存访问次数和内核启动开销。 \n内核融合示例\n__ global __ void fused_kernel(float *  a, float *  b, float *  c, float *  d, int n) {\n        float temp  =  a[idx]  +  b[idx];      / /  第一步：向量加法\n        d[idx]  =  temp  *  c[idx];            / /  第二步：逐元素乘法\n 上述代码将两个独立操作（加法与乘法）融合为一个内核，避免中间结果写回全局内存，提升数据局部性。 \n优化策略\n减少内存事务：合并读写模式以提高合并访问效率 利用共享内存：在块内重用数据，降低全局内存压力 避免分支发散：确保同一线程束执行相同控制路径\n4.2 显存管理：检查点机制与动态分配策略\n 在深度学习训练中，显存资源往往成为性能瓶颈。为缓解这一问题，现代框架引入了检查点（Checkpointing）机制，通过在前向传播中仅保存部分中间结果，在反向传播时重新计算未缓存的张量，从而显著降低显存占用。 \n检查点机制示例\nfrom  torch.utils.checkpoint  import  checkpoint\n# 使用检查点包装前向过程\n 上述代码通过  checkpoint  函数替代标准前向调用，仅保留输入和最终输出，中间激活值在反向传播时按需重建，节省约40%-60%显存。 \n动态显存分配策略\n GPU显存分配器采用基于内存池的动态管理，避免频繁申请/释放带来的开销。典型策略包括： \n首次适配（First-Fit）：快速分配首个足够大的空闲块 分块合并：回收碎片化空间，提升利用率\n 结合检查点与动态分配，可在有限显存下支持更大模型或批量规模。 \n4.3 NCCL通信后端调优与拓扑感知配置\n 在大规模分布式训练中，NCCL（NVIDIA Collective Communications Library）是实现高效GPU间通信的核心。合理调优其后端参数并启用拓扑感知配置，可显著提升集合通信性能。 \n环境变量调优策略\n 通过设置关键环境变量优化通信行为： \n 其中， NCCL_ALGO 指定使用Ring算法以降低带宽竞争， NCCL_PROTO 选择Simple协议减少小消息延迟， NCCL_TOPO_FILE 引导NCCL加载自定义拓扑描述文件。 \n拓扑感知通信优化\n NCCL通过分析PCIe、NVLink和NUMA拓扑自动构建最优通信路径。可通过以下命令生成物理拓扑图： \n 该文件记录了GPU间的连接带宽与跳数，使NCCL在AllReduce等操作中优先选择NVLink直连路径，避免跨NUMA节点通信瓶颈。 \n4.4 实战：结合PyTorch Profiler定位训练瓶颈\n 在深度学习模型训练过程中，性能瓶颈常隐藏于数据加载、GPU利用率不足或算子执行效率低下中。PyTorch Profiler 提供细粒度的执行时间分析，帮助开发者精准定位问题。 \n启用Profiler进行性能采样\n    on_trac"
  },
  {
    "title": "收藏必备！斯坦福大学Transformer图解教程：大模型架构学习的“圣经“级资源-CSDN博客",
    "page_body": "这篇文章介绍了一份斯坦福大学团队制作的Transformer图解教程，通过高度可视化的方式讲解Transformer架构核心原理、大语言模型的提示微调及应用方法。该教程因其可视化程度高、讲解清晰、学术严谨，被AI学习者誉为\"圣经级\"入门材料，适合初学者理解大语言模型基石技术，也为从业者提供深入探究资源。\n今天给大家一份由斯坦福大学研究人员或课程团队精心制作的深度学习技术教程，旨在以直观、易懂的视觉化方式，深入浅出地讲解Transformer神经网络架构的核心原理。\n涵盖：\nTransformer：自注意力机制、架构、变体、优化技术（如稀疏注意力、低秩注意力、Flash Attention） 大语言模型 (LLM)：提示 (prompting)、微调（SFT、LoRA）、偏好调优、优化技术（混合专家模型、知识蒸馏、量化） 应用：LLM 作为评判者、检索增强生成 (RAG)、智能体、推理模型（来自 DeepSeek-R1 的训练时与测试时缩放技术）\n这份《斯坦福Transformer图解》因其 极高的可视化程度、逻辑清晰的讲解顺序和学术严谨性 ，被全球广大AI学习者、研究者和工程师奉为学习Transformer架构的“圣经级”入门材料。它不仅帮助初学者跨越理解障碍，也为从业者提供了快速回顾和深入探究的宝贵资源。这份图解是理解当今大语言模型（如BERT、GPT系列）基石技术不可或缺的学习资料。\n如何学习大模型 AI ？\n由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。\n但是具体到个人，只能说是：\n“最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。\n这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。\n我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。\n我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。\n这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【 保证100%免费 】\n为什么要学习大模型？\n我国在A大模型领域面临人才短缺,数量与质量均落后于发达国家。2023年，人才缺口已超百万，凸显培养不足。随着AI技术飞速发展，预计到2025年,这一缺口将急剧扩大至400万,严重制约我国AI产业的创新步伐。加强人才培养,优化教育体系,国际合作并进是破解困局、推动AI发展的关键。\n大模型入门到实战全套学习大礼包\n1、大模型系统化学习路线\n作为学习AI大模型技术的新手，方向至关重要。 正确的学习路线可以为你节省时间，少走弯路；方向不对，努力白费。这里我给大家准备了一份 最科学最系统的学习成长路线图和学习规划 ，带你从零基础入门到精通！\n2、大模型学习书籍&文档\n学习AI大模型离不开书籍文档，我精选了一系列大模型技术的书籍和学习文档（电子版），它们由 领域内的顶尖专家撰写 ，内容全面、深入、详尽，为你学习大模型提供坚实的理论基础。\n3、 AI大模型最新行业报告\n2025最新行业报告，针对 不同行业的现状、趋势、问题、机会 等进行系统地调研和评估，以了解哪些行业更适合引入大模型的技术和应用，以及在哪些方面可以发挥大模型的优势。\n4、 大模型项目实战&配套源码\n学以致用 ，在 项目实战中检验和巩固你所学到的知识 ，同时为你找工作就业和职业发展打下坚实的基础。\n5、 大模型大厂面试真题\n面试不仅是技术的较量，更需要充分的准备。在你已经掌握了大模型技术之后，就需要开始准备面试，我精心整理了一份大模型面试题库， 涵盖当前面试中可能遇到的各种技术问题，让你在面试中游刃有余 。\n适用人群\n第一阶段（10天）：初阶应用\n该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨论时发表高级、不跟风、又接地气的见解，别人只会和 AI 聊天，而你能调教 AI，并能用代码将大模型和业务衔接。\n大模型 AI 能干什么？ 大模型是怎样获得「智能」的？ 用好 AI 的核心心法 大模型应用业务架构 大模型应用技术架构 代码示例：向 GPT-3.5 灌入新知识 提示工程的意义和核心思想 Prompt 典型构成 指令调优方法论 思维链和思维树 Prompt 攻击和防范 …\n第二阶段（30天）：高阶应用\n该阶段我们正式进入大模型 AI 进阶实战学习，学会构造私有知识库，扩展 AI 的能力。快速开发一个完整的基于 agent 对话机器人。掌握功能最强的大模型开发框架，抓住最新的技术进展，适合 Python 和 JavaScript 程序员。\n为什么要做 RAG 搭建一个简单的 ChatPDF 检索的基础概念 什么是向量表示（Embeddings） 向量数据库与向量检索 基于向量检索的 RAG 搭建 RAG 系统的扩展知识 混合检索与 RAG-Fusion 简介 向量模型本地部署 …\n第三阶段（30天）：模型训练\n恭喜你，如果学到这里，你基本可以找到一份大模型 AI相关的工作，自己也能训练 GPT 了！通过微调，训练自己的垂直大模型，能独立训练开源多模态大模型，掌握更多技术方案。\n到此为止，大概2个月的时间。你已经成为了一名“AI小子”。那么你还想往下探索吗？\n为什么要做 RAG 什么是模型 什么是模型训练 求解器 & 损失函数简介 小实验2：手写一个简单的神经网络并训练它 什么是训练/预训练/微调/轻量化微调 Transformer结构简介 轻量化微调 实验数据集的构建 …\n第四阶段（20天）：商业闭环\n对全球大模型从性能、吞吐量、成本等方面有一定的认知，可以在云端和本地等多种环境下部署大模型，找到适合自己的项目/创业方向，做一名被 AI 武装的产品经理。\n硬件选型 带你了解全球大模型 使用国产大模型服务 搭建 OpenAI 代理 热身：基于阿里云 PAI 部署 Stable Diffusion 在本地计算机运行大模型 大模型的私有化部署 基于 vLLM 部署大模型 案例：如何优雅地在阿里云私有部署开源大模型 部署一套开源 LLM 项目 内容安全 互联网信息服务算法备案 …\n学习是一个过程，只要学习就会有挑战。天道酬勤，你越努力，就会成为越优秀的自己。\n如果你能在15天内完成所有的任务，那你堪称天才。然而，如果你能完成 60-70% 的内容，你就已经开始具备成为一名大模型 AI 的正确特征了。\n这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【 保证100%免费 】"
  },
  {
    "title": "社区说｜用 TensorFlow 实现 GPT 模型",
    "page_body": ""
  },
  {
    "title": "Transformer模型：核心组件和应用场景",
    "page_body": "Transformer模型在自然语言处理（NLP）领域真的太成功了，从BERT开始，它已经成了文本分类、命名实体识别、情感分析、机器翻译等任务里的常客。\n它的厉害之处，全在它的核心组件上。\n     核心组件一：自注意力机制\n这是Transformer的灵魂。它允许模型在处理序列数据时，对每个位置的输入进行加权求和，得到一个全局的上下文表示。在计算自注意力时，模型首先将输入序列通过线性变换得到Q（查询）、K（键）和V（值）三个向量。然后计算Q和K的点积，并应用softmax函数，得到每个位置的权重。最后，将权重与V向量相乘，得到自注意力的输出。\n     核心组件二：多头注意力\n为了提高模型的表达能力，Transformer模型采用了多头自注意力机制。这意味着模型在同一时间关注来自不同表示子空间的注意力信息。多头自注意力的实现方法是通过多个独立的注意力头，每个头使用不同的权重矩阵对输入序列进行线性变换，生成各自的Q、K、V向量，并计算自注意力。最终，这些自注意力的输出被拼接起来，并通过一个线性层得到最终的输出表示。\n     核心组件三：前馈神经网络\n在计算自注意力和多头自注意力之后，Transformer模型使用前馈神经网络对输入序列进行变换。前馈神经网络由多个全连接层组成，每个全连接层都使用ReLU激活函数。前馈神经网络的作用是对输入序列进行非线性变换，以捕捉更复杂的特征。\n     核心组件四：位置编码\n位置编码是通过在输入序列的每个位置添加一个固定长度的向量来实现的。这个向量包含了该位置在序列中的信息，如位置标识符和相对位置等。\n     应用场景\n文本分类\n文本分类是Transformer模型最常见的应用之一。通过将文本输入到模型中，可以得到每个类别的预测概率分布。常见的文本分类任务包括情感分析、新闻分类、电影评论分类等。例如，BERT等经典模型在情感分析任务上取得了很好的效果，能够准确识别文本中的情感倾向。\n命名实体识别\n命名实体识别是自然语言处理中的一项重要任务，旨在识别文本中的特定实体（如人名、地名、组织名等）。"
  },
  {
    "title": "从实践到课堂 从课堂到实战—全省“十佳精品纪检监察课程”评选工作侧记",
    "page_body": "近日，全省 “十佳精品纪检监察课程”和“优秀纪检监察课程”评选结果揭晓。成都市纪委监委、省纪委监委驻四川银行纪检监察组等16个单位申报的“谈话的策略和方法”等20个课程榜上有名，标志着全省“十佳精品纪检监察课程”评选阶段的工作圆满结束。\n \n7月5日，省纪委监委开展“十佳精品纪检监察课程”现场展示评审，入围的29个课题组同台展示、精彩纷呈。\n广泛参与、深研细磨\n为认真贯彻落实中央纪委、省纪委关于深化干部培训培养和加强纪检监察学科建设有关部署，充分发挥干部培训服务保障办案作用，进一步充实优质培训资源、提升干部培训质效，聚力锻造本领高强的纪检监察干部队伍， 2023年底，省纪委监委部署开展“十佳精品纪检监察课程”评选工作。各地各单位积极响应，共43个地方和单位申报80个选题。经严格审核，65个“精而专”的选题进入课程开发阶段。\n \n各地各单位组建课程组，聚智聚力、精心准备。\n众人拾柴火焰高。眉山市纪委监委、省纪委监委驻体育局纪检监察组等单位，由领导班子成员、主要负责同志牵头，抽调 “精兵强将”集智攻关。省纪委监委法规室等单位“以老带新”共同开发，给业务骨干和年轻干部交任务、压担子，人人能担任课程主讲人，把课程开发过程转化为培训骨干、培养师资的过程。\n \n各课程组采取集中研讨、试讲等方式打磨修改课程讲义。\n“村级监督既是一个实践问题，也是一个理论问题，更是一个关乎江山与人民的问题。”省纪委监委驻川师大纪检监察组副组长张晓宏介绍说，“我们充分发挥纪检监察学科建设优势，与院校专家、基层党政干部一道深入田间地头搞调研，先后调研村（社区）30余个，走访村组党员群众400余人次，收集整理相关资料40余万字，将课程写进乡土里，守正创新、不断精进。”\n雅安市纪委监委案件审理室干部向笛谈到， “为把课程讲深讲透，我们在准备阶段系统梳理市监委查办的258件职务犯罪案件，收集整理18件典型新型隐形受贿问题司法认定情况；形成讲义后，我们课题组又多次集中研讨、反复修改、组织试讲，回想起来历历在目。”\n据悉，各地各单位从选题、研题到起草、试讲，再到初审、复审、现场展示，历时 8个多月，先后近200人参与到课程开发当中，形成课程讲义共计120余万字。\n聚焦中心、突出实务\n纪检监察干部的核心业务能力需要从哪些维度提升？哪些问题长期以来没有讲深讲透？哪些新情况问题需要深入研究？哪些方面有比较成熟的经验可以提炼总结？ ……在“十佳精品纪检监察课程”评选工作筹划阶段，省纪委监委机关专题召开相关业务室参加的会商会，按照“当前最缺什么课程就重点开发什么课程”的思路，梳理形成涵盖信访工作、线索处置、日常监督、审查调查、追责问责、以案促改等纪检监察业务全链条的课题开发参考清单。\n一石激起千层浪。全省纪检监察系统以评选工作为牵引，聚焦纪检监察主责主业开发实务课程，开小口、挖深井，掀起了深度研学纪法、总结提炼经验的热潮，形成了一批质量较高的纪检监察课程。\n \n各课程组代表在现场展示评审环节介绍各自课程。\n“目前专案组运行管理上缺乏统一的规范和标准，开发‘如何带好专案组’这个课程，目的是把我们近几年实践中的一些心得体会做个总结，抛砖引玉，供大家参考。”在现场展示评审环节，自贡市纪委常委、市监委委员李波登台介绍课程开发的初衷。\n“笔录制作是一门实践性比较强的课程。对此，我们将整堂课分为课程导入、案例分析、课堂演练、成果展示、课程总结等5个部分，重点组织案例分析和课堂演练。”在现场展示评审环节，省纪委监委驻四川产业基金纪检监察组黄丽珠详细介绍了课程的教学方法。\n \n各课程组代表在现场展示评审环节介绍各自课程。\n“我们以粮食购销领域腐败问题专项整治有关工作为基础，总结开展专项整治的‘四加’工作法：多管齐下+联动研判、一把手紧盯+紧盯一把手……”在现场展示评审环节，省纪委监委第二纪检监察室宋文远介绍课程的特色亮点。\n7月5日，省纪委监委机关开展现场展示评审。29个进入复审的课程逐一登台亮相，围绕教学目标、教学内容及课程的实践性、创新性和特色亮点等作介绍。\n“这些课程规范性、实践性都比较强，亮点纷呈、特色各异，有不少独到的思考和精辟的提炼，让人印象深刻、深受启发。”担任现场主评委的省纪委常委肖克强在点评讲话中给予充分肯定。\n精心组织、公正公开\n据悉，此次是近年来全省纪检监察系统首次开展课程评选工作，包括选题发布、选题申报、选题审核、课程开发、书面初审、书面复审、现场展示等 7个主要环节。委领导亲自审定方案、高度重视，各级积极参与、广泛关注。\n \n省纪委监委周密组织、有序推进课程评审各环节工作。\n“课程评选专业性强，要广泛听取意见，注重借智借力，切忌闭门造车”。省纪委监委组织部、党风廉政建设研究教育中心认真贯彻委领导指示要求，坚持“开门搞评选”，多次采取召开会商会、点对点征询等方式，征求省纪委监委业务室、课题组、专家评委的意见建议，反复修订有关环节工作方案，凝聚最大“公约数”。\n2024年5月，评选工作进入专家评审环节，20名长期在纪检监察战线工作，实践和理论水平较高的室主任、纪检监察组组长、市（州）纪委副书记和专家学者组成评委会，围绕参评课程的实践性、规范性、创新性，先后开展初审、复审、现场展示等3轮评审。\n \n评委们实事求是、客观公正地开展课程评审工作。\n“初审环节采取‘分类盲评+小组会商’的方式进行，从64个参评课程中遴选29个进入复审。”省纪委监委组织部相关负责同志介绍，“复审采取入围课程拉通盲评的方式进行，得分按60%折算计入总分，现场展示得分按40%折算计入总分，最终按照得分高低确定获奖课程。\n \n评委们对 29个入围课程开展现场展示评审。\n评审工作始终坚持质量为先、优中选优，获奖作品质量过硬，受到广泛认可。\n“这次评选模式新颖、贴近实战、突出实用、注重实效，既是擂台比武、更是认知拓荒，既是创新之举、更是提能之需。我们将借他山之石而内自省，反求诸己而宜自修，不断提高纪检监察工作规范化、法治化、正规化水平。”广元市纪委副书记、市监委副主任夏国茂说。\n“通过这次评选既打造了一批优质课程，又储备一批优秀师资。”参加现场评审观摩的小平干部学院培训部负责人史志伟表示，“获奖课程既可以作为日常实操的教材，也可以作为授课辅导的参考模板，这对我们干部培训基地来讲很有意义。”\n课程评选的目的在于运用。据悉，省纪委监委计划采取编印讲义、录制视频、推荐授课等多种方式，加大获奖课程推送、运用的范围和力度，推动各地各单位结合纪检监察学科建设，进一步总结提炼实践经验，研发优质纪检监察课程，为纪检监察干部队伍建设聚智聚力。"
  }
]