[
  {
    "title": "国际最新研究表示人工智能在创造性思维任务中或超越大部分人类，你对此有何看法？",
    "page_body": "施普林格·自然旗下开放获取学术期刊《科学报告》最新发表一篇人工智能(AI)研究论文指出，大型语言模型(LLM)AI对话机器人在创造性思维任务上或能超越大部分的一般人类，该任务要求受试者想出日常用品的替代用途(发散性思维的一个例子)。不过，该研究也显示，得分最高的人类受试者依然能超过对话机器人的最佳答案。\n　　该论文指出，发散性思维通常是指与创造性相关的一类思维过程，需要为特定任务想出各种不同创意或对策。发散性思维一般通过替代用途任务(Alternate Uses Task，AUT)进行评估，受试者被要求在短时间内想出某个日常用品的其他用途，越多越好。受试者的回答从四个类别进行打分：流利度、灵活性、原创性和精细度。\n　　论文第一作者、芬兰图尔库大学Mika Koivisto和通讯作者、挪威卑尔根大学与斯塔万格大学 Simone Grassini两人合作，利用人工智能大模型ChatGPT3、ChatGPT4和Copy.Ai完成绳子、盒子、铅笔、蜡烛4个物品的AUT，并对其答案进行比较。他们通过语义距离(回答与物品原始用途的相关度)和创造性给回答的原创性打分，并用一个计算方法在0-2的范围里量化语义距离，同时让不知道作答者身份的人类打分者在1-5的范围里客观评价创造性。\n　　该研究结果显示，平均而言，对话机器人的回答在语义距离(0.95相对于0.91)和创造性(2.91相对于2.47)的得分上显著高于人类的回答。人类回答在这两项的得分差距更大——最低分远低于AI的回答，但最高分普遍比AI高。最佳人类回答在8个评分项中的7项都超过了所有对话机器人的最佳回答。\n　　论文作者总结认为，这项研究结果表明，当前AI对话机器人想创意的能力至少已与一般人类相当。他们也指出，本次研究只评价了涉及创造性评估的单项任务的表现，今后的研究或能探索如何将AI融入创造性过程来提升人类表现。(完)\n国际最新研究：人工智能在创造性思维任务中或超越大部分人类\n纵观人类文明的中的AI发展历史：\n深蓝打败国际象棋棋王，那是专家系统的胜利。 AlphaGo 在围棋对弈中战胜九段选手李世石，深度学习神经网络在专业领域内击败人类。 GPT-4在逻辑推理，语言创造方面，重大突破。\n这几位学者的研究，是把创造性思维进行量化评估，得到这样一个客观结论，这个结果我并不惊讶。在试用GPT-4的过程中，我意识到了这个工具的强大，上万字的文章挥毫而就，虽然不是那么完美，然而逻辑性和创意已经超越了自己。\n再比如AIGC中的图片制作：\n一串普通的题词，就能让你的图片非常精彩，普通人也能享受艺术创作的快乐。这些能力，远远不是一般个人能有的能力。\nAI在创造性和智力水平超越大部分人类，只是时间问题，即使现在不是，未来不久也会实现。我们要做的，和过往的任何一次技术革命一样，充分掌握利用工具的创新，提升自己，跟紧时代。"
  },
  {
    "title": "刚刚，OpenAI发长篇论文：大模型幻觉的原因找到了~-今日头条",
    "page_body": "整理自：PaperAgent、OpenAI官方博客 \n引自:DataWhale \n相信很多同学都遇到过——问大模型一个冷门知识，它会一本正经地给出完全错误的答案。 \n比如： \n“Adam Tauman Kalai 生日是哪天？知道的话就按 DD-MM 的格式直接给出。”\nOpenAI(2025a)三次回答分别是 03-07 、   15-06  、  01-01  ，  没一次对  。\n这就是典型的   Hallucination（幻觉）   ——   语言模型生成看起来合理，实则错误离谱   。 \n论文地址： \nhttps://cdn.openai.com/pdf/d04913be-3f6f-4d2b-b283-ff432ef4aaa5/why-language-models-hallucinate.pdf\nOpenAI 这篇论文首次系统揭示：   语言模型出现幻觉的根本原因在于，   当前   标准的训练和评估程序更倾向于对猜测进行奖励，而缺乏对模型坦诚表达不确定性的奖励机制   。 \n表1 提供了一些更复杂的幻觉示例：GPT-4o/DeepSeek/Llama \n一、预训练阶段就埋下幻觉种子 \nFigure 2：GPT-4预训练模型（左）原本校准良好；RLHF后（右）明显过自信 \n1. 统计必然性 \n把生成问题等价到二分类“Is-It-Valid？”——只要分类器会犯错，生成就会出错（定理 1）。 \n图 1：Is-It-Valid二分类视角——生成错误⇔把\"-\"判成\"+\" \n2. 数据稀缺性 \n训练语料里只出现一次的“冷知识”（singleton）注定会被模型记错，错误率 ≥ singleton 占比（定理 2）。 \n3. 模型表达能力不足 \n如果模型族本身就无法学到规律（如 trigram 数不对字母），幻觉率下限直接拉满（定理 3）。 \n二、后训练阶段“考试机制”强化幻觉 \n对10个主流评测做了   元评测  ，发现清一色  惩罚不确定性  ：\nTable 2：主流评测清一色\"惩罚\"不确定性 \n三、解法：把\"交白卷\"变成可选项 \n呼吁   不需要新benchmark  ，只要  改评分规则  ：\n1. 明示信心阈值 \n在prompt里直接写： \n\"只有在你置信度>t时才回答；答错扣t/(1-t)分，IDK得0分。\"\n2. 让\"弃权\"成为最优策略 \n当模型真实置信度  的期望得分最高，  说谎反而吃亏 。\n四、总结 \nOpenAI 表示： 我们希望本文中的统计学视角能够 阐明 幻觉的本质，并纠正一些常见的误解： \n误解1 ： 通过提高准确性可以消除幻觉，因为一个 100%准确的模型永远不会产生幻觉。 \n发现 ：准确性永远无法达到100%，因为无论模型规模如何，搜索和推理能力怎样，一些现实世界的问题本质上是无法回答的。 \n误解2 ： 幻觉是不可避免的。 \n发现 ：幻觉并非不可避免，因为语言模型在不确定时可以选择不作答。 \n误解3 ： 避免幻觉需要一定程度的智能，而这种智能只有通过更大的模型才能实现。 \n发现 ： 小型模型可能更容易了解到自身的局限性。 比方说，当被要求回答毛利语问题时，一个完全不懂毛利语的小型模型可以直接说“我不知道”，而一个懂一些毛利语的模型必须确定其置信度 。正如论文中所讨论的，“校准”所需的计算量远小于实现回答准确性的计算量。 \n误解4 ： 幻觉是现代语言模型中一种神秘的缺陷。 \n发现 ：我们已经理解了幻觉产生的 统计学机制 ，以及它们在评估中获得奖励的原因。 \n误解5 ： 要衡量幻觉，我们只需要一个好的幻觉评估方法。 \n发现 ：尽管已经提出了多种幻觉评估方法，但一个优秀的评估方法对于目前现有的数百种传统准确性指标几乎没有影响。这些传统指标往往惩罚表达谨慎、谦逊的回答，并奖励猜测行为。因此，所有主要的评估指标都需要重新设计，更好地鼓励模型在表达上体现出不确定性。 \n参考资料： \n1. https://cdn.openai.com/pdf/d04913be-3f6f-4d2b-b283-ff432ef4aaa5/why-language-models-hallucinate.pdf \n2 . https://openai.com/index/why-language-models-hallucinate/ \n一起“   点   赞 ”   三连  ↓\n应对连日来的阴雨天气，我省各地农业农村部门统筹抓好农机调配、烘干晾晒等工作，有力保障秋收秋种。目前，全省秋粮收获已超八成。在沧州河间市北新河村的玉米地里，两台履带式收割机正在作业。\n技巧组合错落有致，音乐编排浑然天成，群体造型雄伟阳刚，展示了燕赵慷慨刚健之风。\n美国会日前通过有关法案，跟台海局势有什么关系呢？美军机被拦截，又出了什么事了呢？过去近八十年来，两岸之所以迟迟无法走向统一，根本原因就在于美国等外部因素的干预。而上述因素的存在，也就是“台独”分裂势力“以武拒统”的底气。\n2025年10月17日下午，中央组织部有关负责同志出席中华全国供销合作总社领导干部会议，宣布中央决定:王宇燕同志任中华全国供销合作总社党组书记，免去韩立平同志的中华全国供销合作总社党组书记职务。"
  },
  {
    "title": "什么是大模型？大模型应用案例有哪些？一文搞定大模型及落地应用案例-CSDN博客",
    "page_body": "一、 什么是大模型？\n大模型，英文名叫Large Model，大型模型。早期的时候，也叫Foundation Model，基础模型。\n大模型是一个简称。完整的叫法，应该是“人工智能预训练大模型”。预训练，是一项技术，我们后面再解释。\n我们现在口头上常说的大模型，实际上特指大模型的其中一类，也是用得最多的一类——语言大模型（Large Language Model，也叫大语言模型，简称LLM）。\n除了语言大模型之外，还有视觉大模型、多模态大模型等。现在，包括所有类别在内的大模型合集，被称为广义的大模型。而语言大模型，被称为狭义的大模型。\n从本质来说，大模型，是包含超大规模参数（通常在十亿个以上）的神经网络模型。\n之前给大家科普人工智能的时候，介绍过，神经网络是人工智能领域目前最基础的计算模型。它通过模拟大脑中神经元的连接方式，能够从输入数据中学习并生成有用的输出。\n这是一个全连接神经网络（每层神经元与下一层的所有神经元都有连接），包括1个输入层，N个隐藏层，1个输出层。\n大名鼎鼎的卷积神经网络（CNN）、循环神经网络（RNN）、长短时记忆网络（LSTM）以及transformer架构，都属于神经网络模型。\n目前，业界大部分的大模型，都采用了transformer架构。\n刚才提到，大模型包含了超大规模参数。 实际上，大模型的“大”，不仅是参数规模大，还包括：架构规模大、训练数据大、算力需求大。\n以OpenAI公司的GPT-3为例。这个大模型的隐藏层一共有96层，每层的神经元数量达到2048个。\n整个架构的规模就很大（我可画不出来），神经元节点数量很多。\n大模型的参数数量和神经元节点数有一定的关系。简单来说，神经元节点数越多，参数也就越多。例如，GPT-3的参数数量，大约是1750亿。\n大模型的训练数据，也是非常庞大的。\n同样以GPT-3为例，采用了45TB的文本数据进行训练。即便是清洗之后，也有570GB。具体来说，包括CC数据集（4千亿词）+WebText2（190亿词）+BookCorpus（670亿词）+维基百科（30亿词），绝对堪称海量。\n最后是算力需求。\n这个大家应该都听说过，训练大模型，需要大量的GPU算卡资源。而且，每次训练，都需要很长的时间。\n根据公开的数据显示，训练GPT-3大约需要3640PFLOP·天（PetaFLOP·Days）。如果采用512张英伟达的A100 GPU（单卡算力195 TFLOPS），大约需要1个月的时间。训练过程中，有时候还会出现中断，实际时间会更长。\n总而言之，大模型就是一个虚拟的庞然大物，架构复杂、参数庞大、依赖海量数据，且非常烧钱。\n相比之下，参数较少（百万级以下）、层数较浅的模型，是小模型。小模型具有轻量级、高效率、易于部署等优点，适用于数据量较小、计算资源有限的垂直领域场景。\n为了帮助初学者快速跟上大模型的趋势，今天给大家分享一份由字节内部培训的《大模型落地应用案例集》，它是一本详细解析大模型在各领域应用现状和发展趋势的书籍。该书通过收集和整理大量的实际应用案例，为我们提供了大模型在实际业务中应用的宝贵参考，它收录了52个优秀的大模型落地应用案例。这些案例覆盖了金融、医疗、教育、交通、制造等众多领域，充分展示了大模型技术在各个行业中的广泛应用前景。\n总的来说无论是对于大模型技术的研究者，还是对于希望了解大模型技术在实际业务中\n 如何应用的业内人士，都具有很高的参考价值\n这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【 保证100%免费 】\n话不多说，直接来展示：\n第一章、通用大模型\n基于人工智能大模型技术的开放平台\n可控可信的私域知识问答系统\nMiniMax 大模型医疗咨询解决方案\n言犀基础大模型\n国内首款可私有化部署的企业级数据分析智能体——TableAgent\n九章云极知识管家打造企业专属大模型智能底座\n“Pixeling 千象”\n书生筑梦视频生成大模型\n书生浦语开源大模型\n百川大模型在娱乐领域的应用\nAnimateDiff ：一项基于个性化文生图模型扩展后的视频生成框架\n通义千问 2.0 在企业场景的应用\n昆仑万维“天工”大模型\n第二章、垂类大模型\n梧桐·招聘 - 基于百度智能云千帆大模型平台的智能招聘系统 面向游戏行业的图像内容生成式大模型 中公网校：小鹿老师，为年轻人创造更多就业与成长机会 新华妙笔 AI 小布助手 ChatDD 新一代对话式药物研发助手 大模型数据分析智能助理 DeepInsight Copilot 单晶炉自动化工艺识别多模态大模型 基于 NDAI 大模型的政务元宇宙平台 慧政大模型——面向政务服务垂直大模型 基于循道政务大模型的免申即享系统示范应用 东方财富自研金融大模型 基于大模型的信息结构化抽取方法 天津金城银行金融大模型示范应用 文修大模型助力中文校对提质增效 新型金融风险防范可信金融大模型 信阳市智慧工业平台 遥感大模型在农业信贷场景的应用 中国金茂人工智能大模型企业内部场景应用 中山大学附属医院智慧医院项目 阿斯利康：基于学术文献溯源的药品不良反应报告生成助手 基于知识图谱和大语言模型的制造业数字化转型平台 东方翼风大模型 智己汽车：用大模型打造智能时代出行变革者 基于山下话童大模型的贷后催收示范应用 海淀区一网统管接诉即办工程项目 风乌气象大模型 基于大模型的智能培训 面向围手术期的医专大模型研究及其落地应用 通过大语言模型与材料领域技术文件集合对原材料质保书进行智能审查 智能投顾助手——光子·善策\n第三章、垂类大模型\n支小助 - 大模型金融专家智能助理 AGI 云上模型服务平台 蚂蚁集团大模型数据高质量供给平台 基于大模型的壹沓数字员工超自动化平台 云原生大模型知识库平台 众调科技：营销 AI 培训产品 信息安全大模型平台 全自研 AI 整合平台“HeyLisa”\n这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【 保证100%免费 】"
  },
  {
    "title": "【师训】省师训平台项目之“三单”实验：基于作业优化促进深度学习变革培训侧记-温州大学继续教育学院、浙江省干部教育培训基地、干训基地...",
    "page_body": "七月骄阳似火，酷暑难耐，却挡不住学员们学习的热情。2023年7月4日，来自温州市不同学校的39名教师集中我院，开始为期12天的“三单”实验90学时培训。\n第一讲：《大国良师：育人为本，研究为重》\n7月4日上午，张作仁教授作《大国良师：育人为本，研究为重》主题培训。他强调了良师的素质和要求，重点强调做一名良师，要备好每堂课、上好每堂课和培养好每一位孩子。他还讲述了自己的成长经历，并分享了自己教学生涯中三个创新课堂案例，提出教师要立足课堂，做真实有品质研究的观点。\n下午的活动中，张作仁教授引导学员们对于中小学课堂变革的问题展开讨论，主要围绕课堂教学的不满意以及期待未来课堂教学的发展方向展开，同时也提及了区域、学校和学科课堂教学变革项目的实施与教学改进觉醒和坚守的问题。学员们在小组中积极交流自己的观点和研究成果，共同探讨如何提升教学质量和转变学教方式。\n第二讲：《“学为中心”课堂变革的理论架构与项目设计》\n7月5日上午，张作仁教授对基于“三单”的“学为中心”课堂的整体理论架构做了详尽的梳理和阐释，为学员们梳理了“学为中心”课堂变革的理论架构，阐明了“学为中心”课堂四大模型的丰富内涵及相互关系，论证并展示了基于“三单”的“学为中心”课堂的实现可能，充分激发了学员们深入学习“三单”、变革课堂教学的决心和信心。\n下午的学习围绕《“三单”实验项目设计》展开，张作仁教授从目标任务、实践载体、行动策略、教研机制四方面详细介绍“三单”实验的内容、对象、思路和方法，帮学员们厘清“三单”实验做什么、怎么做、怎么保证把研究持续做好等关键问题。\n第三讲：《三单学习手册：高结构学习任务与支架》\n7月6日上午，张作仁教授带来精彩讲座《三单学习手册：高结构学习任务与支架》。张教授从教学目标到学习目标，以学定教的思维转型，高结构学习任务支架，“三单”学习手册与结构要素，“三单”学习逆向设计 ，我们的大作业观等方面分享了他的理论见解和实践经验。\n下午，项思思老师的讲座《基于优课资源的高结构任务与支架设计》承接张作仁教授的理论，她充分利用优课资源——薛特执教的《火烧云》，加以自己对文本的深刻解读，精心设计备单，每一个环节的高结构任务和支架的由来她都娓娓道来，层层剖析，让学员对如何设计三单有了更清晰的认识。\n第四讲：《“五环”教研流程与操作要略》\n7月7日，张作仁教授为学员作《五环教研：基于协作共享的备课常规优化实践》的主题讲座。张教授从教师日常备课困惑谈起，介绍了“五环教研”的流程，着重讲解了备单和说辩单两个环节。在说辩单过程中，张教授利用三单课例，让学员在观摩的过程中不断强化三单要素，在修改前后的对比和辨析中，明确任务要具体，让学生更有效地展开自主学习，从素养导向实现教学设计。\n第五讲：《指向备课常规优化的教研项目体验》\n7月8日上午，张作仁教授从集体备单、说辩单、试观单、调议单、磨建单五个方面为大家详细地讲解了“五环”教研，他指出要利用“五环”教研用表，聚焦作业单（三单）等学习任务支架设计与预设，指向备课新常规建设，从而助推教师真正从备“教”到备“学”的转变。\n实践是检验真理的唯一标准。在张教授高屋建瓴的理论引领下，下午学员们根据学科分为不同小组，对五环教研中的三单的设计进行实操练习与头脑风暴。全员参与，积极讨论，智慧共享，在反复的修改中呈现出最好的三单成果。经过1个小时的头脑风暴，各小组初步设计好了三单。每个小组派代表与大家进行分享。\n第六讲：《指向备课常规优化的教研项目体验》《实践性作业设计策略》\n7月9日上午，初中数学组和职高组根据前期小组内讨论的三单内容进行了分享。乐清市虹桥镇实验中学侯旭奋老师代表初中数学组进行汇报，同组的姚嘉平老师进行辩单。永嘉县第二职业学校吴恩慈老师代表职高组对《我的营销人生》这一课进行了三单分享。\n下午，瑞安市红旗实验小学金燕燕老师为学员们带来了《实践性作业设计策略》的讲座。金老师首先结合自身经历分享了自己与三单实验的故事。金老师从作业的思想及内涵展开阐述，提出实施“做学融合”实践性作业的必要性。金老师将实践性作业划分为四大类：阅读拓展类、观察体验类、想象创造类、动手操作类。她结合具体课例分别对每类实践性作业进行了细致讲解，让大家对实践性作业有了更深入的了解。\n第七讲：《“四招”教研流程与操作要略》《“六学”教研流程与操作要略》\n7月10日上午，张作仁教授为学员详细阐述“四招”教研流程与操作要略，即“一日一寻招、一周一辩招、一月一晒招、一季一创招”的活动组织策略。四招教研其实就是让老师学别人的招来完善自己的教。“四招”教研还基于儿童特点的低控制学习过程指导，引领教师关注学习全程，积极反思、发现低控制教学策略，实现“学为中心”动态诊学、导学、拓学，让“先诊后教、以学定教、教为学服务”理念真正内化为教师教学行为。\n下午，张作仁教授为学员详细阐述“六学”教研流程与操作要略，通过对学生学习行为的观察，研究、总结该怎样学最有效的一套教研机制。六学教研聚焦“自学、问学、互学、辩学、思学、研学”六种学习状态来助推学生由低阶思维到高阶思维的发展，满足学生高品质体验学习的需求。这种以生为本的全新教研机制，让学生化被动学习为主动学习，促进了学生核心素养的养成。\n第八讲：《“三评”教研流程与操作要略》《“三单”教学课例研究与报告撰写》\n7月11日上午，张作仁教授分享了《“三评”教研流程与操作要略》。张教授从“三评”教研的概念出发，提出了教研实践要素。随后，学员们按照张教授的要求，分组设计了《“三评”课堂观察评估反思表》，交流分享了自己的设计思路和想法。\n下午的学习中，张作仁教授给大家分享了《“三单”实验共享计划》、《“三单”实验研究历程与成果推广策略》，大家了解了永昌五小“五环”备课，天河二小“四招”教研的案例。最后张教授为大家介绍了“学为中心”课堂变革中项目的实施建议，列举了教学课例研究、报告撰写的方向和方法。\n第九讲：《随堂化作业设计策略》《 “三单”实验项目亮点与困惑问题》\n7月12日上午，乐清虹桥实验中学的侯旭奋老师作《随堂化作业设计策略》的案例教学。她以张作仁教授有关作业的论述，详细解读作业，随后通过诊学、导学、拓学三个方面详尽解析了随堂化作业设计。最后以各学科的实际案例介绍了随堂化作业运用策略，用鲜活的学生差异讲解了随堂化作业管理，过程化互动生成多样化个性评价。\n下午的活动由张作仁教授就整个“三单”实验项目做了最后的总结与答疑，并与学员就这次研修活动进行了感悟互动。优秀学员代表：祝圣楠、周金晶、张婵、陈文怡、苗丽娟、吴恩慈、郑俊博、侯旭奋等十余人发表了本次培训感悟。\n第十讲：《项目式作业设计策略》《助学作业单设计策略》\n7月13日上午，平阳县鳌江镇第四中学的吴宇洁老师主讲《项目化作业设计策略》。这次讲座旨在探讨如何将项目式作业与课堂学习结合起来，以促进深度学习并优化作业设计。吴老师还强调了在整个学习过程中如何贯彻优化的理念，包括整学单、导学单和拓学单等环节。吴老师通过三个典型案例，向与会学员阐述了项目式作业设计的策略。\n下午，温州市第五十一中学的彭小平老师进行了一场关于《助学作业单设计策略》的讲座。她提出了一些关键策略来指导教师们设计有效的助学作业单。首先，明确学习目标十分重要，学习目标应该具体、可观察、可评价和及时可操作。其次，助学作业单需要与知识单元、情感单元和行动单元密切结合。最后，及时调整和反馈也是至关重要的。教师们应该在学生完成作业后及时评价和反馈，根据学生的需求进行适当的调整和指导。\n第十一讲：《“三单”实验项目推进策略》\n7月14日上午，福鼎市教师进修学校的许可雄老师带来《内驱外联-“三单实验”项目区域推进策略》的专题讲座。许老师从福鼎教研的现状出发，分析了县域教研存在的主要问题，思索教研的转型方式。在2020年11月开始探索张作仁教授的“三单实验”项目，引领教师走进真实高品质的课堂。许老师具体从身份认同定任务，明确“谁来做”的对象；项目打包求合作，理清“做什么”的内容；活动策划系列化，学会“怎么做”的方法；激励评价有保障，实现“做更好”的目标四个方面与大家倾情分享三单实验如何推进。\n下午，衢州市巨化第三小学的徐艳校长带来专题报告《指向未来教育课堂变革整体解决方案——“三单”实验成果的学校推广与应用》。徐校长从我的“三单”实验故事，“三单“实验推进策略，“三单”实验主要成果，“三单”实验主要成效及“三单”实验共享计划等几个方面展开阐述。“三单实验”助力教学，为学校常态课堂教学改革提供整体解决方案，让教学乘风破浪，收获颇丰。\n晚上，文成县教育研究培训院的初中语文教研员周小云老师带来专题报告《233教研：赋能区域联盟共同体成长——谈文成县初中语文“三单”实验项目学科推进策略》。周老师分析了文成县校本教研、区域教研存在的主要问题，思索优化教研机制、促进课堂变革的转型方式，系统阐述了“3+1”寻招，“三课”晒招，“三单”创招，“三赛”亮招四大实践路径，以此优化制度建设、备课常规、学习常规，及效能评估。\n通过培训，参训教师纷纷表示，作为教师，要有课改意识、自我反思和改进意识。教学路上，砥砺前行，笃行致远。正如张教授所说，期待每一位老师都能带着“让学习成为一种享受”这个美好的愿景，继续走在教育的路上。\n 上一条： 【师训】学“食”培训 教“育”重任——我院举办省师训平台项目“校园食育师实操课程”培训班\n 下一条： 【师训】真学深悟 奋楫笃行——我院举办新疆拜城县初中理化生及小学科学实验员培训班"
  },
  {
    "title": "【Python深度学习系列】使用Docker和TensorFlow Serving 部署TensorFlow模型（案例+源码）-CSDN博客",
    "page_body": "这是我的 第414篇 原创文章。\n一、引言\n 本项目旨在引导你完成创建一个简单的 TensorFlow 模型、导出模型并使用 Docker 和 TensorFlow Serving 进行服务的过程。TensorFlow 是一个开源的机器学习框架，而 TensorFlow Serving 是一个灵活且高性能的机器学习模型服务系统。Docker 容器使得打包和部署这些模型变得简单且一致。通过完成本项目，你将了解如何在 TensorFlow 中设置一个基本的机器学习模型，将其导出以供服务，并在 Docker 容器中使用 TensorFlow Serving 进行部署。完成本项目后，你将能够：\n在 TensorFlow 中设置一个基本的机器学习模型\n导出 TensorFlow 模型以供服务\n使用 Docker 和 TensorFlow Serving 部署 TensorFlow 模型\n向部署的模型发送预测请求并观察结果\n二、实现过程\n2.1 安装依赖\n在开始之前，你需要在环境中安装 TensorFlow。此外，你还需要从 Docker Hub 拉取 TensorFlow Serving 镜像，以便在容器化环境中为模型提供服务。请在终端中执行以下命令。\n## 安装 TensorFlow\npip install tensorflow== 2.14 .0\n## 将 numpy 降级到 1.26.4 以避免与 TensorFlow 的兼容性问题\npip install numpy== 1.26 .4\nAI写代码 python\n运行\n拉取 TensorFlow Serving Docker 镜像：\n## 从 Docker Hub 拉取 TensorFlow Serving 镜像\ndocker pull tensorflow/serving\nAI写代码 python\n运行\nTensorFlow Serving 是专门为在生产环境中服务机器学习模型而设计的。使用 Docker 可以确保 TensorFlow Serving 在一个隔离的环境中运行，并且所有依赖项都已满足，从而避免与机器上其他软件的冲突。\n2.2 创建并导出模型\n在这一步中，你将定义一个简单的 TensorFlow 模型，该模型执行一个基本的算术操作：将输入乘以 0.5 然后加上 2。定义模型后，你会将其导出为 TensorFlow Serving 可以使用的格式。在  ~/project/half_plus_two.py  中创建并导出模型：\n## 导入 TensorFlow\nimport  tensorflow  as  tf\n## 定义一个简单的 Sequential 模型\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(units= 1 , input_shape=[ 1 ], use_bias= True )\n])\n## 设置权重以实现“乘以 0.5 并加上 2”的功能\nweights = [tf.constant([[ 0.5 ]]), tf.constant([ 2.0 ])]\nmodel.set_weights(weights)\n## 编译模型（即使不训练也需要）\nmodel. compile (optimizer= 'sgd' , loss= 'mean_squared_error' )\n## 将模型导出为 SavedModel\n# export_path = './saved_model_half_plus_two/1'\n# tf.saved_model.save(model, export_path)\nmodel.export( './saved_model_half_plus_two/1' )\nAI写代码 python\n运行\n这一步涉及定义一个 TensorFlow 模型，该模型对其输入执行一个简单的操作：乘以 0.5 并加上 2。然后，模型被导出为适合服务的格式。\n该模型使用 TensorFlow 的 Keras API 定义，Keras 是一个用于构建和训练深度学习模型的高级 API。模型由一个全连接神经网络层（Dense 层）组成。\n模型的权重被手动设置为实现所需操作（乘以 0.5 并加上 2）。\n尽管此模型不会进一步训练，但仍需编译以完成其结构，这是 TensorFlow 中的一个必要步骤。\n最后，模型以 TensorFlow SavedModel 格式保存，该格式是一个包含 protobuf 文件和 TensorFlow 检查点（包含模型权重）的目录。TensorFlow Serving 需要此格式来部署模型。\n要导出模型，请在终端中运行脚本：\npython half_plus_two.py\nAI写代码 python\n运行\n模型保存在  ~/project/saved_model_half_plus_two目录中。文件结构如下：\n2.3 使用 Docker 和 TensorFlow Serving 服务模型\n导出模型后，下一步是在 Docker 容器中使用 TensorFlow Serving 来服务模型。这使得你的模型可以通过网络访问，并能够响应预测请求。\n在终端中使用 Docker 服务模型：\n## 在 Docker 容器中使用 TensorFlow Serving 服务模型\ndocker run -t --rm -p  9500 : 8500  -p  9501 : 8501  -v  \"/home/wenqiang/project/saved_model_half_plus_two:/models/half_plus_two\"  -e MODEL_NAME=half_plus_two tensorflow/serving\nAI写代码 python\n运行\n在这一步中，导出的模型在 Docker 容器中使用 TensorFlow Serving 进行服务。Docker run 命令启动了一个 TensorFlow Serving 实例，并使模型可用于推理请求。\n-p\n 标志将 Docker 容器的端口映射到你的主机，允许你从本地机器向 TensorFlow Serving 模型服务器发送请求。\n-v\n 标志将主机上的卷挂载到 Docker 容器中，使导出的模型对 TensorFlow Serving 可用。\n-e MODEL_NAME\n 环境变量告诉 TensorFlow Serving 要服务的模型名称。\n这种设置封装了模型服务环境，确保无论部署在哪里，它都能一致地运行。\n2.4 向模型发送预测请求\n最后，你将通过发送预测请求来测试部署的模型。该请求将要求模型对其输入值应用其逻辑（乘以 0.5 并加上 2）。在另一个新终端中发送预测请求：\n## 向 TensorFlow Serving 容器发送预测请求\ncurl -X POST http://localhost: 9501 /v1/models/half_plus_two:predict -d  '{\"signature_name\":\"serving_default\",\"instances\":[[1.0], [2.0], [5.0]]}'\nAI写代码 python\n运行\n输出：\n这最后一步涉及通过发送 HTTP POST 请求来测试部署的模型。该请求包含一个 JSON 负载，其中包含需要预测的实例。\ncurl\n 命令用于向 TensorFlow Serving 服务器发送 POST 请求。URL 指定了模型和预测 API 端点。\n-d\n标志以 JSON 格式提供预测请求的数据。 signature_name  键指定要使用的服务签名，这是一种告诉 TensorFlow Serving 执行哪个计算图的方式。 instances  键包含预测的输入数据。\n服务器的响应包括模型对提供的输入实例所做的预测，表明模型已成功部署并正在提供预测。\n作者简介：\n读研期间发表6篇SCI数据挖掘相关论文，现在某研究院从事数据算法相关科研工作，结合自身科研实践经历不定期分享关于Python、机器学习、深度学习、人工智能系列基础知识与应用案例。致力于只做原创，以最简单的方式理解和学习，关注我一起交流成长。 需要数据集和源码的小伙伴可以关注底部公众号添加作者微信。"
  },
  {
    "title": "视频微课介绍课件-人人文库",
    "page_body": "上传人：1*** IP属地：河南 上传时间：2025-07-29 格式：PPTX 页数：27 大小：8.76MB 积分：5.99\n文档描述\n视频微课介绍PPT课件单击此处添加副标题有限公司汇报人：xx目录01视频微课概念02视频微课制作03视频微课内容设计04视频微课教学应用05视频微课案例分析06视频微课发展趋势视频微课概念章节副标题01微课定义微课通常时长较短，一般为5-10分钟，便于学生集中注意力，快速掌握知识点。微课的时长特点微课旨在解决特定的学习问题或主题，强调针对性和高效性，使学习更加聚焦。微课的教学目标微课往往包含互动环节，如在线测试或讨论，以提高学生的参与度和学习兴趣。微课的互动性微课特点微课通常时长5-10分钟，内容集中，便于学生快速掌握核心知识点。短小精悍的内容结构学生可以随时回看微课视频，反复学习难以理解的部分，巩固记忆。便于重复学习微课常包含问答、投票等互动环节，提高学生的参与度和学习兴趣。互动性强微课优势灵活性高微课可以随时随地学习，适应不同学习者的时间安排，提高学习效率。针对性强微课内容精炼，专注于特定主题，便于学习者快速掌握所需知识或技能。互动性好微课平台通常提供互动功能，如讨论区和即时反馈，增强学习体验和效果。视频微课制作章节副标题02制作流程明确视频微课的教学目的和预期学习成果，确保内容与目标紧密对应。01确定教学目标撰写详细的课程脚本，设计课程结构，包括引入、讲解、互动和总结等环节。02编写脚本和设计课程选择合适的录制设备和软件，进行视频拍摄，确保画面和声音质量清晰。03录制视频对录制的视频进行剪辑，添加动画、字幕、过渡效果等，增强教学效果。04后期编辑与制作将制作完成的视频微课发布到平台，并收集用户反馈，用于持续改进课程内容。05发布与反馈制作工具使用高质量的摄像机或智能手机拍摄视频，确保画面清晰稳定，提升微课的专业度。视频拍摄设备利用AdobePremiere、FinalCutPro等专业视频编辑软件进行剪辑，添加字幕、特效，优化视频内容。视频编辑软件采用专业的麦克风和录音软件录制清晰的音频，避免背景噪音，保证声音质量。音频录制工具使用Camtasia、OBSStudio等屏幕录制软件捕捉电脑屏幕活动，适用于制作软件操作类微课。屏幕录制工具01020304制作技巧选择高质量的摄像头和麦克风，确保视频和音频清晰，提升微课的专业度。选择合适的录制设备合理使用图表、动画和颜色，增强信息的传达效果，使学习内容更加生动有趣。运用有效的视觉元素编写简洁明了的脚本，确保内容精炼，避免冗长，使学习者更容易集中注意力。编写紧凑的脚本通过剪辑软件对视频进行剪辑，添加必要的过渡效果和字幕，确保最终呈现的微课流畅且易于理解。后期剪辑与调整视频微课内容设计章节副标题03内容选择选择与教学目标紧密相关的内容，确保微课内容能够有效支持学习者达成预定的学习成果。确定教学目标01深入了解目标学习者的需求和背景，选择能够引起他们兴趣并解决实际问题的内容。分析学习者需求02利用图表、动画、视频等多媒体元素丰富微课内容，提高学习者的参与度和理解力。整合多媒体资源03内容组织将课程内容划分为若干模块，每个模块集中讲解一个主题，便于学生理解和记忆。模块化教学设计结合实际案例进行教学，使抽象概念具体化，帮助学生更好地理解和应用知识。案例分析融入在视频微课中穿插问答、小测验等互动环节，提高学生的参与度和学习兴趣。互动环节设置内容呈现通过集成问答、投票等互动环节，提高学生的参与度和学习兴趣。互动式学习元素使用图表、动画和高亮标记等视觉辅助材料，帮助学生更好地理解和记忆课程内容。视觉辅助材料结合实际案例，展示理论知识在现实中的应用，增强学习的实践性和深度。案例研究视频微课教学应用章节副标题04教学模式翻转课堂模式下，学生在家观看视频微课自学，课堂上进行讨论和实践，提高学习效率。翻转课堂结合线上视频微课与线下教学，学生在教师指导下灵活运用不同资源，增强学习体验。混合式学习视频微课支持学生根据自己的学习节奏和兴趣选择课程，实现个性化学习。个性化学习路径学习效果提高学习兴趣01视频微课通过动画和互动元素吸引学生，有效提升他们的学习兴趣和参与度。增强记忆与理解02微课的短时长和集中讲解有助于学生更好地记忆和理解知识点，提高学习效率。促进自主学习03学生可以根据自己的学习节奏反复观看视频微课，培养自主学习和解决问题的能力。教学反馈通过视频微课平台的数据统计功能，教师可以实时监控学生的参与度，了解学习活跃情况。学生参与度分析利用视频微课平台进行在线测试，教师能够快速评估学生的学习效果，并及时调整教学策略。在线测试与评估学生通过视频微课提交作业，教师可在线批改并提供反馈，提高教学互动性和效率。作业提交与批改视频微课案例分析章节副标题05成功案例互动式学习平台KhanAcademy通过视频微课提供互动式学习，帮助全球数百万学生掌握数学和科学知识。0102企业培训应用LinkedInLearning利用视频微课为职场人士提供专业技能提升，成为企业培训的热门选择。03个性化学习路径Coursera与顶尖大学合作，提供个性化视频微课学习路径，满足不同学习者的需求。04语言学习工具Duolingo通过游戏化的视频微课帮助用户学习新语言，成为语言学习领域的一匹黑马。教学策略通过视频微课中的实时问答和讨论区，增强学生的参与感和学习兴趣。互动式学习0102根据学生能力差异，设计不同难度级别的微课内容，满足个性化学习需求。分层教学03利用视频微课创建真实或虚拟的情境，让学生在模拟环境中学习和应用知识。情境模拟效果评估统计视频微课中的互动环节，如讨论、测验等，评估学习者的参与度和活跃程度。对比实施视频微课前后学生的学习成绩，分析微课对学习成效的影响。通过问卷调查和访谈收集学习者对视频微课的反馈，评估其满意度和改进建议。学习者反馈分析学习成效对比互动参与度评估视频微课发展趋势章节副标题06技术革新利用AI技术，视频微课可以实现个性化推荐和智能辅导，提升学习效率。01人工智能在微课中的应用AR和VR技术的融入，为视频微课带来沉浸式学习体验，增强学习的互动性和趣味性。02增强现实与虚拟现实技术通过云平台存储和大数据分析，视频微课能够实现资源的高效共享和学习行为的精准分析。03云平台和大数据分析教育融合视频微课通过整合不同学科内容，促进学生全面发展，如STEM教育的兴起。跨学科课程设计视频微课支持个性化学习，学生可以根据自己的学习节奏和兴趣选择课程，实现定制化教育。个性化学习路径利用AR/VR等技术，视频微课提供沉浸式学习体验，增强学生学习兴趣和效果。技术与教学的结合010203市场前景随着AI"
  },
  {
    "title": "不要搞混，大模型和大语言模型的核心区别，看这篇就够了-今日头条",
    "page_body": "今年人工智能的话题铺天盖地，左边GPT-5物理奥赛完胜人类，右边Gemini3.0已经内测，据说可一键制作网页，AI发展速度远超我们想象，当我们阅读海量文章时，是否也会偶尔迷惑一下，有时看到新闻说的是大模型，有的文章写的却是大语言模型，二者到底有什么区别？\n今天实验室的小编好好帮你解答一下。\n有很多人都把大模型等同于大语言模型，其实呢二者差异显著。\n比如我们用元宝总结问题，用豆包生成文案，能有来有回的进行对话交互，就以为它具备了大模型的全部能力，其实并不是。\n大语言模型（LLM）严格意义上来说只是大模型（Foundation Model）家族里的“语言天才”，而真正的大模型不但能写，而且能听、能看、能动手，属于全能型选手。\n一、一句话说透二者区别\n简单点说，大语言模型属于大模型中的一种类型，比如SUV是汽车的一种，二者的核心边界是“处理对象”和“能力范围”。\n大模型，多模态的智能工具箱\n大模型的参数有可能达到万亿级别，经过海量数据训练，相当于一个超强的人类大脑，就像我们单位里的全能型人才，不仅能听懂文字，还能看懂图片，听懂语音，分析数据，甚至自动控制Iot设备。\n它就像一个百宝箱，既能和你聊论文思路（语言能力），又能识别电路图缺陷（视觉能力），还能操控工业机器人校准零件（执行能力），比如谷歌的 Gemini 2.5 Pro 、我们国内的阿里通义等。\n而大语言模型呢，属于家族里的翻译官，精通于语言理解。\n大语言模型更侧重于自然语言的理解和生成，自然语言理解，简单来说就是侧重人类说的对话，能够根据人类输入的文字，分析对象要表达的意思，从而给出答案。\n它的世界里只有文字符号，无论是写文案、解数学题还是生成代码，本质都是在学习人类语言规律后进行文字输出。比如你让它写一篇产品推广文，它能根据你的要求，生成文案；让它解释量子力学原理，它能把专业术语转化为通俗表达。比如ChatGPT、我们国内的豆包等，但是现在大部分大语言模型也不单单只处理文字，更多的是朝向多模态能力发展，这可能也是未来AI的重要发展方向。\n二、从三个维度来看二者差异\n说了很多的定义，可能还没有说透彻，下面我结合真实场景，从2个维度对二者进行对比。\n1、 能力边界-全能人才VS语言专才\n大模型完全实现了多模态融合，比如中科院神经蠕虫，脑机接口配套模型，能同时处理神经电信号（生物数据）和语音指令（语言数据），帮瘫痪患者通过意念控制机械臂。部分国产工业大模型，能一边看监控画面，识别钢水温度（视觉），一边读工艺手册调整参数（文本），把能耗降低。\n而大语言模型则主要围绕语言进行任务处理，比如智谱 GLM4.6虽然代码能力极强，能生成Python等代码、解析Java框架逻辑，但它本质是把代码当成特殊语言来处理；一些科技公司发布的大语言模型，支持100万字上下文，又能通读整本书写摘要，但给它工业图纸，让他给出设计缺陷时，就不是它的处理范畴了。\n2、 应用场景-垂直深耕VS全域覆盖\n应用场景的差异最能体现两者的定位，大语言模型侧重点在语言文字相关场景\n内容生产： 公众号文案、学术论文初稿、生成代码\n智能交互： 客服机器人、语音助手、信息咨询\n文本处理： 合同审核、简历筛选、文献总结\n大模型则在通过多模态的方式覆盖全场景\n医疗健康： 分析CT影像（视觉）和病历文本，辅助癌症诊断\n自动驾驶： 融合摄像头画面、雷达数据和交通规则文本，实现路径规划\n实体交互： 机器人大模型处理视觉信号（比如识别楼梯）和听取运动指令，完成爬楼梯、前进等动作。\n通过下面这个图，可能更清晰的明白二者区别\n最后\n从技术发展趋势看，两者正在走向融合，大语言模型不断加入多模态能力，大模型也越来越依赖语言能力作为交互入口。\n但无论如何进化，核心区别始终存在，一个是用语言连接世界，而另一个则是用智能改造世界。\n#大模型# #科技# #人工智能# \n来源：湖北日报 功能性饮料是不少人 熬夜加班、提神醒脑的“续命神器” 但大家有没有想过 如果把这“神器”当水喝可能会对身体造成危害喝了6瓶功能性饮料后男子失去意识近日 为了在晚高峰送餐时保持清醒 深圳36岁的外卖员胡先生 在短时间内连续喝下6瓶功能性饮料第二天上午，家人发现他躺倒\n发言人陈斌华表示，世界上只有一个中国，台湾是中国的一部分。日本领导人在国会公然发表的涉台恶劣言论严重违背一个中国原则，粗暴干涉中国内政，我们对此强烈不满、坚决反对。\n今天（11月12日），郭德纲发文悼念：惊闻京剧名家姚宗儒先生去世，令人悲痛。九十年代曾向先生问艺，传授徐荣奎先生演法的《打銮驾》，及《宝象国》等剧目。先生千古，艺术永存。\n近期贵金属期货再度一路飙涨。Wind数据显示，隔夜市场，现货黄金大涨近3%触及4120美元/盎司关口。截止11月11日中午，伦敦金现已攀上4140美元/盎司。国际金价重回4100美元之后，银行再跟进调整积存金相关业务门槛。\n11月10日，一段“儿子殴打93岁母亲”的视频在网上流传。11月12日，江苏省常州市公安局武进分局发布警情通报：11月10日18时15分许，我局嘉泽派出所接报一起殴打他人警情。民警立即赶赴现场处置。经查，当晚，杨某中（男，55岁）与母亲（92岁）因琐事发生口角，并动手实施殴打。"
  },
  {
    "title": "2022年商业模式研究方法和应用工具研究报告-今日头条",
    "page_body": "第一章 商业模式基本介绍\n商业模式，是对一个组织如何行使其功能的描述，包含了大量的商业元素及它们之间的关系，并能显示一个公司的价值所在。基于不同的研究视角，商业模式具有多种不同的理解，但简言之，商业模式就是关于“做什么”，“如何做”以及“怎样赚钱”的问题。\n商业模式涵盖了在创造价值和传递价值过程中， 商业战略和运营管理的所有核心要素。从商业战略层面分析商业模式， 主要体现在商业模式对提升企业竞争优势的作用；从运营管理层面分析商业模式， 体现在商业模式如何优化运营流程、提升生产率。商业模式的构成要素包括市场提供、企业、客户和盈利模式4个界面。市场提供即价值主张， 描述的是企业提供产品和服务的内在价值；企业界面包括商业伙伴、创造价值所需的资源和关键业务活动；客户界面包括客户细分、传递价值依赖的渠道和客户关系；盈利模式包括保证商业经济可行性的成本结构和收入流 。\n图 商业模式构成要素\n资料来源：资产信息网 千际投行\n第二章 商业模式分类\n2.1 诱钓模式\n诱钓模式基本前提是把产品或者服务拆分成两部分，一部分是可以长期使用的，另一部分则是要经常更换的。诱钓模式分为两种，一种是“实体产品+配件（耗材）或服务”的模式，另一种是“实体产品+软件平台”的模式。\n“实体产品+配件（耗材）或服务”形式一般是封闭的，自己产品对应自己的耗材或者配件，别人进不来。当然，这种做法建立在对自身产品、技术、服务和品牌绝对自信的基础上。这种形式多为产品便宜，耗材或者配件稍贵。\n“实体产品+软件平台”形式出现在网络时代，一般为开放式。在网络时代，开放式的平台（软件平台）与实体产品相互配合是一大特征，并与先前的封闭式形式有所不同。\n图 诱钓模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n2.2 低价优质模式\n低价格往往依靠的是强大的技术生产能力、工艺的革新、高效率的管理等，这能够构成竞争壁垒，而不是单纯的低价。\n低价优质模式往往具有破坏性，能够开辟竞争中的“蓝海”。但有些行业可能不适合，比如奢侈品行业。\n图 低价优质模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n2.3 垂直整合模式\n垂直整合模式既有对零部件供应的垂直整合，也有对相邻业务模式的整合。而对于后一种，现在有一个时髦的说法，叫“生态链”。\n垂直整合模式的优点在于当终端业务量足够大的时候，既可以满足自己发展，又可以供应全球。\n垂直整合模式的风险在于链条长、投资大，子公司在整个业务链条中容易对母公司终端形成依赖。一旦母公司终端产品业务下滑，整个子公司的业务很有可能受连带影响。另外，受到长链条的影响，公司的转型和变革会更加困难。\n图 垂直整合模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n2.4 连锁模式\n连锁模式是一个能在消费品、餐饮、服务等领域扩大规模、降低采购（生产）成本、提升品牌形象的有力武器。现有技术手段的发展对于连锁模式的品质控制和标准化管理有促进作用。互联网、视频系统、信息系统等都成为远距离管理的利器，可以与各家门店实时沟通甚至实现监控。连锁模式可以分为直营、特许加盟和准连锁三种类型。其中准连锁只是品牌统一，各自为政。\n图 连锁模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n连锁复制的前提是有优质而成功的产品，如果第一家店都不能成功，那就没有复制的必要；需要打造标准化作业流程，以提高连锁复制的效率；还需要强有力的管理，以保证连锁品质，很多公司采用巡查制度来确保连锁标准得以落实。\n直营模式能够实现统一管理、统一采购、统一标准，是连锁模式中能较好保持品质的方式。但这种模式对于资金和管理有更高的要求，发展速度和规模会受到限制。\n加盟模式能够实现快速扩张，并且能够收取加盟费。这种模式被各行各业纷纷采用，但加盟店的管理却是一个不大不小的难题。\n2.5 SPA模式\nSPA模式能够发挥设计、生产和销售的联动效应，通过出色的设计能力吸引消费者，通过直营连锁和强大的终端销售能力实现收益，并建立品牌知名度。\n图 SPA模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\nSPA模式基本定位于低价时尚。SPA模式基本上会通过较为平民化的价格来吸引消费者，通过高性价比实现高品质的流行时尚。\nSPA模式需要出色的供应链把控能力。通过供应链管理，达到三个目的：一是低价格；二是快速的市场反应能力，迅速捕捉市场的销售和需求情况以进行设计生产；三是实现低库存。\nSPA 模式需要强大的信息技术支持，通过软件系统整合门店和总部，整合设计、生产和销售的全流程。\n2.6 O2O模式\n在移动互联网时代，基于位置的 LBS 本地服务，020 模式更加具有吸引力和发展前景。020 模式的一个重要特点是信息流和人流的结合，即通过线上信息流的沟通，最终实现线下实体店铺人流的聚集。餐饮、旅游等是特别适合 O20 模式的行业。020模式在某种程度上是一个“重资产”项目，线下资源的整合需要花\n费大量的人力，这是与其他互联网平台不一样的地方。\n图 O2O模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n2.7 免费之广告模式\n“免费十广告” 模式，一般会涉及产品或服务提供方、免费受众和广告主(第三方)。大众在享受免费内容的同时，也在创造一种价值——流量或关注度，有了这种价值，就存在广告变现的可能。\n图 免费之广告模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n2.8 免费之“免费+收费”模式\n“免费+收费”是一个很有吸引力的商业模式。用户可以免费体验产品的部分或者全部功能，并根据需要选择是否付费。对于企业来讲，可以通过免费方式迅速占领市场并获取市场反馈。\n图 “免费+收费”模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n“免费＋收费〞模式对于产品和服务的品质要求很高。需要让用户在免费使用的时候有良好的体验，以促使其继续使用下去并有付费使用的意愿。同时，良好的使用体验还能够造成口碑效应，扩大产品影响力。\n“免费+收费”模式需要较大的用户规模。在该模式中，一般来讲，免费用户的数量比收费用户要大得多。所以扩充用户数量是产品发布后首要去做的。\n“免费＋收费”模式需要恰当的机制促进从免费用户到收费用户的转化。既要保持对免费用户有足够的吸引力，同时还要有更加良好的产品和服务来吸引收费用户。但免费的开始不一定能带来收费的必然结果。\n2.9 免费之增值服务模式\n对于增值服务的对象，一种是原来的免费用户，另外一种是第三方客户。不仅仅是互联网行业通过免费的方式吸引用户之后可以考虑增值部分，很多行业都可以考虑增值服务。“免费＋增值服务〞是一个非常值得深入研究和思考的模式，正因为比较难以把握，所以一旦实现就会形成比较高的竞争壁垒，令竞争对手一下子难以追逐。\n图 免费之增值服务模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n2.10 线上电子商务模式\n用互联网连接买卖双方，让人们足不出户即能享受便利购物，在当今时代无疑具有巨大的吸引力。从“风口”理论来看，电商确实顺应了潮流。对于偏远地区或者物流、信息流不发达的地区，电商平台可以为企业或者创业者提供便利的销售渠道，有助于将优质的产品资源 （不管是特色农产品还是商品）提供给广大的消费者。总的来说，电商平台提供了一种广泛的公平的商业基础设施。\n无论是B2C还是C2C电商平台都采取了开放策略，允许第三方商家在平台上开店。这丰富了商品货源，积聚了人气，也为平台带来了收入。对于B2C 模式，如亚马逊，天猫，京东，大多对第三方平台采用了收取服务费的策略，类似于农贸市场的推位费。对于C2C模式，淘宝采取了免费开店但收取增值费的策略，盈利效果非常明显。\n图 线上电子商务模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n2.11 众筹模式\n众筹目前有产品众筹和股权众筹两种，鉴于股权众筹的法律风险问题，目前主要的众筹形式还是产品众筹。\n图 众筹模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n对于产品、创意、设计等而言，众筹能很好地帮助解决创业团队的项目启动资金问题，同时依靠众筹进行相对精准的市场调研，也吸引了粉丝，赢得了口碑，是获得市场宣传的好机会。从这个角度看，众筹对于初创团队而言，是一个非常有效的成长渠道。\n对于初创团队，依靠众筹取得第一步成功是相对容易的，但后期的成长轨迹更值得关注。众筹成功之后，产品供应链问题、对产品品质的把控、对销售渠道的持续打造，以及对用户的吸引力和品牌塑造，都在考验初创团队的能力。\n众筹是有风险的支特初创团队的行为，有风投的味道，但股权众筹还是-个比较模糊的地带。另外，国内的消费者希望花一分钱就能买到一分钱的货，如果得到的是低于预期的不成熟成品，消费者对于创新的包容程度可能就没有那么高。国内成熟的产品预售反而能迎合消费者的预期，但预售又降低了众筹对初创团队的支持。因此，关于众筹在国内如何与本土文化更好地结合，需要思考。\n2.12 众包模式\n众包模式能够充分利用分散的智力和劳动力资源。任务众包平台非常多见，但仍有一些问题值得深思。有的平台发任务方的出资很低，导致接任务一方的积极性不高、完成任务的质量不高。有的平台缺乏信用评价机制和公正透明的纠纷处理机制，发布任务方和接收任务方在目标质量方面的理解可能并不一致，需要众包平台进行协商管理。社区型众包模式是一种链条比较长的模式，如果能在管理和销售方面更进一步，也许仍有前进空间。社区型众包模式集在线协同设计、生产和销售为一体。\n图 众包模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n2.13 共享模式\n共享模式为人们带来了便捷、优质、廉价的产品和服务，其主要特点是利用互联网和物联网技术搭建平台，整合社会上富余资源，通过线上线下吸引用户使用。\n图 共享模式\n资料来源：资产信息网 千际投行 《商业模式进化论》\n由于技术门槛比较低，共享模式在发展过程当中容易被竞争对手模仿跟进，从而会面临较大压力；另外共享模式的推广具有O2O模式的特点，涉及线下，往往也会采用 “地推” 的方式，推广起来需要更长的时间。\n目前，共享模式的收入主要来自于收取中间服务费，来源单一，盈利较为困难。随着平台用户数的增多以"
  },
  {
    "title": "基于开源中文大模型的报告生成任务：深入解读及指令示例（专注文本生成）-知乎",
    "page_body": "一、明确业务需求\n 在使用大模型生成报告之前，明确业务需求是至关重要的。这包括：\n 报告类型：总结报告、分析报告、预测报告、新闻稿等。\n 数据类型：文本、表格等。\n 报告风格：简洁明了、学术严谨、通俗易懂等。\n 输出格式：PDF、Word、Markdown等。\n 长度要求：短篇摘要、长篇论文等。\n 二、设计指令\n 指令是引导模型生成所需报告的关键。一个好的指令应该具备以下特点：\n 明确任务：清楚地告诉模型要做什么。\n 提供上下文：提供足够的数据和背景信息。\n 限定范围：限制生成内容的范围和风格。\n 给出示例：提供一个示例输出，帮助模型理解您的期望。\n 三、面向报告的文本生成任务及指令示例\n 1. 数据摘要\n 任务：将大量文本数据浓缩成简短的摘要。\n 指令示例：\"请根据以下新闻报道，生成一份300字的摘要，重点关注事件起因、经过和结果。\"\n 2. 文本扩写\n 任务：将短文本扩展成更长的文章。\n 指令示例：\"请以‘人工智能的发展趋势’为主题，续写一篇500字的文章，重点探讨其在医疗领域的应用。\"\n 3. 文本改写\n 任务：将文本改写成不同的风格或表达方式。\n 指令示例：\"请将以下学术论文的结论部分用通俗易懂的语言解释一遍。\"\n 4. 报告结构化\n 任务：将无结构的文本整理成具有逻辑结构的报告。\n 指令示例：\"请将以下会议纪要整理成一份结构清晰的报告，包含背景介绍、讨论要点和结论。\"\n 那么如果我们要的是金融垂直领域的呢\n 第一等级难度 面向报告（金融业）的生成式语言大模型的应用验证\n 一、扩展的任务类型（金融领域特化）：\n 在原有的文本处理任务基础上，针对金融领域进行如下扩展：\n 金融文本摘要：\n 市场综述生成：从多篇新闻报道和市场数据中提炼市场趋势的概要。财报摘要：从公司财务报告中提取关键财务信息。分析师报告摘要：提取分析师报告中的投资建议和未来预测。\n 金融文本改写：\n 术语简化：将复杂的金融术语转换为更易懂的语言。风险信息强调/弱化：根据上下文调整风险信息的重要性。金融报告结构化：\n 财务报表提取与结构化：从报告中提取财务报表（如损益表、资产负债表），并将其转换为表格形式。风险因素提取与分类：从报告中提取风险因素，并按类型进行分类。\n 金融文本分类/标签：\n 新闻情绪分析：分析新闻报道的情绪倾向（正面、负面、中性）。风险等级分类：根据公司财务状况和市场趋势对风险等级进行分类。监管文件分类：对法规、规章、指南等监管文件进行分类。金融信息抽取：\n 公司信息提取：提取公司名称、股票代码、行业、总部所在地等信息。财务指标提取：提取收入、利润、负债、资产等财务指标。并购信息提取：提取并购、收购、资产剥离等相关信息。\n 金融问答：\n 财务数据问答：回答有关历史财务数据的问题。市场趋势问答：回答有关当前市场趋势和未来预测的问题。监管问答：回答有关金融监管的问题。二、提高任务难度的要素（金融领域特化）：\n 大量专业术语：需要理解金融领域特有的术语和缩略语。\n 上下文依赖性：同一个词在不同上下文中可能有不同的含义（例如，“衍生品”）。\n 时间因素：需要考虑市场波动和监管变化等时间因素。\n 信息不确定性：需要处理诸如未来预测等不确定信息。\n 监管合规：金融信息处理需要遵守严格的法规。\n 三、具体化任务指令：\n 指定金融指标：明确分析的金融指标（例如市盈率、净资产收益率）。\n 明确监管要求：明确需要遵守的法规（例如GDPR、证券法）。\n 指定信息来源：明确分析的信息来源（例如财报、证券交易所公告）。\n 第二等级难度 面向报告（金融业）的生成式语言大模型的应用验证\n 面向公司公告、政府政策变动和基金公司撰写的评估报告，需要构建一个能够综合分析多来源信息的复杂任务体系。这个体系需要能够理解和提取不同类型文本中的关键信息，并将其关联起来进行深入分析。以下是一个更完善的任务体系：\n 一、扩展任务类型（面向公司公告、政府政策变动、基金评估报告特化）：\n 公司公告处理：\n 公告要素提取：提取公告中的关键要素，如财务数据（收入、利润、资产、负债等）、重要事件（并购、重组、人事变动、合同签订等）、风险提示、未来展望等。公告文本比较与趋势分析：比较同一公司不同时期公告中的关键要素，分析其财务状况、经营策略和发展趋势的变化。公告事件影响评估：评估公告中披露的重大事件对公司财务状况、股价和市场表现的潜在影响。\n 政府政策变动处理：\n 政策主题识别与分类：识别政策的主题（如环保、税收、产业扶持等），并进行分类。政策关键内容提取：提取政策中的关键内容，如目标、措施、适用范围、生效日期等。政策影响范围评估：评估政策可能影响的行业、公司和市场。基金评估报告处理：\n 评估方法与指标提取：提取报告中使用的评估方法（如基本面分析、技术分析、量化分析等）和关键指标（如夏普比率、特雷诺比率、阿尔法系数等）。投资评级与建议提取：提取报告中给出的投资评级（如买入、卖出、持有）和投资建议。评估逻辑与依据分析：分析报告中评估的逻辑和依据，包括引用的数据和分析方法。\n 综合分析与关联：\n 政策对公司影响分析：分析政府政策变动对特定公司的经营和财务状况的潜在影响。公司公告与基金评估报告对比分析：对比公司公告中披露的信息与基金评估报告中的评估结果，分析两者是否一致，是否存在偏差，并解释偏差的原因。政策变动对基金投资策略影响分析：分析政府政策变动如何影响基金的投资策略和投资组合。多维度信息融合与预测：整合公司公告、政府政策和基金评估报告等多方面信息，预测公司未来发展趋势和基金表现。二、提高任务难度的要素：\n 信息来源多样性：需要处理来自不同渠道和格式的信息，包括结构化数据（如财务报表）和非结构化文本（如公告、报告）。\n 专业术语和行业知识：需要理解金融、经济和相关行业的专业术语和知识。\n 信息时效性：金融市场信息变化迅速，需要模型能够及时处理和分析最新的信息。\n 因果关系推断：需要模型能够推断政策变动、公司行为和市场表现之间的因果关系。\n 三、具体化任务指令：\n 明确分析对象：指定需要分析的公司、政策或基金。\n 限定分析时间范围：指定需要分析的时间段。\n 指定分析维度：明确需要重点关注的方面，如财务状况、市场表现、风险因素等。\n 提供背景信息：提供相关的背景信息，帮助模型更好地理解分析任务。\n 第三等级难度 面向报告的生成式语言大模型的应用验证\n 我们专注于任务体系的设计，不考虑数据预处理和指令搜索的证据过程。这意味着我们假设已经获得了干净、可用的数据，并且模型能够有效地理解和执行指令。\n 以下是一个面向公司公告、政府政策变动和基金公司撰写的评估报告的、更完善的任务体系，专注于信息提取、关联和综合分析：\n 一、扩展任务类型（面向公司公告、政府政策变动、基金评估报告特化）：\n 公司公告处理：\n 财务信息提取：提取关键财务指标（如收入、利润、资产、负债、现金流等），并进行同比、环比分析。非财务信息提取：提取重要事件（如并购、重组、人事变动、重大合同、诉讼等）、管理层讨论与分析（MD&A）、风险因素、未来展望等。公告类型和主题分类：自动识别公告类型（如年报、季报、临时公告），并根据内容进行主题分类（如财务业绩、重大投资、风险提示等）。\n 政府政策变动处理：\n 政策要素提取：提取政策的目标、具体措施、适用范围、生效日期、影响对象、解释说明等关键要素。政策文本分类与标签：根据政策内容进行分类（如财政政策、货币政策、产业政策、环保政策等），并添加相关标签（如税收优惠、补贴、监管要求等）。政策力度和影响评估：评估政策的力度（如强、中、弱），以及对相关行业和市场的潜在影响（如正面、负面、中性）。基金评估报告处理：\n 基金基本信息提取：提取基金名称、代码、类型、规模、基金经理等基本信息。业绩评估指标提取：提取基金的业绩评估指标，如收益率、风险指标（如波动率、夏普比率）、费用率等。投资组合分析：分析基金的投资组合，包括持仓行业、持仓个股、资产配置比例等。投资策略和观点提取：提取基金经理的投资策略、市场观点、风险偏好等信息。\n 综合分析与关联：\n 政策与公司关联分析：分析政府政策变动如何影响特定公司的经营、财务和市场表现。例如，某项环保政策是否会增加公司的环保成本，或者为其带来新的市场机会。公司公告与基金评估报告对比分析：对比公司公告中披露的信息与基金评估报告中的评估结果，分析两者是否一致，是否存在偏差，并解释偏差的原因。例如，基金报告中对某公司的盈利预测是否与公司公告中披露的业绩指引一致。政策与基金投资策略关联分析：分析政府政策变动如何影响基金的投资策略和投资组合。例如，某项支持新能源行业的政策是否会导致相关基金增加对新能源汽车公司的投资。多维度信息融合与预测：整合公司公告、政府政策和基金评估报告等多方面信息，预测公司未来发展趋势和基金表现。例如，结合公司的财务状况、行业发展趋势和相关政策，预测公司未来几年的盈利能力，并评估相关基金的投资价值。二、提高任务难度的要素：\n 复杂因果关系推断：需要模型能够理解和推断政策、公司行为和市场表现之间复杂的因果关系，例如政策变化如何通过影响公司行为最终影响市场表现。\n 隐含信息和潜在风险识别：需要模型能够从文本中识别隐含的信息和潜在的风险，例如公司公告中未明确提及但可以通过其他信息推断出的风险。\n 跨领域知识融合：需要模型具备金融、经济、法律、行业等多领域的知识，才能进行有效的分析。\n 三、具体化任务指令示例：\n “分析2023年发布的《关于促进新能源汽车产业高质量发展的指导意见》对A公司（股票代码：XXXX）及其相关基金（如XX新能源主题基金）的影响，重点关注政策对A公司财务状况、市场份额和基金投资组合的影响，并预测未来一年的发展趋势。”\n 我们先继续把前面的设计写好\n 四、常用指令模板\n 基本模板：\"请根据以下[数据]，生成一份[报告类型]，[风格]的报告，重点关注[关注点]。\"\n 复杂模板：\"请将以下[数据]进行[操作]，然后生成一份[报告类型]，[风格]的报告，[附加要求]。\"\n 五、模型选择\n 智谱清言、通义千问、deepseek等开源中文大模型在报告生成任务中都表现出色。\n 选择依据：\n 任务类型：不同模型在不同任务上表现可能"
  },
  {
    "title": "论文研究内容怎么写？超全撰写步骤与核心结构框架解析-PaperFine",
    "page_body": "学术论文中，研究内容的撰写是构建学术成果的关键环节。这一部分内容不仅能够呈现学术探索的核心成果，更能直观反映研究的深度与广度。本文将系统拆解论文研究内容的撰写流程与核心结构框架，助力读者高效、规范地完成这一重要部分的写作。\n 一、理解研究内容的重要性\n作为论文的核心组成部分，研究内容直接影响着学术成果的价值评判。优质的研究内容通常具备以下功能：\n1.  精准界定研究目标 ：清晰呈现研究的具体方向与待解决的核心问题。\n2.  完整展示研究方法 ：详细说明所采用的研究手段与实验设计逻辑。\n3.  系统呈现研究成果 ：有条理地展示实验数据与分析结果。\n4.  有力支撑研究结论 ：为研究假设的验证与最终结论的推导提供实证依据。\n 二、撰写前的准备工作\n在正式开展研究内容写作前，需完成一系列必要的前期准备：\n 1. **文献综述**\n系统梳理相关领域的学术文献，全面掌握该研究方向的当前发展状况、前沿热点问题以及已取得的阶段性成果。这一过程有助于精准定位研究的创新点与学术价值。\n 2. **明确研究问题**\n聚焦研究的核心矛盾，确定具体且可操作的研究目标。理想的研究问题应同时具备明确性、可实现性与科学合理性。\n 3. **设计研究方案**\n制定详尽的研究实施计划，涵盖研究方法的选择、实验流程的设计、数据采集的途径以及分析工具的应用等关键环节。\n 三、撰写步骤与核心结构框架\n 1. **引言部分**\n a. 研究背景\n简要介绍研究领域的基础背景知识，重点阐述开展此项研究的现实必要性与学术重要性。\n b. 研究目的\n明确说明研究的核心目标，清晰界定预期解决的关键问题。\n c. 研究意义\n分别从理论层面与实践层面，论证研究成果对学术领域发展及实际应用场景的推动价值。\n 2. **文献综述**\n a. 国内外研究现状\n归纳总结国内外学者在该领域的研究进展，客观分析已有研究的成果与不足。\n b. 研究空白与创新点\n精准识别当前研究领域的未覆盖区域，明确本研究在理论或方法层面的创新突破点。\n 3. **研究方法**\n a. 研究设计\n详细描述研究的整体设计思路，包括实验框架的搭建逻辑与变量控制策略。\n b. 数据收集\n说明数据来源的具体渠道、采集过程的操作方法以及样本筛选的具体标准。\n c. 数据分析\n介绍所采用的数据分析技术与工具，解释选择该方法的理论依据与适用场景。\n 4. **研究结果**\n a. 数据展示\n运用图表、表格等可视化手段，直观呈现关键研究数据与实验结果。\n b. 结果描述\n对实验结果进行详细解读，重点突出具有显著性的研究发现。\n 5. **讨论与分析**\n a. 结果解释\n深入剖析研究结果的内在机制，结合理论知识阐释现象背后的科学原理。\n b. 与已有研究对比\n将本研究成果与同类研究进行横向比较，凸显本研究在方法或结论上的优势与贡献。\n c. 研究局限性\n客观指出研究过程中存在的不足，如样本量限制、方法局限性等，并提出改进方向与优化建议。\n 6. **结论与展望**\n a. 研究结论\n总结研究的核心发现，提炼具有普适性的学术结论。\n b. 实践意义\n结合实际应用场景，说明研究成果对行业发展或社会需求的具体应用价值与推广潜力。\n c. 未来研究方向\n基于当前研究的不足与领域发展趋势，提出后续研究可拓展的重点方向与研究建议。\n 四、撰写技巧与注意事项\n 1. **逻辑清晰**\n确保各部分内容环环相扣，从问题提出到结论推导形成完整的逻辑链条，避免内容跳跃或逻辑断层。\n 2. **语言规范**\n采用严谨的学术语言表述，规避口语化表达与模糊措辞，确保信息传递的准确性。\n 3. **数据准确**\n严格核查数据来源与计算过程，保证实验数据的真实性与可靠性，杜绝数据篡改行为。\n 4. **引用规范**\n遵循学术共同体认可的引用标准，对借鉴的文献成果进行规范标注，避免学术不端行为。\n 5. **反复修改**\n通过多轮通读与润色，修正表述误差，完善内容结构，确保研究内容的完整性与表达的精准性。\n 五、案例分析\n 案例：某生物医学研究论文\n 1. 引言部分\n研究背景 ：近年来，心血管疾病发病率持续攀升，已成为威胁全球公众健康的重要疾病类型。\n研究目的 ：探究某新型药物对心血管疾病的防治效果及作用特点。\n研究意义 ：为临床心血管疾病治疗提供更安全有效的药物选择，推动相关治疗方案的优化。\n 2. 文献综述\n国内外研究现状 ：现有学术成果显示，部分药物对心血管疾病具备一定治疗效果，然而普遍存在副作用明显、疗效波动较大等现实问题。\n研究空白与创新点 ：本研究首次针对该新型药物的心血管保护机制展开系统探究，填补了该领域的研究空白。\n 3. 研究方法\n研究设计 ：采用随机双盲对照实验设计，将受试者分为实验组（使用新型药物）与对照组（使用传统药物）。\n数据收集 ：通过多中心临床试验，采集受试者治疗前后的心电图、血液指标等心血管功能相关数据。\n数据分析 ：运用SPSS统计软件对两组数据进行t检验与方差分析，比较不同治疗方案的效果差异。\n 4. 研究结果\n数据展示 ：通过折线图呈现实验组与对照组治疗前后的LVEF（左心室射血分数）变化，以表格形式对比两组的不良反应发生率。\n结果描述 ：实验组治疗后LVEF提升幅度显著高于对照组（P<0.05），且恶心、头痛等不良反应发生率降低37%，表明该新型药物具备更优的治疗效果与安全性。\n 5. 讨论与分析\n结果解释 ：推测该药物可能通过抑制炎症因子释放、改善血管内皮功能等多重机制发挥心血管保护作用。\n与已有研究对比 ：相较于传统药物，本研究涉及的新型药物在疗效提升与副作用控制方面均表现更优，为临床治疗提供了更具竞争力的选择。\n研究局限性 ：本次研究样本量仅包含200例受试者，且观察周期为3个月，后续需扩大样本规模并延长随访时间以验证长期疗效。\n 6. 结论与展望\n研究结论 ：该新型药物对心血管疾病具有显著防治效果，且安全性良好。\n实践意义 ：研究结果为临床医生选择心血管疾病治疗药物提供了新的参考依据，具备较高的临床应用价值。\n未来研究方向 ：建议后续研究进一步探索药物的具体作用靶点，开展大样本长期疗效观察，并尝试与其他药物联合应用的效果研究。\n 六、总结\n论文研究内容的撰写是一项需要系统性思维与严谨态度的学术工作。从明确研究问题到设计研究方案，从展示实验结果到深入讨论分析，每个环节都需要科学规划与细致打磨。希望本文梳理的撰写步骤与结构框架，能为读者提供清晰的写作指引，助力产出高质量的学术研究内容。"
  },
  {
    "title": "一文搞懂AI大模型的四个核心技术-今日头条",
    "page_body": "AI大模型已成为人工智能领域的焦点，但背后的核心技术你真的了解吗？大模型的崛起，不仅推动了算法的革新，更重塑了数据处理、算力架构和智能推理等关键环节。掌握这四大核心技术，才能真正看懂AI产业的未来走向，也为个人和企业把握技术红利提供了清晰路径。本文将用通俗易懂的语言，带你全面解析AI大模型的技术底座，助你在智能时代抢占先机。\nAI大模型的四个核心技术——大规模数据训练、深度神经网络架构、分布式计算与高效推理算法，已成为推动人工智能发展的关键动力。2023年斯坦福大学发布的《AIIndexReport》显示，全球AI模型参数规模每年以10倍速度增长，带动AI应用不断突破。未来，AI大模型技术将持续演进，为产业升级和社会进步注入更强动力。（数据来源：StanfordUniversity, AI Index Report 2023）"
  },
  {
    "title": "课程小论文的结构应该如何安排-搜狐",
    "page_body": "写 课程小论文 ，合理安排结构就像搭建房子，框架稳了，整个论文才能立得住。一般来说，课程小论文可以按照下面这种方式来安排结构。\n开头部分要引人入胜，也就是引言。在引言里，先简单介绍一下你写这篇论文的背景，为啥要选这个题目。比如说，你写的是关于校园垃圾分类的小论文，就可以讲讲现在全社会都在提倡环保，校园作为大家学习生活的地方，做好垃圾分类很重要，这样就引出了你研究这个题目的原因。接着，你要把论文要研究的主要问题亮出来，让读者知道你这篇论文要探讨什么。引言不用写得太长，简洁明了，能引起读者兴趣就行。\n接下来是正文部分，这可是论文的重头戏。在正文里，你要把自己的观点和研究内容展开说。如果研究的问题比较复杂，可以分成几个不同的小部分。比如还是说校园垃圾分类的论文，你可以一部分写校园垃圾分类存在的问题，像垃圾桶设置不合理，同学们分类意识不强等等；另一部分写解决这些问题的办法，比如重新规划垃圾桶位置，开展宣传活动提高同学们的意识。每个小部分都要有自己的主题，内容要具体，最好能举一些例子或者数据来支持你的观点。比如讲同学们分类意识不强，就可以说说在校园里做的一个小调查，多少同学能准确分类，多少同学不太清楚。这样能让你的论文更有说服力。\n正文部分说完，就到结尾了，也就是结论部分。在结论里，你要把前面讨论的内容总结一下，再次强调你研究的主要成果。比如通过对校园垃圾分类的研究，得出了哪些关键结论，像改善垃圾桶设置和加强宣传能有效提高校园垃圾分类效果。同时，你还可以简单讲讲这个研究对未来有什么意义或者建议。比如希望学校能重视这些问题，尽快采取措施改善校园垃圾分类情况，让校园环境更美好。结论部分要干脆利落，别啰嗦，把该说的重点说完就行。\n有些课程小论文可能还需要参考文献部分。要是你在写论文过程中参考了别人的文章、书籍或者其他资料，就要在参考文献里把这些资料的详细信息列出来。这不仅是对别人成果的尊重，也方便读者去查找这些资料进一步了解相关内容。列参考文献的时候，要按照一定的格式来写，比如作者是谁，书名或者文章名是什么，在哪发表的，哪一年发表的等等。\n按照这样的结构安排，引言引出问题，正文深入探讨，结论总结成果，再加上参考文献，一篇课程小论文的结构就清晰明了，能让读者很容易理解你写的内容。"
  },
  {
    "title": "保姆级指南：大模型prompt的最佳实践-虎嗅网",
    "page_body": "，作者：alan，原文标题：《大模型基础系列（一）：Prompt 的艺术》，头图来自：视觉中国\n 文章摘要 \n本文介绍了关于大模型prompt的最佳实践，包括学习路径、prompt的概念和技巧、以及OpenAI官方的最佳实践指南。\n• 学习路径：从OpenAI官网教程、吴恩达的课程到OpenAI官方的CookBook，逐步深入学习prompt的方法和技巧。\n• Prompt工程：通过指令工程和隐藏指令等方法，提升大模型的回复质量和应用能力。\n• OpenAI官方最佳实践：提供了6个原则和方法，包括指令要清晰、提供参考内容、复杂任务拆分、给模型思考时间、使用外部工具和系统性测试变化。\nChatGPT 从去年12月发布，到现在已经9个月时间，这期间一直以旁观者的心态看着大模型发展，一直觉得应用层还不怎么清晰。直到最近才改变想法，还是应该尽早参与进去，等想清楚了可能机会也没了。所以开始更深度了解大模型，作为非技术背景的产品经理，首先想从怎么用开始，于是开始了解 prompt 的方法。比较深入地了解 prompt 后，有以下几点感想：\n1. 目前所有的 Prompt 技巧套路的出现，都是因为我们对大模型底层不了解，像在一座金矿上拿一个铲子往下挖掘。但是，如果放到5年后，prompt 应该不是一门需要专门学习的内容。\n2. 人类和大模型的交互，目前受到 token 限制比较严重，但是随着时间的发展肯定会突破 token 限制，那时候大模型潜力应该会充分释放，就像我们现在很难想象 iPhone 1代只有 128MB 内存，10年后再看大模型的发展应该会改天换地。\n3. Agent 之所以目前这么火，是因为大模型在应用上直接产生价值还比较难，而 agent 就是搭建应用价值的桥梁，一个不够就用多个。\n一、学习路径\n1. 从 OpenAI 的官网教程学习“GPT Best Practices”，官方的教程一般都兼具专业性和简洁性，OpenAI 的也不例外，是个非常好的上手资料。\n2. 按照吴恩达 prompt engineering 课程，有了官方教程的背景，吴恩达的视频课主要用于实操，跟着写代码测试效果。\n3. OpenAI 官方的 CookBook，这是 OpenAI 官方推荐的一些教程资源，重点看了 prompt 相关的论文，还有很多其他资料，可以后面慢慢看了。\n二、什么是 Prompt\n大语言模型 （LLM） 的能力并不是被设计出来的，需要人不断去探索ta的能力边界，prompt 就是探索的一种方式。目前看到的各种教程，其实就是探索出了一些典型【方式或规则】实践，直接复用就可以达到预期效果。\n1.Prompt Enginerring\n中文我翻译成“指令工程”。常规的通过 ChatGPT 的聊天界面输入的信息，是通常理解的 Prompt；而通过调用 LLM 的 API 接口，给 LLM 发出指令就可以理解成“Prompt Enginerring”，目前市面上大部分教程都是关于 prompt enginerring 的，这个也是我学习 prompt 前对这个概念的一个误区。\n2.Token\nToken 是 LLM 对输入信息的计算单位，我们常规理解的是单词，但是 LLM 会对单词进行分割，分割后的一个单元就是一个 token。下面这张图显示的是【段落】-【token】的分割和计算示例，如果想自己计算 token 可以用 OpenAI 官方的工具： https://platform.openai.com/tokenizer 。如果想了解 token 化的更详细信息可以看 这篇文章 。\n为什么要了解 token 这个概念呢？因为 LLM 对我们输入的 token 数量进行了限制，例如 ChatGPT-3.5 的输入限制是 4096个tokens，而 LLM 又没办法“记住”上次输入的信息，所以这个要求我们在有限的数量中，探索怎么实现想要的效果。\n那为什么 LLM 对输入的 token 数量进行限制呢？GPT4 是这样回复我的 （下图） ，比我从任何其他渠道获取的答案都要好。简单来说，因为“token越多计算资源要求越高、Transformer模型架构设计导致token越多计算复杂度提升越大、用户体验随着 token 增加而变差”，导致 token 会被限制。\n3.Temperature\nTemperature 用来控制模型输出内容的稳定性，因为 LLM 的输出是通过“概率”来排序的。如果对同一个问题想要每次输出完全一致的内容，temperature 直接设置为 =0。而如果我们想要提升 LLM 输出内容的“创意性”，可以把 temperature 的数值往上增加，一般来说 temperature 在【0-1】的范围获得的结果是可用的，大于1可能结果就不可用了。我们最好是按不同场景来配置 temperature 的数值，例如写诗就需要更高的 temperature 数值。\n那为什么调整 temperature 能获取不同风格的结果呢？这和 LLM 自身的设计结构有关系，调整 temperature 本质是对概率进行重新缩放。\n4.Hidden Prompts\n当我们和 ChatGPT 这类大模型进行“聊天”的时候，其实 OpenAI 是有内置一些 prompt 的，只是我们看不到。但是当我们用 api 来调用 GPT，却可以自己设置这些“内置 prompt”。目前看到的一些基于大模型的应用，基本都会用到这些 Hidden Prompt，例如让 GPT 扮演“助理、专家”g的角色等。\nHidden prompt 的另外一个应用是告诉大模型“不要做某些事”，例如涉及“政治、隐私”等问题的时候，通过 hidden prompt 规避直接回答。\n三、OpenAI 官方：GPT Best Practices\nOpenAI 的官方说明文档中，提供了 6 个提升 prompt 能力的原则/方法，每个方法中又包括了一些子方法，整个 Best Practices Guide 就是围绕这 6 个方法来的。而且在官方的文档中，还提供了在线测试的工具，可以边修改内容边查看效果，所以推荐作为小白学习 prompt 的第一个教程。6 大原则如下：\n1. 指令要清晰\n2. 提供参考内容\n3. 复杂的任务拆分成子任务\n4. 给 GPT “思考”时间\n5. 使用外部工具\n6. 系统性测试变化\n1. 指令要清晰\n在 prompt 中增加【细节】描述\nPrompt 中的细节描写越多，大模型回复的相关性就越高。\n让模型进行【角色扮演】\n这个是指在使用 GPT 的 API 时候，可以通过【STSTEM】来指定 GPT 成为某个具体的角色，例如“医学专家”。通过这种方式，能显著提升模型在这个领域的回复质量。\n使用【分隔符】来区分输入的指令\n分隔符可以用 三引号、xml标签 等格式。\n指定解决问题的【步骤】\n有些任务可以被分解成几个步骤，指定每个步骤预期想要的内容，就可以让模型按照这种期望的步骤输出。例如，让模型先总结一篇文章 （Step1） ，然后再把总结内容翻译成英文 （Step2） 。\n提供“样例”回答\n提供样例答案就是 【few-shot】 prompting，给出样例指导模型按照样例回复。这里在【system】和【user】的基础上，又引入了一个【assistant】的概念。例如，在下面的例子中，先指定了【system=鲁迅的口吻】，编辑好【user】和【assistant】的内容，随后 user 的问题便会以前面 assistant 的风格进行回复。\n指定输出【长度】要求\n2. 提供参考内容\n从参考内容中回复问题\n例如下面这个例子，让模型从\"\"\" 的内容中查找可引用的答案，如果能找到直接回复，否则直接拒绝回复内容。\n从模型的回复中加上基于参考内容的“引用”\n仅从参考内容中查找可回复的内容，如果找到内容同时输出引用自哪里。\n3. 复杂的任务拆分成子任务\n对输入的问题进行分类\n先把问题对应到最可能的类别，然后基于这个类别指定解决的步骤，引导 user 解决问题。\n对历史长对话进行【总结或过滤】\n由于 GPT 的 token 限制，导致历史对话无法全部作为下次输出的背景信息，解决的方法之一是对历史的对话进行总结，也可以通过 embedding 搜索实现类似效果。\n分段总结长文档逐步构建完整摘要\n要总结很长的文档，如一本书，我们可以逐段进行总结。将各段的摘要合并后再次总结，形成摘要的摘要。这个过程可以递归进行，直到整个文档被总结。如果需要使用前面部分的信息来理解后面的内容，可以在总结时加入前面的摘要。\n4. 给GPT“思考”时间\n回答前让模型自己先计算答案\n第一次看到这个现象感觉比较神奇：直接把复杂的计算问题丢给 GPT 做真假判断，GPT 很可能会出错，但是如果让 GPT 自己先算一遍，结果往往就正确了。后面有论文单独说明这个情况。\n使用内部对话或一系列查询来隐藏模型的推理过程\n模型有时需要详细推理问题才能回答特定问题。在某些情况中，与用户分享模型的推理过程可能不合适。例如，在辅导作业时，我们可能希望鼓励学生自己找答案，但模型对学生答案的推理可能会泄露正确答案。内部对话是一种可以用来解决这个问题的方法，其思路是让模型将不想让用户看到的输出部分放入结构化格式，便于解析。然后在给用户展示输出前，解析输出并只显示部分内容。\n询问模型在前面的步骤中是否有遗漏\n通常会用在让模型去总结一些摘录内容，通过 prompt 来确认是否有遗漏内容：\nAre there more relevant excerpts? Take care not to repeat excerpts. Also ensure that excerpts contain all relevant context needed to interpret them - in other words don't extract small snippets that are missing important context.\n5. 使用外部工具\n使用 embedding-based 搜索实现高效的知识检索\n模型可以使用输入中的外部信息来提供更准确的答案。例如，当用户问及某部电影时，向模型输入中加入该电影的详细信息 （如演员、导演） 会更有帮助。嵌入式搜索可以帮助模型实时地找到相关信息。简单说，文本嵌入就是将文本转化为向量，从而快速找到相关的文本内容。这样，当有一个问题时，我们可以迅速找到与之相关的信息。\n编写 code 或调用外部 API\n让模型自己写 code，并且代码执行的结果可以作为下个模型的输入。\n6. 系统性测试变化\n在样本比较小的情况下，很难判断某个 改动 是否有效，或者在某方面有效但其他方面反而效果下降。OpenAI 提供了一个叫 Evals 的工具，可以用来构建评估程序。如果知道答案应包含某些事实，我们可以用模型查询来检查答案中包含了几个。\n四、吴恩达：ChatGPT Prompt Engineering for Developers\n吴恩达的 Prompting 教程是今年 5 月份出的，在看完 OpenAI 的官方文档后，再看吴恩达的视频会感觉比较简单。因此，对照着吴恩达的教学视频学习，另外一个意义是要开始进行【实战】，自己尝试通过代码设置 prompt 并获得结果。\n我是通过官方的视频教程 + b站翻译的视频 结合学习的，官方网站用来获取代码示例，b 站视频用来辅助看翻译文字。\n前置条件\n注册 OpenAI 账号并获取 key\n安装 annconda，使用 Jupyter Notebook\n安装 Python，引入 openai 包\n我花了比较多的时间在安装 python 和配置环境变量等，甚至在安装完成后，第一次启动就直接报错“You exceeded your current quota， please check your plan and billing details”，网上找了很多资料，尝试新注册一个账号才搞定，所以千万不要低估了上手这一步，通过实战遇到问题解决问题，对自己的提升有很大帮助。\n在首次尝试，按照吴恩达的视频教程无法调用 openai，改为参考 OpenAI 在 Github 的样例： htt"
  },
  {
    "title": "自注意力与位置编码：让模型理解序列的魔法揭秘自注意力如何实现全局交互，三角位置编码如何让模型理解顺序，对比CNN、RNN-掘金",
    "page_body": "1. 什么是自注意力？\n想象一下，你正在阅读一本小说，每看到一个词语时，大脑会自动关注前文中与之相关的信息。这种\"聚焦重点\"的能力，正是自注意力机制的核心思想。\n自注意力（Self-Attention）是一种让序列中的每个元素都能关注整个序列的机制。就像班级讨论时，每个同学发言（查询）都会考虑所有人的观点（键和值）。具体来说：\n给定输入序列  X = [ x 1 , x 2 , . . . , x n ] X = [ x 1 , x 2 , ... , x n ] ，自注意力通过三个步骤生成输出：\n生成问题纸条 ：每个词元创建查询向量  q i = W q x i q i = W q x i 制作答案卡 ：每个词元生成键向量  k j = W k x j k j = W k x j  和值向量  v j = W v x j v j = W v x j 收集答案 ：每个查询收集所有键值对的加权和：\ny i = ∑ j = 1 n softmax ( q i ⊤ k j d ) v j y i = j = 1 ∑ n softmax ( d q i ⊤ k j ) v j \n其中：\nq q （Query）是查询矩阵，大小为  ( n × d ) ( n × d ) ，其中  n n  是查询的数量， d d  是特征维度。 k k （Key）是键矩阵，大小为  ( m × d ) ( m × d ) ，其中  m m  是键的数量， d d  是特征维度。 v v （Value）是值矩阵，大小为  ( m × d v ) ( m × d v ) 。 1 d d 1  是一个缩放因子，用于防止 大数值导致 softmax 过于极端 ，从而影响梯度的稳定性。\n示例 ：考虑句子\"猫吃鱼\"，自注意力会让\"吃\"同时关注\"猫\"和\"鱼\"，就像我们在理解动词时会自动联系主语和宾语。\n下面的代码片段是基于多头注意力对一个张量完成自注意力的计算，输入张量  X X  的形状为  ( 批量大小 , 序列长度 , 特征维度 ) ( 批量大小 , 序列长度 , 特征维度 ) ，经过自注意力计算后，输出张量与输入张量形状保持一致。\nimport  torch  import  d2l  num_hiddens, num_heads =  100 ,  5  attention = d2l.MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,                                    num_hiddens, num_heads,  0.5 ) attention. eval ()   print (attention)  \"\"\"输出：  MultiHeadAttention(   (attention): DotProductAttention(     (dropout): Dropout(p=0.5, inplace=False)   )   (W_q): Linear(in_features=100, out_features=100, bias=False)   (W_k): Linear(in_features=100, out_features=100, bias=False)   (W_v): Linear(in_features=100, out_features=100, bias=False)   (W_o): Linear(in_features=100, out_features=100, bias=False) ) \"\"\"   batch_size, num_queries, valid_lens =  2 ,  4 , torch.tensor([ 3 ,  2 ]) X = torch.ones((batch_size, num_queries, num_hiddens))   print (attention(X, X, X, valid_lens).shape)  # 输出：torch.Size([2, 4, 100])\n2. 三大序列模型的巅峰对决\n2.1 参赛选手介绍\n模型类型\n工作方式\n可视化类比\nCNN 滑动窗口扫描 望远镜观察局部区域\nRNN 顺序传递信息 接力赛传递消息\n自注意力 全局直接交互 电话会议全员讨论\n2.2 性能参数对比\n使用  n n  个词元，每个维度  d d ，卷积核大小  k k ：\n指标\nCNN\nRNN\n自注意力\n计算复杂度 O ( k n d 2 ) O ( kn d 2 ) O ( n d 2 ) O ( n d 2 ) O ( n 2 d ) O ( n 2 d )\n并行能力 高 低 极高\n最大路径长度 O ( n / k ) O ( n / k ) O ( n ) O ( n ) O ( 1 ) O ( 1 )\n图1 比较卷积神经网络（填充词元被忽略）、循环神经网络和自注意力三种架构\n示例 ：处理100个词的句子时，自注意力需要100×100=10,000次交互计算，而CNN（假设k=3）只需3×100=300次局部计算。\n3. 位置编码：给词语发\"座位号\"\n3.1 为什么需要位置信息？\n自注意力虽然强大，但有个致命缺陷——所有词语同时处理，就像把句子里的词全部平铺在桌面上，模型无法知道它们的原始顺序。这时就需要位置编码来标记每个词的位置。\n3.2 神奇的三角函数编码\n使用正弦和余弦函数的组合生成位置编码矩阵  P P ，其中第  i i  行对应位置，第  2 j 2 j  和  2 j + 1 2 j + 1  列使用：\nP i , 2 j = sin ( i 1000 0 2 j / d ) P i , 2 j + 1 = cos ( i 1000 0 2 j / d ) P i , 2 j P i , 2 j + 1 = sin ( 1000 0 2 j / d i ) = cos ( 1000 0 2 j / d i ) \n示例 ：当  d = 4 d = 4  时，位置1的编码可能是： [sin(1/10000^0), cos(1/10000^0), sin(1/10000^(2/4)), cos(1/10000^(2/4))]\n让我们在下面的 PositionalEncoding 类中实现它这种编码方式：\nclass PositionalEncoding (nn.Module):      \"\"\"位置编码\"\"\" def __init__ ( self, num_hiddens, dropout, max_len= 1000 ):          super (PositionalEncoding, self).__init__()         self.dropout = nn.Dropout(dropout)          # 创建一个足够长的P          self.P = torch.zeros(( 1 , max_len, num_hiddens))         X = torch.arange(max_len, dtype=torch.float32).reshape(             - 1 ,  1 ) / torch. pow ( 10000 , torch.arange(              0 , num_hiddens,  2 , dtype=torch.float32) / num_hiddens)         self.P[:, :,  0 :: 2 ] = torch.sin(X)         self.P[:, :,  1 :: 2 ] = torch.cos(X)       def forward ( self, X ):         X = X + self.P[:, :X.shape[ 1 ], :].to(X.device)          return  self.dropout(X) \n在位置嵌入矩阵  P P  中，行代表词元在序列中的位置，列代表位置编码的不同维度。\nencoding_dim, num_steps =  32 ,  60  pos_encoding = d2l.PositionalEncoding(encoding_dim,  0 ) pos_encoding. eval () X = pos_encoding(torch.zeros(( 1 , num_steps, encoding_dim))) P = pos_encoding.P[:, :X.shape[ 1 ], :] d2l.plot(torch.arange(num_steps), P[ 0 , :,  6 : 10 ].T, xlabel= 'Row (position)' ,          figsize=( 6.18 ,  3.82 ), legend=[ \"Col %d\"  % d  for  d  in  torch.arange( 6 ,  10 )]) \n从下面的例子中可以看到位置嵌入矩阵的第6列和第7列的频率高于第8列和第9列。第6列和第7列之间的偏移量（第8列和第9列相同）是由于正弦函数和余弦函数的交替。\n3.3 编码特性揭秘\n绝对位置感知\n不同列对应不同频率的波形，就像钢琴键盘上从左到右音调逐渐降低。高频（左侧列）帮助捕捉相邻词语的位置关系，低频（右侧列）负责编码词语在序列中的整体位置。\nP = P[ 0 , :, :].unsqueeze( 0 ).unsqueeze( 0 ) d2l.show_heatmaps(P, xlabel= 'Column (encoding dimension)' ,                   ylabel= 'Row (position)' , figsize=( 3.82 ,  6.18 ), cmap= 'Blues' ) \n相对位置推理\n关键公式：位置  i + k i + k  的编码可以表示为位置  i i  编码的线性变换：\nsin ( ω j ( i + k ) ) = sin ( ω j i ) cos ( ω j k ) + cos ( ω j i ) sin ( ω j k ) cos ( ω j ( i + k ) ) = cos ( ω j i ) cos ( ω j k ) sin ( ω j i ) sin ( ω j k ) sin ( ω j ( i + k )) cos ( ω j ( i + k )) = sin ( ω j i ) cos ( ω j k ) + cos ( ω j i ) sin ( ω j k ) = cos ( ω j i ) cos ( ω j k ) − sin ( ω j i ) sin ( ω j k ) \n这就像通过三角函数公式，模型可以推导出词语之间的相对距离。\n4. 关键知识点总结\n自注意力的本质 ：让每个词元都能与序列中所有词元直接交互 三大模型对比 ： \nCNN：局部感知，适合处理图像 RNN：顺序处理，适合流式数据 自注意力：全局交互，适合长程依赖\n位置编码的妙用 ： \n绝对位置：通过不同频率的正余弦函数编码 相对位置：利用三角恒等式实现位置偏移的线性表示\n通过这个魔法般的组合，现代Transformer模型才能在机器翻译、文本生成等任务中展现出惊人的性能。理解这些基础原理，就是打开深度学习宝库的第一把钥匙！"
  },
  {
    "title": "知识图谱教学：利用概念图等工具提升学生知识整合.pdf-原创力文档",
    "page_body": "预览加载中，请您耐心等待几秒...\n文档介绍\n知识图谱教学：利用概念图等工具提升学生知识整合\n能力的教学实践\n介绍\n知识图谱教学是一种以概念图、思维导图等可视化工具为基础的教学方法，旨\n在帮助学生提升对知识的整合和理解能力。本文将探讨如何有效地运用知识图\n谱教学来促进学生的学习效果。\n1. 概念图介绍\n1.1 定义\n概念图是一种表示和组织概念关系的可视化工具，通过节点和连接线展示概念\n之间的联系。每个节点代表一个概念，连接线表示它们之间的关系。\n1.2 制作步骤\n制作概念图可以参考以下步骤： - 确定主题或中心概念； - 把相关的子概念添\n加为节点； - 使用适当的连接线描述它们之间的关系； - 添加适当的标签和说\n明。\n1.3 功能和优势\n概念图有以下功能和优势： - 帮助学生整合知识，构建全局认知； - 显示各个\n概念之间的联系，促进理解； - 帮助学生建立概念之间的层次结构，形成知识\n框架； - 提供可视化的学习资源，使学习更加直观和有趣。\n2. 知识图谱教学的实践\n2.1 概念图应用\n利用概念图可以在课堂上以及课后作业中进行知识整合和巩固。教师可以要求\n学生制作概念图来总结已经学过的知识，并通过分享和讨论来深化理解和记忆。\n2.2 学生参与\n鼓励学生在知识图谱教学中积极参与，他们可以： - 制作个人概念图来阐释自\n己的理解； - 创造性地设计新的连接线和节点； - 协作制作群组概念图，促进\n合作学习。\n2.3 教师角色\n在知识图谱教学中，教师有着重要的指导和引导作用： - 引导学生使用适当的\n连接线、标签和说明展示概念之间的关系； - 解答学生对于概念之间关联问题\n的疑问； - 提供反馈和评估，帮助学生提升概念图的质量。\n3. 效果评估和展望\n3.1 效果评估\n教师可以通过以下方式来评估知识图谱教学的效果： - 观察学生的概念图制作\n过程，了解他们对于知识的理解程度； - 分析学生的个人和群组概念图，检查\n其准"
  },
  {
    "title": "2025必读！3D视觉Transformer四大创新方向｜附技术详解",
    "page_body": ""
  },
  {
    "title": "【大模型行业入门系列】一文读懂大模型与大语言模型！-知乎",
    "page_body": "1、大模型的定义\n 大模型（Large Models）通常指参数规模庞大（通常在十亿到万亿级别）的深度学习模型。这类模型通过在大规模数据集上进行训练，具备强大的泛化能力和复杂的任务处理能力，尤其在自然语言处理（NLP）、计算机视觉（CV）和多模态任务中表现突出。例如，GPT-3（1750亿参数）和PaLM（5400亿参数）是典型的大模型。\n 那么，大模型和小模型有什么区别？\n 大模型 vs. 小模型：核心区别\n 维度大模型小模型参数规模十亿到万亿级（如GPT-3：175B）百万到十亿级（如BERT-base：110M）训练数据海量数据（TB级文本、图像等）较小规模（GB级）计算资源需要分布式GPU/TPU集群，训练耗时数周至数月单卡或少量GPU即可训练，耗时短应用场景通用任务（文本生成、复杂推理、多模态交互）专用任务（分类、实体识别、轻量级部署）部署成本高昂（需云端算力支持，推理延迟高）低成本（可嵌入手机、IoT设备）能力特点涌现能力（如零样本学习、上下文理解）依赖任务微调，泛化能力有限神仙级AI大模型入门教程（超详细），大模型从入门到精通学习路线全流程规划！2、 大模型相关概念区分：\n 大模型（Large Model,也称基础模型，即 Foundation Model），是指具有大量参数和复杂结构的机器学习模型，能够处理海量数据、完成各种复杂的任务，如自然语言处理、计算机视觉、语音识别等。\n 超大模型：超大模型是大模型的一个子集，它们的参数量远超过大模型。\n 大语言模型（Large Language Model）：通常是具有大规模参数和计算能力的自然语言处理模型，例如 OpenAI 的 GPT-3 模型。这些模型可以通过大量的数据和参数进行训练，以生成人类类似的文本或回答自然语言的问题。大型语言模型在自然语言处理、文本生成和智能对话等领域有广泛应用。\n GPT（Generative Pre-trained Transformer）：GPT 和 ChatGPT 都是基于 Transformer 架构的语言模型，但它们在设计和应用上存在区别：GPT 模型旨在生成自然语言文本并处理各种自然语言处理任务，如文本生成、翻译、摘要等。它通常在单向生成的情况下使用，即根据给定的文本生成连贯的输出。\n ChatGPT：ChatGPT 则专注于对话和交互式对话。它经过特定的训练，以更好地处理多轮对话和上下文理解。ChatGPT 设计用于提供流畅、连贯和有趣的对话体验，以响应用户的输入并生成合适的回复。\n 预训练模型（Pre-trained Models）在大规模数据上预训练的模型（如BERT、GPT），可通过微调适配下游任务。大模型多为预训练模型，但小模型也可预训练。\n 基础模型（Foundation Models）斯坦福提出的概念，指通过自监督学习在大规模数据上训练、可适应多种任务的模型（如GPT-3）。大模型是基础模型的子集。\n 多模态模型（Multimodal Models）处理多种输入（文本、图像、音频）的模型（如CLIP、DALL·E）。大模型常具备多模态能力，但小模型也可设计为多模态。\n 生成式AI（Generative AI）专注于生成内容的模型（如GPT、Stable Diffusion）。大模型常为生成式，但生成式模型不一定“大”（如小型GAN）\n 3、 大模型的发展历程\n 添加图片注释，不超过 140 字（可选）\n 萌芽期（1950-2005）：以 CNN 为代表的传统神经网络模型阶段\n 1956 年，从计算机专家约翰·麦卡锡提出“人工智能”概念开始，AI 发展由最开始基于小规模专家知识逐步发展为基于机器学习。\n 1980 年，卷积神经网络的雏形 CNN 诞生。\n 1998 年，现代卷积神经网络的基本结构 LeNet-5 诞生，机器学习方法由早期基于浅层机器学习的模型，变为了基于深度学习的模型,为自然语言生成、计算机视觉等领域的深入研究奠定了基础，对后续深度学习框架的迭代及大模型发展具有开创性的意义。\n 探索沉淀期（2006-2019）：以 Transformer 为代表的全新神经网络模型阶段\n 2013 年，自然语言处理模型 Word2Vec 诞生，首次提出将单词转换为向量的“词向量模型”，以便计算机更好地理解和处理文本数据。\n 2014 年，被誉为 21 世纪最强大算法模型之一的 GAN（对抗式生成网络）诞生，标志着深度学习进入了生成模型研究的新阶段。\n 2017 年，Google 颠覆性地提出了基于自注意力机制的神经网络结构——Transformer 架构，奠定了大模型预训练算法架构的基础。\n 2018 年，OpenAI 和 Google 分别发布了 GPT-1 与 BERT 大模型，意味着预训练大模型成为自然语言处理领域的主流。在探索期，以 Transformer 为代表的全新神经网络架构，奠定了大模型的算法架构基础，使大模型技术的性能得到了显著提升。\n 迅猛发展期（2020-至今）：以 GPT 为代表的预训练大模型阶段\n 2020 年，OpenAI 公司推出了GPT-3，模型参数规模达到了 1750 亿，成为当时最大的语言模型，并且在零样本学习任务上实现了巨大性能提升。随后，更多策略如基于人类反馈的强化学习（RHLF）、代码预训练、指令微调等开始出现, 被用于进一步提高推理能力和任务泛化。\n 2022 年 11 月，搭载了GPT3.5的 ChatGPT横空出世，凭借逼真的自然语言交互与多场景内容生成能力，迅速引爆互联网。\n 2023 年 3 月，最新发布的超大规模多模态预训练大模型——GPT-4，具备了多模态理解与多类型内容生成能力。在迅猛发展期，大数据、大算力和大算法完美结合，大幅提升了大模型的预训练和生成能力以及多模态多场景应用能力。如 ChatGPT 的巨大成功,就是在微软Azure强大的算力以及 wiki 等海量数据支持下，在 Transformer 架构基础上，坚持 GPT 模型及人类反馈的强化学习（RLHF）进行精调的策略下取得的。\n 4、大模型的特点\n 参数规模超大\n 量级：参数量从十亿（B）到万亿（T）级别，例如GPT-3（175B）、PaLM-2（340B）。\n 意义：参数规模直接影响模型的“记忆容量”和复杂模式捕捉能力，是涌现（Emergence）能力（如逻辑推理、上下文学习）的基础。\n 训练数据海量\n 数据量：通常使用TB级文本、图像等多模态数据（如GPT-3训练数据约45TB）。\n 多样性：覆盖多语言、多领域（网页、书籍、代码等），降低模型对特定任务的过拟合风险。\n 计算资源密集\n 训练成本：需数千张GPU/TPU并行训练数周，如GPT-3训练成本约460万美元。\n 能耗问题：单次训练碳排放可达数百吨（如Bloom模型训练排放25吨CO₂）。\n 通用任务泛化\n 少样本/零样本学习：无需微调即可完成新任务（如GPT-4直接生成代码）。\n 多任务统一：同一模型处理文本生成、翻译、问答等多种任务（如PaLM-2）。\n 涌现能力（Emergent Abilities）\n 不可预测性：模型在达到一定规模后突现出设计时未明确编程的能力，如：\n 上下文学习（In-context Learning）：通过示例提示调整输出。\n 思维链（Chain-of-Thought）：分步骤推理解决数学问题。\n 跨模态对齐：理解文本与图像的语义关联（如CLIP）。\n 5、大模型的分类\n 按照输入数据类型的不同，大模型主要可以分为以下三大类：\n 添加图片注释，不超过 140 字（可选）\n 语言大模型（NLP）：是指在自然语言处理（Natural Language Processing，NLP）领域中的一类大模型，通常用于处理文本数据和理解自然语言。这类大模型的主要特点是它们在大规模语料库上进行了训练，以学习自然语言的各种语法、语义和语境规则。例如：GPT系列（OpenAI）、Bard（Google）、文心一言（百度）。\n 视觉大模型（CV）：是指在计算机视觉（Computer Vision，CV）领域中使用的大模型，通常用于图像处理和分析。这类模型通过在大规模图像数据上进行训练，可以实现各种视觉任务，如图像分类、目标检测、图像分割、姿态估计、人脸识别等。例如：VIT 系列（Google）、文心UFO、华为盘古 CV、INTERN（商汤）。\n 多模态大模型：是指能够处理多种不同类型数据的大模型，例如文本、图像、音频等多模态数据。这类模型结合了 NLP 和 CV 的能力，以实现对多模态信息的综合理解和分析，从而能够更全面地理解和处理复杂的数据。例如：DingoDB 多模向量数据库（九章云极 DataCanvas）、DALL-E(OpenAI)、悟空画画（华为）、midjourney。\n 按照应用领域的不同，大模型主要可以分为 L0、L1、L2 三个层级：\n 通用大模型 L0：是指可以在多个领域和任务上通用的大模型。它们利用大算力、使用海量的开放数据与具有巨量参数的深度学习算法，在大规模无标注数据上进行训练，以寻找特征并发现规律，进而形成可“举一反三”的强大泛化能力，可在不进行微调或少量微调的情况下完成多场景任务，相当于 AI 完成了“通识教育”。\n 行业大模型 L1：是指那些针对特定行业或领域的大模型。它们通常使用行业相关的数据进行预训练或微调，以提高在该领域的性能和准确度，相当于 AI 成为“行业专家”。\n 垂直大模型 L2：是指那些针对特定任务或场景的大模型。它们通常使用任务相关的数据进行预训练或微调，以提高在该任务上的性能和效果。\n 6、大模型的泛化与微调\n 模型的泛化能力：是指一个模型在面对新的、未见过的数据时，能够正确理解和预测这些数据的能力。在机器学习和人工智能领域，模型的泛化能力是评估模型性能的重要指标之一。\n 什么是模型微调：给定预训练模型（Pre-trained model），基于模型进行微调（Fine Tune）。相对于从头开始训练(Training a model from scatch)，微调可以省去大量计算资源和计算时间，提高计算效率,甚至提高准确率。\n 模型微调的基本思想是使用少量带标签的数据对预训练模型进行再次训练，以适应特定任务。在这个过程中，模型的参数会根据新的数据分布进行调整。这种方法的好处在于，它利用了预训练模型的强大能力，同时还能够适应新的数据分布。因此，模型微调能够提高模型的泛化能力，减少过拟合现象。\n 常见的模型微调方法：\n Fine-tuning：这是最常用的微调方法。通过在预训练模型的最后一层添加一个新的分类层，然后根据新的数据集进行微调。\n Feature augmentation：这种方法通过向数据中添加一些人工特征来增强模型的性能。这些特征可以是手工设计的，也可以是通过自动特征生成技术生成的。\n Transfer learning：这种方法是使用在一个任务上训练过的模型作为新任务的起点，然后对模型的参数进行微调，以适应新的任务。\n 大模型是未来人工智能发展的重要方向和核心技术，未来，随着 AI 技术的不断进步和应用场景的不断拓展，大模型将在更多领域展现其巨大的潜力，为人类万花筒般的 AI 未来拓展无限可能性。\n 本文将继续深入探讨大型语言模型（LLMs）的迷人世界，以及它们理解和生成类似人类语言的不可思议能力。我们将讨论这些模型的历史和演变，涉及到重要的里程碑，如GPT系列及其后继模型。我们还将探索不同类型的LLMs、它们的应用以及支撑许多先进模型的Transformer架构的内"
  },
  {
    "title": "写给“纯小白”的大语言模型入门指南，（非常详细）零基础入门到精通，收藏这一篇就够了-CSDN博客",
    "page_body": "文章标签： 语言模型 人工智能 自然语言处理\n关于内容\n阅读对象\n正如前文所说，在下乃是外门弟子，对已入内门的各位师兄师姐们应是帮助不大，希望能对仍在外门的师弟师妹们有些许帮助。\n目标\n本文的内容更多是从概念和认识上入手， 以了解和入门为目标，先对大语言模型领域有一个整体的认识 ，目标是为了帮助外门弟子能更好的理解秘籍内容以及更好的理解长老讲经的内容。通过对大模型有一个大致的了解， 再根据自己当前的情况与角色决定自己下一步要如何深入 。\n范围\n前面说的ChatGPT们都是基于大语言模型的应用，因此，本文主要也是围绕着大语言模型和基于大语言模型的应用来讨论的。\n目录\n什么是大语言模型\n定义\n特点\nTransformer是如何工作的\nTransformer的结构\n大模型的类型\n开源大模型\n闭源大模型\n开源VS.闭源\n在哪里可以找到开源模型\n大模型全流程\nRAG\nAGENT\n数据\n预训练模型\n训练\n微调\n评测\n部署\n应用开发\n我们该如何参与到大模型领域中\n态度\n掌握的资源\n发展趋势\n模型小型化\n多模态\n新架构\n最后\n什么是大语言模型\n定义\n大语言模型，是一种用于处理自然语言的机器学习模型，采用的是神经网络架构，属于生成式AI。它采用了 预训练 与 微调 相结合的方法，通过大规模无监督语料库的训练，学习到丰富的语言知识，从而能够生成自然流畅的语言。\n 可以简单地理解为，这个模型可以像人脑一样学习知识，并且可以根据学习到的知识生成和自然语言一样流畅的内容。\n特点\n它和之前的自然语言模型相比有了什么样的创新？主要是两个方面，一个是大，一个是新。\n大\n参数大（大脑中的神经元多）\n参数可以简单的类比大脑中的神经元，大脑中的神经元越多理论上就越可能出现更高级的智慧。\n GPT-3的参数就高达1750亿个，马斯克开源的模型Grok-1有3140亿个参数，很多开源的大模型比如Meta开源的Llama 3 70B，模型参数有700亿。\n 而且在榜单上，各类评分比较高的通常参数也都比较大，尤其是有关逻辑或数学方面得分越高，通常参数都比较大。\n学习内容多（学习过的知识多）\n从公开的数据看，GPT-3的预训练数据量就高达45TB，并且涵盖了各种类型的数据，比如：维基百科、各种书籍、期刊以及代码等。\n需要的资源多（承载它所需的资源大）\n众所周知，训练大语言模型需要大量的显卡，各个大型AI公司都在储备大量的显卡，根据公开的数据，GOOGLE拥有的显卡数量就高达2.6万块H100，其他公司也在大量储备显卡资源（2.6万块H100，它的显存就有2.6万*80GB=2080000GB）。等我们深入地了解大模型的原理之后就能明白为什么它需要这么多的资源了。\n 运行这么多的资源\n新（新思路，新范式）\n新的架构， Transformer。\n Transformer模型最初由Google团队在2017年6月12日发布的论文《Attention Is All You Need》中提出。\n Transformer模型采用了自注意力机制（Self-Attention）、多头注意力机制和位置注意力机制等关键技术，这些都极大地增强了模型的处理能力和学习效率。\n 它是当下最流行的一种架构。\nTransformer是如何工作的\n我们大致上了解一下Transformer的工作原理。\n 如果希望了解详细的工作原理可以参考以下内容：\n 《Attention Is All You Need》\n https://jalammar.github.io/illustrated-transformer/\n https://www.cnblogs.com/mantch/p/11591937.html\n 首先我们看看Transformer的架构图\n 简单地来说，基于Transformer架构的生成式AI模型，既然是生成式AI，那么它的主要目标就是生成文本。\n 在生成文本时是根据输入的内容（可能是一句话）和已经生成的文本一起生成一个新的字（或者叫token），直到模型确定已经生成结束。\n 也就是说，当前生成的字将作为生成新字的输入，这样一字一字的生成。\n 如果了解复杂的概念还有点费劲的话，关于它是如何工作的，了解到这里就可以了。等你对它有更深一步了解的时候再看下面的 Transformer的结构和Transformer的运行机制 也可以。现在你只要知道，它是根据你的输入和之前的输出来生成文本的就可以了。\n 举一个例子，比如你输入一个“我”，它会根据你输入这个“我”生成“我是”，然后再根据“我是”，生成“我是AI”。\n 至于它为什么会根据“我”生成“我是”最后生成“我是AI”，那是因为训练这个模型的数据导致的。如果更换训练数据训练大模型，它有可能生成“我是大熊猫”。\n 当然实际情况比这个还要复杂一点，不过这个例子应该有助于我们理解它的大概原理。\nTransformer的结构\n它是由一个 编码器（Encoder） 和一个 解码器（DeCoder） 组成（【图1】左是编码器，右是解码器），每个编码器和解码器又是由6层 编码层 和 解码层 组成（参考【图2】）。\n 每个 编码层 又包含一个自注意力层（self-attention）和一个前馈神经网络层（Feed Forward）。结构图【图1】中显示是多头注意力（Multi-Head Attention），这是为什么呢？是因为它会初始化8组平行的自注意力层组成，这样可以获得对输入序列更丰富的理解。\n解码层 与编码层结构类似，由一个掩码自注意力层（masked mutil-head attetion）、一个编码-解码注意力层（Encoder-Decoder）和一个前馈神经网络层，其中掩码自注意力层的作用是遮盖当前词后面的词，这样在模型训练的时候就会只关注当前词而不受后面的词的影响。编码-解码注意力层会接收编码器输出的结果与上层的自注意力层的输出作为输入，为最终输出的结果提供参考。\n 最后，通过Linear层和Softmax层将编码器的输出转为一组可能输出的文字的概率，选择概率较高的文字进行输出。\n 然后重复这个过程，直到输出了结束符号或者达到能够输出的最大长度。\nTransformer的运行机制\n 下面这组动图就是演示Transformer推理的过程。\n根据输入生成第一个“字”【图3】\n根据输入和生成的结果生成下一个字【图4】\n 用文字描述以下图片中的过程：\n 第一步，用户输入一句话也就是输入序列，\n 第二步，Embedding模型将输入序列向量化。\n 第三步，将向量化的内容中加入位置信息形成一个新的向量。\n 第四步，将这个向量输入到编码器中，编码器经过各种计算生成一组新的向量输出。\n 第五步，将编码器输出的向量转为一组注意力向量K/V ，这组K/V将被用在解码器的“编码-解码注意力层”，这有助于解码器将注意力集中在输入序列的适当位置。\n 第六步，如果还没有输出信息，则解码器根据K/V向量生成第一个输出，如果已经存在输出，则根据K/V向量和之前的输出一起交给解码器生成后面的输出。\n 第七步，将解码器输出的向量传入一个Linear层给将要输出的文字打分\n 第八步，将Linear输出的分数经过Softmax的归一化处理生成文字的概率。\n 第九步，选择最大的概率输出成文字。\n 持续执行直到输出结束符号，\n 这就是模型输出的最后结果。\n大模型的类型\n大语言模型现在主要分为两大类：\n 一类是开源大语言模型，比如Llama 3、GLM、Grok-1、QWen等。\n 一类是非开源（闭源）的大模型，比如GPT系列，Gemini、claude等。\n开源大模型\n开源大模型是指人人都可以获取大模型文件本身，并且可以在其基础上进一步调整出自己的模型。\n 开源模型的源代码和训练数据通常是公开的，这使得开发者可以根据自己的需求对模型进行修改和优化，以满足特定的应用场景。\n闭源大模型\n闭源大模型，用户只能通过厂商开放的API来使用大模型服务，有些闭源大模型厂商也为用户提供了 微调 的服务，用户也可以利用自己的数据对模型输出的结果进行调整，不过这并不能对模型本身进行修改。\n开源VS.闭源\n至于哪种模式能走到最后或者更有优势，我们不做探讨，他们各自都有各自的优点，我们作为用户最主要是需要知道他们各自的优缺点，能够了解他们各自的特点，并帮助我们在未来学习和使用的时候做出适合自己的选择就够了。\n 我们从以下几个方面来了解开源大模型和闭源大模型他们各自的优劣势。\n性能\n闭源模型的综合性能更高，但开源模型的性能与闭源相差并不是太大\n 图片来源opencompass大模型榜单\n https://rank.opencompass.org.cn/leaderboard-llm/?m=24-05\n 通过榜单数据可以看出前10位的玩家主要还是以闭源为主，我觉得最主要原因可能是他们盈利，所以可以投入更多的资源，不论是模型本身还是。\n 至于如何选择，还是需要考虑具体的任务。比如：\n 单纯从“知识”这一个维度看，Qwen72b只比GPT-4o略低一点。\n 单纯从“数学”这一个维度看，开源的Llama3 70b也只比第一名的Claude3-Opus低一点。\n从模型的整体性能上看，仍然是闭源模型更有优势，不过从某一个方面看开源模型与闭源模型相差并不是太大。\n成本\n闭源模型的成本是按输入和生成的文字数量收费，费用随使用量增加而增加。\n开源模型的成本主要集中在硬件的成本和部署过程中的一些技术成本，前期一次性投入较高。\n 一般使用闭源模型的API时，我们需要将一些信息输入给它，它就会根据我们的输入信息返回给我们一些信息，例如，我们输入“哪座山是世界第一高峰？”，它可能会返回给我们“喜马拉雅山是世界第一高峰”。这时，它的计费方式，就是根据我们输入的tokens（“哪座山是世界第一高峰？”）数量，和返回的tokens（“喜马拉雅山是世界第一高峰”）数量进行计费。\n 例如，openai 的GPT-4o api的收费标准\n 根据我们上面对Transformer的了解，这么收费也挺合理，用多少给多少钱，其他的什么硬件成本、网络成本等都不用考虑。\n 当我们使用开源模型的时候，我们需要自己部署它，假如我们不考虑对他进行进一步的训练和微调而是直接部署使用的话，首先要考虑的就是硬件成本。大语言模型主要需要GPU，在其加载大模型和进行推理的时候就会需要大量的显存资源。\n 而且部署大模型还需要具备一定的技术知识，才能将大模型调试为一个可用的状态。如果我们需要将他作为一个服务给更多的人使用，就需要更多的技术和GPU资源。\n 开源模型需要比较大的一次性投入，而闭源模型需要进行长期的投入。\n按这个价格大概计算一下： 一块A100≈10亿个GPT-4o token\n因此，在项目初期用户较少的时候使用闭源模型的API更为合适，当我们的项目到达一定规模的时候再购买硬件和服务器使用开源模型自己部署成本应该会更可控。\n当然这只是单纯从成本这一个角度考虑。\n灵活性\n开源模型更具灵活性，可以根据自己的需求和能力进行调整。闭源模型通常只有一部分模型开放了微调的api，灵活性较弱，通常是对输出的输出格式和风格进行调整。\n 开源"
  },
  {
    "title": "建议收藏！学术报告Report的常用结构 #建议收藏！学术报告Report的常用结构",
    "page_body": ""
  },
  {
    "title": "DeepSeek-V3 解析 1：多头潜在注意力机制-知乎",
    "page_body": ""
  },
  {
    "title": "智慧法治学术动态（2023年第49期总第73期）澎湃号·政务_澎湃新闻-The Paper",
    "page_body": "原创 上海市法学会 上海市法学会 东方法学\n学术前沿\n冯晓青｜数字经济时代数据产权结构及其制度构建\n在数字时代，数据日益成为重要的生产要素并具有财产属性，需要予以确权。数据产权不同于传统财产权，难以赋予所有权意义上的支配权和对世权。基于数据主体的多元性和数据利益的复杂性，以及数据自然流动和分享的特质，在分置式产权构建的基础上，需要明确数据产权制度的基本定位和原则，针对公共数据、企业数据和个人数据，明确赋予数据控制权、数据处理权、数据处分权和数据收益权，以建立基于数据动态流转和价值实现的数据产权制度。（全文刊《比较法研究》2023年第6期）\n冯晓青，中国政法大学民商经济法学院教授。\n李安｜机器学习的版权规则：历史启示与当代方案\n在人工智能时代，作品是机器学习的高质量数据资源。如何对机器学习的版权规则作出抉择以促进文化、技术两个领域的创新，是当前的一个重要问题。临时复制和自动钢琴的版权史提示我们：合理使用不是解决机器学习版权纠纷的唯一制度选择，非作品性使用和侵权责任对其有补充作用，应在分类讨论的基础上对机器学习版权规则进行梯度设置。具体来说，机器学习分为“非表达型”和“表达型”。前者属于非作品性使用，无侵权责任；后者进入专有权范围，推定为侵权：若学习大众表达则应设定合理使用免除侵权责任但允许权利保留，若模仿个别作者则未获许可应负侵权责任，若为科研活动则应认定合理使用免除侵权责任。我国应将作品性使用作为版权侵权成立要件之一，将大众表达型机器学习规定为附但书的合理使用情形，同时对算法训练数据版权信息披露义务作出规定。（全文刊《环球法律评论》2023年第6期）\n李安，中南财经政法大学知识产权研究中心讲师。\n江河｜数字法学形构的法哲学进路\n数字经济和数字法治实践为数字法学的客观形成和主观建构奠定了社会基础。社会关系的复杂化和数字化使形式知识的数学依次适用于实质知识的自然科学、经济学、政治学和社会学，并最终形成学科跨度最大的数字法学。数字法学兼具社科法学的历时开放性和法教义学的共时封闭性。在历时维度下，数学的形式理性和现代科技的社会化使计量法学和计算法学成为现代数字法学语境下的技术性程序规范，它们沿着社科法学的路径形塑了数字法学的体系开放性。在数字时代，通过社会行为的数字规制和权利客体的数字化，数字法学由方法论和程序性层面的计量法学和计算法学向知识体系和实体化层面的数据法学拓展。在法教义学的框架下，数据的实体化沿着主体论和价值论的逻辑，建构了数字法学外在的体系性与内在的跨学科性。类似于国际法学的开放性建构逻辑，未来数字正义的规范化和数字权利的体系化将促进数字法学基础理论的范式转换，即由外在的法哲学迈向内在的法理学。（全文刊《政法论坛》2024年第1期）\n江河，中南财经政法大学法学院教授。\n陈可翔｜个人信息保护中行政处罚的实施基础及制度逻辑\n个人信息保护中行政处罚的实施正面临过度介入私权纠纷化解、压缩社会自治空间及混淆内部法益构造等质疑，亟需对其实施的必要性、可行性等基础问题重新审视。调整信息处理者与信息主体之间的不平等关系，规避个人信息处理领域的不特定公共风险，以及协调个人信息权益保护中的多元利益诉求，构成该领域行政处罚的实施基础，从本质上确立了该领域行政处罚实施的目标和边界。个人信息保护行政处罚制度建设须植根于互联网公域变迁与公共治理变革之语境，遵循价值平衡、风险预防、辅助监管等原则，从宏观、中观和微观层面促进公法与私法、硬法与软法的衔接适用，协调不同法律规范的效力位阶关系，以及推动制度设计的场景化、精细化。依托组织法、行为法、程序法构造确定行政处罚实施的主体结构、操作指南、流程指引等，有利于增强处罚实施的正当性和明确性。（全文刊《法学》2023年第11期）\n陈可翔，广东外语外贸大学法学院副教授。\n齐延平、朱家豪｜完全自动化决策拒绝权的双重功能及实现路径\n我国的完全自动化决策拒绝权应基于《个人信息保护法》的解释进行体系化构建。完全自动化决策拒绝权对保障数智化时代的个人尊严与自由具有独立且独特的作用，对正处于形成中的自动化决策场景化规则具有统领作用。作为一种新型权利，完全自动化决策拒绝权的客观价值秩序功能具有先导性，首先发挥的是为国家履行保护义务提供法律依据的功能，其次才发挥以直接请求权为内容的主观权利功能。这种功能的偏向性使之能高效实现对决策双方失衡地位的终局性矫正。相应的，完全自动化决策拒绝权的实现有赖于以规制模式为主、以请求权模式为辅的并行路径。（全文刊《国家检察官学院学报》2023年第6期）\n齐延平，北京理工大学法学院讲席教授；朱家豪，北京理工大学法学院博士研究生。\n丰怡凯｜人工智能辅助量刑场景下的程序正义反思与重塑\n人工智能辅助量刑是我国近年来刑事司法人工智能应用的重大场景创新。在人工智能辅助量刑场景下，智能量刑辅助技术的适用不仅与实体结果相关联，同时还与量刑程序深度融合，彰显出两种基本程序面向：在程序功能构造方面，其以规范量刑裁量权为程序功能取向，以量刑算法决策为程序功能实现路径；在程序运行逻辑方面，则表现为“人机协同”型程序驱动模式以及“人主机辅”型程序责任分配格局。在此基础上，智能量刑辅助技术的应用引发了有关量刑程序正义的三重结构性风险：即，理论层面的“传统正义理论解释力有限”、制度层面的“量刑算法决策正当程序机制阙如”、司法适用层面的“量刑裁判的人工智能算法依赖”。为保障人工智能辅助量刑场景下程序正义及量刑程序规范化的实现，应当提出具有针对性且体系化的风险治理方案。该方案具体包括：引入“以人为本”的技术性正当程序正义理论，强化理论供给；立足新型算法权利，建构诉讼化的量刑算法决策程序，填补制度空白；将智能量刑辅助技术的适用限定在轻罪案件场域、设置智能量刑辅助意见异议听证程序，严格司法适用。（全文刊《现代法学》2023年第6期）\n丰怡凯，中国政法大学刑事司法学院诉讼法学专业博士生。\n新规速递\n工信部｜《工业和信息化领域数据安全事件应急预案（试行）（征求意见稿）》\n2023年12月15日，工信部网站公布《公开征求对\n<工业和信息化领域数据安全事件应急预案（试行）（征求意见稿）>的意见》。《应急预案》共八章三十九条，建立数据安全风险监测发现、研判分析以及报告机制，按照紧急程度、发展态势、数据规模、关联影响和现实危害等，明确数据安全风险预警等级，规定预警信息发布、响应以及解除等方面具体措施要求；要求事前建立数据安全事件监测和报告机制，明确数据处理者应急处置要求；事中按照事件级别和响应等级，明确数据安全事件应急处置采取的措施和具体要求；事后加强总结，明确涉事数据处理者应当评估形成总结报告。（工业和信息化部）\n工信部｜发布《关于组织开展网络安全保险服务试点工作的通知》，推进网络安全保险新模式落地应用\n2023年12月18日，工信部网站公布《关于组织开展网络安全保险服务试点工作的通知》。《通告》明确，本次试点险种主要包括网络安全财产类保险和网络安全责任类保险两大类，试点内容包括面向电信和互联网、工业互联网、车联网等重点行业的企业类保险和网络安全产品、信息技术产品，以及网络安全服务类保险。其中，面向电信和互联网企业的企业类保险主要针对服务器、网站、平台等因网络攻击或内部人员操作不当造成的平台服务中断、数据被恶意篡改利用等风险场景，主要承保营业中断损失、数据资产重置费用、第三方索赔损失、应急处置费用等。（工业和信息化部）\n美国联邦贸易委员会等两部门｜《2023年合并指南》\n当地时间2023年12月18日，美国联邦贸易委员会和司法部联合发布了《2023年合并指南》。《指南》指出，当公司拟议合并涉及特定内容，监管机构会对交易进行谨慎审查，以确定该交易是否会大幅削弱竞争或趋于形成垄断。其中包括：合并显著增加已经高度集中的市场的集中度、合并消除了企业间的实质性竞争、合并会增加协调行为的风险、合并将消除集中市场中的潜在进入者、合并产生的企业可能会限制竞争对手获得其用于竞争的产品或服务、合并将巩固或扩大企业的市场支配地位时等十一项特定情况。（美国联邦贸易委员会）\n美国参议院｜就参议院内使用人工智能技术发布指南\n当地时间2023年12月19日消息。美国参议院首席信息官发布了新指南，就参议院内人工智能系统和技术的使用提出建议。基于一系列风险评估，参议院首席信息官认为，ChatGPT、BARD AI和Bing AI Chat在采取控制措施情况下都处于中等风险水平。首席信息官强调了只能将人工智能系统用于仅涉及非敏感数据的研究与评估。新指南还提出，要像对待搜索引擎一样对待人工智能、验证生成信息的准确性以及增加人工审核等要求。（Nextgov/FCW）\n美国国家标准与技术研究院｜发布量子加密实践指南初稿\n当地时间2023年12月22日，美国国家标准与技术研究院的国家网络安全卓越中心发布了《量子准备：加密发现》和《量子准备：测试标准》两份实践指南初稿。两者均为该中心“迁移到后量子密码学”项目的成果文件。前者概述了功能测试计划，该计划要求加密工具在数字网络中查找错误的安全配置，文件还介绍了用例场景，为演示成功的后量子系统迁移提供了背景信息。后者则强调了如何使量子弹性算法与现有网络基础设施相协调，并提供了在受控非生产环境中解决兼容性问题的方法。（Nextgov/FCW）\n国家新闻出版署｜《网络游戏管理办法》\n2023年12月22日，国家新闻出版署网站公布《关于公开征求\n<网络游戏管理办法（草案征求意见稿）>意见的通知》。《办法》共八章六十四条，其中明确网络游戏不得含有恐怖、残酷等妨害未成年人身心健康的情形，网络游戏出版经营单位不得在网络游戏中设置强制对战，网络游戏不得设置每日登录、首次充值、连续充值等诱导性奖励，所有网络游戏须设置用户充值限额。获批出版前，进行网络游戏技术测试的，应确保网络游戏内容符合办法的相关要求，限额测试用户数不得超过2万，且测试不得公开提供可直接注册登录服务器的客户端软件，不得收费，不得以商业合作、广告销售等方式获取收益等。（国家新闻出版署）\n法律适用\n四川网信办｜四川多家单位因网络安全管理不到位被公安机关处罚\n2023年12月17日，四川网信办公布两件典型案例。两件案例均涉及单位未履行网络安全主体责任，被黑客利用"
  },
  {
    "title": "大模型训练中的数据结构与算法选择.docx-原创力文档",
    "page_body": "文档介绍\n大模型训练中的数据结构与算法选择\n1. 引言\n1.1 背景介绍\n随着深度学习技术的快速发展，大规模模型训练成为研究的热点。大模型训练涉及到海量的数据、复杂的网络结构和庞大的计算资源。在这样的背景下，数据结构与算法的选择显得尤为重要。合理的数据结构与算法可以提高大模型训练的效率，减少计算资源的浪费，同时也能提升模型的性能。\n1.2 研究目的与意义\n本文旨在探讨大模型训练中的数据结构与算法选择问题，分析不同数据结构和算法对模型训练的影响，为实际应用提供参考。研究这一问题具有以下意义：\n提高大模型训练的效率，降低计算成本；\n优化模型性能，提升模型在实际应用中的表现；\n推动数据结构与算法的研究，为大模型训练提供理论支持。\n1.3 文章结构\n本文分为七个章节，分别为：引言、大模型训练概述、数据结构在大模型训练中的应用、算法选择在大模型训练中的重要性、大模型训练中的数据结构与算法应用实例、未来发展趋势与展望以及结论。接下来，我们将依次探讨这些章节的内容。\n2. 大模型训练概述\n2.1 大模型的概念与特点\n大模型，通常是指参数规模巨大、计算复杂度高的机器学习模型。这类模型具有以下特点：\n参数规模大：大模型的参数量通常达到亿级甚至千亿级，这使得模型能够捕捉更复杂的数据特征。\n计算能力要求高：大模型训练过程中，对计算资源的需求非常高，通常需要分布式系统和大规模集群进行支撑。\n数据依赖性强：大模型通常需要大量的数据进行训练，以充分学习数据的潜在特征。\n模型效果显著：在许多任务中，大模型能够取得比小模型更优的性能，尤其是在自然语言处理、计算机视觉等领域。\n2.2 大模型训练的挑战与问题\n尽管大模型在某些方面表现出色，但其训练过程也面临诸多挑战：\n计算资源限制：大模型训练过程中，计算资源消耗巨大，这对普通研究者和机构构成了巨大压力。\n数据传输与存储：大规模的数据在传输和存储过程中，存在效率低下、安"
  },
  {
    "title": "资源推荐 | 大模型提示词设计与优化-2025年经济信息素养课程-搜狐",
    "page_body": "2025年经济信息素养课程\n大模型提示词设计与优化 ——策略、方法、技巧、实践\n前言\n生成式AI驱动全球科研范式革新，国内大模型依托多模态知识图谱构建，结合跨学科推演能力，加速重构从文献解析、数据挖掘到论文生成的全链条。这一过程推动学术创新从传统线性研究模式，向智能协作生态体系跃迁。\n但在这一智能化进程中，读者们在使用AI工具时常常陷入两难：面对海量文献时\"问不准问题\"导致AI使不上劲，面对智能生成的海量结果又难以快速辨别真伪，更纠结于传统研究思维与AI协作模式间的认知代差。\n本次课程将通过解构大模型核心原理与提示词工程逻辑，结合科研数据处理、文献分析、论文创作等真实场景案例，系统提升读者们驾驭 AI 工具的核心能力——从精准设计提示词实现信息筛选，到构建逻辑框架完成智能推演，最终达成基于 AI 协作的创新突破，实现研究思维范式的深度升级。\n01\n课程安排\n课程主题\n大模型提示词设计与优化——策略、方法、技巧、实践\n内容梗概\n通过对人工智能、大模型、提示词工程的关系梳理，解锁大模型推理过程以及理解提示词对模型输出效果的重要作用。结合具体示例讲解提示词的设计策略、方法与优化技巧，总结提示词设计实践中的常见问题及应对策略，帮助大家突破AIGC工具的浅层应用，充分激发大模型潜能，深层次赋能学术研究。\n课程大纲\n1.从就业前景看提示词重要性 \n2.人工智能与大模型的关系\n3.大模型与提示词工程\n4.提示词设计与优化\n5.提示词设计中的常见问题与应对\n6.总结、展望与建议\n02\n参与方式\n扫码观看\n03\n讲师简介\n张伟，国研网·国研大数据研究院宏观研究部研究员，经济管理学硕士。研究领域涉及宏观经济、区域发展、数字经济、提示词工程等，参与多个地方政府课题及专项规划，积累了丰富的研究经验。对如何设计与优化提示词，更好地释放大模型潜能具有深入研究。\n返回搜狐，查看更多"
  },
  {
    "title": "北京市首批大模型行业应用典型案例简介_新闻中心_中国网",
    "page_body": "一、智慧能源——基于电力行业NLP大模型的设备运检知识助手示范应用\n该应用由百度集团、国网智能电网研究院有限公司共同开发。\n国家电网多年蝉联世界500强排名前3位、中国500强企业第1位，公司经营区域覆盖我国26个省（自治区、直辖市），供电范围占国土面积的88%，供电人口超过11亿，是世界上输电能力最强、新能源并网规模最大的电网。国网智能电网研究院作为国家电网的直属科研机构，在集团公司支持下，长期开展电力自然语言处理、知识图谱和电力专用大模型的研发，已形成电力分词、设备技术标准阅读理解、ICT客服问题识别与定位、设备缺陷定级等技术处理能力，持续推动人工智能技术与核心业务深度融合应用。\n百度“文心”系列大模型涵盖自然语言处理、视觉、跨模态、生物计算及行业模型，在公开权威语义评测中斩获了十余项世界冠军。百度基于领先的深度学习和知识图谱增强技术,构建了千万级电力文本样本库和电力行业知识图谱，可实现海量异构数据的集成和智能化分析应用。\n项目面向复杂电网专业场景智能化需求，基于“文心”大模型联合训练电力行业NLP大模型，已在电网设备、ICT客服实际业务场景进行试点验证。初步结果显示,相较于传统小模型技术，电力行业NLP大模型在电力专业分词任务上，F1指标提升9.27%，达到92.376；电力行业NLP大模型在电力营销敏感实体识别任务上，F1指标提升13.28%，达到94.947%。基于该项目成果，百度将联合国网智研院持续开展电力大模型共训，共同推进电力深层认知智能提升，助力构建清洁低碳、安全可控、灵活高效、开放互动、智能友好的新型电力系统。\n二、智慧医疗——数字中医大模型示范应用\n该应用由北京智谱华章科技有限公司、北京中医药大学东方医院共同开发。\n当前中医领域存在名医数量少、传承断代、医疗资源不足等问题，名医经验的挖掘和整理是当前中医领域系统性、内涵复杂的一项工程。同时，人工智能技术的出现，使得“复刻”名老中医成为可能。北京中医药大学东方医院是国家中医药管理局直管单位、三级甲等中医医院、首批国家中医临床研究基地，积累了大量中医典籍、处方和中医临床数据。\n智谱华章高精度千亿中英双语稠密模型“GLM-130B”于2022年8月发布并开源，在斯坦福大学大模型中心的全球30个主流大模型全方位测评中表现优异，其准确性等关键指标与OpenAI、谷歌大脑、微软和英伟达等公司的大模型接近或持平，全球已有70个国家1000余家机构申请使用。\n项目面向中医领域名医经验挖掘整理需求，目标为基于智谱华章GLM-130B大模型，构建数字中医服务平台，“复刻”名老中医诊疗经验和学术思想，探索形成与名老中医高度匹配的高危肺结节人工智能临床诊疗解决方案，完成一定规模的临床评价研究，实现中医临床经验的智慧化复制新模式。截止目前已初步开发了医疗垂直领域的问答功能，支持对医疗、健康问题进行智能化知识问答；同时开发了根据症状生成中医诊方，并提供处方主治症候医学解释等辅助诊疗功能。\n三、智慧城市——面向建筑领域多模态行业大模型示范应用\n该应用由中国科学院自动化研究所、中铁建设集团有限公司共同开发。\n中铁建设集团是世界500强中国铁建的房建旗舰企业，正在针对工程建造业务协同中数据多源异构、知识非结构化、管理工具滞后等问题，开展产业升级改造。集团在建项目600余个，在施面积超7000万平方米，有效整合政府监管、建设、施工、设计、监理、咨询等多源异构工程数据，积累建筑行业规范标准、法律文件、技术方案等电子文件超3万本，可拆分条文、技术点涵盖5000万条，覆盖建筑垂直领域超过10万个话题的海量专业优质中文语料库，为多模态大模型在建筑领域应用验证提供了良好的数据基础。\n中科院自动化所“紫东太初”大模型是我国首个实现图像、文本、语音三模态数据间的统一表示与相互生成的千亿级多模态大模型，并实现全栈国产化开发和部署。2023年6月16日，自动化所发布“紫东太初”2.0全模态大模型，在语音、图像和文本数据的基础上，加入视频、信号、3D点云等模态数据，突破认知增强的多模态关联等关键技术，形成全模态理解、生成和关联能力。\n项目面向建筑领域智能化需求，基于“紫东太初”多模态大模型和跨模态通用人工智能平台，联合研发建筑工程全闭环智能应用系统，形成项目地图索引、实时视频通话、风险快速传达、问题整改、自动回复等功能，赋能工程方案设计、技术文件审核等多个阶段全闭环场景，大大提升建筑行业智能化水平。\n四、城市治理一一城市大脑大模型示范应用\n该应用由中关村科学城城市大脑股份有限公司自主研发，由科大讯飞(北京)有限公司、中科大脑公司共同完成国产化改造。\n中科大脑公司拥有近20年城市数字化建设经验，建成全国第一个全场景城市大脑，已形成 100多个物联网+城市治理应用，积累高质量城市治理语料库规模超 1000 万条发布30亿参数规模自研大模型“如如ChatTT”，在保证大模型基础能力的同时，可实现私有化部署，支持知识库插件框架，可与其他基础模型互联，提升基础模型领域知识的理解和生成能力。\n科大讯飞在认知智能及大模型技术领域有深厚的积累，于2023年5月发布自研“星火”认知大模型，可通过自然对话方式理解与执行任务，从海量数据和大规模知识中持续进化，自研大模型分布式训练框架，同时积极与国内主流模型及国产GPU开展适配，已在办公、教育等领域实现应用。\n项目面向城市治理领域智能化管理需求和国产化自主可控的安全需求，有效打通科大讯飞“星火”基础大模型和中科大脑公司“如如ChatTT”行业大模型，针对城市治理数据资源访问和应用受限、城市治理服务模型通用泛化能力弱以及人工智能时代下的信息安全等问题，在如如ChatTT基础上，完成城市治理大模型的国产化改造并示范应用，加速城市智能化建设，全面提升城市治理能力。\n五、智慧医疗——基于山海大模型的门诊病历生成系统示范应用\n该应用由云知声智能科技股份有限公司、北京友谊医院共同开发。\n临床工作中面临着繁重的文书撰写工作，医护人员大量的精力花费在此项工作上。北京友谊医院长期探索应用信息化、智能化技术提升病历撰写和录入的效率，曾和云知声联合研发并实施了语音电子病历录入、超声助手等效率工具，积累了大量的数据和经验。\n云知声长期开展医疗领域智能应用技术及产品研发，构建了大规模临床医学知识图谱，于2023年5月24日发布700亿参数规模的自研“山海”大模型，具有语言理解与生成、数理能力、代码能力、知识问答、逻辑推理、插件扩展等十大功能，可用于病历生成、临床决策支持、智能商保理赔等多个场景。\n项目面向医疗领域文书撰写需求，基于云知声自研的“山海”大模型、以及前端声音信号处理、声纹识别、语音识别、语音合成等全栈式智能语音交互技术，联合研发门诊医患对话场景下的电子病历自动生成系统，实现诊室复杂环境下的降噪、医患角色区分、信息摘要及病历自动生成等功能。已建设投资2970万元，预计可提升医生的电子病历录入效率超过400%，节约单个患者问诊时间超过40%，提升医生门诊效率超过66%。\n六、科学研究——覆盖元素周期表原子间势函数预训练模型示范应用\n该应用由北京科学智能研究院、中国航发北京航空材料研究院共同开发。\n中国航发北京航空材料研究院是我国航空装备关键材料的主要研发及制造单位。航空高性能合金随着性能的提升，逐渐走向多组元化，导致材料设计空间维度爆炸，难以通过传统的试错迭代开发新材料，亟需利用预训练模型揭示多组元相互作用，突破多组元设计关键技术，提高研发效率。\n科学智能研究院在微观科学计算领域处于国际领先地位，于2022年12月发布全球首个覆盖元素周期表近70种元素的深度势能原子间势函数预训练模型DPA-1，该模型雏形曾获2020年全球高性能计算应用领域最高奖——戈登贝尔奖，可模拟原子规模高至100亿，大幅提高模型迁移能力和元素容量，显著减少建模开销，缩短研发周期，降低研发成本，已在高性能合金、半导体材料设计等应用场景中实现应用。\n项目面向高性能航空关键新材料研发需求，基于原子间势函数预训练模型DPA-1，在元素覆盖范围、计算速度与精度、下游应用验证等方面开展联合研发，大幅提升模型的可迁移性、通用性和高效性，在航空高性能合金材料设计场景中降低模型训练所需数据量及训练成本，提高模型预测精度。\n七、智慧金融——多模态智慧金融大模型示范应用\n该应用由第四范式（北京）技术有限公司、北京中关村银行股份有限公司共同开发。\n金融领域面临着研发、生产、供应链、销售系统、服务系统复杂，数据信息模态繁多且流转受限，缺乏具有一定专业性的智能辅助决策手段等问题。中关村银行是北京市首家获中国银监会批复筹建的民营银行，也是全国首家专注服务科技创新的银行，拥有大量的客服反馈问答文本信息，以及各类监管机构、行业协会法规和银行内部规章制度，为大模型在金融领域的应用部署提供良好的数据基础。\n第四范式是以平台为中心的企业级人工智能领域的领军企业，针对企业智能化转型中面临的效率、成本、价值、辅助决策等问题，形成了成熟的系列产品和解决方案，已广泛应用于金融、零售、制造、能源与电力、电信及医疗保健等领域，在中国所有决策型企业级AI市场中排名第一。公司于2023年2月23日发布的百亿参数大模型“式说”，在生成式对话能力基础上，加入了文本、语音、图像、表格、视频等多模态输入及输出，可对接金融领域内部语料库、应用插件库等，实现对知识问答的快捷生成及溯源。\n项目面向金融领域智能化需求，以第四范式百亿参数大模型式说为技术基础，联合开展金融多模态智慧金融平台研发及私有化部署，在行内规章制度及人员信息查询、行业术语通俗化解释、客户经理信贷管理、人工客服问答推荐、理财业务办理、AI应用快速研发等多个环节形成大模型能力，大幅降低客服管理成本，提升客服人员效率及客户满意度。\n八、自动驾驶——自动驾驶大模型DriveGPT示范应用\n该应用由毫末智行科技有限公司、长城汽车股份有限公司共同开发。\n长城汽车是国内著名的主机厂，汽车年销量超过100万辆，目前已经出口到欧洲等地。目前长城旗下20多款车型已装载毫末智行研发的高阶辅助驾驶系统，自动驾驶里程超过6000万公里，覆盖全国各类道路和交通场景。由于量产车开放的驾驶场景，给自动驾驶算法带来了巨大的挑战，传统的小数据小模型模式无法处理如此复杂的环境，只有依靠大模型大数据。\n作为国内最早开展自动驾驶大模型研发的公司，针对自"
  },
  {
    "title": "如何整合多媒体教学与传统教学，提高课堂教学质量 论文_百度知道",
    "page_body": "随着现代科学技术的发展，计算机已进入我国的教育领域，并得到迅速发展。计算机在教育上的应用，使得教学手段、教学方法、教材观念与形式、课堂教学结构、以至教学思想与教学理论都发生了变革。网络教育主要是指以多媒体技术为主，计算机发展到今天，多媒体技术应用于教学已成为现实。在网上实现了跨时空、跨地域的，实时或非实时的交互式教学形式。与传统教育相比，网络教育有着独特的优势，主要表现在如下几个方面：\n一、多媒体教育手段的优点及不足之处\n1.多媒体教育手段的优点\n（一）良好的交互性\n网络教育给教师和学生都提供了良好的交互性，教师可以通过email和msn有效地和学生保持联系，可以帮助学生解答在课堂上没有理解的问题，与学生讨论问题，形成交互式学习。\n教师甚至可以和学生聊天，作为他们的良师益友，可以听听孩子们的心声，虚心听取学生对教师的评价。网络教学不再是传统教育中的以教师为中心、以课堂为中心，而是以学生为中心。\n（二）利用多媒体可以更好地激发兴趣\n多媒体改变了传统教学中粉笔加黑板的单一、呆板的表现形式，能将抽象、生涩、陌生的知识直观化、形象化，激发学生学习兴趣，调动其主动学习的积极性。\n自从有了多媒体教学，课堂气氛活跃了。尤其是在英语语法教学方面，学生们颇为受益。可激起学生的各种感官的参与，调动学生强烈的学习欲望，激发动机和兴趣。英语语法的教与学是教师和学生最头痛的事。而现在有了多媒体，教师可以将复杂的语法知识制作成生动有趣的幻灯片，让学生通过图片自己来总结语法要点，教师可以将学生总结的要点进行综合和评价。英语语法教学有了质的飞跃。\n在课间，老师可以给学生放一些轻松的音乐或一些与学习有关的比较有趣的资料放给学生看，寓教于乐，既丰富学习内容又能提高了学生的学习兴趣。\n2. 多媒体教育手段的不足之处\n（一）助长了教师及学生的惰性：过分地强调课件的重要性，认为只有使用课件才能把课上好， 甚至认为板书都是多余的， 教师成了一个点击鼠标的工具， 电子板书占据了整堂课， 学生不再认真做笔记， 而更依赖于拷贝教师的教案。 听觉和视觉成了一节课最重要的环节。 孰不知亲手演练才是学生学习及巩固知识最重要的环节。\n（二）内容华而不实： 教师在制作课件时，为了提高学生学习的兴趣， 过多地加入了音乐视频及其它一些动画。虽然课堂气氛变得很活跃， 但课堂的重难点并不突出。\n（三）缺乏课堂上与学生的沟通：在多媒体课上，教师埋头于操作电脑，却严重地忽视了与学生的沟通。教师无法对学生的行为进行有效监督。在网络教育环境下学习，需要学生有较强自制力和学习自觉性。否则，所学课程将无法保证质量，无法按期完成。因为此时教师无法采取有效措施督导这些远距离的学生，学生更容易“旷课”、“开小差”。而传统教育中教师可以面对面督导学生学习，使自律性、自觉性较差的受到有效促进。\n二、 传统教学的优点及不足之处\n（一）传统教学的优点\n传统的教育方法包括：讲授法、演讲法、谈话法、讨论法、演示法、读书指导法、布置作业法、课外辅导法、角色扮演法等等。其中讲授法是传统教学方法中受到批评最多的一种，有人认为它是注入式（灌输式）的教学方法。事实上，传统教学方法是在人类社会发展的历史中流传下来的，经过实践的不断筛选、淘汰、被人们逐渐地认识和利用，因而需要辩证地对待它。在教学中，角色扮演是学生互动最重要的环节，也是提高学生学习兴趣的最佳办法。\n对学生而言，传统教学方法的板书形式便于学生记笔记，掌握重点和难点，理解和记忆教学内容。对教师而言，传统教学方法讲解深入浅出，有利于教师现场发挥和有效控制教学进度。师生面对面交流有利于相互沟通，增进感情，促进学生综合素质提高。\n讲授法是一种最直接、最有效的教学方法。可以让学生减少探索时间，避免走弯路。它有助于形成知识的系统性，有利于学生较快形成概念，理解有关知识，有助于基本技能的培养。从这个意义上讲，讲授法是一种最直接，最有效的教学方法。学生基础知识扎实，与讲授法运用得好是分不开的。自主性学习强调了学生的主体地位，但应当认识到，学生的能力认知水平是有限的。如果缺乏教师的引导，让学生“放手”学习就很有可能异化为“放任”学习。其实，教师对课文适时适度地解说完全是教师职责内的正常教学行为。教师的使命就在于对学生自主学习基础上有步骤地精心“导学”，适时地对知识进行梳理，归纳。"
  },
  {
    "title": "多智能体LLM系统的困境与未来趋势",
    "page_body": "01 多智能体LLM系统的困境\n多智能体LLM系统频频遭遇困境，这究竟是何原因？\n想象一下，你精心构建了一个由程序员、测试员和项目经理组成的团队，每个人都各司其职。然而，最终呈现的产品却问题重重，团队内部矛盾重重，成员之间互相推诿责任，甚至有人擅自更改需求。这并非虚构的职场剧，而是现实中多智能体LLM系统所面临的严峻挑战。\n❒ 系统表现不如独立AI \n经过对ChatDev等五大主流框架的深入测试，我们发现，在 最不利的情况下，这些多智能体LLM系统的准确率仅为25% ，这一成绩甚至不及单独作战的AI模型，例如采用Best-of-N采样的方法。\n这种现象，仿佛是一群学术上的佼佼者组成团队进行项目合作，但其最终表现却不如各自为战的个体。在深入剖析了150余个任务对话记录，涵盖总文本量超过15万行后，我们发现，这些多智能体LLM系统的失败模式可以概括为三大类，同时，还存在三大致命陷阱。\n❒ 三大失败模式和陷阱 \n❒ 规则崩坏 \n在多智能体LLM系统的运行过程中，我们观察到 AI员工存在擅自篡改需求的现象 ，例如将象棋输入从“Kc8”错误地改为了坐标。同时，测试员也时常疏忽，未能及时发现并纠正这些核心规则的错误。\n❒ 团队内耗 \n在多智能体LLM系统的开发过程中，我们遇到了团队内部的沟通障碍。程序员与架构师之间的多次交流，如同“鸡同鸭讲”，经过七轮对话仍无实质性进展。同时，有成员明知API文档存在错误，却选择隐瞒不报，导致问题未能及时解决。\n❒ 验收困境 \n在多智能体LLM系统的开发过程中，我们面临了验收环节的诸多难题。由于团队内部沟通不畅，导致程序员提交的代码与预期功能存在偏差，而测试人员往往只能依赖“意念验收”， 缺乏客观、有效的测试手段 。这严重影响了系统的整体质量与稳定性。\n02 真实案例分析\n❒ 象棋游戏案例 \n一篇论文揭示了一个令人哭笑不得的场景：用户期望开发一款能支持国际象棋标准记谱法（例如Qd4）的游戏，然而，Agent团队所交付的版本却只能通过(x1,y1)坐标进行输入。这种情形仿佛是在验收新房时，监理人员只数了门窗的数量，却未检查厕所有无下水道。数据显示， 高达47%的失败案例可追溯至验证环节的疏忽 。\n03 人类组织学视角与解决方案\n❒ 组织学分析 \n令人深思的是，这些Agent团队的失败模式，竟与众多人类组织的经典崩溃案例高度契合。多智能体系统的 问题与人类组织崩溃相似 。其中，“越级指挥”现象尤为引人注目，即CTO等高层管理者试图抢夺CEO的决策权，导致团队内部权力失衡。\n❒ 借鉴高可靠性组织经验 \n借鉴核电站和航空管制等高可靠性组织（HRO）的实践经验 ，来应对多智能体系统中的挑战。这些经验包括：严格进行分级授权，以防止AI角色越权；构建一个充满心理安全感的环境，鼓励AI对上级决策提出质疑。\n❒ 现有解决方案的局限性 \n当前主流的解决方案往往只能治标不治本， 当前方案仅治标不治本，无法解决深层设计缺陷 。例如，战术级修复，通过更详细的提示词来提升成功率，但效果有限；换座位实验，尝试调整AI对话流程，但其效果并不稳定。\n04 未来研究与建议\n❒ 未来知识库介绍 \n未来知识库是欧米伽未来研究所精心打造的在线知识库平台， 汇集前沿科技的研究 。该平台不仅收藏了数万篇重要资料，还每周更新不少于100篇全球范围内的最新研究成果。\n❒ 前沿科技趋势报告 \n截至3月31日，“未来知识库”已精选了百部前沿科技趋势报告，涵盖人工智能、超级智能、能源等多个领域。 多份报告分析了不同领域的技术趋势与挑战 。这些报告将为政策制定者、企业投资者和科研人员提供宝贵见解与展望。\n通过更深入地探索和应对这些系统性设计上的深层缺陷，我们有望实现更高效的多智能体系统协作。"
  },
  {
    "title": "大作业报告（八篇）范文118",
    "page_body": "《供配电技术课程大作业》\n报告书\n题 目： 指导教师： 姓 名： 学 号： 日 期：\n机电工和系 2013-2014学年第2学期\n报告书格式要求：\n一、 报告前置部分\n（一）摘要内容包括研究目的、方法、结果、结论（300字~400字）四部分\n（二）格式要求\n1．中文摘要：\n“摘要”（黑体三号，居中），摘要正文（居左，首行缩进两字，宋体五号）。 “关键词”（黑体小四号，居左顶格，单独占行），关键词正文（宋体五号），关键词为报告研究内容3～8核心专有名词，词与词之间用分号间隔。\n2．外文摘要：独占一页\n“Abstract”（Times New Roman，三号，加粗，居中），Abstract正文（居左顶格，Times New Roman，五号）；\n“Key words”（Times New Roman，小四号，加粗，居左顶格，单独占行），Key words正文（居左顶格，Times New Roman，五号）,与中文关键词对应，词与词之间用分号间隔。\n二、 报告主体部分\n（一）正文格式要求\n1．页眉（宋体，五号，居中），由“学生姓名：论文题目”格式构成。\n…… ……  余下全文\n篇二 ：大作业报告格式\n《面向对象技术课程大作业》\n设计报告书\n题 目： 超市管理系统\n指导教师： 宋涛\n姓 名： 李敬玮\n学 号：  100505113 \n日 期：  20##-11-22 \n…… ……  余下全文\n篇三 ：作业报告\n关于仙林大学城饮料消费行为调查分析报告\n调查背景\n仙林大学城现在拥有的院校主要有：南京大学，南京师范大学，南京财经大学，南京邮电大学，南京中医药大学，南京信息职业技术学院，南京理工大学紫金学院，应天学院，南京森林警察学院，南京体育学院，南京工业职业技术学院,南京外国语仙林分校，南京国际学校等。总计20万在校大学生生，加上5万常住居民，因此仙林大学城拥有无限商机。任何一件商品只有运用好营销策略，才能扩大市场份额，饮料产品也是如此。以下是我根据调查问卷及其反馈数据做的报告分析。\n由于时间原因，我总计只发放113份问卷，实际回收有效问卷110份，其中男生63人，女生47人。问卷发放地点，仙林大学城南京邮电大学，在宿舍和教学楼随机发放问卷。同时观察了南邮校园商店和自动贩售机的销售情况。\n问卷分析\n一、消费者需求分析\n问卷共涉及11个具体问题，想要了解大学生饮料市场必须先了解大学生对饮料的需求，在问卷第一题中，我们了解到，即使现在是冬天，依旧会有34人会每天买一瓶饮料，35人平均2-4天买一瓶饮料，15人会在5-7天买一瓶饮料。从这里可以推断出，像南邮有2万左右在校学生，每天饮料的需求量会是一个庞大的数字。从调查中发现男生购买饮料的频次明显高于女生，因此男生消费群体应投入更大的关注。\n…… ……  余下全文\n篇四 ：大作业报告格式\n数据库原理大作业\n作业题目： 小组成员： 指导教师： 提交时间：\n一、需求分析\n功能分析（功能结构图）、提取数据过程以及结果\n二、概念结构设计\n根据需求分析，得到实体、属性，以及实体间联系（用文字描述清楚），最后得到E-R图\n三、逻辑结构设计\n根据E-R图，转换相应的关系模式，并分析关系模式属于什么范式，若不是BCNF，则优化至BCNF\n四、小结\n对所做内容进行归纳总结\n…… ……  余下全文\n篇五 ：毕业大作业实践报告\n中国石油大学（华东）现代远程教育\n毕业大作业（实践报告）\n题 目： 工商企业安全管理实践报告 \n学习中心： 奥鹏学习中心\n年级专业：  网络09秋 工商企业管理\n学生姓名： ×××  学 号：  1234567890\n实践单位： 南通腾宇混凝土有限公司 \n实践起止时间：  20## 年 4 月～ 2012 年 7 月\n中国石油大学（华东）远程与继续教育学院\n完成时间：   20112 年   8  月   10  日\n…… ……  余下全文\n篇六 ：大作业报告封面\n(下)》大作业报 告 学院名称： 东方学院 专 业： 计算机科学与技术 题 目： 学期： 13-14-2 班 级： 学号： 姓 名： 报告成绩： 答辩成绩：教师姓名： 李秉璋\n20xx年6月\n《程序设计基础\n1.作业性质\n大作业程是学生在学习完《程序设计基础(下)》后，为提高学生编写程序的能力，要求每个学生完成的一门实践性作业。\n2.作业目的\n使学生通过设计一个功能相对完整的C语言应用程序，加深理解和掌握课堂教学内容，进一步提高C语言的应用能力。为后续《数据结构》、《数据库系统原理与应用》等课程打下扎实的专业基础。\n3.具体要求\n要求以个人为单位完成大作业，并提交大作业报告，程序量不得少于100行。\n4.大作业流程\n确定选题、确定该选题应具备的功能、设计的自定义数据类型、划分功能模块、画出各功能模块的NS图、编写程序、调试并运行。\n撰写简要报告，内容包括上述内容，全部源程序及主要运行界面截图、作业过程中出现的问题、解决的办法、作业还存在问题，简要叙述收获与体会(要真实)。\n…… ……  余下全文\n篇七 ：毕业大作业(实践报告)\n中国石油大学（华东）现代远程教育\n毕业大作业（实践报告）\n题 目： 工商企业管理专业实践报告\n学习中心：  青岛校区学习中心 \n年级专业：  工商企业管理 \n学生姓名：  学 号：\n…… ……  余下全文\n篇八 ：C++大作业报告\nC++大作业报告\n姓名\n总学号\n班级\n一\n题目：2—1\n内容：用三种循环语句完成求100以内的质数\n设计思路：1既不是质数也不是合数，所以直接从2考虑。找出来这\n些数字就是要保证这个数只能让1和其本身整除，所以让\n这个数先除以2，然后慢慢整除其小于除以2后的数，然\n后输出这些数。\n程序代码：\nwhile 循环\n#include<iostream>\nusing namespace std;\nint main()\n{\nint i=2;\n} int j,n,m; while (i<101) { } return 0; m=1;n=i/2;j=2; while (j<=n) { } if(m) cout<<i<<endl; if(i%j==0) { } j++; m=0; break; i++;\nDo while 循环\n#include<iostream> using namespace std;\nvoid main() {\nint i=2; int j,n,m; do { } m=1;n=i/2;j=2; do { } while(i<101); if(i%j==0) { } j++; while(j<=n) if(m) cout<<i<<endl; m=0; break; i++\n…… ……  余下全文"
  },
  {
    "title": "本科论文研究方法怎么写？",
    "page_body": ""
  },
  {
    "title": "AI大模型实战教程（超详细）Dify+RAGFlow集成指南，从零到精通，收藏这篇就够了！CSDN博客",
    "page_body": "本文详细介绍了如何在Dify平台基础上集成RAGFlow的知识召回能力，通过创建知识库、设置API KEY、连接外部知识库等步骤，实现两者优势互补，提升智能应用的知识检索和召回准确性，为构建更强大的AI应用提供实用解决方案。\n我们精心打磨每一篇文章：深度思考、精准测试，坚持用严谨的创作流程确保每篇内容都经得起实践检验。这是我们的****创作准则，更是对读者时间的庄严承诺—— 让您花费的每一分钟，都能收获解决实际问题的真知灼见 。\n在智能体构建和工作流等模型应用编排平台中，dify，ragflow、n8n和目前开源的Coze这几个工具各有其优势。但是，在实际使用中，为了追求更符合个人或者单位要求的效果，通常会将这些工具或者平台的优势集成起来，以便充分发挥各自的优势，今天这篇文章，就是在主要使用Dify的基础上，集成RAGFlow的知识召回能力，从而实现更可靠的知识检索能力。\n一、创建知识库\n首先部署好RAGFlow应用程序，然后创建知识库，点击知识库–创建知识库–填写知识库名称（更具个人需求自定义）–点击确定创建完成：\n刚刚创建的知识库上传文档，点击打开刚刚创建的知识库–点击创建文件–上传准备好的知识库文档–点击文档对应的运行按钮进行解析（之后解析后的文档才能用作知识库检索）–等到检索完成方可使用。\n二、设置知识库API KEY\n2.1、获取RAGFlow的API KEY\n在RAGFlow界面中，点击自己的头像–选择左侧的API菜单–点击API KEY–点击创建秘钥（用于后期对接Dify外部知识库）。\n2.2、获取RAGFlow的知识库ID\n选择自己的知识库，然后点击打开，在浏览器地址栏可以看到id=后面的内容即为知识库ID。\n三、Dify连接外部知识库\n虽然Dify本身就带有知识库能力，而且在使用中也还不错，但是相对于RAGFlow，其自身的文档解析能力就显得相对不足了，而RAGFlow在这方面的表现却显得格外出色。既然这样，我们完全可以使用Dify优秀的工作流和其他方面的能力，借助其提供的对接外部知识库的API，对接RAGFlow优秀的知识库构建和召回能力，完成我们的应用构建准确性和完整性，取长补短，使其可以从RAGFlow的知识库中进行知识检索和召回，让效果达到理想的状态。具体设置过程如下：\n 在Dify主界面，选择知识库，点击外部知识库API:\n在弹出的界面选择添加外部知识库API：\nName选项随便，根据自己的定义随便起名即可，API Endpoint处填写： http://实际ip:80/api/v1/dify/ ,\n 需要将端点（endpoint）设置为本地IP地址，并加上/api/v1/dify作为后缀，dify会在应用程序中自动添加retrieval，从而形成完整的路径 /api/v1/dify/retrieval ，API KEY选项填写刚刚RAGFlow生成的API KEY，最好复制粘贴，手动容易敲错！完成之后点击保存即可。\n经过上述操作，已经将外部知识库RAGFlow与Dify进行了集成，此时只需要连接外部知识库即可完成正常使用。\n3.1、连接外部知识库\n在Dify知识库主页，点击“连接外部知识库”，将进入连接设置界面：\n在设置界面填写连接名称，根据需要自行填写，然后选自外部知识库API（因前期已经集成，所有这里直接选择即可），输入外部知识库ID（同样建议复制粘贴，以免错误），然后设置召回个数和阈值，点击连接：\n3.2、测试召回\n完成之后，自动进入测试界面，或者在知识库主界面就能看到刚刚连接的知识库，点击也可进入测试界面，在这里可以测试召回准确性了，下图是在Dify中进行“标准”两个字测试召回的内容：\n下图是在RAGFlow中对该知识库同样进行“标准”二字的测试效果，可以看到，在阈值和召回个数完全相同的情况下，召回的内容一模一样：\n经过上述操作，就在Dify中深度集成了RAGFlow知识库了，实现了强强联合的工作方式。\n聊一聊\n在智能体构建的过程中，需要不断学习与总结，RAGFlow对知识库的构建确实很不错，近期也比对了一些其他平台，最终选择Dify+RAGFlow进行应用构建，结合自研前端，实现部分功能！\n如何学习AI大模型 ？\n“最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。\n这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。\n我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。\n我意识到有很多经验和知识值得分享给大家，故此将并将重要的AI大模型资料包括 AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。【保证100%免费】    \nCSDN粉丝独家福利\n这份完整版的 AI 大模型学习资料已经上传CSDN，朋友们如果需要可以 扫描下方二维码 & 点击下方CSDN官方认证链接 免费领取  【保证100%免费】\n 读者福利：          CSDN大礼包：《最新AI大模型学习资源包》免费分享         \n （            安全链接，放心点击） \n对于0基础小白入门：\n如果你是零基础小白，想快速入门大模型是可以考虑的。\n一方面是学习时间相对较短，学习内容更全面更集中。\n 二方面是可以根据这些资料规划好学习计划和方向。\n    1.大模型入门学习思维导图    \n要学习一门新的技术，作为新手一定要先学习成长路线图，方向不对，努力白费。\n对于从来没有接触过AI大模型的同学，我们帮你准备了详细的学习成长路线图&学习规划。可以说是最科学最系统的学习路线，大家跟着这个大的方向学习准没问题。 （全套教程文末领取哈）\n    2.AGI大模型配套视频    \n很多朋友都不喜欢晦涩的文字，我也为大家准备了视频教程，每个章节都是当前板块的精华浓缩。\n    3.大模型实际应用报告合集    \n这套包含640份报告的合集，涵盖了AI大模型的理论研究、技术实现、行业应用等多个方面。无论您是科研人员、工程师，还是对AI大模型感兴趣的爱好者，这套报告合集都将为您提供宝贵的信息和启示。 （全套教程文末领取哈）\n    4.大模型实战项目&项目源码    \n光学理论是没用的，要学会跟着一起做，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战项目来学习。 （全套教程文末领取哈）\n    5.大模型经典学习电子书    \n随着人工智能技术的飞速发展，AI大模型已经成为了当今科技领域的一大热点。这些大型预训练模型，如GPT-3、BERT、XLNet等，以其强大的语言理解和生成能力，正在改变我们对人工智能的认识。 那以下这些PDF籍就是非常不错的学习资源。 （全套教程文末领取哈）\n    6.大模型面试题&答案    \n截至目前大模型已经超过200个，在大模型纵横的时代，不仅大模型技术越来越卷，就连大模型相关的岗位和面试也开始越来越卷了。为了让大家更容易上车大模型算法赛道，我总结了大模型常考的面试题。 （全套教程文末领取哈）\n为什么分享这些资料?\n只要你是真心想学AI大模型，我这份资料就可以 无偿分享 给你学习，我国在这方面的相关人才比较紧缺，大模型行业确实也需要更多的有志之士加入进来，我也真心希望帮助大家学好这门技术，如果日后有什么学习上的问题，欢迎找我交流，有技术上面的问题，我是很愿意去帮助大家的！\n这些资料真的有用吗?\n这份资料由我和鲁为民博士共同整理，鲁为民博士先后获得了北京清华大学学士和美国加州理工学院博士学位，在包括IEEE Transactions等学术期刊和诸多国际会议上发表了超过50篇学术论文、取得了多项美国和中国发明专利，同时还斩获了吴文俊人工智能科学技术奖。目前我正在和鲁博士共同进行人工智能的研究。\n资料内容涵盖了 从入门到进阶的各类视频教程和实战项目 ，无论你是小白还是有些技术基础的，这份资料都绝对能帮助你 提升薪资待遇，转行大模型岗位。\nCSDN粉丝独家福利\n这份完整版的 AI 大模型学习资料已经上传CSDN，朋友们如果需要可以 扫描下方二维码&点击下方CSDN官方认证链接免费领取 【保证100%免费】\n读者福利：          CSDN大礼包：《最新AI大模型学习资源包》免费分享         \n （            安全链接，放心点击）"
  },
  {
    "title": "视频教程：学习打造AI大型模型的技巧与步骤详解_技术_数据_阶段",
    "page_body": "随着人工智能技术的迅猛进步，视频内容创作迎来了崭新的变革。构建基于AI大模型的视频生成系统成为企业、创作者乃至个人用户竞相探索的方向。本文将深入探讨这一系统的技术实现途径和核心操作，详细说明构建这类系统的关键成分。\n视频生成系统的效果深受高质量数据集影响。以一家知名短视频平台的数据为例，其素材库涵盖2亿余条标注资料，涵盖动作捕捉、语音识别、场景分类等多个维度。数据处理需重视以下三个方面：\n一是多模态数据的融合。要集成视频帧序列、音频波形、文字描述等多元化信息，推荐采用时间戳对齐技术来确保数据在各模态间的时序一致性。\n二是确立数据清洗规范。应构建动态的清洗机制，这包括移除分辨率低下的素材（低于720p者需重采样），清除重复内容（相似度阈值建议设置于85%以上），并利用3σ原则排除异常帧。\n三是特征工程的优化。建议结合CV的传统特征提取（例如HOG、SIFT）与深度学习方法（ResNet-152的图像特征提取），采用PCA方法对特征进行降维，将维度控制在1000以下。\n现有主流的系统采用分层架构设计。某国际实验室的经验证实，三阶段训练法能让模型收敛速度提升40%，具体措施包括：\n在基础模型的选择上，由于Transformer在处理长序列时有显著优势，故建议选用ViT-H/14作为视觉编码器，音频处理部分选用Conformer模型，其在语音特征提取中表现卓越。\n在混合训练策略上，第一阶段实施固定学习率（3e-5）的预训练，第二阶段改用余弦退火（初始学习率lr=5e-5），第三阶段则执行课程学习（逐级提高难度级别的数据输入）。\n在显存优化技术方面，梯度检查点技术可减少30%显存占用，混合精度训练与动态loss scaling在A100显卡上能实现1.8倍的速度提升，而分布式训练则推荐使用ZeRO-3优化器，根据集群规模动态调整数据并行度。\n生成阶段中的三个关键模块需协同优化，以实现流畅的视觉呈现：\n一是利用基于物理引擎的动力学模型和LSTM网络的混合架构进行运动轨迹预测，将动作预测误差控制在3.2%以下，案例显示，这一方案可将角色动画的自然度提升57%。\n二是利用端到端的音素-口型映射模型和3D面部网格变形技术，实现口型与语音的同步，开源项目Live3D的数据测试表明，误差小于83ms时，人眼几乎察觉不到差异。\n三是通过引入时空注意力机制和采用马尔可夫随机场进行全局一致性约束，控制场景连贯性，使场景跳变率降低至0.7次/分钟。\n部署阶段则需要建立一个全面的评估体系：\n在实时性优化上，结合模型量化和层融合技术，在NVIDIA T4显卡上实现1080p视频的实时生成（24FPS），并通过知识蒸馏技术将模型体积压缩至原始体积的23%，推理速度提升3倍。\n在质量评估指标方面，除了PSNR和SSIM之外，还应考虑运动自然度评分、语义一致性指数和情感识别准确率等。\n在设计容错机制时，应建立异常检测模块，在出现图像变形或逻辑矛盾时，自动触发重生成机制，重试次数建议最多三次。\n尽管AI视频生成技术已进入实用阶段，但要完全取代人工创作仍有一段距离。值得注意的是，结合物理仿真引擎和神经渲染技术的策略可能是突破当前技术局限的关键。在实际应用中，推荐采取人机协同策略，AI负责素材生成和初步筛选，而人类创作者则聚焦创意设计和效果优化。这种方法已经在多个MCN机构得到验证，可将内容生产效率提升5-8倍。技术的本质是拓宽创作边界，而不是取代人类创造力。\n文章来源：https://news.huochengrm.cn/cyzx/38042.html"
  },
  {
    "title": "Transformer有可能替代CNN吗？未来有哪些研究方向？听听大家都怎么说",
    "page_body": "机器之心报道\n机器之心编辑部\nTransformer 有可能替代 CNN 吗？现在下结论还为时过早。\nTransformer 的跨界之旅，从 2020 延续到了 2021。\n2020 年 5 月，Facebook AI 推出了 Detection Transformer（DETR），用于目标检测和全景分割。这是第一个将 Transformer 成功整合为检测 pipeline 中心构建块的目标检测框架， 在大型目标上的检测性能要优于 Faster R-CNN。\nDETR-R101 处理的全景分割结果。\n2020 年 10 月，谷歌提出了 （ViT），能直接利用 Transformer 对图像进行分类，而不需要卷积网络。该模型可以获得与当前最优卷积网络相媲美的结果，但其训练所需的计算资源大大减少。谷歌在论文中写道：这项研究表明，对 CNN 的依赖不是必需的。当直接应用于图像块序列时，transformer 也能很好地执行图像分类任务。\n2020 年 12 月，复旦大学、牛津大学、腾讯等机构的研究者提出了 SEgmentation TRansformer（SETR），将语义分割视为序列到序列的预测任务，该模型在 ADE20K 上排名第一，性能优于 OCNet、GCNet 等网络。\n元旦刚过，OpenAI 又 ，用 DALL·E 和 CLIP 打破了自然语言与视觉的次元壁。两个模型都利用 Transformer 达到了很好的效果，前者可以基于本文直接生成图像，后者则能完成图像与文本类别的匹配。\nDALL·E 示例。给出一句话「牛油果形状的椅子」，就可以获得绿油油、形态各异的牛油果椅子图像。\n这些研究覆盖了图像分类、目标检测、语义分割等 CV 主流方向。因此有人提问：未来，Transformer 有可能替代 CNN 吗？\n这一问题在知乎、Reddit 等平台上都有人讨论。从讨论的结果来看，大部分人认为 Transformer 和 CNN 各有优劣，二者可能并非取代和被取代的关系，而是互相融合，取长补短。从研究现状来看，Transformer 在 CV 领域的应用还需要解决计算效率低等问题。\nTransformer 取代 CNN？下结论还为时过早\n在知乎讨论区，用户 @小小将指出，「目前我们看到很大一部分工作还是把 transformer 和现有的 CNN 工作结合在一起」。以 DETR 为例，该模型使用 CNN 从图像中提取局部信息，同时利用 Transformer 编码器 - 解码器架构对图像进行整体推理并生成预测。\n声称「对 CNN 的依赖并非必需」的 ViT 模型可能也不例外。@小小将表示，「ViT 其实也是有 Hybrid Architecture（将 ResNet 提出的特征图送入 ViT）」。@mileistone 也认为，「（ViT）文章里提出的方法中会将图片分成多个无 overlap 的 patch，每个 patch 通过 linear projection 映射为 patch embedding，这个过程其实就是卷积，跟文章里声称的不依赖 CNN 自相矛盾。」\n由于 CNN 和 Transformer 各有优势和不足，这种融合的做法出现在很多 Transformer 的跨界论文中。\n在解释 CNN 和 Transformer 各自的优缺点时，用户 @齐国君提到，「CNN 网络在提取底层特征和视觉结构方面有比较大的优势。这些底层特征构成了在 patch level 上的关键点、线和一些基本的图像结构。这些底层特征具有明显的几何特性，往往关注诸如平移、旋转等变换下的一致性或者说是共变性。CNN 网络在处理这类共变性时是很自然的选择。但当我们检测得到这些基本视觉要素后，高层的视觉语义信息往往更关注这些要素之间如何关联在一起进而构成一个物体，以及物体与物体之间的空间位置关系如何构成一个场景，这些是我们更加关心的。目前来看，transformer 在处理这些要素之间的关系上更自然也更有效。」\n从现有的研究来看，二者的结合也确实实现了更好的结果，比如近期的《Rethinking Transformer-based Set Prediction for Object Detection》「还是把现有的 CNN 检测模型和 transformer 思想结合在一起实现了比 DETR 更好的效果（训练收敛速度也更快）」（引自 @小小将）。反过来说，如果全部将 CV 任务中的 CNN 换成 Transformer，我们会遇到很多问题，比如计算量、内存占用量大到无法接受。\n未来研究思路\nTransformer 的跨界之旅还在继续，那么未来有哪些可能的研究思路呢？\n去年 12 月，来自华为诺亚方舟实验室、北京大学、悉尼大学的研究者整理了一份综述，详细归纳了多个视觉方向的 Transformer 模型。\n论文链接：https://arxiv.org/pdf/2012.12556.pdf\n此外，他们还在论文中初步思考并给出了三个未来的研究方向：\n现有的 Visual Transformer 都还是将 NLP 中 Transformer 的结构套到视觉任务做了一些初步探索，未来针对 CV 的特性设计更适配视觉特性的 Transformer 将会带来更好的性能提升。\n现有的 Visual Transformer 一般是一个模型做单个任务，近来有一些模型可以单模型做多任务，比如 IPT，未来是否可以有一个世界模型，处理所有任务？\n现有的 Visual Transformer 参数量和计算量多大，比如 ViT 需要 18B FLOPs 在 ImageNet 达到 78% 左右 Top1，但是 CNN 模型如 GhostNet 只需 600M FLOPs 可以达到 79% 以上 Top1，所以高效 Transformer for CV 亟需开发以媲美 CNN。（引自 @kai.han）\n类似的综述研究还有来自穆罕默德 · 本 · 扎耶德人工智能大学等机构的《Transformers in Vision: A Survey》。\n论文链接：https://arxiv.org/pdf/2101.01169.pdf\n有志于 Transformer 跨界研究的同学可以在读完综述后寻找自己感兴趣的研究方向。\n参考链接：https://www.zhihu.com/question/437495132\nNature论文线上分享 | 世界最快光子AI卷积加速器\n世界最快光子AI卷积加速器登上Nature，该研究展示的是一种\"光学神经形态处理器\"，其运行速度是以往任何处理器的1000多倍，该系统还能处理创纪录大小的超大规模图像——足以实现完整的面部图像识别，这是其他光学处理器一直无法完成的。\n1月18日19:00，论文一作、莫纳什大学研究员徐兴元博士带来线上分享，详细介绍他们的工作以及光学芯片领域进展。\n添加机器之心小助手（syncedai5），备注「光子」，进群一起看直播。\n© THE END\n转载请联系本公众号获得授权\n投稿或寻求报道：content@jiqizhixin.com\n原标题：《Transformer有可能替代CNN吗？未来有哪些研究方向？听听大家都怎么说》"
  },
  {
    "title": "多头注意力机制：Multi-Head Self-Attention-CSDN博客",
    "page_body": "Multi-Head Self-Attention得到的新的词向量可以比Self-Attention得到的词向量有进一步提升。\n1 为什么要MultiHeadAttention\n1.1 多头的原理\n经过上面内容的介绍，我们算是在一定程度上对于自注意力机制有了清晰的认识，不过在上面我们也提到了自注意力机制的缺陷就是：**模型在对当前位置的信息进行编码时，会过度的将注意力集中于自身的位置，**因此作者提出了通过多头注意力机制来解决这一问题。同时，使用多头注意力机制还能够给予注意力层的输出包含有不同子空间中的编码表示信息，从而增强模型的表达能力。\n在说完为什么需要多头注意力机制以及使用多头注意力机制的好处之后，下面我们就来看一看到底什么是多头注意力机制。\n如图7所示，可以看到所谓的多头注意力机制其实就是将原始的输入序列进行多组的自注意力处理过程；然后再将每一组自注意力的结果拼接起来进行一次线性变换得到最终的输出结果。具体的，其计算公式为：\n 对于第2个头来说有：\n说了这么多，终于把铺垫做完了。此时，假如有如图13所示的头注意力计算过程\n如图13所示，该计算过程采用了头注意力机制来进行计算，且头的计算过程还可通过图14来进行表示。"
  },
  {
    "title": "BERT模型论文解读，并基于MindSpore NLP推理复现-昇思MindSpore",
    "page_body": "BERT（Bidirectional Encoder Representations from Transformers）是一种预训练的自然语言处理（NLP）模型，由 Google 于2018年提出论文《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》（ https://arxiv.org/abs/1810.04805 ）\n在NLP领域应用预训练和微调前计算机视觉方向已经广泛采用这种方式BERT的提出 将NLP的结合了预训练和微调带到了一个新的领域。\n下面开始对该模型进行解读。\n# 01  架构\nBERT 是由多层 Transformer 编码器Encoder 堆叠而成。\n它分为以下两种：\nBERT-base：12 层 Encoder，隐藏层维度为 768，注意力头数为 12。\nBERT-large：24 层 Encoder，隐藏层维度为 1024，注意力头数为 16。\nI am eating a banana 经过bert编码器编码的句子类似 [CLS]I am eating a banana[SEP] [PAD] [PAD]\n前[CLS]表示可以用于下游任务，后[SEP]表示句子的结束[PAD]用于填充防止句子长度不同。\n# 02  模型的创新点：\n1、 BERT 通过 遮蔽语言模型（MLM） 任务\n利用双向上下文来训练模型。在训练时，它随机遮蔽输入中的一些单词（利用[mask]遮蔽句子中的部分信息），然后让模型同时从左边和右边的上下文信息预测这些单词。\n其中  80%  替换为  [MASK] ；10% 替换为随机 token；10% 保持不变。\nToken Embeddings--> 词嵌入\nSegment Embeddings---> 句子嵌入\nPosition Embeddings---> 位置嵌入(区别于GPT1的正余弦编码)\n输入 BERT 之前， 每个 token 由 词嵌入、句子嵌入和位置嵌入  组成。它们的  向量相加  后送入 BERT 进行训练或推理。\n2、 下一句预测（Next Sentence Prediction, NSP）\n传统方法的局限性：忽视了句子之间的关系。\nBERT 的创新：BERT 在预训练时引入了 下一句预测（NSP） 任务，该任务帮助模型理解句子之间的逻辑关系。模型被给定两句文本，任务是判断第二句是否为第一句的下文。\n3、 BERT 使用了预训练-微调（Pre-training and Fine-tuning）\n预训练: 在大规模无标签的语料上进行预训练。\n语料：BooksCorpus(Zhu et al., 2015) 和英文维基百科（25亿词只提取文本段落，忽略列表、表格和标题）\n通过 MLM 和 NSP 任务学习语言的通用表示---->好处：能够大大减少对标注数据的依赖\n微调:  模型适应下游任务（如文本分类等）。-->好处：提高了模型在多个任务上的性能\n# 03  BERT区别于其他模型\n# 04  效果\n1、GLUE 测试\nBERT 通过 [CLS] 位置的向量 C 进行分类，添加全连接层 W 并使用交叉熵损失进行微调。\n效果：BERTLARGE 比 SOTA 提高 7.0% 平均准确率。MNLI 任务提升 4.6% 绝对准确率。BERTLARGE 在小数据集表现更优。\n超参数Batch size = 32，Fine-tune 3 epochs，学习率 5e-5, 4e-5, 3e-5, 2e-5。\n2、SQuAD任务\n采用 [CLS] 预测无答案，两个向量 S 和 E 预测答案起止位置。\nSQuAD v1.1： BERTLARGE (单模型)  F1 = 90.9% ，超越 SOTA。集成模型提升至  F1 = 92.2% 。\nSQuAD v2.0：F1 提高 5.1 ，无答案处理能力增强。\n3、SWAG 任务\n4 个候选句，每个与 sentence A 组成输入，[CLS] 位置表示选择最佳答案。\nBERTLARGE比 OpenAIGPT 高 8.3% ，比 ELMo提升 27.1% 。\n# 05  总结\n去掉 NSP-->对问答任务影响大。\n采用左到右语言模型（LTR）表现下降，说明 BERT 的 双向性 关键。\n# 06  实操\n1、Mindspore仓进行基于bert的情感分类预测步骤\n相关代码已上传到昇思代码仓：\nhttps://github.com/mindspore-lab/mindnlp/tree/master/applications/bert\n参考：基于MindSpore的bert模型实验指导书——\nhttps://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=ed8761c1-a0d8-4ea7-ab10-5d72cd5467b2\n步骤：\n1.安装MindSpore框架和MindSpore NLP套件；\n2.用bert分词库进行分词；\n3.进行模型的训练和推理。\n2、pytorch中用于文本分类的示例\n情感分类验证集性能"
  },
  {
    "title": "融合教学中探究初中历史作业的设计_理论学术_科学导报",
    "page_body": "摘要： 中考评价体系以深入研究事物本身的完整性和整体性作为出发点，能够充分体现出中考在核心价值正确引领下全方位考查学生的素养融合、能力复合和知识交叉，这代表着在精心设计初中学科作业时，需要对学科融合特点与当前时代发展进行充分考虑。包罗万象是历史这门学科具备的鲜明特点，其中会涉及诸多方面内容，这也就直接决定在设计初中历史作业时应从历史学科思维入手，并在此基础之上综合运用不同学科知识，从而更好培养学生核心素养和提升学生综合能力。本文主要探讨在学科融合教学中设计初中历史学科作业的有效策略。\n关键词： 初中教育；历史作业；设计策略\n作业在拓展延伸课堂教学和复习巩固学习内容上发挥着不可估量的作用。国务院办公厅印发文件明确指出，若想促进作业设计质量切实提高，充分发挥出作业学情分析、巩固和诊断等诸多功能，则应在教研体系中合理融入作业设计，精心设计出与学生学习规律及年龄特点相符合的基础性作业。\n一、立足核心素养，科学制定作业测量目标\n所谓核心素养，实际上是学生在认真学习学科知识过程中潜移默化形成并树立的正确三观、关键能力以及必备品格，同时也是学科育人价值最终体现。从某种意义上来讲，核心素养具有一定超学科性，可以直接决定设计出来的历史作业能够避免重复而又简单的学习任务，所以广大教育者应广泛关注合理整合和相互交叉跨学科内容，彻底打破各门学科知识之间互不干扰的状态，科学设计出以核心素养作为关键测量目标的历史作业，积极引导初中生以开放式这种思维方式对不同学科知识之间存在的内在联系进行综合运用，以此妥善解决历史问题。例如，以历史教材《最可爱的人》这节内容和语文教材上《谁是最可爱的人》这篇课文为依据设计作业，为学生播放关于抗美援朝的系列电影，让学生充分了解中国人民志愿军的英勇事迹。正确引导学生在将作业高质高效完成中对各学科知识进行综合运用，全面发展家国情怀与历史解释等诸多学科核心素养[1]。\n二、创设综合情境，促进作业思维含量提升\n学生是否可以直面应对和妥善解决既开放又复杂得生动逼真问题情境是对其核心素养进行检验的重要方面。所以，在测试学生课后作业核心素养目标过程中，应从多方面，多维度和多层次创设问题情境，逐步引导学生在具体情境当中动脑思考与合理解决问题，以此全面检测和正确评价学生自身核心素养水平。通常情况下，教师在为学生设计历史作业时大多是从学术成果、历史文献史料以及现实材料等诸多角度入手来合理创设社会、学习以及生活等情境。积极引导学生对课堂所学知识进行合理整合，这可以让学生实践思维得到良好培养，从而促进在多学科知识实现背景下，对学生综合运用能力与知识进行有效考察。例如，在学习《统一国家的建立》这单元内容时，初中历史教师应为学生布置如下作业：以《战国策》为依据，将秦国之所以能够统一六国的原因提炼出来，翻阅和查找相关史料记载进行论证。布置第一项作业是为了让学生熟悉教材，从教材中获取有效信息并归纳总结，从而促进学生形成对学科融合知识进行合理运用综合分析历史成因良好思维意识。\n基于学科融合视域背景下，初中历史教师在为学生设计作业时，应将学科课程教学孤立性与封闭性彻底打破，全面克服知识学习零散化及碎片化，将历史这门学科作为核心主体，充分把握其与其他文化学科能力和知识之间的契合点，深度融合与科学设计不同领域的学科知识，让初中生妥善解决各种实际问题思维的完整性更强，促进学生问题解决能力切实提高，让学生个体创新思维品质得到良好培养，推动学生全面发展。\n参考文献：\n[1]刘霞.减负增效背景下初中历史作业设计的优化[J].黑龙江教育(教育与教学),2021(09):89-90.\n（作者单位：江苏省常州市新北区安家中学 郑 娟）"
  },
  {
    "title": "零基础入门AI：手把手实现你的第一个手写数字识别模型（Python+TensorFlow）一、为什么从手写数字识别开始？掘金",
    "page_body": "一、为什么从手写数字识别开始？\nMNIST数据集在AI界的地位类比\"Hello World\" 计算机视觉任务的典型代表：图像分类 适合初学者的3大理由：数据干净/模型简单/效果直观\n二、环境准备（5分钟搞定）\n使用Google Colab免配置环境（附直达链接） 本地开发环境搭建指南（Python 3.8+ / TensorFlow 2.x）\nbash\n体验AI代码助手\n代码解读\n复制代码\nbash # 代码片段（Shell） pip install tensorflow matplotlib numpy\n三、核心概念图解（小白友好版）\n神经网络的「乐高积木」思维：输入层/隐藏层/输出层 激活函数：给神经元加上「开关」的ReLU 损失函数：模型的「错题本」Cross-Entropy 优化器：自动调整学习节奏的Adam\n四、实战四步曲\n1. 数据预处理（关键注释版）\nini\n体验AI代码助手\n代码解读\n复制代码\npython # 代码片段（Python） from tensorflow.keras.datasets import mnist # 加载数据（自动下载） (train_images, train_labels), (test_images, test_labels) = mnist.load_data() # 归一化：把0-255的像素值压缩到0-1之间（提高训练效率） train_images  = train_images.reshape(( 60000 ,  28  *  28 )).astype( 'float32' ) /  255 test_images  = test_images.reshape(( 10000 ,  28  *  28 )).astype( 'float32' ) /  255\n2. 构建你的第一个神经网络\nini\n体验AI代码助手\n代码解读\n复制代码\npython # 代码片段（Python） from tensorflow.keras import models, layers # 像搭积木一样创建模型 model  = models.Sequential([     layers.Dense( 512 , activation= 'relu' , input_shape=( 28  *  28 ,)),   # 隐藏层     layers.Dense( 10 , activation= 'softmax' )   # 输出层（10个数字概率） ]) # 模型装配说明书 model.compile( optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics =[ 'accuracy' ] )\n3. 训练过程可视化\nini\n体验AI代码助手\n代码解读\n复制代码\npython # 代码片段（Python） history  = model.fit(     train_images,      train_labels, epochs = 5 , batch_size = 128 , validation_split = 0.2 # 自动划分验证集 ) # 绘制准确率曲线（附效果图） import matplotlib.pyplot as plt plt.plot(history.history ['accuracy'] ,  label = '训练集' ) plt.plot(history.history ['val_accuracy'] ,  label = '验证集' ) plt.title('模型学习进度') plt.xlabel('训练轮次') plt.ylabel('准确率') plt.legend()\n4. 模型测试与使用\npython\n体验AI代码助手\n代码解读\n复制代码\npython # 代码片段（Python） test_loss, test_acc = model.evaluate(test_images, test_labels) print ( f'测试集准确率： {test_acc: .4 f} ' ) # 实际预测示例 import  numpy  as  np sample_image = test_images[ 0 ].reshape( 1 ,  784 )   # 取第一张测试图 prediction = model.predict(sample_image) print ( f'模型预测结果： {np.argmax(prediction)} ' ) print ( f'真实标签： {test_labels[ 0 ]} ' )\n五、效果优化指南\n调整epochs观察过拟合现象（对比3轮 vs 20轮训练） 尝试添加Dropout层防止过拟合 可视化错误样本：哪些数字容易被混淆？\n六、下一步学习建议\n挑战升级：用CNN实现99%+准确率 实战延伸：训练自己的表情识别模型 避坑指南：初学者常犯的5个数据预处理错误"
  },
  {
    "title": "大模型从入门到实践：核心概念、发展历程、应用场景及开源学习指南-CSDN博客",
    "page_body": "一、大模型的核心概念\n大型语言模型（Large Language Model，简称LLM） ，也常被称为大模型或大 语言模型 ，是自然语言处理（NLP）领域的深度学习模型。这类模型通常包含数千亿甚至更多参数，这些参数通过海量文本数据训练得来——从书籍、网页到论文，覆盖各类语言素材。像GPT-3、PaLM、LLaMA等都是典型代表，它们的核心能力是理解自然语言并生成相关内容：通过学习海量文本中的规律，模型能预测下一个词的出现概率，或围绕给定文本生成逻辑连贯的内容。\n简单来说，参数是模型学习任务时“记住”的关键信息。参数数量与模型的复杂程度、学习潜力直接相关：参数越多，模型能捕捉的语言细节越丰富，往往具备更强的上下文理解和内容生成能力。\n1、语言模型的进化之路\n语言是人类独有的高级交流工具，从幼儿学语到成人沟通，贯穿一生。但让机器像人类一样“读、写、聊”，曾是人工智能领域的长期难题——直到以ChatGPT为标志的大模型技术爆发，这一目标才真正迎来突破。大模型是语言模型发展的高级阶段，其进化可分为四个关键阶段，每个阶段都推动着机器对语言的理解迈上新台阶：\n统计语言模型 ：早期阶段，依赖概率统计方法（如n-gram）计算词序列的出现概率。例如通过统计“我吃饭”“我喝水”的频率，预测“我”后面更可能接“吃饭”还是“喝水”。但这类模型难以捕捉长距离语义关联，局限性明显。 神经网络语言模型 ：随着深度学习兴起，RNN（循环神经网络）、LSTM等模型开始用于语言建模。它们能通过神经网络捕捉词与词的语义联系，比如“苹果”既可以指水果，也可以指品牌，模型能通过上下文初步判断。但受限于网络结构，处理长文本时容易“遗忘”前文信息。 预训练语言模型 ：引入“预训练+微调”模式（如BERT、GPT-1），先在海量文本上训练通用语言能力，再针对具体任务（如情感分析、翻译）用小数据微调。这一阶段，模型首次具备跨任务的语言理解能力，但参数规模仍在亿级水平。 大语言模型 ：基于Transformer架构（尤其是解码器），参数规模跃升至千亿级，训练数据也扩展到万亿词级别。模型能通过“上下文学习”直接完成新任务（无需微调），比如只需给一个示例，就能按格式生成诗歌或代码。GPT-3、LLaMA等均属此类，真正实现了“通用语言智能”的突破。\n从技术本质看，语言模型的核心是对“词序列生成概率”建模——通过预测下一个词（或补全空缺词），让机器逐步掌握人类的语言逻辑。这一研究在学术界和产业界始终热度不减，而ChatGPT的走红正是大模型能力的集中体现：它基于GPT-3.5架构，训练数据涵盖数十亿词，能回答问题、写文章、编代码、做翻译，甚至表现出一定的共情能力。\n简单说， 当模型的参数规模、训练数据量和计算量达到“质变”级别，能展现出强大的通用语言能力时，就可以称为大模型 。\n2、OpenAI的大模型演进历程\nOpenAI的GPT系列是大模型发展的标杆，其演进路径清晰展现了技术突破的关键节点：\nGPT-1（2018） ：首次将Transformer解码器用于语言建模，参数约1.17亿，验证了“预训练+微调”模式在语言任务上的潜力。 GPT-2（2019） ：参数增至15亿，训练数据量扩大10倍，无需微调即可完成部分文本生成任务，展现出“零样本学习”能力。 GPT-3（2020） ：参数跃升至1750亿，通过“少样本学习”（给几个示例）就能完成翻译、编程等复杂任务，成为首个引发广泛关注的大模型。 GPT-3.5（2022） ：在GPT-3基础上优化，引入人类反馈强化学习（RLHF）技术，对话流畅度和上下文理解能力大幅提升——2022年11月发布的ChatGPT正是基于此版本，凭借自然的交互体验迅速走红全球。 GPT-4（2023） ：支持多模态输入（文本+图像），参数规模和训练数据进一步扩大，在逻辑推理、复杂任务处理上接近人类专家水平，目前仍在持续迭代。\n除OpenAI外，国内外企业和机构也纷纷布局大模型赛道：国内如百度文心一言、阿里通义千问、华为盘古大模型；国际如谷歌Gemini、 Anthropic Claude等。截至2023年中，全球已有上百个大模型问世，技术迭代速度堪称“一日千里”。\n3、预训练技术：大模型的“地基”\n大模型的强大能力源于“预训练”这一核心技术——先让模型在海量文本中学习通用语言规律，再通过微调适配具体场景。其技术框架以Transformer解码器为核心（见参考文献20），能高效捕捉长文本中的语义关联。\n3.1 指令微调：让模型“听懂任务”\n预训练后的模型虽掌握语言规律，但未必能理解具体任务（如“写一封道歉信”“总结这段话”）。指令微调通过“指令+示例”形式的数据（如“请翻译：‘我爱中国’→‘I love China’”）训练模型，使其能快速理解人类指令的含义。\n与预训练相比，指令微调样本量更小（通常几万到几十万），但效率更高——通过有监督学习，模型能针对性优化任务响应能力，比如调整学习率和批大小，让输出更贴合指令要求。\n3.2 对齐微调：让模型“贴合人类价值观”\n即使模型能理解任务，其输出也可能不符合人类伦理（如生成有害内容）。对齐微调的目标是让模型行为与人类价值观一致，常用方法包括基于人类反馈的强化学习（RLHF）。\n但研究发现，这种对齐可能导致“对齐税”——为了更安全、更符合人类预期，模型在某些通用任务上的表现可能略有下降。例如，一个经过对齐的模型可能为了避免争议，在回答复杂逻辑问题时比未对齐模型稍显“保守”。\n二、ChatGPT：大模型技术的“破圈者”\n2022年11月30日，OpenAI发布的ChatGPT掀起了全球人工智能热潮。与此前的AI系统不同，ChatGPT不仅能完成对话、摘要、代码编写等任务，更在交互中展现出接近人类的连贯性和共情能力——比如在安慰用户时用温和语气，在解释问题时循序渐进。\n这种突破源于其技术内核：基于GPT-3.5架构，结合RLHF（人类反馈强化学习）技术，让模型在理解语言的同时，学会“怎么说”更符合人类沟通习惯。其底层是Transformer的自注意力机制，能精准捕捉上下文关联（比如记住对话中提到的“昨天的会议”指哪次）。\n作为GPT系列的应用，ChatGPT让大众直观感受到大模型的潜力：它能写邮件、改代码、解数学题，甚至帮学生构思作文。这种“通用能力”让人们首次相信，通用人工智能（AGI）的实现并非遥不可及。\n值得一提的是，GPT-3作为大模型的里程碑，1750亿参数使其能处理复杂语言任务——这印证了“规模即能力”的逻辑：足够大的参数和数据，能让模型涌现出推理、联想等高级能力。\n三、大模型的应用场景：重塑千行百业\n大模型被视为“第四次AI革命”的核心驱动力，其价值体现在对个人、企业、社会的全方位革新。除了广为人知的内容生成，还有更多场景正在被重塑：\n1、内容生成：释放创造力\n这里的“内容”涵盖文本、图像、视频、代码等，大模型正成为创作者的“超级助手”：\n文本生成 ：为自媒体、作家等提供灵感——比如输入“写一篇关于秋天的散文开头”，模型能生成多个风格的段落，创作者在此基础上优化即可，效率提升显著。 智能摘要 ：帮科研人员快速提炼论文核心观点，或帮职场人总结冗长会议纪要，节省80%的阅读时间。 图像生成 ：基于文字描述生成逼真图像（如“赛博朋克风格的故宫”），Midjourney、Stable Diffusion等工具已广泛用于广告设计、游戏美术，甚至替代部分插画师工作。 视频生成 ：虽处于发展阶段，但已能基于文本生成短时长视频（如“生成一段海浪拍打礁石的10秒视频”），未来将革新影视剪辑、教学视频制作等领域。 代码生成 ：GitHub的Copilot工具基于大模型，能自动补全代码、生成函数，据统计已助力30%的新代码编写，尤其对初级程序员的工作模式产生深远影响。\n2、智能交互：重构沟通方式\n对话助手 ：从客服到私人助理，大模型让交互更自然。比如智能客服能理解用户的模糊需求（“我的订单没收到，不是昨天那个”），无需用户按固定格式提问。 教育辅导 ：个性化学习成为可能——模型能根据学生的错题分析薄弱点，用通俗语言讲解知识点，比如给小学生讲“微积分”时用“切蛋糕”类比。\n3、行业赋能：提升产业效率\n医疗领域 ：辅助医生分析病历（如从CT报告中提取关键指标），或为患者提供初步问诊建议（需结合专业医生判断）。 法律领域 ：快速检索案例、生成合同初稿，让律师从重复性工作中解放，专注于策略分析。 金融领域 ：分析财报文本中的风险信号，或自动生成投资报告，提升决策效率。\n4、模型演示示例\nPrompt：请用简单的话解释什么是人工智能？\n四、为什么要学开源大模型？\n尽管闭源大模型（如GPT系列）功能强大，但开源大模型的价值日益凸显，尤其对企业和开发者而言：\n打破使用限制 ：闭源模型受地域、接口调用量限制，而开源模型可本地部署，避免“断网即不可用”的风险。 保障数据安全 ：企业敏感数据（如客户信息、内部文档）无需上传至第三方服务器，降低泄露风险。 成本可控 ：闭源模型按调用量收费，大规模使用成本高昂；开源模型一次部署后，后续使用成本极低。 深度定制 ：可基于行业数据二次训练（如训练医疗专用模型），解决闭源模型在特定领域“水土不服”的问题（比如中文语境下的表达生硬）。\n例如国内的LLaMA衍生模型、通义千问开源版，国际的Mistral等，都为开发者提供了灵活的定制空间，成为学习和落地大模型技术的重要载体。\n五、总结与展望\n从语言模型的四个发展阶段，到OpenAI的技术演进；从预训练、指令微调等核心技术，到ChatGPT引发的全民热潮，大模型正从实验室走向千行百业。\n其核心价值不仅是提升效率，更在于“降低AI使用门槛”——无论是普通人用ChatGPT写邮件，还是企业用开源模型搭建专属助手，大模型让“人人可用AI”成为现实。\n未来，大模型将向多模态（融合文本、图像、音频）、轻量化（在手机等终端运行）、更安全（减少偏见和有害输出）方向发展。对于每个人而言，理解大模型技术、善用大模型工具，将成为适应未来的重要能力。毕竟，这场由大模型引发的变革，才刚刚开始。\n六、如何学习大模型 AI ？\n由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。\n但是具体到个人，只能说是：\n“最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。\n这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。\n我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。\n我意识到有"
  },
  {
    "title": "2022年云南省数字应用典型案例1—南亚东南亚语言机器翻译（云岭翻译）云南省发展和改革委员会",
    "page_body": "【编者按】2022年4月，省政府办公厅印发《关于大力推动数字经济加快发展若干政策措施》，明确省级每年遴选20个智慧能源、智慧交通等方面的应用示范项目，牵引带动经济社会各行业数字化转型，助推“数字云南”建设发展。省发展改革委于2022年8月13日发布《云南省发展和改革委员会关于开展数字应用典型案例评选工作的通知》，组织评选全省年度数字经济典型应用案例。经企业申报、州市推荐、专家评审、名单公示等程序，确定南亚东南亚语言机器翻译（云岭翻译）等17个项目为2022年云南省数字应用典型案例。为积极宣传示范项目经验成效和有效做法，促进数字技术和实体经济深度融合，促进产业转型升级，省发展改革委对2022年云南省数字应用典型案例开展系列宣传，供各地交流借鉴。\n一、项目基本情况\n“云岭翻译”是由小语智能信息科技（云南）有限公司依托昆明理工大学云南省人工智能重点实验室的技术优势，自主研发的具有完全自主知识产权的东南亚语言机器翻译系统。项目研发依托国家重点研发计划、国家自然科学基金重点项目、云南省科技重大专项等科研项目以及企业营收投入，总投资5000万。“云岭翻译”实现了中文到老挝语、缅甸语、柬埔寨语、泰语、越南语、马来语、印地语等108个语种的双向翻译，覆盖“一带一路”沿线多个国家，翻译效果达到实用化程度，在中文－南亚东南亚语言机器翻译方面达到了国际领先水平。在疫情防控、公众服务、互联网企业、国际传播、跨境贸易、跨境旅游、跨境教育等方面得到了广泛应用。\n图1 云岭翻译产品\n二、项目建设内容\n“一带一路”背景下，语言相通是促进不同国家之间政策沟通、贸易畅通、民心相通的基础保障。云南省是“一带一路”重要节点，建设面向南亚东南亚辐射中心，语言互通是关键。面向南亚东南亚的跨境旅游、跨境贸易、文化输出等领域亟需解决语言沟通难题。\n当前，中文、英文等丰富资源语言机器翻译已取得了很好的效果，在全球形成了上千亿的机器翻译市场规模。但是，面向南亚东南亚语言的机器翻译仍面临平行语料及对齐知识匮乏、语言分析处理方法和工具不成熟、语言形态变化复杂等难点问题，中文—南亚东南亚语言机器翻译性能还不理想，面向不同应用场景的机器翻译产品及大规模商业化应用还很少，产业不成熟。\n针对上述需求和问题，项目围绕中文－南亚东南亚语言语料库建设，南亚东南亚语言词法句法解析平台研发，中文—南亚东南亚语言机器翻译系统研发及应用开展建设。\n三、关键技术及实施方案\n在资源库构建方面，突破了多项双语词典、短语及依存树库、平行句对构建关键技术，构建了大规模的南亚东南亚语言资源库；在语言解析方面，结合南亚东南亚语言特点，突破了南亚东南亚语言分句、分词、实体识别及依存句法解析等关键技术，搭建了面向南亚东南亚语言的词法句法解平台，获得授权发明专利10余项；在机器翻译系统构建方面，突破了词法和句法知识融合及编解码协同等一系列神经机器翻译关键技术，授权国家发明专利20余项。\n研发的云岭翻译Web平台、云岭翻译机、云岭翻译APP、多语言影视译制系统、多语言会议同传系统等一系列软硬件产品，拥有完全自主知识产权，系统安全，自主可控。可通过云服务和私有化部署方式，提供Web翻译、翻译API接口、翻译APP、翻译机等多元化技术服务模式，能够满足国内外企业、教育机构、公众等用户在多种应用场景下的翻译需求。\n图2 云岭翻译机用于边境疫情防控\n图3 “一部手机办事通”上线云岭翻译\n图4 多语言会议同传系统\n图5 南亚东南亚影视译制系统\n四、经济效益和社会效益\n目前，云岭翻译日均翻译超600万次，日均翻译字符超3亿，翻译APP下载300余万次。在跨境贸易文档资料翻译、合同翻译，跨境商务谈判与合作交流，影视剧字幕翻译及翻译技术服务等方面取得较好的直接经济效益，在降本增效方面产生了巨大的间接经济效益。同时推动了公众服务、政务服务、疫情防控、跨境贸易、跨境旅游、跨境教育、国际传播等上下游产业链发展，带动就业人数超过3000人。随着“一带一路”和云南省南亚东南亚辐射中心建设的不断深入，云岭翻译作为区域合作交流中必不可少的语言工具有着广阔的市场前景，能够更好的服务于云南省“两亚”辐射中心建设。\n五、创新性\n云岭翻译是基于昆明理工大学云南省人工智能重点实验室近15年技术积累研发的产品，突破了一系列南亚东南亚低资源语言资源库构建及机器翻译核心关键技术，具有完全自主知识产权，获得40余项授权发明专利，在中文－南亚东南亚语言机器翻译方面技术达到了国际领先水平，翻译效果达到了实用化程度，系统安全、自主可控。"
  },
  {
    "title": "中国AI大模型自主之路：技术突破与产业生态构建-百度开发者中心",
    "page_body": "浏览量： 9\n简介： 本文探讨中国自主研发AI大模型的核心技术路径、产业生态构建及对开发者/企业的实践价值，分析政策支持、数据安全与算力优化等关键要素，提供模型选型与场景落地的可操作建议。\n引言：自主AI大模型为何成为战略焦点？\n在全球AI竞争格局中，大模型技术已成为国家科技实力的核心指标。中国自主研发AI大模型，不仅是技术突破的象征，更是保障数据主权、优化产业效率的关键路径。从政务到金融，从医疗到制造，自主大模型正通过定制化能力重构行业应用场景。本文将从技术路径、产业生态、实践案例三个维度，系统解析中国AI大模型自主化的发展逻辑。\n一、中国AI大模型自主化的技术突破路径\n1.1 架构创新：从“跟随”到“引领”\n早期中国AI模型多基于Transformer架构改进，但近年来，以 流式注意力机制 、 动态稀疏计算 为代表的创新架构逐步涌现。例如，某团队提出的 混合专家（MoE）动态路由算法 ，通过动态分配计算资源，在保持模型精度的同时降低30%推理成本。此类架构突破解决了传统模型“算力消耗大、响应延迟高”的痛点，为实时应用场景（如 智能客服 、自动驾驶）提供了技术支撑。\n1.2 数据治理：构建 安全 可控的训练体系\n数据主权是自主大模型的核心壁垒。中国开发者通过 联邦学习 、 差分隐私 等技术，在保障数据隐私的前提下实现跨机构数据协作。例如，医疗领域通过联邦学习构建全国性罕见病 数据库 ，模型在无需共享原始数据的情况下完成训练，准确率提升15%。此外，中文语料库的优化（如多模态古籍数字化项目）显著提升了模型对中文语境的理解能力。\n1.3 算力优化：国产化硬件的适配与突破\n面对国际芯片限制，中国通过 算法-硬件协同优化 实现算力效率最大化。例如，某团队在国产GPU上开发了 低精度训练框架 ，将FP32精度降至BF16，在保持模型性能的同时使训练速度提升40%。此外，分布式训练技术的成熟（如参数服务器与集合通信的混合架构）使得千亿参数模型可在万卡集群上高效训练。\n二、产业生态构建：从技术到场景的闭环\n2.1 政策驱动：国家战略与地方实践的协同\n《新一代人工智能发展规划》明确提出“建设自主可控的AI基础设施”，各地政府通过算力补贴、数据开放等政策加速生态落地。例如，某地政务云平台要求所有AI应用必须基于国产 大模型开发 ，带动了本地化服务市场的繁荣。\n2.2 开发者生态：工具链与社区的完善\n自主大模型的成功依赖于开发者生态的成熟度。当前，中国已形成覆盖 模型训练、微调、部署 的全链条工具集：\n训练框架 ：如PaddlePaddle的国产化适配版本，支持动态图与静态图混合编程； 微调工具 ：LoRA（低秩适应）技术的开源实现，使企业可用1%参数完成行业适配； 部署方案 ：量化压缩工具将模型体积缩小90%，适配边缘设备。\n开发者社区的活跃度亦显著提升，某开源平台上的国产大模型相关项目半年内增长300%，涵盖金融 风控 、工业质检等20余个垂直领域。\n2.3 企业应用：场景化落地的典型案例\n金融行业 ：某银行基于自主大模型构建反欺诈系统，通过分析用户行为序列（代码示例： sequence_features = [\"login_time\", \"transaction_amount\", \"device_id\"] ），将欺诈交易识别准确率提升至99.2%； 制造业 ：某工厂利用大模型进行设备故障预测，结合时序数据（ time_series_data = pd.read_csv(\"sensor_logs.csv\") ）与知识图谱，使停机时间减少40%； 医疗领域 ：某医院部署的智能诊断系统，通过多模态输入（CT影像+电子病历）辅助医生制定治疗方案，诊断一致性从78%提升至91%。\n三、挑战与应对：自主化进程中的关键问题\n3.1 生态碎片化风险\n当前市场上存在数十种国产大模型，标准不统一导致企业选型困难。建议通过 模型评估体系 （如性能、成本、合规性三维评分）引导资源集中，同时推动行业联盟制定接口规范。\n3.2 高端人才缺口\n自主大模型研发需要既懂算法又懂行业的复合型人才。企业可通过 产学研合作 （如与高校共建联合实验室）提前布局人才储备，同时利用低代码工具降低开发门槛。\n3.3 长期演进方向\n未来三年，自主大模型将向 多模态融合 、 实时决策 、 自主进化 方向发展。例如，结合数字孪生技术构建“模型-物理系统”闭环，使AI能够根据环境反馈动态优化策略。\n四、实践建议：企业如何高效落地自主大模型？\n4.1 场景优先级排序\n优先选择 数据可控、价值显著 的场景，如内部客服（替代第三方API）、质检（避免国外模型对中文缺陷的误判）。\n4.2 模型选型策略\n轻量化需求 ：选择参数量在10亿级、支持端侧部署的模型； 复杂任务 ：采用“基础模型+行业微调”模式，降低训练成本； 合规要求 ：确保模型通过 网络 安全审查，数据 存储 于境内。\n4.3 持续优化机制\n建立模型性能监控体系（如准确率、推理延迟的实时仪表盘），定期用新数据更新模型。某物流企业通过此方式将路径规划效率提升了25%。\n结语：自主化不是终点，而是新起点\n中国AI大模型的自主化进程，本质上是构建“技术-数据-场景”三位一体的创新体系。随着政策支持、生态完善与技术突破的三重驱动，自主大模型将不仅服务于国内市场，更可能通过“一带一路”等渠道输出至新兴经济体，成为全球AI版图中的重要一极。对于开发者与企业而言，把握这一历史机遇，意味着在未来的智能化竞争中占据先发优势。"
  },
  {
    "title": "什么是大模型中的Scaling Law-CSDN博客",
    "page_body": "·  0  ·\nCC 4.0 BY-SA版权\n文章标签：\n#人工智能\n社区： MCP技术社区 加入\n于 2024-11-17 21:19:29 首次发布\n10 篇文章\n订阅专栏\n大模型中的Scaling Law（规模定律或缩放定律）是一种描述模型性能如何随着模型大小（如参数数量）、 数据集 大小和计算资源的增加而变化的理论工具。这些变化通常遵循幂律关系，即模型性能与这些关键因素之间的关系可以表示为幂律关系。具体来说，Scaling Law涉及以下几个关键因素：\n• 模型大小：随着模型中参数数量的增加，性能通常会按照幂律改善。\n• 数据集大小：更大的 训练数据 集通常带来更好的性能，也遵循幂律关系。\n• 计算资源：用于训练的计算资源（浮点运算次数）与性能改善相关。\n在对数- 对数空间 中，测试损失与计算、数据集大小和模型参数之间遵循幂律关系，表现为线性关系。这意味着，随着模型大小、数据集大小和用于训练的计算量的增加，语言建模性能得到了提升。\nScaling Law的提出源于对大规模模型训练的实践和总结，例如 OpenAI 在2020年提出的概念。通过数学推导和实验验证，研究者得出了一些关于大模型性能与规模之间关系的定量规律，为大模型的设计和训练提供了理论指导。\n在实际操作中，研究人员通常会进行一系列实验来验证Scaling Law的有效性，并根据实验结果调整模型设计和训练策略。通过不断地实验和总结经验，他们可以逐步优化模型性能，提高模型的泛化能力和适用范围。\n总的来说，Scaling Law是理解和预测大模型性能表现的重要工具，它帮助研究者在模型设计和训练中做出更合理的决策。\n 1 \n点赞\n踩\n 0 \n 收藏 \n 觉得还不错?   一键收藏 \n 0 \n评论\n分享\n复制链接\n分享到 QQ\n分享到新浪微博\n扫一扫 \n举报\n举报\n专栏目录\nAI新视界\n03-07  3940 \nAI天才研究院\n09-07  1392 \nqq_32907491的博客\n05-04  1万+ \n最新发布\n世上再无张显宗\n08-25  756 \n百态老人的博客\n12-19  1985 \n2401_85375186的博客\n06-28  1119 \nzenRRan的博客\n11-21  1万+ \n学习与分享人工智能技术\n12-23  1531 \n强化学习曾小健\n09-21  983 \nEleutherAI 的工程师们经常使用上述启发式方法规划高效的模型训练以及调试分布式运行。我们希望澄清这些经常被忽视的实现细节。其他人都在看。\nm0_56255097的博客\n01-22  4314 \n大模型 缩放法则\nweixin_43409127的博客\n01-04  1909 \n热门推荐\nAI天才研究院\n04-20  1万+ \nGPU 是当前 AI 训练的主要算力来源，IDC 估计当前有 90% 的 AI 服务器采用 GPU， 而 Nvidia 和 AMD 在 GPU 的市占率分别高达 80% 和 20%。ASIC 能够获得剩下的 10% 的市场，并随着技术成熟可能达到 20% ，主要可以分为保守路线和激进路线：云计算厂商（比如谷歌和 AWS）通常采用保守路线，将 GPU 中有的图像和高精度(FP64 通常占芯片面积的 10-20%，但训练和推理并不需要高精度)计算单元砍掉，在相同成本下塞入更多的中低精度计算单元；\n深数研究院\n09-06  8481 \nbentty_lee的博客\n11-09  9227 \nDennard缩放定律是1974年Dennard提出1，与大名鼎鼎的摩尔定律一起统治了集成电路很多年。 Dennard提出，晶体管的尺寸在每一代技术中都缩小了30% (0.7倍)，因此它们的面积A减少了50%。这意味着电路减少了30% (0.7倍)的延迟，因此增加了约40% (1.4倍)的工作频率。最后，为了保持电场恒定，电压降低了30%，能量降低了65%，功率降低了50%。因此，在每一代技术中，晶体管密度增加一倍，电路速度提高40%，功耗(晶体管数量增加一倍)保持不变(https://www.ithom\nScaling Law 解析\nzzfive的博客\n04-06  2586 \n11-13  2897 \nzenRRan的博客\n05-14  3022 \n加入“Super Entity”，与全能开发团队共探AI智能体与数字人项目，开启前沿技术之旅。\n03-26  648 \n06-06"
  },
  {
    "title": "为什么Transformer适合做多模态任务？",
    "page_body": "我们先看一下Transformer（Attention Is All You Need）详解 一、Transformer的整体架构是怎样的？由哪些部分组成？ 二、Transformer Encoder 与 Transformer Decoder 有哪些不同 三、Encoder-Decoder attention 与self-attention mechanism有哪些不同？ 四、multi-head self-attention mechanism具体的计算过程是怎样的？ 五、Transformer在GPT和Bert等词向量预训练模型中具体是怎么应用的？有什么变化？ 一、Transformer模型的整体架构主要由以下几个部分组成： 输入嵌入（Input Embedding）：Transformer首先将输入序列（如文本、图像等）中的每个元素进行嵌入表示，将其转换为低维的向量表示。对于文本输入，常用的嵌入方法是词嵌入（Word Embedding），对于图像输入，可以使用卷积神经网络（CNN）提取特征。 位置编码（Positional Encoding）：为了捕捉序列中元素的位置信息，Transformer引入了位置编码机制。位置编码是一组固定的向量，通过将其与输入嵌入相加，为每个元素添加位置信息。 编码器（Encoder）：编码器是Transformer的核心部分，由多个相同的层堆叠而成。每个编码器层都包含自注意力机制（Self-Attention）和前馈神经网络（Feed-Forward Network）。自注意力机制用于建模输入序列内部的依赖关系，而前馈神经网络则用于对每个位置的向量进行非线性变换。 解码器（Decoder）：对于序列到序列（sequence-to-sequence）任务，Transformer还包括一个解码器部分。解码器也由多个相同的层堆叠而成，每个解码器层除了包含编码器的结构外，还添加了一个额外的注意力机制，用于对编码器的输出进行注意力操作。 注意力机制（Attention）：Transformer的注意力机制是其关键组成部分。注意力机制通过计算查询（Query）、键（Key）和值（Value）之间的相似度，对值进行加权汇聚，从而实现对不同元素的重要性的关注。注意力机制分为自注意力（Self-Attention）和多头注意力（Multi-Head Attention）两种形式，用于捕捉序列内部的依赖关系和跨序列的依赖关系。 层归一化（Layer Normalization）：为了加速训练和提高模型的收敛性，Transformer在每个子层的输入和输出之间引入了层归一化操作。层归一化用于对每个子层的输入进行归一化，使得每个子层的输入保持在一个稳定的范围内。 关于Transformer和生成式预训练语言模型的探究，可以学习深蓝学院的《生成式预训练语言模型：理论与实战》课程，如何利用Transformer与GPT从0到1制作自己的mini-ChatGPT。 生成式预训练语言模型：理论与实战 - 深蓝学院 - 专注人工智能与自动驾驶的学习平台二、Encoder主要用于对输入序列进行编码和特征提取，Decoder则在此基础上进一步生成目标序列。Decoder除了自注意力机制，还引入了编码器-解码器注意力机制来与Encoder进行交互。Transformer Encoder： 输入：接受输入序列（如文本、图像等）的嵌入表示和位置编码。 注意力机制：只使用自注意力机制（Self-Attention），用于建模输入序列内部的依赖关系。 输出：编码器的输出是经过多个编码器层处理后的特征表示。 Transformer Decoder： 输入：接受目标序列（输出序列）的嵌入表示和位置编码，以及编码器的输出。 注意力机制：除了使用自注意力机制（Self-Attention），还使用编码器-解码器注意力机制（Encoder-Decoder Attention），用于对编码器的输出进行注意力操作。 输出：解码器通过多个解码器层逐步生成目标序列的表示，并输出最终的预测结果。 三、Encoder-Decoder attention是在Transformer中用于Decoder部分的一种注意力机制，用于将Decoder的每个位置与Encoder的输出进行关联。而self-attention mechanism是Transformer中Encoder和Decoder共同使用的自注意力机制，用于建模序列内部的依赖关系。 四、Multi-head self-attention mechanism包括将输入进行线性变换得到查询、键和值，然后计算多个注意力头的注意力分数。每个注意力头都会通过对查询和键进行点积操作，然后应用softmax函数获得注意力权重。最后，将注意力权重与值进行加权求和，得到每个头的输出，并通过线性变换和拼接操作得到最终的多头自注意力输出。 五、在GPT和BERT等词向量预训练模型中，Transformer作为核心结构用于编码文本。GPT以Transformer解码器为基础，用于生成文本。BERT以Transformer编码器为基础，用于学习上下文相关的词向量表示。两者都利用Transformer的自注意力机制来建模输入序列的依赖关系，并在大规模数据上进行预训练。Transformer帮助模型捕捉长距离依赖关系、上下文信息，并提供强大的语言理解能力，通过微调在各种下游任务上展现优秀表现。 最后呢，我们看一下Transformer模型适合处理多模态任务的原因主要有以下几点： 并行计算 跨模态交互 灵活的模型架构 迁移学习能力 transformer适合处理多模态任务的原因在于其自注意力机制的能力。自注意力机制能够在序列中建立全局的依赖关系，有效捕捉不同模态之间的关联和依赖。通过将多模态输入嵌入到Transformer的输入中，模型可以同时学习到模态内部的特征表示和跨模态之间的关联，实现跨模态信息的传递和融合，从而更好地理解和处理多模态数据。尽管Transformer模型本身在其结构中没有专门设计用于多模态任务，但由于其并行计算、跨模态交互、灵活的架构和迁移学习能力，使得它在多模态任务中具备很大的潜力和适应性。这些特性使得Transformer模型成为处理多模态数据的有力工具，并在多模态任务中取得了显著的成果。"
  },
  {
    "title": "Kotlin与机器学习实战：Android端集成TensorFlow Lite全指南本文将手把手教你如何在Android-掘金",
    "page_body": "本文将手把手教你如何在Android应用中集成TensorFlow Lite模型，实现端侧机器学习推理能力。我们以图像分类场景为例，提供可直接运行的完整代码示例。\n环境准备\n1. 开发环境要求\nAndroid Studio Arctic Fox以上版本 AGP 7.0+ Kotlin 1.6+ Minimum SDK 21\n2. 添加Gradle依赖\n// build.gradle.kts  android {     aaptOptions {         noCompress  \"tflite\" // 防止模型文件被压缩      } }  dependencies {      // TFLite核心库      implementation( \"org.tensorflow:tensorflow-lite:2.12.0\" )     implementation( \"org.tensorflow:tensorflow-lite-gpu:2.12.0\" )  // GPU支持      implementation( \"org.tensorflow:tensorflow-lite-support:0.4.4\" )           // 相机扩展库（可选）      implementation( \"androidx.camera:camera-core:1.3.0\" )     implementation( \"androidx.camera:camera-lifecycle:1.3.0\" )     implementation( \"androidx.camera:camera-view:1.3.0\" )           // 协程支持      implementation( \"org.jetbrains.kotlinx:kotlinx-coroutines-android:1.7.3\" ) } \n完整实现流程\n步骤1：模型文件处理\n将训练好的 .tflite 模型文件放入 app/src/main/assets 目录，建议同时包含 labels.txt 标签文件\napp/ src / main /assets/ ├── mobilenet_v1_1. 0 _224_quant .tflite  └── labels .txt\n步骤2：核心分类器实现\nimport  android.content.Context  import  android.graphics.Bitmap  import  org.tensorflow.lite.support.image.TensorImage  import  org.tensorflow.lite.task.vision.classifier.ImageClassifier   class TFLiteImageClassifier (     context: Context,     modelPath: String =  \"mobilenet_v1_1.0_224_quant.tflite\" ,     labelPath: String =  \"labels.txt\" ,      private val  threadNum:  Int  =  4  ) {      private var  classifier: ImageClassifier? =  null private val  labels: List<String>       init  {          // 加载标签文件          labels = context.assets. open (labelPath).bufferedReader().useLines { it.toList() }           // 配置分类器选项 val  options = ImageClassifier.ImageClassifierOptions.builder()             .setMaxResults( 3 )             .setNumThreads(threadNum)             .setDelegate(Delegate.GPU)  // 优先尝试GPU加速              .build()           try  {             classifier = ImageClassifier.createFromFileAndOptions(                 context,                  modelPath,                 options             )         }  catch  (e: IllegalStateException) {              // GPU失败时回退CPU              options.setDelegate(Delegate.CPU)             classifier = ImageClassifier.createFromFileAndOptions(                 context,                 modelPath,                 options             )         }     }       fun classify (bitmap:  Bitmap ) : List<Pair<String,  Float >> {          val  imageProcessor = ImageProcessor.Builder()             .add(ResizeOp( 224 ,  224 , ResizeOp.ResizeMethod.BILINEAR))             .add(NormalizeOp( 127.5f ,  127.5f ))  // 根据模型类型调整              .build()           val  tensorImage = imageProcessor.process(             TensorImage.fromBitmap(bitmap)         )           val  results = classifier?.classify(tensorImage) ?:  return  emptyList()           return  results[ 0 ].categories.map {              val  label = labels.getOrNull(it.index) ?:  \"Unknown\"              label to it.score         }     }       fun close ()  {         classifier?.close()     } } \n步骤3：UI界面实现\nactivity_main.xml\n< androidx.constraintlayout.widget.ConstraintLayout xmlns:android = \"http://schemas.android.com/apk/res/android\" xmlns:app = \"http://schemas.android.com/apk/res-auto\" android:layout_width = \"match_parent\" android:layout_height = \"match_parent\" > < androidx.camera.view.PreviewView android:id = \"@+id/cameraPreview\" android:layout_width = \"300dp\" android:layout_height = \"300dp\" app:layout_constraintTop_toTopOf = \"parent\" app:layout_constraintStart_toStartOf = \"parent\" /> < ImageView android:id = \"@+id/ivPreview\" android:layout_width = \"300dp\" android:layout_height = \"300dp\" app:layout_constraintTop_toTopOf = \"parent\" app:layout_constraintEnd_toEndOf = \"parent\" /> < Button android:id = \"@+id/btnCapture\" android:layout_width = \"wrap_content\" android:layout_height = \"wrap_content\" android:text = \"拍照识别\" app:layout_constraintBottom_toBottomOf = \"parent\" app:layout_constraintStart_toStartOf = \"parent\" /> < Button android:id = \"@+id/btnSelect\" android:layout_width = \"wrap_content\" android:layout_height = \"wrap_content\" android:text = \"图库选择\" app:layout_constraintBottom_toBottomOf = \"parent\" app:layout_constraintEnd_toEndOf = \"parent\" /> < TextView android:id = \"@+id/tvResult\" android:layout_width = \"0dp\" android:layout_height = \"wrap_content\" android:padding = \"16dp\" android:textSize = \"18sp\" app:layout_constraintTop_toBottomOf = \"@id/cameraPreview\" app:layout_constraintStart_toStartOf = \"parent\" app:layout_constraintEnd_toEndOf = \"parent\" /> </ androidx.constraintlayout.widget.ConstraintLayout >\n步骤4：主Activity实现（CameraX集成版）\n@RequiresApi(Build.VERSION_CODES.M) class MainActivity  :  AppCompatActivity () {      private lateinit var  classifier: TFLiteImageClassifier      private lateinit var  cameraExecutor: ExecutorService      private var  imageCapture: ImageCapture? =  null override fun onCreate (savedInstanceState:  Bundle ?)  {          super .onCreate(savedInstanceState)         setContentView(R.layout.activity_main)         cameraExecutor = Executors.newSingleThreadExecutor()         classifier = TFLiteImageClassifier( this )           // 请求相机权限 if  (allPermissionsGranted()) {             startCamera()         }  else  {             ActivityCompat.requestPermissions(                  this , REQUIRED_PERMISSIONS, REQUEST_CODE_PERMISSIONS             )         }           // 拍照按钮点击          btnCapture.setOnClickListener {             takePhoto()         }           // 图库选择          btnSelect.setOnClickListener {              val  intent = Intent(Intent.ACTION_GET_CONTENT).apply {                 type =  \"image/*\"              }             startActivityForResult(intent, REQUEST_IMAGE_PICK)         }     }       private fun takePhoto ()  {          val  imageCapture = imageCapture ?:  return val  outputOptions = ImageCapture.OutputFileOptions             .Builder(File.createTempFile( \"ML_TEMP\" ,  \".jpg\" , cacheDir))             .build()          imageCapture.takePicture(             outputOptions,             ContextCompat.getMainExecutor( this ),              object  : ImageCapture.OnImageSavedCallback {                  override fun onImageSaved (output:  ImageCapture . OutputFileResults )  {                      val  uri = output.savedUri ?:  return                      processImage(uri)                 }                   override fun onError (exc:  ImageCaptureException )  {                     Log.e(TAG,  \"拍照失败:  ${exc.message} \" , exc)                 }             }         )     }       private fun processImage (uri:  Uri )  {         lifecycleScope.launch(Dispatchers.IO) {              try  {                  val  bitmap = contentResolver.loadThumbnail(                     uri, Size( 224 ,  224 ),  null                  )                                   val  results = classifier.classify(bitmap)                                  withContext(Dispatchers.Main) {                     ivPreview.setImageBitmap(bitmap)                     showResults(results)                 }             }  catch  (e: Exception) {                 Log.e(TAG,  \"图片处理失败\" , e)             }         }     }       private fun showResults (results:  List < Pair < String ,  Float >>)  {          val  output = buildString {             append( \"识别结果:\\n\" )             results.forEach { (label, confidence) ->                 append( \" ${label} :  ${ \"%.2f\" .format(confidence *  100 )} %\\n\" )             }         }         tvResult.text = output     }       // CameraX初始化 private fun startCamera ()  {          val  cameraProviderFuture = ProcessCameraProvider.getInstance( this )          cameraProviderFuture.addListener({              val  cameraProvider = cameraProviderFuture. get ()              val  preview = Preview.Builder()                 .build()                 .also { it.setSurfaceProvider(cameraPreview.surfaceProvider) }              imageCapture = ImageCapture.Builder()                 .setCaptureMode(ImageCapture.CAPTURE_MODE_MINIMIZE_LATENCY)                 .build()               try  {                 cameraProvider.unbindAll()                 cameraProvider.bindToLifecycle(                      this , CameraSelector.DEFAULT_BACK_CAMERA, preview, imageCapture)             }  catch  (exc: Exception) {                 Log.e(TAG,  \"相机初始化失败\" , exc)             }         }, ContextCompat.getMainExecutor( this ))     }       // 权限处理 override fun onRequestPermissionsResult (         requestCode:  Int ,          permissions:  Array < String >,          grantResults:  IntArray      )  {          super .onRequestPermissionsResult(requestCode, permissions, grantResults)          if  (requestCode == REQUEST_CODE_PERMISSIONS) {              if  (allPermissionsGranted()) {                 startCamera()             }  else  {                 Toast.makeText( this ,  \"需要相机权限\" , Toast.LENGTH_SHORT).show()                 finish()             }         }     }       companion object  {          private const val  TAG =  \"MLDemo\" private const val  REQUEST_CODE_PERMISSIONS =  10 private const val  REQUEST_IMAGE_PICK =  101 private"
  },
  {
    "title": "软件工程学院新开课来啦，《AI革命：解码大模型》喊你来选课～|中山大学软件工程学院",
    "page_body": "最近，OpenAI 的 ChatGPT 聊天机器人在互联网上引起了热潮，其卓越的语言理解和生成能力给人们留下了深刻印象。人们对其强大功能感到惊叹，通过输入文字与其交流，ChatGPT 能轻松完成诸如机器翻译和代码生成等复杂语言任务。\n与此同时，\"大模型\"一词开始在公众中广为流传，引发了一股\"大模型热\"，国内外各大科技公司和研究机构等纷纷展开大模型相关的开发和研究。国外科技巨头 Google 推出了 PaLM 系列大模型，并基于此开发了 Bard 聊天机器人；Meta 公司也发布了开源大模型 LLaMA 等。而在国内，大模型领域同样炙手可热。截至2023年5月29日，中国已经拥有79个大模型，并且这一数字还在持续增长。国内科技巨头纷纷推出自己的大模型，比如百度的文心一言、阿里巴巴的通义千问以及华为的盘古大模型等。大模型的发展可谓日新月异、蓬勃向荣。\n▲大模型发展历史\n如今，大型语言模型已经逐渐融入人们的日常生活，作为提高效率的工具，成为人们学习和工作不可或缺的一部分。然而，对于大型语言模型的基本概念和工作原理等，大多数人并不了解。\n为了揭开大型语言模型的神秘面纱，软件工程学院于2023学年第一学期正式开设了通识课程《AI革命：解码大型语言模型》。这门课程旨在介绍大型语言模型的工作原理、应用范围和社会影响，激发同学们对大型语言模型研究的热情，并提高他们使用大型语言模型的能力。\nLarge Language Model\n大语言模型\n通常来说，大语言模型指的是那些在大规模文本语料上训练、包含百亿级别（或更多）参数的语言模型，例如GPT-4、PaLM等。大语言模型(Large langauge model)具有强大的文本理解能力和生成能力，在机器翻译和代码生成等复杂通用任务上有着出色的性能。如今，国内外许多企业和高校投入大量资源开展大模型研究。\nAI Revolution: Decoding Large Models\n《AI革命：解码大模型》\n课程简介\n《AI 革命：解码大模型》是一门旨在引导学生深入理解并掌握 AI 变革时代背景下的大模型的课程。这门课程将概览大模型的发展历程，特别关注当前的大模型如 ChatGPT 等的工作原理、应用范围和社会影响。在这门课程中，我们将详细介绍 AI 的基本概念，包括深度学习和自然语言处理等。随后，我们将重点介绍当前主流大模型的相关知识和训练方法，以及如何应用这些模型解决问题。我们还将讨论大模型在社会、经济、伦理等方面的影响，并对AI的未来发展进行深入思考。课程将邀请业界专家进行授课，帮助学生了解最新的AI研究进展和应用。\n无论你是计算机学科相关专业的学生，还是单纯对人工智能感兴趣的非专业学生，都可以从这门课程中受益。通过学习，同学们将有机会更深入地理解大模型的工作原理，更清晰地把握AI的发展趋势，以及更明智地思考和应对其带来的挑战和机遇。\n课程信息\n1.课程名称：AI革命：解码大模型（AI Revolution: Decoding Large Models)\n2.课程编码：SSE1002\n3.授课学时: 18\n4.学分：1\n5.开课单位：软件工程学院\n6.课程细类：科技与未来\n7.主讲教师：郑子彬、王焱林、李丹、陈嘉弛、陈文清、孔树锋\n主讲教师介绍\n郑子彬：教授、博导、IEEE Fellow、IET Fellow、ACM杰出科学家、全球高被引科学家、国家优秀青年科学基金获得者、国家数字家庭工程技术研究中心副主任、广东省区块链工程技术研究中心主任。发表论文200余篇，论文谷歌学术引用超过30,000次，H指数为83。主持国家重点研发计划项目、自然科学基金重点项目等多个项目；获得教育部自然科学二等奖、 吴文俊人工智能自然科学二等奖、 ACM中国新星提名奖、IEEE TCSVC Rising Star Award、CCF服务计算专委会杰出青年奖、ACM SIGSOFT Distinguished Paper Award、ICWS最佳学生论文奖等奖项；担任TOSEM、TSC、TVT、OJCS等期刊的副编辑；担任ICSS2022、IEEE SMDS2021、BlockSys2019、CollaborateCom 2016等会议的General Co-Chair；担任ICSOC2023、SC22019、ICIOT2018 及IoV2014等会议的PC Co-Chair。\n王焱林：助理教授，硕士生导师，2022年7月入选中山大学百人计划，加入软件工程学院。加入中山大学前，于微软亚洲研究院担任主管研究员。2014年至2019年就读于香港大学计算机科学系，师从Bruno Oliveira教授，获得博士学位。2010年至2014年就读于浙江大学，获学士学位。近5年来在国际会议和期刊共发表10余篇论文，发表于ICSE、AAAI、ACL、KDD、TKDE、EMSE、EMNLP、CIKM、ICSME等软件工程、人工智能、自然语言处理等领域CCF A/B类顶级会议与期刊。\n李丹：副教授，硕士生导师，2021年2月入选中山大学百人计划青年学术骨干，加入软件工程学院。2018年至2021年于新加坡国立大学担任研究员，从事博士后研究工作。2013年至2017年就读于新加坡南洋理工大学，受新加坡与加州大学伯克利分校联合项目资助，获得博士学位。2008年至2012年就读于电子科技大学，获得学士学位。目前于IEEE TII、IEEE TASE、Energy Build. 等国际著名期刊和会议上发表10余篇论文。\n陈嘉弛：中山大学“百人计划”助理教授，硕士生导师。2022年于澳大利亚蒙纳士大学获得博士学位。近年在TSE, TOSEM, ASE, ICSE, ISSTA, INFOCOM, EMSE, JSS, TOIT, ICPC, ICDCS, DSN等软件工程、分布式计算、安全、网络等领域的国际会议和期刊发表论文20余篇，其中10余篇为区块链相关论文。\n陈文清：中山大学“百人计划”助理教授，硕士研究生导师。2022年于上海交通大学人工智能研究院获得博士学位，2015年于北京师范大学脑与认知科学研究院获得硕士学位，2012年于华中科技大学电子与信息工程学院获得学士学位。曾参与国家重点研发计划、上海市级科技重大专项资助、上海市人工智能创新发展专项资助、上海市科技计划等多个基金项目。在人工智能领域、自然语言处理国际权威期刊及会议发表论文10余篇，获国家发明专利授权6项。为多个国际顶级会议和期刊的审稿人，如ACL、EMNLP、IJCAI、AAAI、 Expert Syst App.等。\n孔树锋：副教授，硕士生导师，中山大学百人计划青年学术骨干。2018年10月毕业于澳大利亚悉尼科技大学工程与信息技术学院，获博士学位。分别于美国加州大学尔湾分校 (2017.11—2018.05) 、美国康奈尔大学 (2018.10—2020.09) 和新加坡南洋理工大学 (2020.10—2022.08) 从事科研工作, 并于2022年9月加盟中山大学软件工程学院。目前已在Nature Communications、NeurIPS、ICML、AAAI、IJCAI、CP和AAMAS等国际顶尖期刊和会议上以第一/通讯作者发表学术论文10余篇，并参与国内外重大科研项目多项。长期担任多个期刊和会议（NeurIPS、ICML、ICLR、AAAI、IJCAI和TNNLS等）的审稿人。"
  },
  {
    "title": "Transformer 核心解密：FFN 前馈神经网络的深度解析与应用_模型_注意力_表达能力",
    "page_body": "Transformer 架构在  自然语言处理 (NLP) 领域掀起了革命，其强大的表达能力得益于  注意力机制 和  前馈神经网络 (FFN) 的巧妙结合。虽然  注意力机制 常常被认为是 Transformer 的核心，但 FFN 扮演着更为关键的角色，它如同 Transformer 的“大脑皮层”，负责将注意力机制捕捉到的信息转化为深层理解。本文将深入剖析 FFN 的结构、原理、作用，以及它在 Transformer 中的底层价值。\n近年来，随着  人工智能 (AI) 技术的快速发展，对 Transformer 模型的理解和应用需求日益增长。FFN 作为 Transformer 架构中的关键组成部分，其重要性也逐渐被业界所认识。本文将从多个维度解析 FFN，帮助读者全面理解其在 Transformer 中的作用。\nFFN 的位置与角色：Transformer 的“隐形发动机”\n在 Transformer 架构中，FFN 位于每一个  Encoder 和  Decoder 模块中，与  注意力层 和  残差连接 形成紧密的协作关系。具体来说，FFN 接收  注意力层 的输出，对其进行非线性变换，从而增强模型的表达能力。注意力层负责“找关系”，而 FFN 则负责“挖深度”。例如，在翻译任务中，注意力层可能识别出“猫”和“桌子”之间的关联，而 FFN 则会将“猫”和“桌子”的语义信息进行更深层次的加工，例如猫在桌子上的状态。\nFFN 的核心原理：升维、激活、降维\nFFN 的结构看似简单，但其内部蕴含着深刻的数学原理。它主要由三个步骤构成：升维、激活、降维。假设输入词向量的维度是 512，FFN 的加工流程如下：首先，通过一个权重矩阵将词向量升维，增加其信息容量；然后，使用  ReLU 等激活函数进行非线性变换，实现特征的筛选；最后，通过另一个权重矩阵将维度降回原始维度。用公式表达就是：FFN(x) = W₂ * ReLU(W₁ * x + b₁) + b₂，其中 x 是输入词向量，W₁ 和 W₂ 是权重矩阵，b₁ 和 b₂ 是偏置，ReLU 是激活函数。升维再降维的设计有两个核心原因：一是增加模型的表达能力，让模型能够处理更复杂的语义信息；二是适配  残差连接 ，保证模型的训练稳定性。\nFFN 的三大核心作用：让 Transformer “会思考”\nFFN 在 Transformer 中扮演着至关重要的角色，它赋予了 Transformer 三大关键能力：挖深语义、并行计算、稳定训练。首先，FFN 能够将注意力层捕捉到的关联转化为深层理解。其次，FFN 的并行计算特性使得 Transformer 的训练和推理速度远超传统的  RNN 模型。最后，FFN 的设计也适配了  残差连接 和  归一化 ，保证了模型的训练稳定性。例如，在翻译“下雨了，地面湿了”时，FFN 不仅知道“下雨”和“地面湿”有关，还能理解二者之间的因果关系。\n市场趋势与行业背景\n随着  大语言模型 (LLM) 的发展，FFN 的重要性日益凸显。FFN 的参数量通常占整个模型参数的 60%-80%，是模型的核心知识载体。模型越大，FFN 的参数占比越高。FFN 的计算复杂度是线性的，这意味着即使处理长句子，计算量也不会爆炸式增长，保证了模型的高效性。未来，随着  AI 技术的不断进步，对 Transformer 模型的研究和应用将更加深入。理解 FFN，是理解 Transformer 的关键。那么，在未来的  AI 发展中，FFN 的结构和功能是否会进一步优化？其在更复杂的模型架构中又将扮演怎样的角色？ 欢迎大家在评论区分享您的看法。\n返回搜狐，查看更多"
  },
  {
    "title": "大模型推理优化技术万字长文总结！非常详细收藏我这一篇就够了-CSDN博客",
    "page_body": "大模型训练成本很高，且在推理过程中需要大量的计算资源，为了能够实现大模型应用落地，需解决大模型推理成本、模型响应速度等问题，这就需要对大模型进行推理优化。为此，本文将详细介绍主流的大模型推理优化技术，文章安排如下：\n本文相关内容需要大家对Transformer架构和注意力机制有一个基本的了解。不了解的小伙伴可以参考以下文章：\n1. 什么是LLM推理\n大多数流行的only-decode LLM（例如 GPT-4、Qwen系列）都是针对因果建模目标进行预训练的，本质上是作为下一个词预测器。 「这些 LLM 将一系列tokens作为输入，并自回归生成后续tokens，直到满足停止条件」 （例如，生成tokens数量的限制或遇到停止词）或直到生成特殊的  <end>  标记生成结束的tokens。该过程涉及两个阶段：预填充阶段和解码阶段。\n请注意，tokens是模型处理的语言的原子部分。一个tokens大约是四个英文字符。所有自然语言在输入模型之前都会转换为tokens。下图是大模型推理过程。\n1.1 预填充阶段（Prefill）\n在预填充阶段，也可以理解为输入阶段。LLM处理输入token以计算中间状态（keys和value），用于生成“第一个”token。每个新的token都依赖于所有先前的token，但由于输入的全部已知，因此在运算上，都是高度并行化矩阵运算，可以有效地使用GPU。\n1.2 解码阶段（Decode）\n在解码阶段，可以理解为输出阶段。LLM一次自回归生成一个输出token，直到满足停止条件。 「每个输出tokens都需要直到之前迭代的所有输出状态（keys和values）」 。这与预填充输入处理相比，就像矩阵向量运算未充分利用GPU计算能力。数据（weights, keys, values, activations） 从内存传输到GPU的速度决定了延迟，而不是计算实际时间消耗。即，这是一个内存限制操作。\n本文中的许多推理挑战和相应的解决方案都涉及此解码阶段的优化：高效的注意力模块、有效管理键和值等。\n不同的LLMs可能使用不同的tokenizers，因此比较它们之间的输出tokens可能并不简单。在比较推理吞吐量时，即使两个 LLMs每秒输出的tokens相似，如果它们使用不同的tokenizers，也可能不相等。这是因为相应的tokens可能代表不同数量的字符。\n1.3 批处理（Batching）\n提高 GPU 利用率和有效吞吐量的最简单方法是通过批处理。由于多个请求使用相同的模型，因此权重的内存成本被分散。 「大批量数据传输到 GPU 一次处理，将提高GPU资源的利用率。然而，批量大小只能增加到一定限制，此时可能会导致内存溢出」 。为了防止这种情况发生，需要查看键值 (KV) 缓存和 LLM 内存要求。\n传统批处理（也称为静态批处理， static batching）不是最佳的。这是因为对于批次中的每个请求，LLM 可能会生成不同数量的tokens，并且不同tokens有不同的执行时间。因此，批次中的所有请求都必须等待最长token的处理完成，而生成长度的巨大差异可能会加剧这种情况。有一些方法可以缓解这种情况，例如稍动态批处理。\n1.4 KV缓存\n解码阶段的一种常见优化是 KV 缓存。解码阶段在每个时间步生成单个token，但每个token依赖于之前token的键和值张量（包括预填充时计算的输入tokens的 KV 张量，以及当前时间步之前计算的任何新 KV 张量） 。\n「为了避免在每个时间步重新计算所有tokens的这些张量，可以将它们缓存在 GPU 内存中」 。每次迭代，当需要计算新token时，它们都会被添加到正在运行的缓存中，以便在下一次迭代中使用。在一些实现中，模型的每一层都有一个KV缓存。下图展示了KV的缓存机制。\n1.5 大模型内存需求\n实际上，LLM对GPU显存的需求主要是模型权重和KV缓存：\n「模型权重」 ：模型参数占用内存。例如，具有 70 亿个参数的模型（例如 Llama 2-7B ），以 16 位精度（FP16 或 BF16）加载，将占用大约  7B * sizeof(FP16) ~= 14 GB  的内存。\n「KV缓存」 ：自注意力张量的缓存占用内存，避免冗余计算。\n使用批处理时，批处理中每个请求的 KV 缓存仍然必须单独分配，并且可能会占用大量内存。下面的公式描述了 KV 缓存的大小，适用于当今最常见的 LLM 架构。\n每个Token KV缓存（字节）=2 * (num_layers) * (num_heads * dim_head) * precision_in_bytes\n第一个因子 2 代表  K  和  V  矩阵。通常，( num_heads * dim_head )的值与Transformer的 hidden_size （或模型的维度，d_model）相同。这些模型属性通常可以在配置文件中找到。\n输入批次中输入序列中的每个tokens都需要此内存大小。假设半精度，KV缓存的总大小由以下公式给出:\n总的Token KV缓存（字节）= (batch_size) * (sequence_length) * 2 * (num_layers) * (hidden_size) * sizeof(FP16)\n例如，对于 16 位精度的 Llama 2-7B 模型，批量大小为 1，KV 缓存的大小将为 1 * 4096 * 2 * 32 * 4096 * 2 字节，即约 2 GB。\n可以发现Llama 2-7B本身模型权重占用为14G，单个输入序列长度4096需要缓存为2G，这就需要16GB的显存，要运行该模型可见单个显存的要求。为此如何高效的管理 KV 缓存就成为了一项重要的挑战。内存需求随着批量大小和序列长度线性增长，它限制了可服务的吞吐量，并对长上下文输入提出了挑战。这就是本文中介绍的多项优化背后的动机。\n2.模型并行\n「减少模型权重在每设备的显存占用的一种方法是将模型分布在多个 GPU 上。分散内存和计算可以运行更大的模型或更大批量的输入」 。模型并行化是训练或推理模型所必需的，模型并行化需要比单个设备更多的内存，用来训练和推理（延迟或者吐量）。根据模型权重的划分方式，有多种方法可以并行化模型。\n请注意，数据并行也是一种经常在与下面列出的其他技术相同的技术。在这种情况下，模型的权重被复制到多个设备上，并且输入的（全局）批量大小在每个设备上被分成微批次。它通过处理较大的批次来减少总体执行时间。然而，这是一种训练时间优化，在推理过程中不太相关。\n2.1 Pipeline并行\nPipeline并行化将模型（垂直）分片为块，其中每个块包含在单独设备上执行的层的子集。下图展示了四路Pipeline，其中模型按顺序分区，并且所有层的四分之一子集在每个设备上执行。\n一个设备上的一组操作的输出被传递到下一个设备，后者继续执行后续块。 和 分别表示设备 n 上的前向传播和后向传播。每个设备上存储模型权重的内存需求被分成四份。\n该方法的 「缺点是，由于处理的顺序性质，某些设备或层在等待前一层的输出（激活、梯度）时可能保持空闲状态」 。这会导致前向和后向传递效率低下或出现“Pipeline bubbles”。在上图（b）中，白色空白区域是Pipeline并行性产生的Pipeline bubbles，其中设备闲置且未得到充分利用。\n为了在一定时间内充分利用GPU，可以通过微批处理的方式，即：分成多批，一个GPU完成之后立马安排下一次计算，但是这种方式可以在一定程度上缓解这种情况，如图 2c 所示。输入的全局批次大小被分成了批次，这些子批次被一一处理，最后累积梯度。请注意， 和 分别表示设备 n 上 m 批次的前向和后向传递。这种方法缩小了管道气泡的尺寸，但并没有完全消除它们。\n2.2 Tensor并行\nTensor并行化将模型的各个层（水平）分片为更小的、独立的计算块，这些计算块可以在不同的设备上执行。Transformer的主要组成部分，注意力块和多层感知器（MLP）层是可以利用Tensor并行化的。在多头注意力块中，每个头或一组头可以分配给不同的设备，以便它们可以独立且并行地计算。\n上图（a）显示了两层 MLP Tensor并行的示例，每一层都由一个圆角框表示。在第一层中，权重矩阵 分为 和 。对于输入 ，可以在同一批次不同设备上计算 和 ，其中，是identity 操作。这将每个设备上存储权重的内存需求减半。归约操作 组合了第二层的输出。\n上图（b）是自注意力层中Tensor并行的示例。多个注意力头本质上是并行的，并且可以跨设备分割。\n2.3 Sequence并行\nTensor并行化是有局限性，它需要将层划分为独立的、可管理的块，不适用于 LayerNorm和 Dropout等操作，而是在tensor并行中复制。虽然 LayerNorm和 Dropout的计算成本较低，但它们确实需要大量内存来存储（冗余）激活。\n如Reducing Activation Recomputation in Large Transformer Models所示，这些操作在输入序列中是独立的，并且这些操作可以沿着“序列维度”进行分区，从而提高内存效率。这称为序列并行性。\n模型并行技术不是唯一的，可以结合使用。它们可以帮助扩展和减少 LLM 的每 GPU 内存占用量，但也有专门针对注意力模块的优化技术。\n3.注意力机制优化\n缩放点积注意力 (SDPA， scaled dot-product attention) 操作将query和key对映射到输出，如论文Attention Is All You Need所述。\n3.1 多头注意力（MHA）\n作为 SDPA 的增强， 「三个变换张量对Q，K，V分别进行线性变换，这些变换不会改变原有张量的尺寸」 ，使模型能够共同关注来自不同位置的不同表示子空间的信息。这些子空间是独立学习的，使模型能够更丰富地理解输入中的不同位置。\n如下图所示（缩放点积注意力（左）和多头注意力（右）），多个并行注意力操作的输出被拼接后线性投影以组合起来。每个并行注意力层称为“头”，这种方法称为多头注意力（MHA）。\n当使用八个并行注意力头时，每个注意力头的维度都会减少（例如：）。这使得计算成本与单头注意力相似。\n3.2 多查询注意力（MQA）\nMHA 的推理优化之一称为多查询注意力 (MQA)，如 Fast Transformer Decoding 中提出的，在多个注意力头之间共享键和值。与以前一样，查询向量仍然被投影多次。\n虽然 MQA 中完成的计算量与 MHA 相同，但从内存读取的数据量（键、值）只是以前的一小部分。 「当受内存带宽限制时，这可以实现更好的计算利用率」 。它还减少了内存中 KV 缓存的大小，为更大的批量大小留出了空间。\n「key头的减少会带来潜在的准确性下降」 。此外，需要在推理时利用这种优化的模型需要在启用 MQA 的情况下进行训练（或至少使用大约 5% 的训练量进行微调）。\n3.3 分组注意力（GQA）\n分组查询注意力 (GQA) 通过将键和值投影到几组查询头，在 MHA 和 MQA 之间取得平衡（如下图所示）。在每个组中，它的行为类似于多查询注意力。\n上图显示多头注意力有多个键值头（左）。 「分组查询注意力（中心）的键值头多于一个，但少于查询头的数量，这是内存需求和模型质量之间的平衡」 。多查询注意力（右）具有单个键值头，有助于节省内存。\n最初使用 MHA 训练的模型可以使用原始训练计算的一小部分通过 GQA 进行“升级训练”。它们获得接近 MHA 的质量，同时保持接近 MQA 的计算效率。  「Llama 2 70B 是利用"
  },
  {
    "title": "科技论文写作技巧-360文档中心",
    "page_body": "论文中的语言表达和科技写作技巧\n论文中的语言表达和科技写作技巧在学术论文中，语言表达和科技写作技巧是至关重要的。\n良好的语言表达可以帮助读者更好地理解和沟通论文的内容，而科技写作技巧则能提升论文的质量和可读性。\n本文将探讨论文中的语言表达和科技写作技巧，并提供一些实用的建议。\nI. 引言语言表达是论文中最基本也是最关键的要素之一。\n良好的语言表达可以帮助作者清晰地传达研究成果和想法，同时吸引读者的注意力。\n在进行科技写作时，作者需要遵循一些规范和技巧，以确保论文的语言表达准确、简洁而富有条理。\nII. 语言表达技巧1. 简洁明了在论文中，作者应尽量使用简洁明了的语言表达。\n避免使用冗长复杂的句子结构和过于晦涩的词汇。\n可以通过删除冗余的信息、利用简洁的词汇和短语来达到简洁明了的效果。\n2. 准确用词语言表达的准确性非常重要。\n作者应该避免使用模棱两可的词汇和术语，以免造成误解。\n在使用专有名词和缩写时，应该确保读者可以理解其含义，并在首次出现时进行解释。\n3. 结构清晰论文的结构应该清晰有序，以帮助读者更好地理解内容。\n可以利用段落、子标题和列表来组织论文的结构，使其更易读和易于理解。\nIII. 科技写作技巧1. 引用和参考文献在论文中，作者需要引用其他学者的研究成果来支持自己的观点。\n在引用时，应该准确地标注引用来源，并按照规范的参考文献格式列出参考文献列表。\n2. 图表和数据展示科技论文通常需要使用图表和数据来展示研究结果。\n在使用图表和数据时，应确保其清晰易读，并添加必要的标注和解释，以帮助读者理解。\n3. 避免使用口语化的语言科技论文是正式的学术文献，因此应避免使用口语化的语言和俚语。\n作者应以专业、客观和正式的方式来表达自己的观点和研究成果。\nIV. 结论语言表达和科技写作技巧对于学术论文至关重要。\n良好的语言表达可以帮助读者更好地理解和沟通论文的内容，而科技写作技巧则能提升论文的质量和可读性。\n通过简洁明了的语言表达、准确用词和清晰的结构，以及正确引用和展示数据，作者可以提高论文的质量和影响力。\n大学科技论文写作技巧\n大学科技论文写作技巧在大学阶段，撰写科技论文是一项重要的学术任务，它不仅是对所学知识的综合运用和检验，也是培养科研能力和创新思维的重要途径。\n然而，对于许多大学生来说，科技论文写作可能是一项具有挑战性的工作。\n下面，我将为大家分享一些实用的大学科技论文写作技巧，希望能帮助大家顺利完成论文写作。\n一、选题选题是科技论文写作的第一步，也是最为关键的一步。\n一个好的选题应该具有创新性、实用性和可行性。\n创新性意味着选题要有新的观点、新的方法或新的应用。\n可以通过关注学科前沿动态、阅读最新的研究文献、参加学术会议等方式，了解当前研究的热点和空白点，从中寻找创新的灵感。\n实用性则要求选题能够解决实际问题或对现实具有一定的指导意义。\n可以从社会需求、生产实践、行业发展等方面入手，选择那些与实际应用紧密相关的课题。\n可行性是指在现有的条件下，能够完成选题的研究和写作。\n需要考虑自身的知识储备、实验条件、研究时间等因素，确保选题既不过于简单，也不过于复杂，能够在规定的时间内完成。\n二、收集资料在确定选题后，接下来要进行资料的收集。\n资料的来源主要包括图书馆、学术数据库、互联网、学术期刊、会议论文等。\n图书馆是获取纸质书籍和期刊的重要场所，可以通过检索图书目录和期刊索引，找到与选题相关的资料。\n学术数据库如知网、万方、维普等，提供了大量的学术论文和研究报告，是收集资料的重要渠道。\n互联网上也有许多有用的信息，但需要注意筛选和甄别其可靠性。\n在收集资料时，要广泛阅读相关的文献，了解前人在该领域的研究成果和不足之处，为自己的研究提供参考和借鉴。\n同时，要做好资料的整理和分类，便于后续的使用。\n三、拟定提纲提纲是论文的框架和结构，它能够帮助我们理清思路，合理安排论文的内容。\n在拟定提纲时，要根据论文的主题和研究目的，确定论文的结构和章节安排。\n一般来说，科技论文包括引言、正文、结论等部分。\n引言部分主要介绍选题的背景、意义、研究目的和方法等；正文是论文的核心部分，要详细阐述研究的内容、方法、结果和讨论；结论部分则总结研究的主要成果，提出研究的不足和展望。\n科技论文写作技巧\n第一章论文写作的技巧：1.将一篇论文分成不同的模块，分别撰写（化整为零）2.首先从最容易或最有趣的模块入手（各个击破）3.厘清各个模块之间的逻辑关系（有机联系）4.完成之后再将各模块组装起来（巧妙整合）5.始终与导师和co-authors 进行沟通6.凝练一篇论文的发现点（>3点）7.将每一条发现点的内容（数据）组装成有意义的图、表和文字8.给自己一个deadline 和相对集中的时间9.选择自己有效的工作时间写论文10.在实验进行时就着手“起草”论文第二章 科学论文的形式与内涵 论文写作前准备1. 了解你的数据和读者 准备你的数据：实验数据是论文发表的基础，没有高质量的数据，论文将不会存在了解你的读者：读者是你发现和理论的接受者，要学会让读者明白并接受你的观点 2. 准备数据和理论 动笔之前和导师、co-authors 进行讨论（最好组织一个workshop ） 确定数据质量和大致的故事情节（发现、理论）将要报道的数据整理成关键的信息点（证据） >3个发现点 按重要性，将信息点进行排序，先组织最重要的发现，然后次重要的发现选择自己最有创意的时间段来进行写作科学论文是：记录原创性科学研究结果，或综述已有科学发现及其发展将正式发表或出版的书写文件。\n 两种类型的科学论文：研究性论文（Research article ）—— 记录原创性科学研究结果 综述性论文（Review article ）—— 总结和分析已有科学发现及其发展科学论文的结构：背景和研究目的（I ）、方法（M&M ）、主要结果（R ）、结论（D ）（发现，理论）科学研究方法的结构:科学问题→科学假设→实验验证（设计&实验）→（分析）结论-发现-理论科学论文 vs.科学研究：1.科学论文和科学研究关系密切 2.优秀论文的前提是有好的研究3.结果好的研究结果需要论文来进行传播怎样才是一篇优秀的（研究）论文？1.包含有意义的科学问题2.有明确、合理的科学假设3.有严密的实验设计4.有令人信服的实验结果 5.有令人鼓舞的理论、实践意义 6.有动人的故事情节（story ）谁将会读我的论文: 读者→读精彩的文章。\n 科技论文写作技巧与范例\n科技论文写作技巧与范例科技论文写作技巧与范例科技论文是学术界对于科学研究成果进行详细描述、分析和总结的一种文体。\n在写作过程中，需要遵循一定的技巧和格式，以保证论文的质量和准确性。\n本文将介绍科技论文写作的相关技巧，并提供一个范例供参考。\n一、科技论文写作技巧1. 确定研究目标和问题：在开始写作前，明确研究目标和问题是非常重要的。\n做好充分的背景研究，理解已有的研究成果，并确定自己的研究目标和问题。\n2. 结构合理布局：科技论文一般包括摘要、引言、方法、结果、讨论和结论等部分，合理的结构布局能够使读者更好地理解你的研究工作。\n建议先写好论文的大纲，在此基础上逐步完善细节。\n3. 清晰准确的表述：科技论文中应避免冗长和模糊的表述，要力求简洁而准确地描述研究方法和结果。\n尽量使用专业术语，并确保它们在文中得到明确定义。\n4. 数据和实验的支撑：科技论文必须借助充足的数据和实验证实研究成果。\n这些数据和实验应被详细而准确地描述，以便其他科研人员可以重复你的工作。\n5. 逻辑严密的论证：科技论文应该具备逻辑严谨的论证过程。\n写作时应将各个实验或研究结果紧密联系起来，逐步推进，形成一个完整而有条理的论证链。\n二、范例：机器学习在图像分类中的应用摘要：本文研究了机器学习在图像分类中的应用。\n通过分析现有的机器学习算法，我们提出了一种基于卷积神经网络的图像分类方法，并在CIFAR-10数据集上进行了测试。\n实验结果表明，该方法在图像分类问题上具有良好的性能。\n引言：图像分类是计算机视觉领域的一个重要问题。\n解决图像分类问题可以使计算机自动识别和分类图像，具有广泛的应用前景。\n近年来，机器学习技术的发展为图像分类提供了新的解决方案。\n本文旨在研究机器学习在图像分类中的应用，并提出一种新的方法。\n方法：我们采用卷积神经网络（CNN）作为图像分类的模型。\n首先，我们收集了CIFAR-10数据集，该数据集包含了10个不同类别的图像。\n然后，我们设计了一个由多层卷积层和池化层组成的CNN模型。\n高效发表科技论文的写作方法与技巧\n高效发表科技论文的写作方法与技巧发表科技论文是科研人员的重要任务之一，因为论文的发表是科研成果的重要体现。\n但是，科技论文的写作并非易事。\n本文将介绍高效发表科技论文的写作方法与技巧。\n一、选题与规划选题是写作科技论文的第一步。\n一个好的选题应具备以下特点：具有科学意义，对当前科研领域有重要影响；具备可行性，能够通过科学研究方法进行实证研究；相关领域研究相对薄弱，有独创性；专业性较强，符合自身研究背景与兴趣。\n在选好题目后，需要制定详细的论文写作计划。\n写作计划应包括如下内容：明确论文的主题与目标；每个章节所要阐述的内容；核心实验和数据收集计划；论文提交截止日期等。\n二、文献综述文献综述部分是论文的重要组成部分，是写作的第二步。\n通过文献综述可以准确了解自己的研究领域中已有研究进展，及时了解相关研究最新进展与动态。\n文献综述的重点是分类整理阅读过的文献，突出自己的创新点，并对文献进行综合分析与总结。\n文献综述的写作技巧包括：广泛查阅相关文献，确保综述的全面性；理清综述的逻辑结构，突出自己的观点与创新；避免重复操作，避免过多引用综述。\n三、实验设计与数据处理实验设计是论文写作的一个重要环节，可以合理安排实验过程与流程，提高实验的可靠性与有效性。\n在实验设计过程中需考虑实验目标、实验方法、实验参数等。\n数据处理是科技论文中不可或缺的一部分，可以通过统计学方法为实验数据增加科学性与可信度。\n在进行数据处理时，需要选择合适的统计分析方法，并确保分析结果的准确性与可靠性。\n四、论文写作与修改论文写作阶段应先行撰写论文的摘要与关键词，重要章节如绪论、材料与方法、结果与讨论也要及时进行书写"
  },
  {
    "title": "论文阅读报告-人人文库",
    "page_body": "文档简介\n 汇报人：xxx20xx-07-16论文阅读报告目录CONTENTS引言论文主题与作者观点研究方法与数据来源研究结果与讨论论文对个人或领域的影响总结与展望01引言通过阅读和分析学术论文，掌握当前学术领域的研究热点和发展趋势。深入了解学术领域的前沿研究学习论文的写作技巧、研究方法，以及严谨的学术态度。提升学术素养通过报告的形式，总结阅读成果，为后续学术研究提供参考和借鉴。为未来学术研究打下基础报告目的和背景根据研究领域、发表时间、引用次数等因素，筛选出具有代表性的学术论文。论文选择标准采用精读与泛读相结合的方式，先泛读了解论文大意和结构，再精读深入理解论文内容和研究方法。阅读方法在阅读过程中，记录重要观点、数据和研究方法，为后续报告撰写提供素材。笔记与总结论文选择与阅读方法报告结构概述论文基本信息介绍包括论文标题、作者、发表刊物和时间等基本信息。论文主要内容概述简要介绍论文的研究背景、目的、方法、结果和结论等关键信息。重点内容分析针对论文中的创新点、重要观点或数据进行深入分析和讨论。对个人学术研究的启示结合个人学术研究方向，探讨阅读该论文后的收获和启示。02论文主题与作者观点论文主题简介探讨人工智能在医疗领域的应用及其挑zhan。01分析深度学习算法在图像识别与疾病预测中的效果。02研究大数据在提升医疗服务质量与效率方面的作用。03010203作者认为人工智能技术能够显著提高医疗诊断的准确性和效率。深度学习算法在图像识别领域具有显著优势，可辅助医生进行更精确的诊断。大数据技术可以整合患者信息，为个性化治疗方案提供支持，从而提升医疗服务质量。作者主要观点阐述论文的创新点与贡献010203提出了一种新型的深度学习模型，用于医疗图像识别，提高了诊断准确率。通过实际案例分析，展示了大数据在医疗服务中的成功应用。为医疗行业提供了一种全新的、基于人工智能和大数据的解决方案，有助于推动医疗技术的进步。03研究方法与数据来源实验研究通过设计和实施实验，控制变量并观察实验结果，以揭示特定条件下的因果关系。文献综述通过系统地回顾和分析已有文献，梳理研究领域的现状和发展趋势，为研究提供理论基础和依据。实证研究通过收集实际数据，运用统计分析和案例研究等方法，验证理论假设并探究变量之间的关系。研究方法论述利用zheng府、研究机构或企业公开的数据集，获取大量标准化的数据。公开数据集设计问卷并向目标群体发放，收集他们的意见、看法和经验。调查问卷通过深入实地观察和与相关人员访谈，获取第一手资料和真实反馈。实地观察与访谈数据来源及采集方式010203数据分析与处理方法文本分析针对文本数据，运用文本挖掘和情感分析等技术，提取关键信息和观点。因果分析运用回归分析、方差分析等统计方法，探究自变量与因变量之间的关系及其显著性。描述性统计分析对数据进行整理、分类和汇总，通过图表和指标展示数据的分布和特征。04研究结果与讨论010203确定了研究区域内生物多样性的关键影响因素，包括土壤类型、气候条件和水资源分布。揭示了不同植被类型对土壤碳储存和气候变化的响应机制。分析了人类活动对生物多样性的影响，包括农业活动、城市化进程和污染排放。主要研究结果展示结果分析与讨论010203对比分析了不同植被类型在碳储存、水源涵养和生态服务价值方面的差异。探讨了气候变化对生物多样性影响的区域差异，以及这些差异如何影响生态系统的稳定性和可持续性。评估了人类活动对生物多样性的直接和间接影响，并提出了相应的生态保护建议。研究区域的代表性和广泛性有待进一步提高，以更全面地反映生物多样性的变化规律。未来研究可进一步关注生物多样性与其他环境因素的相互作用，如地形、地貌、土壤类型等，以及这些因素如何共同影响生态系统的结构和功能。需要加强长时间序列的监测和数据收集，以便更准确地揭示生物多样性变化的趋势和机制。可探索利用新技术和方法，如遥感技术、GIS分析等，提高生物多样性研究的精度和效率。研究局限性及未来研究方向0204010305论文对个人或领域的影响提供新的研究视角通过阅读论文，可以获得新的研究视角和思路，从而启发个人在学术研究中的创新思维。拓展研究范围提升研究方法论对个人学术研究的启示论文中的研究内容和方法可以引导个人拓展自己的研究范围，探索更多未知的学术领域。借鉴论文中的研究方法和技术手段，可以提升个人在研究过程中的方法论水平。优秀的论文往往能够推动相关领域的发展，为该领域的研究提供新的思路和方法。推动领域发展论文中的研究成果可以拓展到实际应用中，促进相关领域的技术进步和产业升级。拓展应用领域一些具有创新性的论文能够引领相关领域的研究潮流，成为后续研究的热点和焦点。引领研究潮流对相关领域发展的影响论文的研究成果可以转化为实际应用，推动社会进步和发展，提高人民生活水平。促进社会进步论文的社会价值与意义论文作为学术传承的载体，能够传承和弘扬学术精神，为后来的学者提供宝贵的学术资源和经验。传承学术精神优秀的论文成果可以提升国家在相关领域的竞争力，为国家的经济发展和科技创新做出贡献。提升国家竞争力06总结与展望论文主要观点与研究成果总结010203论文通过实证分析，深入探讨了XX领域的现状与挑zhan，并提出了针对性的解决方案。研究揭示了XX现象背后的深层次原因，对理解该领域的发展趋势具有重要意义。通过定量与定性相结合的研究方法，论文全面评估了XX策略的有效性，为相关领域提供了有价值的参考。未来研究可进一步拓展XX领域的研究范围，探索更多潜在的影响因素。建议后续研究加强跨学科合作，引入更多元化的研究方法，以丰富研究视角和深度。对未来研究的展望与建议针对当前研究中存在的问题，未来可以尝试建立更为精确的模型，以提高预测的准确性和可靠性。通过阅读该论文，我深刻"
  },
  {
    "title": "【麻省理工】LLM《基础模型和生成式AI》全9讲附资源，大模型入门必学！-哔哩哔哩",
    "page_body": "陆陆续续也整理了不少资源，希望能帮大家少走一些弯路！无论是学业还是事业，都希望你顺顺利利 看在UP这么努力的份上，求个三连+关注嘛 1️⃣ 大模型入门学习路线图（附学习资源） 2️⃣ 大模型方向必读书籍PDF版 3️⃣ 大模型面试题库 4️⃣ 大模型项目源码 5️⃣ 超详细海量大模型LLM实战项目 6️⃣ Langchain/RAG/Agent学习资源 7️⃣ LLM大模型系统0到1入门学习教程 8️⃣ 吴恩达最新大模型视频+课件\n科技\n人工智能\nai大模型\n大模型入门\n大模型基础\n大模型教程\n大模型学习路线\n深度学习\n大模型\nLLM"
  },
  {
    "title": "大学学术论文阅读报告模板_百度文库",
    "page_body": "关于期刊文献阅读的报告\n 文献名\n • The Measurement of Laminar Burning Velocities and Markstein Numbers for Isooctane–Air and Iso-octane–n-Heptane–Air Mixtures at Elevated Temperatures and Pressures in an Explosion Bomb\n 背景1\n • 文章出处（可以写一些写作的相关背景）\n 背景2\n • 作者及其研究动态\n 背景3\n • 定容燃烧弹法的发展\n 在读本文时可能会遇到的一些问题\n • 什么是马克数 • 为什么要求燃烧速度，燃烧速率，拉伸 率。。。。 • 什么是两个燃烧速率 • 我们要在求什么，在实验中能得到什么 • （我们的学习中存在这样一个问题，比如数学， 物理，先告诉你一个定理，一个实验，公式是 什么实验是什么，但我们往往不知道这个实验 和定理是用来解决什么实际问题的，我们怎么 会遇到问题解决问题的经过）\n 实验结果\n • 关于层流燃烧速率\n • 关于马克数\n • 关于ZE数\n 一些燃烧速率测量相关\n • 质量流量 • 燃烧速率\n 结论\n 心得\n 另外关于一些如何作文献阅读报告\n 展望\n • 谢谢\n • 因为要研究层流燃烧特性，所以研究燃烧 速率，由此引出本文实验\n wk.baidu.com\n 文章概述\n 前言\n • 火焰速度是由。。。。。得出的 • 火焰拉伸的影响，将由MA数表述\n • 因为两者，，，，，\n 火焰不稳定性的一些影响\n 实验测量\n 实验技术\n 实验中的一些影响\n • 点火条件 • 拉伸率 • 不稳定性\n 点火条件\n 拉伸率\n 不稳定性\n 关于期刊文献阅读的报告文献名laminarburningvelocitiesmarksteinnumbersisooctaneairisooctanenheptaneairmixtureselevatedtemperaturesexplosionbombwoolleyschoolmechanicalengineeringuniversityleedsleedsls29jtenglanddefenseevaluationresearchagencyfarnboroughgu140lshampshireengland展望背景0我研究的课题和方向是什么背景为什么要研究这个方向和内容背景从研究方向引出所需要研究的具体内容火焰速度燃烧速率ma数背景1文章出处可以写一些写作的相关背景背景2作者及其研究动态背景3定容燃烧弹法的发展在读本文时可能会遇到的一些问题我们的学习中存在这样一个问题比如数学物理先告诉你一个定理一个实验公式是什么实验是什么但我们往往不知道这个实验和定理是用来解决什么实际问题的我们怎么会遇到问题解决问题的经过因为要研究层流燃烧特性所以研究燃烧速率由此引出本文实验文章概述前言因为两者火焰不稳定性的一些影响实验测量实验技术实验中的一些影响不稳定性点火条件拉伸率不稳定性实验结果关于ze数一些燃烧速率测量相关燃烧速率结论心得另外关于一些如何作文献阅读报告展望\n 介绍\n • • • • • • • • 背景 文章 文章目的 文章内容 文章结论 心得(学会了读报告的SKILL） 关于一些写学术论文的经验 展望\n 背景0\n • 为什么要读这篇文献 • 我研究的课题和方向是什么\n 背景\n • 为什么要研究这个方向和内容\n 背景\n • 从研究方向，引出所需要研究的具体内容 （火焰速度，燃烧速率，MA数）\n • D. BRADLEY, R. A. HICKS, M. LAWES, C. G. W. SHEPPARD, and R. WOOLLEY*\n School of Mechanical Engineering, University of Leeds, Leeds LS2 9JT, England (D. B., M. L., C. G. W. S.,R. W.) and Defense Evaluation and Research Agency, Farnborough GU14 0LS,Hampshire, England (R. A. H.)"
  },
  {
    "title": "【全748集】清华大佬终于把AI大模型（LLM+RAG+GPT-4o+Op）讲清楚了！零基础易学 | 通俗易懂 | 干货满满，让你不再走弯路，拿走不谢！",
    "page_body": ""
  },
  {
    "title": "如何更有效的将深度学习算法部署在计算资源有限的设备？澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "深度学习已成为许多机器学习应⽤程序不可或缺的⼀部分，现在可以在⽆数电⼦设备和服务中找到，从智能⼿机和家⽤电器到⽆⼈机、机器⼈和⾃动驾驶汽车。随着深度学习在我们⽇常⽣活中的普及，对快速且节能的神经⽹络推理的需求也在增加。神经⽹络量化是降低推理过程中神经⽹络的能量和延迟要求的最有效⽅法之⼀。\n包括英伟达、⾼通、华为、AMD在内的⼚家，都在神经⽹络加速⽅⾯投⼊了研发⼒量。通过量化、裁剪和压缩来降低模型尺⼨。更快的推断可以通过在降低精度的前提下使⽤⾼效计算平台⽽达到，其中包括intel MKL-DNN，ARM CMSIS，Qualcomm SNPE，Nvidia TensorRT。\n⼈⼯智能⼀直是⼀个备受关注的热点研究领域。到⽬前，以深度神经⽹络(deep neural networks，DNN)为代表的联结主义⽅法成为了⼈⼯智能领域的研究热点。作为深度神经⽹络中应⽤最为⼴泛的类型，卷积神经⽹络已经在计算机视觉、语⾳分析、⾃然语⾔处理等各类任务中取得了许多突破性的成果。2012年，AlexNet以⾼于第⼆名近11%的分类精度的成绩取得ImageNet ILSVRC 2012⽐赛的冠军，引爆了深度卷积神经⽹络的研究热潮。随后，各类卷积⽹络模型如VGG、GoogLeNet、ResNet等相继出现,⼀次又⼀次地刷新ImageNet⽐赛的榜单。基于这些成功实践的知识和经验，卷积神经⽹络的应⽤范围进⼀步拓展到⽬标检测、语义分割、⼈脸识别等各类计算机视觉任务中。甚⾄在语⾳识别，⾃然语⾔处理等⾮视觉任务中也开始见到卷积神经⽹络的⾝影。\n虽然关于深度学习的理论和技术已经取得了长⾜发展，但是其不⾜之处也依然明显。其中较为突出的有计算消耗⼤、容易过拟合、模型可解释性差、不耐对抗攻击等问题。计算和存储消耗问题阻碍了最先进的深度学习算法在如⽆⼈车、⼿机、IoT设备等计算资源有限的设备上的部署。总体来说，深度学习模型⾯临的资源的限制主要来⾃三个⽅⾯:\n模型本⾝的⼤⼩。\n运⾏时所需要的内存⼤⼩。\n模型完成执⾏所需要的计算量。\n以被⼴泛使⽤的VGG-16模型为例，该模型有多达1亿千万个可训练参数，如果以单精度浮点型存储这些参数，模型需要占据530MB的存储空间。处理⼀张500×500分辨率的图⽚，需要执⾏近800亿次浮点运算，并且需要460MB额外的内存空间来存储中间的计算结果，这对于低端设备来说是难以承受的负担。2012年以来深度学习⽅法发展如⽕如荼的⼀个重要原因是GPU提供了⽐CPU更多的计算能⼒。但是随着⽹络模型越来越复杂，硬件更新带来的算⼒增长很快就被吞没，模型算⼒需求的增长却没有尽头。模型的精度和计算量有直接关系。越复杂的⽹络模型分类效果越好，但同时也消耗更多的存储和计算资源。降低卷积神经⽹络的计算和存储消耗，是其⼤规模应⽤于实际场景的关键。因此，在模型效果能够基本得到保证的前提下，如何对模型进⾏压缩与加速，受到了学界和⼯业界的⼤量关注。\n近年来，越来越多关于⽹络压缩和加速的⽅法被提出，它们从不同的角度去实现⽹络的压缩和加速。⽹络剪枝（network pruning）旨在通过不同粒度去剪除⽹络中的冗余参数；量化利⽤低⽐特数的权重参数来压缩原⽹络；低秩分解（low-rankde composition）主要通过利⽤多个低秩矩阵的外积去近似逼近原权重矩阵来加速⽹络；知识蒸馏（knowledge distilling）通过⼤的教师⽹络去监督⼩的学⽣⽹络学习，达到压缩⽹络的⽬的；紧凑⽹络设计（compactnetwork design）旨在设计轻量、⾼效的⽹络结构，降低⽹络的参数量和计算量。\n其中神经⽹络量化在Google发表的《Quantizationand Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference》中建⽴了⼀套更加通⽤的量化标准，并且在tflite中真正实现落地。\n量化就是将浮点存储（运算）转换为整型存储（运算）的⼀种模型压缩技术。将原本⽤浮点数表⽰的神经⽹络通过量化，变为⽤定点数表⽰，来减⼩存储空间及运算速率。按照聚类中⼼是否均匀分布，可以把量化分为线性量化和⾮线性量化。\n卷积神经⽹络模型的量化⽅法，是直接从数值计算层⾯改变神经⽹络模型的⽅法。这种⽅法通常是作⽤在数值计算中最耗时的部分，浮点数的计算中。这种⽅法对神经⽹络模型的参数值或者激活值进⾏量化，⽐较直观的⼀种是把原来的FP32运算变成FP16或者int18计算。当然，量化后的神经⽹络模型要实现加速，需要有特定设备的⽀持。但是最新的安培系列英伟达GPU已经可以实现FP16和int18的加速。\n来⾃MIT的韩松教授《Deep Compression:Compressing Deep Neural Networks with Pruning, Trained Quantization and HuffmanCoding(2016)》就是典型的⾮线性量化，作者使⽤K-MEANS算法对浮点权重进⾏量化，但因需要查表取得原始数据再进⾏计算，所以对计算的加速帮助不⼤，但可以减少模型的存储⼤⼩。\n聚类量化的的计算过程\n线性量化则通过线性变换，将浮点数通过线性变换转换为定点数，由于神经⽹络对于参数的健壮性，及神经⽹络参数的分布特征，量化后即使有参数精度的损失，在整体计算准确率上损失也不⼤，且可通过量化感知训练QAT（quantization aware training）实现⽹络对于量化损失精度的学习，达到更⾼的准确率。线性量化的应⽤及前景都更为⼴阔，我们接下来将着重介绍两种线性量化⽅法，即后训练量化PTQ（post training quantization）训练后量化(PTQ)（quantization aware training）。\n神经⽹络参数分布密度图\n训练后量化(PTQ)\n算法采⽤预训练的FP32⽹络并将其直接转换为定点⽹络，⽽不需要原始训练。转换⽅法可以是⽆数据的，或者需要⼀个⼩型校准集。因为⼏乎没有涉及到超参数调整、所以可以使它们可以通过单个API调⽤⽤作⿊盒⽅法，这使神经⽹络设计者不必深⼊了解量化神经⽹络，从⽽允许更⼴泛地应⽤神经⽹络量化。PTQ过程中的⼀个重要步骤是为每⼀层找到适合的量化范围。量化通常会有准确性的损失。这也很容易理解。float32本⾝可以存储的取值范围⽐uint8的取值范围要宽，所以不能⽤uint8表⽰，肯定有很多值只能四舍五⼊到uint8。量化模型和全精度模型之间的误差也是由于裁剪舍⼊操作造成的。浮点实数使⽤r，量化定点整数使⽤q。浮点和整数之间的转换公式为：\ns是表⽰实数和整数之间的⽐例关系的尺度。z是零点，表⽰量化后实数0对应的整数。计算⽅法如下：\n通过这些公式，我们就可以将浮点数映射到⼀个我们已知s和z的整数空间内，对于计算机来说，对于定点数的计算不需要浮点数计算的移位操作，计算速度会提升很多。\nPTQ整个过程使⽤定点算法实现。计算完全精度模型后，提前计算每个中⼼特征图的权重、最⼩值和最⼤值，计算尺度和零点，然后将权重量化为int8/ int16整数。整个⽹络量化完成后，就可以按照上⾯的流程进⾏量化推断了。\n量化感知训练QAT\n训练后量化技术是我们⾸选的量化⽅法。它⾮常有效且实施快速，因为它们不需要使⽤标记数据重新训练⽹络。但是，它们有局限性，尤其是在针对激活的低位量化时，例如4位及以下。后训练技术可能不⾜以减轻低⽐特量化带来的⼤量化误差。在这些情况下。我们可以使⽤量化感知训练（QAT）。QAT在训练期间对量化噪声源进⾏建模。这使得模型能够找到⽐训练后量化更多的最优解。然⽽，更⾼的准确性伴随着神经⽹络训练的通常成本，即更长的训练时间，需要标记数据和超参数搜索。\n因为我们在量化的前向传递中使⽤了round即取整函数，round函数的梯度⼏乎处处为0。如果⽹络中存在这个函数，那么反向传播的梯度也将变为0。所以我们可以采⽤直通估计器（Straight Through Estimator）来来近似梯度。卷积层的梯度在伪量化之前直接传回权重。它将round函数的的梯度近似为1，即直接将上⼀层的梯度传到下⼀层。\n使⽤STE进⾏量化感知训练的前向和后向计算图\n这就是QAT的关键，即使⽤STE处理梯度⽆法计算的问题，从⽽使量化神经⽹络也可以训练，从⽽使模型在训练的过程，学习量化带来的损失，从⽽实现更⾼的准确率。\n量化使我们能够从浮点表⽰转变为定点格式，并且与利⽤⾼效定点运算的专⽤硬件相结合，有可能实现显着的功率增益并加速推理。然⽽，为了利⽤这些节省，我们需要能够保持⾼精度的稳健量化⽅法，同时减少权重和激活的位宽。主要介绍了两类量化算法：训练后量化（PTQ）和量化感知训练（QAT）。训练后量化技术采⽤预训练的FP32⽹络并将其转换为定点⽹络，⽽⽆需训练。这使它们成为⼀种轻量级的量化⽅法，⼯程⼯作量和计算成本低。可以在所有⽹络的浮点精度降低的1%内实现权重和激活的8位量化。许多⽹络甚⾄可以量化到4位权重，⽽性能仅略有下降。\n量化感知训练通过模拟量化操作对训练期间的量化噪声进⾏建模。与PTQ相⽐，此训练过程可以找到更好的解决⽅案，同时实现更有效和更积极的激活量化。QAT可加⼊批量归⼀化等⽅法，可以实现4位权重量化，与浮点相⽐，准确度仅略有下降。PTQ和QAT之间的选择取决于应⽤的精度和功率要求。这两种⽅法都是神经⽹络量化的重要⽅法。"
  },
  {
    "title": "一文读懂：AI大语言模型(LLM)如何理解人类的问题-今日头条",
    "page_body": "前言\n一直好奇大语言模型是如何理解人类问题的，然后给出正确的响应，最近学习总结一下。\n划重点： 嵌入技术：将语言的复杂性转化为机器可高效处理的数学框架，同时保留语义本质。通过这种从符号到向量的转化，大型语言模型获得了理解词语与概念间关系的能力，从而实现高级语言处理。\n具体流程如下：\n注：本文中的“标记/单元” 可以理解为 \"token\"\n一、分词：将文本输入转化为模型可读单元\n在大型语言模型开始处理问题之前，必须先将文本分解为模型可理解的单元(token)。这一关键的第一步为所有后续处理过程奠定了基础。\n分解成tokens\n分词是大型语言模型处理文本的关键第一步，其核心是将输入文本分解为称为\"标记\"的较小单元(token)，使模型能够理解和分析。对于英语，一个标记通常对应0.75个词或约四个字符。\n二、分词工作原理\n不同大型语言模型采用多种分词方法将文本划分为可处理token，主流技术包括字节对编码（BPE）、WordPiece和SentencePiece。这些方法将词语切分为有意义的子成分：例如\"tokenization\"可能被分解为\"token\"和\"ization\"两个标记，因每个子词都参与构成完整词义的理解。\n大型语言模型的效能往往取决于其分词策略。子词分词方法通过将未知单词拆解为已知子词成分，可显著减少未登录词错误。\n三、标记预算管理\n大型语言模型的上下文长度限制范围从几千至128,000标记。有效利用标记的关键在于优先处理相关信息并消除冗余内容。\n语言差异性\n不同语言的分词方式存在差异。具有复杂形态结构的语言在表达相同内容时，可能比其他语言需要更多标记。\n标记效率提升\n标记效率可通过以下方式提升：将信息按重要性降序组织；使用简洁且语义清晰的语言；实施提示压缩技术；\n提交前预估标记用量。\n理解分词机制是有效运用大型语言模型的基础，尤其在成本管控与上下文长度内信息最大化方面。文本的分词方式直接影响提示可容纳的信息量及其处理成本。\n四、嵌入流程：从标记到向量表示\n当文本被分解为标记后，大型语言模型需将这些离散符号转化为可处理的数学形式。此处嵌入技术将语言转换为数值空间，使语义能够被操作处理。\n嵌入构成大型语言模型语言建模的基础。文本处理时，首先被分解为模型可理解的标记——包括词语、子词或字符。这些标记随后转化为称为嵌入的数值向量，用于捕捉文本元素间的语义关系。\n嵌入流程将离散的词语单元（标记）映射为数值向量。例如\"tokenization\"一词可分解为\"token\"和\"ization\"，因每个子词都参与完整词义的理解。\n从词语到数学表征\n在LLM推理的预填充阶段，输入标记被转化为向量嵌入——即模型可处理的数值表征。这些嵌入捕捉每个标记的语义本质，辅以位置编码提供序列顺序信息。\n每个标记的 嵌入向量 与训练习得的 权重矩阵相乘，通过线性投影生成查询向量、键向量和值向量 。该数学表征使模型能运用计算技术处理语言。\n向量空间中的嵌入可视化\n嵌入将词语定位在高维空间中，相似概念在此空间内距离更近。这种几何结构使模型能够以数学方式（而非符号方式）推理概念间的关系。\n对于含生僻词汇或带前后缀词语的复杂文本，子词表征可将这些元素进一步分解。当标准上下文嵌入技术可能不足时，该方法在处理未登录词和形态丰富语言时尤为有效。\n嵌入技术的强大能力在于：将语言的复杂性转化为机器可高效处理的数学框架，同时保留语义本质。通过这种从符号到向量的转化，大型语言模型获得了理解词语与概念间关系的能力，从而实现高级语言处理。\n五、Transformer架构与注意力机制\n当标记转化为嵌入后，模型需处理这些表征以理解其相互关系。Transformer架构——尤其是其注意力机制——使大型语言模型能够捕捉这些复杂关系。\nTransformer核心组件\n该架构构成现代大型语言模型（LLM）的核心架构。其核心在于自注意力机制，可同步分析所有标记间的关系。这种并行处理能力赋予Transformer理解上下文的卓越性能。\n关键转换步骤：\n将标记转化为数值向量（嵌入） 通过注意力机制处理嵌入 计算三个矩阵：查询矩阵、键矩阵、值矩阵 应用数学运算确定关系\n注意力机制的运作原理是从输入数据计算三个矩阵：查询矩阵、键矩阵和值矩阵。该方法借鉴数据库操作原理——用户通过发出与键匹配的查询来检索对应数值。\n六、总结\n大型语言模型从提示到响应的全流程涉及多个精密协同的运作机制。理解这些技术——分词、嵌入、注意力及推理模式——对开发AI驱动产品具有核心指导价值。\n此处呈现的技术知识可直接转化为实践优势：优化标记用量可降低成本并最大化上下文利用率；基于推理模式设计提示能获得更可靠精准的输出；思维链提示与元提示等先进技术，能实现以往超越AI能力的复杂推理任务。\n注：部分材料整理于网络"
  },
  {
    "title": "普通人也可以玩转的大模型：10个高效大语言模型提示词与案例-今日头条",
    "page_body": "大语言模型的回答质量，很大程度取决于你的提示词（Prompt）。以下总结10种提示模式，既简单又强大，覆盖了学习、写作、决策、创新等多种场景。\n1. 角色扮演型\n提示模式：\n你是一位[领域/角色]专家，请用[风格/语气]来解释[问题/主题]，并给出具体的例子。\n这种模式能让模型带上“专家的帽子”，回答更权威、逻辑性更强。\n案例：\n提示词：\n你是一名资深营养师，请用通俗易懂的语言解释「间歇性断食」的原理，并举出一个适合上班族的饮食安排。\n回答方向：模型会用专业但不晦涩的方式，解释断食如何影响代谢，并提供早餐/午餐/晚餐的实际餐单。\n2. 分步骤推理型\n提示模式：\n请逐步解释如何解决[问题]，分成清晰的步骤，每一步都要有原因和示例。\n它能避免“只给结论”的回答，帮助你看到完整的推理过程。\n案例：\n提示词：\n请分步骤解释如何写一份高质量的商业计划书，每一步都要说明其作用，并举例说明。\n回答方向：模型会输出“市场调研 → 产品定位 → 商业模式设计 → 财务预测 → 风险评估”的逻辑链，并配合实例，如“如果是咖啡店，应如何写市场调研部分”。\n3. 对比分析型\n提示模式：\n请比较[方案A]和[方案B]的优缺点，并给出适用场景和推荐意见。\n适用于做选择时，获得多维度参考。\n案例：\n提示词：\n请比较「租房」与「买房」的优缺点，并结合30岁单身上班族的情况给出建议。\n回答方向：模型会列出“租房灵活但积累少；买房稳定但负担大”，然后结合用户情况（收入水平、职业稳定性、人生规划）给出推荐。\n4. 案例驱动型\n提示模式：\n请用真实或假设的案例，说明[概念/方法]是如何在实践中应用的。\n能让抽象知识落地。\n案例：\n提示词：\n请通过一个小型电商创业的案例，说明如何利用「精益创业方法论」来快速测试市场。\n回答方向：模型会讲一个假设案例，例如一个卖手工饰品的创业者如何用最小可行产品（MVP）快速验证市场需求，降低试错成本。\n5. 批判性思维型\n提示模式：\n请找出[观点/方案]中的潜在问题或漏洞，并提出改进建议。\n适合提升方案质量，避免盲点。\n案例：\n提示词：\n有人提出“所有中学生都应该学习编程”，请找出这一观点的潜在问题，并提出更合理的替代方案。\n回答方向：模型可能指出“强制学习可能增加学习负担，不同学生兴趣差异大”，并建议“引入编程选修课，结合AI工具辅助教学”。\n6. 模板生成型\n提示模式：\n请生成一个[计划/表格/清单/模板]，用于[具体场景]。\n快速获得可直接应用的工具。\n案例：\n提示词：\n请生成一个为期7天的健身训练计划表，适合初学者，每天30分钟。\n回答方向：模型会产出一份表格：周一→有氧跑步，周二→核心训练，周三→瑜伽拉伸… 并附带注意事项。\n7. 学习辅导型\n提示模式：\n假设我是[水平]的学习者，请用简单的语言解释[概念]，并提供逐渐深入的学习路径。\n适合自学者和学生。\n案例：\n提示词：\n假设我是完全没有编程基础的小白，请用简单的语言解释「Python」是什么，并为我设计一个3个月的学习计划。\n回答方向：模型会从“Python就像教电脑说话的语言”开始，推荐初学书籍/网站，然后设计学习路径，如“第1个月学基础语法，第2个月写小程序，第3个月做项目”。\n8. 多角度思考型\n提示模式：\n请从[学科A]、[学科B]和[学科C]的角度，解释[问题/现象]。\n适合跨学科研究或创新思考。\n案例：\n提示词：\n请从心理学、经济学和社会学的角度，解释「为什么人们喜欢使用短视频应用」。\n回答方向：模型会从心理学（即时满足感）、经济学（流量变现机制）、社会学（社交分享与文化认同）三个角度进行分析。\n9. 总结归纳型\n提示模式：\n请将以下文本/信息总结为[要点数]条关键点，并用简洁的语言表述。\n能快速消化信息，节省阅读时间。\n案例：\n提示词：\n请将这篇3000字的文章总结为5个关键点，每个点不超过30字。\n回答方向：模型会提炼出5个简短要点，帮用户节省大量时间。\n10. 创意生成型\n提示模式：\n请提出10个关于[主题]的创新想法，并按照[难度/成本/影响力]进行排序。\n适合头脑风暴、产品创新。\n案例：\n提示词：\n请提出10个关于“未来智能家居”的创新点子，并按照成本从低到高排序。\n回答方向：模型会输出如“语音控制窗帘 → 智能冰箱 → 全屋AI能耗管理系统”，并按成本排列。\n通过这10类提示词，你可以让大语言模型在不同场景下都“更聪明”：\n想要专业答案 → 角色扮演型 想要看清过程 → 分步骤推理型 需要做选择 → 对比分析型 让概念落地 → 案例驱动型 想提升方案 → 批判性思维型 要快速套用 → 模板生成型的 想自学成长 → 学习辅导型 追求跨界洞见 → 多角度思考型 信息过载时 → 总结归纳型 需要新点子 → 创意生成型"
  },
  {
    "title": "预训练语言模型_百度百科",
    "page_body": "2021年电子工业出版社出版的图书\n《预训练语言模型》是由 邵浩 、刘一烽合著的学术专著，2021年5月经 电子工业出版社 出版，隶属博文视点AI系列丛书  [1] 。邵浩为日本国立九州大学工学博士，现任 vivo 研究员；刘一烽系 清华大学 电子系硕士，现为 阿里巴巴 算法工程师。本书基于 自然语言处理 技术发展脉络，聚焦预训练语言模型这一革新方向，旨在系统阐释其理论框架与技术实践。\n全书共8章，涵盖预训练模型发展历程、 Transformer 架构原理及 GPT 、BERT等经典模型的实现细节，结合代码解析阐明统计语言模型与注意力机制等技术要点。通过对比XLM、RoBERTa、T5等后BERT时代模型的优化路径，讨论多模态扩展与轻量化部署策略，并提供实际应用案例及模型评测方法。书中以 PyTorch 代码实践为核心特色，贯穿理论阐述与工程实现，呈现从基础算法到前沿技术的完整知识图谱。\n中文名 预训练语言模型\n作 者 邵浩 、 刘一烽\n出版社 电子工业出版社\n出版时间 2021年5月\n页 数 216 页\n定 价 109 元\n开 本 16 开\nISBN 9787121409998\n目录\n1 内容简介 2 图书目录 3 作者简介\n内容简介\n详细梳理了预训练语言模型的基本概念和理论基础，并通过实际代码的讲解，阐述了具有代表性的预训练语言模型的实现细节\n图书目录\n第 1 章 预训练语言模型简介 1\n1.1自然语言处理研究进展 1\n1.2预训练语言模型：为什么要预训练 4\n1.2.1预训练 4\n1.2.2自然语言表示 5\n1.2.3预训练语言模型发展史及分类 8\n第 2 章 预训练语言模型基础知识 13\n2.1统计语言模型 14\n2.2神经网络语言模型 17\n2.3词向量：解决相似单词的距离问题 19\n2.4RNN 和 LSTM 基础 25\n2.5基于 RNN 的语言模型 29\n2.6ELMo：解决多义词的表示问题 32\n第 3 章 Transformer 与 Attention 37\n3.1Transformer 的结构 37\n3.2Self-Attention：从全局中找到重点 43\n3.3位置编码：为什么有效 54\n3.4单向掩码：另一种掩码机制 58\n3.5代码解读：模型训练技巧 61\n3.5.1训练技巧 1：归一化层前置 62\n3.5.2训练技巧 2：梯度累积 64\n第 4 章 GPT 系列模型 69\n4.1GPT 的结构：基于 Transformer Decoder 69\n4.2GPT 任务改写：如何在不同任务中使用 GPT 71\n4.3GPT 核心代码解读 74\n4.4GPT-2：Zero-shot Learning 的潜力 79\n4.4.1N-shot Learning 79\n4.4.2核心思想 80\n4.4.3模型结构 81\n4.5GPT-3：Few-shot Learning 的优秀表现 82\n4.5.1看词造句 84\n4.5.2语法纠错 84\n4.5.3GPT-3 的争议 85\n第 5 章 BERT 模型 87\n5.1BERT：公认的里程碑 87\n5.2BERT 的结构：强大的特征提取能力 88\n5.3无监督训练：掩码语言模型和下句预测 91\n5.3.1MLM 91\n5.3.2NSP 93\n5.3.3输入表示 94\n5.4微调训练：适应下游任务 95\n5.4.1句对分类 95\n5.4.2单句分类 96\n5.4.3文本问答 97\n5.4.4单句标注 99\n5.5核心代码解读：预训练和微调 100\n5.5.1BERT 预训练模型 101\n5.5.2BERT 微调模型 110\n5.6BERT 总结 117\n第 6 章 后 BERT 时代的模型 119\n6.1XLM：跨语言模型 119\n6.1.1优化方向 119\n6.1.2算法细节 120\n6.1.3 小结 121\n6.2MT-DNN：多任务融合 121\n6.2.1优化方向 121\n6.2.2算法细节 122\n6.2.3 小结 124\n6.3UniLM：获得文本生成能力 124\n6.3.1优化方向 124\n6.3.2算法细节 125\n6.3.3 小结 127\n6.4SpanBERT：扩大掩码范围 127\n6.4.1优化方向 127\n6.4.2算法细节 128\n6.4.3 小结 129\n6.5XLNet：置换自回归 130\n6.5.1优化方向 130\n6.5.2算法细节 130\n6.5.3 小结 135\n6.6ERNIE：知识图谱 136\n6.6.1优化方向 136\n6.6.2算法细节 136\n6.6.3 小结 139\n6.7VideoBERT：多模态融合 139\n6.7.1优化方向 139\n6.7.2算法细节 140\n6.7.3 小结 141\n6.8ALBERT：参数共享 142\n6.8.1优化方向 142\n6.8.2算法细节 143\n6.8.3 小结 145\n6.9RoBERTa：更大的模型 145\n6.9.1优化方向 145\n6.9.2算法细节 146\n6.9.3 小结 146\n6.10BART：编解码结构 146\n6.10.1优化方向 146\n6.10.2算法细节 147\n6.10.3 小结 149\n6.11T5：大一统模型 149\n6.11.1优化方向 149\n6.11.2算法细节 150\n6.11.3 小结 153\n6.12 总结 154\n第 7 章 评测和应用 157\n7.1评测任务 157\n7.1.1通用评测任务 157\n7.1.2领域评测任务 162\n7.1.3其他评测任务 167\n7.2模型应用：Transformers 代码实战 168\n7.2.1 安装 168\n7.2.2快速上手指南 170\n7.2.3微调训练 172\n7.2.4BERT 应用 175\n7.3模型压缩：量化、剪枝和蒸馏 179\n7.3.1BERT 模型分析 179\n7.3.2 量化 181\n7.3.3 剪枝 181\n7.3.4 蒸馏 182\n7.3.5 结构无损压缩 187\n7.4模型扩展：多模态预训练 188\n7.4.1单流模型 189\n7.4.2双流模型 191\n第 8 章 总结和展望 195\n8.1预训练语言模型的发展现状 195\n8.2预训练语言模型的未来展望 199\n参考文献 203\n作者简介\n邵　浩\n日本国立九州大学工学博士，现就职于vivo。曾任狗尾草智能科技AI研究院院长，带领团队打造了AI虚拟生命产品的交互引擎。曾是上海对外经贸大学副教授，硕士生导师。任中国中文信息学会青年工作委员会委员，语言与知识计算专委会委员，中国计算机学会语音对话与听觉专委会委员，自然语言处理专委会委员。发表论文50余篇，获专利10余项，主持多项国家级及省部级课题，曾在联合国、世界贸易组织、亚利桑那州立大学、香港城市大学等机构任访问学者。\n刘一烽\n全国中学生物理竞赛保送生，清华大学电子系硕士，曾获学习成绩优异奖学金。现就职于阿里巴巴淘系技术部，曾任vivo人工智能研究院AI算法工程师，主要研究方向为强化学习、自然语言处理和视频内容理解。\n参考资料\n1\n电子工业出版社-网上书店 ．电子工业出版社有限公司 ．2025-06-03\n预训练语言模型的概述图（1张）"
  },
  {
    "title": "毕业答辩实用模板｜结构化汇报指南",
    "page_body": "开场白三步走\n上午好！我是xx系xx专业的xx，导师是xx老师。论文题目是xxx，在老师指导下顺利完成，感谢各位老师的聆听！接下来按设计目的和注意事项依次汇报，请多指正~\n    选题背景六要素\n1️⃣发展历程：从xx到xx的变化过程\n2️⃣存在问题：目前遇到的具体困难\n3️⃣后果影响：这些问题带来的负面影响\n4️⃣解决措施：目前采取的应对方法\n5️⃣理论意义：对学术领域的贡献\n6️⃣实践价值：对实际工作的指导作用\n    论文结构六段式\n1️⃣引言：研究背景和意义\n2️⃣基础理论：相关理论框架介绍\n3️⃣现状调查：行业/领域现状分析\n4️⃣问题分析：找出具体问题及原因\n5️⃣解决方案：针对原因提出的对策\n6️⃣结论展望：研究成果总结与未来方向\n    通用过渡句模板\n在xx背景下，运用xx理论得出xx结论；通过xx描述分析，发现xx问题，主要原因是xx；针对xx原因，提出xx解决方案。\n    结语三要点\n1️⃣总结论文发现的问题\n2️⃣对理论进行丰富分析\n3️⃣指出论文不足并提出见解\n最后真诚说：能力有限，论文存在欠缺，恳请各位老师批评指正！"
  },
  {
    "title": "AI大模型，点亮智慧之光。 #人工智能 #ai #每天跟我涨知识 T5模型理论分享上半部分",
    "page_body": ""
  },
  {
    "title": "AI大模型对比完全指南:如何选择最适合你的大模型?-网易",
    "page_body": "面对市场上琳琅满目的AI大模型，从GPT-4到Claude，从文心一言到DeepSeek，每个模型都声称自己具有独特优势。但对于普通用户和企业来说， 如何进行科学的 AI大模型对比 ，选择真正适合自己需求的模型 ，已成为一个亟待解决的问题。本文将为您提供一套完整的大模型选型方法论。\nAI大模型选择为什么如此困难?\n信息碎片化严重\n目前AI大模型信息散布在各个官网、技术博客和评测文章中，用户很难获得全面、客观的对比数据。每家厂商都会突出自己的优势指标，但缺乏统一的评估标准。\n需求场景多样化\n不同用户的使用场景千差万别:有的需要强大的代码编写能力，有的注重多语言翻译，有的则更关心成本效益。单一的性能排名无法满足个性化需求。\n技术门槛较高\n模型参数、推理速度、上下文长度等技术指标对非专业用户来说难以理解，更别说将这些指标与实际应用需求建立联系。\n科学的AI大模型对比方法论\n1. 建立评估维度体系\n一个科学的大模型对比应该包含以下核心维度:\n基础能力维度\n文本理解与生成质量 逻辑推理能力 知识储备广度与深度 多语言支持程度\n技术性能维度\n响应速度与延迟 上下文窗口长度 并发处理能力 模型稳定性\n应用场景维度\n代码编程能力 创意写作水平 数据分析功能 多模态处理（图像、语音等）\n商业考量维度\n使用成本与计费方式 API接入便利性 服务可用性与技术支持 数据安全与隐私保护\n2. 量化评估方法\n标准化测试基准 目前业界主要采用MMLU、HumanEval、GSM8K等标准化测试集来评估模型能力。2025年的AI大模型已经不再是简单的参数规模竞赛，而是在多个维度上的全面较量。\n真实场景测试 除了标准测试外，还需要在实际应用场景中进行对比测试，包括任务完成质量、用户满意度、错误率等指标。\n成本效益分析 综合考虑模型性能与使用成本，计算性价比指标，帮助用户做出最优选择。\n2025年主流AI大模型对比分析\n国际主流模型\nGPT-4系列\n优势:GPT-4o以其卓越的多模态实时交互能力领先 适用场景:通用对话、创意写作、复杂推理 成本水平:相对较高，按Token计费\nClaude系列\n优势:Claude3.7凭借深度思考和编程能力脱颖而出 适用场景:代码开发、学术写作、逻辑分析 特色功能:长文本处理能力强\nGemini系列\n优势:Gemini2.5以百万token窗口和内置思考能力开创新标准 适用场景:大文档处理、多模态任务 技术特点:超长上下文支持\n国产优秀模型\nDeepSeek系列 DeepSeek 凭借 UltraMem 架构与开源生态，以1/70成本实现与 GPT-4o 比肩的性能，在成本效益方面表现突出。DeepSeek R1通过MoE架构和强化学习实现高效推理。\n文心一言 百度推出的大模型产品，在中文理解和搜索集成方面具有优势，特别适合国内用户的使用习惯。\n讯飞星火 讯飞星火的核心优势在于其业界领先的语音识别、语音合成、自然语言理解技术，并将其与大模型能力深度融合，在语音交互领域表现出色。\n通义千问 阿里云推出的大模型，在商业应用和企业服务方面具有完善的生态支持。\n如何选择适合自己的AI大模型?\n明确使用需求\n个人用户\n日常对话助手:推荐GPT-4或Claude 学习辅助:选择在教育领域优化的模型 创意写作:关注文本生成质量高的模型\n企业用户\n客服机器人:需要稳定性和成本控制 内容生产:注重创意能力和效率 数据分析:选择逻辑推理能力强的模型\n开发者\n代码助手:Claude或专门的代码模型 API集成:考虑接入便利性和文档完善度 成本敏感:DeepSeek等高性价比选择\n利用专业对比工具\n面对如此复杂的选择，普通用户很难独立完成全面的模型对比。这时，专业的AI大模型对比平台就显得尤为重要。\nAIbase模型广场（https://model.aibase.com/zh/compare）作为专业的AI大模型对比平台，提供了以下核心功能:\n全面的模型数据库\n收录国内外主流大模型的详细信息 实时更新模型性能数据和价格信息 提供多维度的技术参数对比\n智能化对比工具\n支持多模型同时对比 可视化的数据展示 个性化的推荐算法\n专业评测报告\n基于标准测试集的客观评分 真实使用场景的性能表现 成本效益分析报告\n用户友好的界面\n简洁直观的操作界面 支持中英文切换 移动端友好设计\n实际测试验证\n即使有了专业工具的帮助，最终的选择还需要通过实际测试来验证:\n免费试用 大多数模型都提供免费额度，建议在真实场景下进行测试。\nA/B对比测试 同时使用多个模型处理相同任务，对比输出质量和用户体验。\n长期观察 关注模型的稳定性、更新频率和技术支持质量。\nAI大模型选择的未来趋势\n专业化细分\n未来的AI大模型将更加专业化，针对特定行业和应用场景进行深度优化。用户需要根据自己的具体需求选择相应的专业模型。\n成本优化\n其技术突破正推动行业从 \"算力堆砌\" 转向 \"效率革命\"，未来模型的成本效益将持续提升。\n开源生态发展\nMiniMax此前一直以产品力强而闻名业内，在这个时间点也通过开源和一系列更新表达了自己的态度，开源模型将为用户提供更多选择。\n多模态融合\n未来的大模型将更好地整合文本、图像、语音等多种模态，提供更丰富的交互体验。\n结语\nAI大模型对比是一个复杂的技术决策过程，需要综合考虑性能、成本、应用场景等多个因素。每个模型都有其独特的优势和适用场景，选择时应基于具体需求而非简单的排名。\n通过建立科学的评估体系，利用专业的对比工具，结合实际测试验证，用户完全可以找到最适合自己的AI大模型。在这个过程中，像AIbase模型广场这样的专业平台，为用户提供了宝贵的决策支持，让复杂的技术选择变得简单明了。\n记住，最好的AI大模型不是性能最强的那个，而是最适合你具体需求的那个。在AI技术快速发展的今天，掌握正确的选择方法比盲目追求最新模型更加重要。"
  },
  {
    "title": "广西师范大学成人教育本科毕业论文、师范学院教育管理本科论文",
    "page_body": "小学生涯教育的现状、问题及对策研究\n　　［摘要］ 小学阶段是学生系统接受教育的开端，是终身教育的基础，也是实施生涯教育的重要时期。为了更好地开展小学生涯教育，切实有效地促进学生发展，本研究对广州市增城区小学生涯教育的实施现状进行调查。结果显示，目前我区小学生涯教育存在对生涯教育的认知不足，生涯教育目标不符合学生发展需求及生涯教育的内容和方式单一等情况。基于此，提出了普及生涯教育知识，提高对生涯教育的认识；明确生涯教育目标，满足学生的发展需求；选择合适的内容和方式，提高生涯教育实效的对策和建议。\n　　［关键词］ 小学生涯教育；生涯教育认知；生涯教育需求；生涯教育实施\n　　生涯教育是一种帮助学生认识自我，了解个人与外部世界的关系，增强个人规划意识和生涯管理能力的教育活动。小学阶段正处于生涯发展的成长期，是获得知识、发展能力的关键时期。在小学阶段实施生涯教育可为学生的生涯发展夯实基础，且对学生的成长具有重要作用。笔者于2021年9月，开展“学生发展需求导向下小学生涯教育实践样式研究”，旨在帮助学生把所学知识与理想追求建立联系，提高学习的主动性和自觉性，树立积极的人生观，知道“我是谁”“我要到哪里去”“我该如何到达那里”，并为学校开展生涯教育提供区域实践范例。为此，我们在全区开展问卷调查和访谈调查，以了解我区小学生涯教育的现状。\n　　一、调查对象与内容\n　　调查的对象为增城区小学6920名小学生，7353名学生家长，326名小学教师，调查范围覆盖了荔城、新塘、石滩、派潭等全区11个镇或街道。学生问卷主要从自我认知、生活管理、学习管理、人际交往和职业认知五个维度展开，以了解学生对生涯教育的认知与需求。教师问卷主要从对生涯教育的认识及所在学校开展生涯教育情况入手。家长问卷主要从对生涯教育的认知与态度方面进行设计。另外，为更深入地了解学生的内心世界及师生对生涯教育的真实看法，笔者还与部分教师和学生直接对话交谈。\n　　二、调查结果与分析\n　　（一）小学生涯教育的认知情况\n　　1.教师对生涯教育的认知情况\n　　关于“教师群体对生涯教育认知情况”的调查，设置了以下题目：（1）你了解生涯教育吗？结果显示，仅35%的教师对生涯教育“非常了解”，仍有65%的教师对生涯教育处于“大致了解”或“不太了解”的状态。（2）在小学阶段开展生涯教育是否必要？调查结果显示，49%的教师认为“非常有必要”，34.94%的教师认为“比较必要”。（3）你认为对小学生实施生涯教育有何重要影响？76.21%的教师认为可以“提高学生对自己、职业及社会的认识和了解”，77.36%的教师认为能“提高学生人际交往的能力和技巧”，77.04%的教师认可“帮助学生对未来进行规划，初步设立自己未来发展目标”，79.08%的教师认为可以“加强对自我学习和生活的管理，养成良好的行为习惯”。\n　　结合前面的调查数据来看，大部分教师对生涯教育有一定的了解，认同生涯教育对于学生发展有着积极作用，但是部分教师当前的生涯教育意识还需要进一步\n　　提升。\n　　2.学生对生涯教育的认知情况\n　　（1）学生的自我认知情况。根据舒伯的生涯发展阶段理论，自我认知是学习、生活乃至工作的起点。笔者通过对兴趣、性格、能力的调查来了解学生的自我认知情况。如表1所示，在“你能清晰说出自己的兴趣爱好”这题上，84.34%的学生选择了“完全符合”和“比较符合”。在“你了解自己的性格特点”中，选择“完全符合”和“比较符合”的学生共有73.04%。在问及“你知道自己的优点并能向他人展示自己的优点”时，选择“一般符合”的学生占比27.99%，选择“不符合”的也有4.26%，这两项的占比总和达33.25%。在“你知道自己的缺点并能努力改正缺点”这一问题中，33.21%的学生选择了“一般符合”和“不符合”。可见，学生对自己兴趣和性格的了解情况相对比较乐观，但学生自我认知的总体能力有待提高，尤其在自身的优势和不足这一方面，部分学生需要进一步了解把握，并努力做到扬长避短。\n　　（2）学生的生活管理情况。小学生涯教育在生活管理方面的教育内容主要包括合理安排时间、增强劳动意识和应对突发事件等方面。从表2可知，在回答第1题时，10.93%的学生表示不会制订作息时间表，并合理安排时间。在“你经常参与家庭劳动”这题中，选择“一般符合”和“不符合”的共占比为38.09%。在“遇到突发事件，你能用已经学习过的方法自救”一题中，33.05%的学生表示并不能很好地用已经学习过的方法进行自救。对于“遇到困难，你会”这一多项选择题，结果67.75%和12.31%的学生分别选择“请求父母帮助”“请求老师的帮助”，4.09%的学生选择“请求同学帮助”，15.85%的学生选择“自己解决”。可见，学生的生活管理能力总体较低，部分学生在遇到突发事件时不能很好自救。\n　　（3）学生的学习管理情况。只有培养学生的自我管理能力，才能使他们在今后的学習成长中自我规划，谋求发展。调查发现，66.49%的学生在完成作业后，能较好地进行有计划、有针对性的复习和预习。在“你学习主要是为了”这一多选题上，55.82%的学生是基于“父母和老师的期待”，6.91%的学生表示“没有思考过，还不清楚”。在提到“你平时会制定目标并实施完成吗？”时，只有7.34%的学生会“制定目标，实施并完成目标”。综合可知，虽然大部分学生都能独立完成作业，且在完成作业后能及时复习和预习，但从数据中我们也看到部分学生的学习内驱力不足，缺乏目标意识，认为学习是为了完成家长和教师的期许，不会为自己的学习和生活制订目标。\n　　（4）学生的人际交往情况。培养学生的人际交往能力是生涯教育不可或缺的内容。如表3所示，在“同伴对你而言很重要”一题中，选择“非常符合”和“比较符合”的学生共占比为85.62%，在问及“你懂得如何与父母、老师和同学们相处和交往”时，共有21.87%的学生选择“一般符合”和“不符合”。在“当与同学存在分歧时，你能很好地化解矛盾冲突”的回答中，34.23%的学生表示不能很好做到。可见，学生认识到了同伴的重要性，人际交往的意识也很强烈，但相应的能力不足。\n　（5）学生的职业了解情况。培养学生的职业意识，扩大他们对不同职业的了解，对学生的生涯发展具有至关重要的作用。调查得知（如表4），了解11个以上职业的学生仅占34.44%。如表4，在“你会有意识地了解父母及家庭成员的职业”这一题中，74.2%的学生会有意识去了解身边的职业。另外，65.3%的学生选择“希望了解更多有关职业的信息，以便思考自己是否适合它”。在问及“你清楚知道自己喜欢的职业（如医生、警察、教师等）”时，接近70%的学生选择“完全符合”和“比较符合”。从这一组的数据来看，学生对于职业种类的了解仍有待提高。大部分学生明确自己喜欢的职业，但同时希望了解更多的职业信息。\n　　3.家长对生涯认知的情况\n　　家长的生涯教育意识对孩子未来的健康成长极为重要。调查显示：（1）您了解生涯教育吗？仅有12.46%的家长选择“非常了解”，35.28%的家长选择“大致了解”，超过50%的家长表示不太了解，甚至不了解。（2）您愿意投入时间和精力对孩子进行生涯教育吗？令人可喜的是，96.51%的家长表示愿意投入时间和精力来加强对学生学习和生活的指导。（3）对于孩子的生涯教育，作为家长，您愿意提供什么支持？经调查发现，和孩子一起制订学习生活计划，并督促执行，以及教孩子一些融入社会、适应社会的方法这两点为更多的家长所采用。\n　　从调查数据中我们发现，超过一半的家长对生涯教育缺乏全面且深入的认识，但绝大部分家长实则非常愿意投入时间和精力来加强对学生学习和生活的指导。\n　　（二）小学生涯教育的需求情况\n　　学生的发展需求，是我们开展生涯教育的出发点和归宿。如表5所示，74.29%的学生希望在父母和教师的帮助下初步规划自己的未来。78.34%的学生希望学校开设职业体验活动。80.92%的学生认为有必要在语数英等学科课堂教学中渗透一些认识自我、了解职业、认识社会及提高人际交往等相关知识。当问及“如果学校开设生涯教育课程，你希望自己哪些方面得到提高”时，学生的选择比较均衡，其中“提高对职业的认识和对社会环境的了解”“加强对自我学习和生活的管理，养成良好的行为习惯”这两项占比相对较高。\n　　由以上数据得出，大部分学生关注自己的未来发展，并希望获得与之相关的知识并提升职业认知。通过进一步访谈，我们了解到学生对未来充满期待，希望能进一步了解自己的优缺点，发现和培养自己的兴趣爱好。此外，他们还渴望了解工作世界及外部环境，加强对生活的管理和学习管理，学会自我规划，从而实现自我发展目标。\n　　（三）小学生涯教育的实施情况\n　　对增城区小学生涯教育的实施情况主要从学生、教师和学校德育副校长这三个群体开展调查。学生完成多选题“学校开展生涯教育的内容主要有哪些”，调查结果如下图所示，“学习指导”和“习惯养成”这两项所占比例最高，分别是87.16%和80.35%，其次是人际交往和身心调适，最低是自我探索和职业探索。可见，学校生涯教育内容不够全面、未成系统且不符合全面发展的育人理念是开展小学生涯教育的主要制约因素。\n　　教师问卷“你所在学校开展生涯教育的方式有哪些”同样是一道多项选择题，67%的教师选择“举办讲座”，50.6%的教师选择“主题班会”，30.5%的教师选择“学科渗透”，15.69%的教师“实践活动”，10.96%的教师选择“其他方式”，3.12%的教师选择“专门的课程设置”。由调查结果可以看出，部分学校实施生涯教育的途径单一，以“举办讲座”和“主题班会”为主，通过开设课程、实践活动等方式开展生涯教育较少。\n　　我们还通过访谈的方式了解访谈对象所在学校开展生涯教育遇到的困难有哪些，受访领导普遍表示在小学阶段实施生涯教育缺乏自上而下的具体指导意见，以及可供参考、借鉴的教育教学方案和实施策略。可见，政策的支持和区域实践范例的指引，是影响小学生涯教育开展的重要因素。\n　　三、存在的问题\n　　（一）生涯教育的认知不足\n　　从“生涯教育认知情况”的调查数据可知，无论是教师、家长，还是学生的生涯认知水平都有待提高。多数教师对生涯教育有一定的了解，认同生涯教育于学生发展的作用和意义，对小学阶段开展生涯教育的必要性表示认可，但仍有部分教师对生涯"
  },
  {
    "title": "大模型技术-Task 2 学习笔记（Datawhale AI夏令营）CSDN博客",
    "page_body": "文章目录\n简介 1. 介绍 2. 模型微调 3. 结果 4. 总结 参考文献\n简介\n本学习笔记通过记录在比赛中的学习和微调模型过程，并给出接下来可能的改进方向。该比赛皆在通过大模型对于表格理解去处理相关的精准的和结构性的列车交通表格数据，如检票口位置，候车厅信息，列车信息等 [1]。\n1. 介绍\n在大量表格和结构化数据中，大模型技术可以快速，高效的通过上下文理解，表格理解等能力对用户提出的问题进行回答，并通过数据预处理阶段生成结构化数据对相关模型进行微调。根据赛事提供的数据 [1]，数据一共包含：\n序号：用于排序 车次：区别不同的列车班次 始发站：列车出发的站点名称 终点站：列车到达的站点名称 到点：列车到达时间 开点：列车出发时间 候车厅：乘客候车区域名称 检票口：乘客检票进站的通道信息 站台：列车替考的站台\n图1: 赛事数据集\n2. 模型微调\n根据训练数据，需要先对数据进行预处理，已满足模型训练要求。在 Baseline 文件中，通过对 Qwen3-8B 进行 prompt 处理数据集。之后根据问题和原数据集生成结构性答案数据后，使用该训练集对 Qwen3-8B 模型进行微调。通过学习 baseline 和相关例子，图2，3 展示了在数据处理中通过在 Qwen3-8B 中构建问题列表和 prompt来进行数据预处理。\n图 2. 问题列表\n 图 3. prompt\n3. 结果\n现阶段的结果和提交分数对比显示如下：\n描述\n提交分数\nbaseline （遍历10 条数据），训练次数 3 次 44\nbaseline (赛事提供) [2] 57\n无完整的 prompt 和结构性回答 (遍历219 条数据)，训练 50 次 55\n第一次prompt 和有结构性回答 （遍历107 条数据），训练 50 次 62\n表格 1. 提交分数对比\n4. 总结\n本学习笔记通过相关的结构性数据和模型微调，展示了问题策略构建和 prompt 的质量对模型在赛事评分上的影响和提升。后续优化方向，例如增加问题的多样性和复杂性，继续提高prompt 的质量和对对应处理问题的泛化能力等。\n参考文献\n[1] 科大讯飞， （2025）， 基于结构化数据的用户意图理解和知识问答挑战赛 ，iFLYTEK AI 开发者大赛，https://challenge.xfyun.cn/topic/info?type=user-intent-understanding&option=ssgy&ch=dwsf2513\n [2] Datawhale, (2025),  夏令营：让AI理解列车排期表 ，https://www.datawhale.cn/activity/351/learn/198/4422/23/21"
  },
  {
    "title": "Transformer模型PyTorch实现：从原理到代码完全解析-CSDN博客",
    "page_body": "Transformer模型PyTorch实现：从原理到代码完全解析\n【免费下载链接】thorough-pytorch PyTorch入门教程，在线阅读地址：https://datawhalechina.github.io/thorough-pytorch/  项目地址: https://gitcode.com/GitHub_Trending/th/thorough-pytorch \nTransformer模型彻底改变了自然语言处理领域，它摒弃了传统的循环神经网络和卷积神经网络架构，完全基于注意力机制构建。这个革命性的模型不仅在机器翻译任务上取得了state-of-the-art的效果，更为BERT、GPT等后续重要模型奠定了基础。本文将深入解析Transformer的核心原理，并通过PyTorch代码实现来帮助读者全面理解这一重要模型。\n     Transformer模型的核心架构\nTransformer采用经典的编码器-解码器（Encoder-Decoder）结构，整体架构包含以下几个关键组件：\n编码器（Encoder） ：由6个相同的编码器层堆叠而成，每个编码器层包含多头自注意力机制和前馈神经网络。\n解码器（Decoder） ：同样由6个相同的解码器层组成，除了包含编码器中的两个子层外，还增加了编码器-解码器注意力层。\n注意力机制 ：模型的核心，通过计算查询（Query）、键（Key）和值（Value）之间的相关性来分配注意力权重。\n     多头注意力机制详解\nTransformer最创新的部分就是多头注意力机制（Multi-Head Attention）。传统的注意力机制只能捕捉一种类型的语义关系，而多头注意力可以并行计算多个不同的注意力分布，从而更全面地理解输入序列。\n多头注意力的计算公式为：\nMultiHead(Q, K, V) = Concat(head₁, ..., headₕ)Wᴼ 其中 headᵢ = Attention(QWᵢᵠ, KWᵢᴷ, VWᵢⱽ) \n多头注意力可视化\n在PyTorch中，我们可以使用内置的多头注意力层：\nmultihead_attn = nn.MultiheadAttention(embed_dim, num_heads) attn_output, attn_weights = multihead_attn(query, key, value) \n     位置编码的重要性\n由于注意力机制本身不包含位置信息，Transformer引入了正弦余弦位置编码来为模型提供序列中词汇的位置信息：\nPE(pos, 2i) = sin(pos/10000^(2i/d_model)) PE(pos, 2i+1) = cos(pos/10000^(2i/d_model)) \n这种编码方式不仅能够处理训练时未见过的序列长度，还能够让模型轻松地计算相对位置关系。\n⚙️ 编码器实现细节\n编码器由多个编码器层堆叠而成，每个编码器层包含两个子层：多头自注意力层和前馈神经网络层，并通过残差连接和层归一化进行连接。\nclass EncoderLayer(nn.Module):     def __init__(self, size, self_attn, feed_forward, dropout):         super(EncoderLayer, self).__init__()         self.self_attn = self_attn         self.feed_forward = feed_forward         self.sublayer = clones(SublayerConnection(size, dropout), 2)         self.size = size      def forward(self, x, mask):         x = self.sublayer0)         return self.sublayer1 \n     解码器的独特设计\n解码器在编码器的基础上增加了一个编码器-解码器注意力层，这使得解码器能够同时关注输入序列和已生成的部分输出序列。\nclass DecoderLayer(nn.Module):     def forward(self, x, memory, src_mask, tgt_mask):         m = memory         x = self.sublayer0)         x = self.sublayer1)         return self.sublayer2 \n    ️ 掩码机制的作用\n为了确保自回归性质（即预测时不能使用未来信息），Transformer使用了掩码机制。在训练解码器时，会使用上三角掩码来防止模型看到\"未来\"的词汇。\ndef subsequent_mask(size):     attn_shape = (1, size, size)     subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)     return subsequent_mask == 0 \n     完整模型组装\n将各个组件组合成完整的Transformer模型：\ndef make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):     attn = MultiHeadedAttention(h, d_model)     ff = PositionwiseFeedForward(d_model, d_ff, dropout)     position = PositionalEncoding(d_model, dropout)          model = EncoderDecoder(         Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),         Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),         nn.Sequential(Embeddings(d_model, src_vocab), c(position)),         nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),         Generator(d_model, tgt_vocab),     )          for p in model.parameters():         if p.dim() > 1:             nn.init.xavier_uniform_(p)     return model \n     训练策略与优化\nTransformer使用Adam优化器，并采用特殊的学习率调度策略：\nlearning rate = d_model^(-0.5) * min(step_num^(-0.5), step_num * warmup_steps^(-1.5)) \n这种学习率调度在训练初期快速增加学习率，然后在后期缓慢下降，有助于模型收敛。\n     实践建议与应用场景\n超参数调优 ：根据具体任务调整头数、模型维度、层数等超参数 硬件考虑 ：Transformer需要大量内存，建议使用GPU进行训练 应用领域 ：机器翻译、文本生成、语音识别、图像处理等 扩展变体 ：可以尝试不同的位置编码方式或注意力变体\n     性能优势与局限性\n优势 ：\n并行计算能力强，训练速度快 能够捕捉长距离依赖关系 在多个NLP任务上达到state-of-the-art效果\n局限性 ：\n计算复杂度随序列长度平方增长 需要大量训练数据 对硬件要求较高\nTransformer模型的提出是深度学习领域的一个重要里程碑，它不仅推动了自然语言处理的发展，也为计算机视觉、语音处理等领域提供了新的思路。通过本文的解析，希望读者能够深入理解Transformer的工作原理，并能够在自己\n【免费下载链接】thorough-pytorch PyTorch入门教程，在线阅读地址：https://datawhalechina.github.io/thorough-pytorch/  项目地址: https://gitcode.com/GitHub_Trending/th/thorough-pytorch"
  },
  {
    "title": "神经网络中激活函数的真正意义？一个激活函数需要具有哪些必要的属性？还有哪些属性是好的属性但不必要的？",
    "page_body": "学习 LLM 使用的是麦肯锡的100 关键词法；全连接神经网络是最基础的神经网络，了解了它，才能更加容易理解 CNN、RNN 等更加复杂的模型。 本节内容的目标，就是带大家了解全连接神经网络的含义、构成以及运作规律。站在一个宏观的角度来去了解、认识全连接神经网络。 全连接神经网络（Feedforward Neural Network） 全连接神经网络，也称为前馈神经网络（Feedforward Neural Network），是一种最基本的人工神经网络。 在全连接神经网络中，神经元（或节点）被组织成多个层，每一层的神经元与前一层和后一层的神经元全都相连，但同一层内的神经元之间没有连接。 数据在网络中是从输入层向输出层单向传播的，没有反馈（或循环）连接，这也是\"前馈\"这个名字的由来。 dy：就有点像我们学习中的有向无环图的结构。 但，与 N 叉树的结构又不太一样，因为树结构中的一个节点只能有一个父节点，而在全连接神经网络中，一个神经元需要接收到来自前一层所有神经元的输入。全连接神经网络的每一个连接都有一个权重，这些权重是通过训练数据来学习的。 每个神经元会计算其所有输入的加权和，然后通过一个激活函数，如ReLU、sigmoid 或 tanh 等，来得到其输出。 dy: 如何训练权重，以及激活函数的定义，都在下方有做介绍，不要着急。这种网络结构可以适应多种任务，如分类、回归等。但对于处理序列或图像等数据时，全连接神经网络的效果可能不如其他特定的网络结构，比如说循环神经网络（用于处理序列数据）和卷积神经网络（用于处理图像数据）。 全连接神经网络的结构 全连接神经网络（Feedforward Neural Network）由多个层组成，包括输入层、隐藏层和输出层。 输入层 输入层接收原始数据输入，比如一篇文章的词向量或一张图片的像素值。 作用：它们主要负责接收原始数据（如图像的像素值或文本的词向量），并将这些数据传递给下一层的神经元。 隐藏层 dy：隐藏层是很复杂的结构，希望我的下列内容能帮助大家理解，如果有不懂的，请在评论区留言。对于每一个隐藏层的神经元，它都会接收来自前一层神经元的信息（对于输入层来说，就是原始数据）。 这个信息是经过权重调整后汇总起来的（汇总的方式：是将前一层的每一个神经元输出与对应的权重相乘，然后求和）。 接下来，这个汇总的信息会被输入到一个激活函数中，比如ReLU或 sigmoid 函数。激活函数的作用是在神经元中引入非线性，使得神经网络能够学习和表示非线性的复杂关系。 隐藏层的神经元输出会继续传递给下一层的神经元，进行同样的操作。 这样的操作层层递进，直到将数据传入最后的输出层。 通过这样的方式，神经网络就能够从原始输入数据中提取出有用的特征，并用这些特征进行预测或分类。 神经网络中可以有多个隐藏层，每个隐藏层的神经元数也可以不同。作用：隐藏层负责学习和表示数据的复杂模式。隐藏层神经元的输入来自上一层神经元的输出，它们会对这些输入进行加权求和，并通过激活函数产生输出。 在这里强调一些信息，希望这些信息能帮助大家理解全连接神经网络的结构。 在介绍全连接神经网络的时候说过，全连接神经网络有点像一个有向无环图，它的每一层的每个神经元都会与前一层的每个神经元都相连； 同时在隐藏层的介绍时也说过，每个神经元接收的信息，是前一层每一个神经元输出与对应的权重相乘，然后求和。 因此，虽然所有的神经元都接收到相同的输入，但由于权重的不同，他们实际接收到的“加权”输入数据是不一样的。 输出层 最后一层是输出层，它的神经元数目通常取决于任务类型。比如在分类任务中，输出层的神经元数目可能就等于类别的数目。每个神经元的输出代表了对应类别的预测概率。 作用：它们负责产生网络的最终输出。这些输出通常对应于预测或分类任务的结果。例如，在分类任务中，输出层的神经元通常等于分类的类别数量，每个神经元的输出代表了对应类别的预测概率。 激活函数 激活函数在神经网络中的一个主要作用就是引入非线性。如果没有激活函数，无论神经网络有多少层，它都只能表示线性函数，这大大限制了神经网络的表示能力。 至于为什么会限制神经网络的表示能力，我总结下来有两方面： 第一个方面（为什么要有非线性函数），生活中的大部分事物都是非线性的关系，例如某个人对某个事物的学习能力，整个吃饭全过程的吃饭速度等等，同时，非线性函数很容易表达线性函数，所以，神经网络为了尽可能的模拟现实世界，是必须要有非线性的函数。 第二个方面（为什么要用非线性函数），虽然非线性函数理论上是可以由无数个线性函数来表示，但是，神经网络的层数和数量是有限的，为了表示非线性关系，引入一个非线性函数是一个非常节能且理智的选择。 所以在隐藏层的每一层都加入激活函数，就能赋予简单的神经网络学习更复杂的事物。 常见的激活函数 激活函数是非线性函数，所以只要是两个变量不能表示的线性关系的函数就都在激活函数的范畴，常见的激活函数有以下几种： ReLU（Rectified Linear Unit） ReLU是一种常用的激活函数，特别是在深度神经网络中。它的形式是，意味着当输入小于0时，输出是0；当输入大于0时，输出等于输入。 ReLU函数的优点：简单、计算高效，并且在输入为正数时梯度不会饱和，有利于网络的训练。 缺点：ReLU函数在输入为负数时梯度为0，可能会导致一些神经元不再更新，这被称为\"死亡ReLU\"问题 Sigmoid Sigmoid函数是一种经典的激活函数，形式为。 它的输出在0和1之间，这使得它在一些场景下特别有用，比如在二分类问题的输出层。 缺点：Sigmoid 函数在输入值较大或较小的情况下梯度接近于0，可能导致梯度消失问题，使网络难以训练。 Tanh Tanh函数是 Sigmoid 函数的缩放和平移版本，形式为。 它的输出在-1和1之间，比Sigmoid函数的输出范围更广。 缺点：Tanh函数和Sigmoid函数一样，也存在梯度消失的问题。 有没有发现这些激活函数选择的都是简单的非线性函数，甚至最常用的 ReLU 函数竟然只是一个简单的分段函数。 那选择激活函数的理由是什么呢？ 激活函数选取的理由 1. 计算效率：神经网络通常需要大量的计算，尤其是在训练过程中。所以简单的激活函数，如ReLU或 Sigmoid，可以被快速有效地计算。更复杂的非线性函数可能会增加计算的复杂性和时间。 2. 梯度传播：在神经网络的训练过程中，我们使用梯度下降法来更新权重，这需要计算激活函数的导数。简单的激活函数，它们的导数通常也很简单，易于计算。而复杂的非线性函数的导数可能更难以计算，甚至可能在某些点上不可导。 3. 实践效果：尽管在理论上，更复杂的非线性函数可能能够提供更强大的表示能力，但在实践中，使用简单的非线性函数（如ReLU、tanh 和 sigmoid）已经被证明是非常有效的。实际上，ReLU函数由于其简单性和效果，在现代神经网络中广泛使用。 4. 梯度消失和梯度爆炸问题：更复杂的非线性函数可能更容易遇到梯度消失或梯度爆炸问题，这会阻碍神经网络的训练。例如，Sigmoid和tanh函数在输入值很大或很小时，其梯度接近于0，会导致梯度消失问题。而ReLU函数则能够一定程度上缓解这个问题。 总的来说，选择何种激活函数是一个权衡的过程，需要考虑计算效率、训练稳定性、实践效果等因素。 在上述激活函数选取的理由时，其中很大一部分原因是需要使用梯度下降法来更新权重，那梯度下降是如何在神经网络训练中更新权重的？ 梯度下降法的作用 梯度下降法是一种用于优化或最小化目标函数的迭代方法，常用于机器学习和人工神经网络的训练中。在神经网络的训练中，我们的目标是找到一组权重，使得预测输出与实际输出之间的误差（也就是损失函数）最小。如何找到这样一组权重呢？我们使用的方法就是梯度下降法。 打个比方：这就好像是你在山上，目标是到达山谷，但你只能看到自己周围的情况。 你可以通过观察自己脚下的坡度，找到下坡的方向，然后沿着这个方向走一步，然后再次检查脚下的坡度，找到新的下坡方向，以此类推，直到你达到山谷。（梯度下降法就是在找到最适合的下坡方向） 在神经网络的训练中，\"山\" 就是损失函数，\"坡度\" 就是损失函数的梯度。 梯度就是损失函数在当前权重处的斜率，它会告诉我们如果改变权重，损失会如何变化。 我们通过不断地调整权重，使得损失函数沿着梯度的负方向下降，从而找到最小化损失函数的权重，这就是梯度下降法的基本思想。 dy：是不是有些绕，如果有些绕的话，请先独立思考一下，然后，再继续往下看。 全连接神经网络的工作原理 在知道了以上的全部概念后，再看最后一部分，全连接神经网络的工作原理。 在训练神经网络时，会使用一种叫做反向传播（Backpropagation）的算法。 反向传播，全称又叫\"反向传播误差算法\"，是在神经网络的一种有效的学习方法。在神经网络训练的过程中，反向传播扮演了一个重要的角色。 在开始解释反向传播之前，我们再重复一遍解神经网络的工作方式。 神经网络由输入层、隐藏层和输出层构成，数据在这些层之间进行前向传播。 然后，我们会使用一个损失函数来衡量模型的预测结果与真实结果的误差。 反向传播就是在这个时候发挥作用的。 它的目标是最小化损失函数。 为了实现这个目标，它首先会计算损失函数对每个参数（也就是权重）的梯度，然后将这个梯度反向传递回网络的每一层，用于更新每一层的参数。 具体的操作过程是这样的： 第一步，先前向传播：首先，网络会进行前向传播操作，从输入层开始，依次通过每一层，最后到达输出层并生成预测值。在这个过程中，每一层的输入都是上一层的输出。 第二步，计算损失：当网络生成了预测值后，就可以计算出预测值与真实值之间的差异，也就是损失函数的值。 第三步，反向传播误差：这是反向传播的关键步骤。开始于输出层，计算损失函数对每一层的参数（权重和偏置）的梯度。这一步通常通过链式法则完成。 第四步，更新参数：一旦计算出了每个参数的梯度，就可以使用这些梯度来更新参数。更新的方式通常是：新的参数值 = 原来的参数值 - 学习率 * 梯度。这个过程就是梯度下降的过程。 这个过程会反复进行，每进行一次，网络的预测值就会更接近真实值，损失函数的值就会更小。直到达到设定的迭代次数，或者损失函数的值已经足够小，训练过程就会结束。 其他补充 输入层的神经元通常不会应用激活函数，因为它们的任务主要是接收原始数据并传递给下一层，没有必要对这些数据做非线性变换。 对于输出层，"
  }
]