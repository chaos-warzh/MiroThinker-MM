[
  {
    "title": "获奖论文|论大数据在类案类判中的应用_澎湃号·政务_澎湃新闻-The Paper",
    "page_body": "喜报\n7月26日，“沈家本与新时代知识产权保护”论坛暨沈家本研究会2019年年会在湖州市吴兴区召开。\n我院干警赵翼昂、袁者共同撰写的论文《论大数据在类案类判中的应用》在本次论文交流评选中荣获二等奖。\n论大数据在类案类判中的应用\n论文提要：\n近年来随着智慧法院建设强有力的促进审判体系和审判能力现代化，在大数据司法领域深入应用中，类案类判作为人工智能支持司法审判的重要内容。借着其在当前话题层面热议的机会，将从该技术的原理、其前景如何并在实践运行中存在哪些问题着手。首先从类案类判的概念着手，明确什么是类案类判。核心是确定类案标准，两个独立案件如何才能被视为是同类案件，又应当以什么样的标准来判断；类案类判的关键是类案推送，类案推送系统依托自然语言处理技术，借助知识图谱构建类案知识树和知识库，利用相关算法完成类案匹配。其次是着眼类案类判的现状，对类案类判制度进行探索。再是从类案类判机制在实践中的困难入手，研究法信平台、类案推送系统、北大法宝、裁判文书网等相关系统时候在准确性、精确性、积极性等方面缺陷。分析得出主要因为需求分析的不够准确，AI算法及推送技术不够成熟、案例数据不够规范造成以上困难。考虑到类案类判与人工智能深度融合，从明确规范标准、构建操作规则等方法，完善类案类判机制三个方面入手。全文共7631字。\n主要创新观点：\n分析大数据在类案类判中的应用，应该分别从类案类判的概念和大数据的特点分别把握。首先是建立类案标准， 案件审理是一个综合运用法律知识、经验法则、裁判技巧、解释法律的裁判过程，法官虽考虑接受法律约束，但也有自由裁量权做出价值判断，法官正在审理的案件应当与其所在法院和上一级法院已经审结的或者其他具有指导意义的同类案件裁判尺度一致，不能脱离法律、政治、社会三个效果一致的目的，否则类案标准将无法控制裁判偏离度。同时关键是积极利用类案检索，通过数学建模及模拟算法，得到合适的案例和判决结果。目前大数据在类案类判应用情况中还存在无法区分类案和推送技术不成熟的问题，主要体现在结果准确性、范围精细性和使用积极性上。可以采取规范类案类判机制、构建充足的类案数据库及发展提高算法来尝试解决大数据在类案类判应用中的窘境。\n以下正文：\n随着大数据在司法领域的深入应用和社会信息化的深入发展，借助智慧法院建设强有力的促进审判体系和审判能力现代化，类案类判作为人工智能支持司法审判的重要内容，是司法改革背景下推进审判权运行机制改革的重要尝试，对提升法院整体裁判水平、实现类案适法统一和促进司法公正有积极意义。其功能在于通过多种途径，为审判人员推送当前正处理的相似案例，启发及拓宽思路，能有效控制裁判偏离，统一相同地区领域的司法裁判尺度，同时也为新型疑难案件提供新的解决途径，实现关联案件之间法律、政治及社会效果一致。借着类案类判在当前话题层面热议的机会，笔者将着重探讨该技术的原理、其前景如何并在实践运行中存在哪些问题。\n一、类案类判在审判应用中的现状\n2017年8月1日最高人民法院印发《最高人民法院司法责任制实施意见（试行）》，期冀以通过类案和关联案件检索机制明确承办法官在审理案件进行类案检索，目的就要进一步统一裁判尺度。2017年10月26日中央办公厅印发《关于加强法官检察官正规化专业化职业化建设，全面落实司法责任制的意见》，明确依托大数据和云算法技术，完善智能辅助系统的类案推送、结果比对、数据分析等功能。2018年1月5日最高院紧跟着实施意见上线类案智能推送系统，覆盖全面1330个案由，从案件性质、案情特征、争议焦点、法律适用四个方面为查询和推送类案提供技术平台支撑（1）。在此之前最高院也确定审判人员应把握裁判趋势，在审理案件时候应对本院已审结或正在审理的类案进行全面检索，制作检索报告，可以说类案类判正式从试点探索、政策倡导走向司法部门及群众需求的层面。\n积极响应中央政策的同时，各省市也依托办案平台和档案系统先后开发各自的类案推送系统，如上海高院运行刑事案件智能专审平台；浙江高院开展的“类案推送项目”；贵州高院建立类案标准数据库及关联案件强制检索机制。虽然类案类判机制有其独特优势和积极作用，可以对推送的内容进行分析、推理及决策，还可以提供角色登录、用户兴趣、语义理解和信息筛选等实用功能，但在实践中也存在不少的困难。现以浙江省高院类案推送系统为例，某个原被告均为自然人的追偿权纠纷，诉讼请求是被告归还借款代偿本息101841.66元并支付利息。事实与理由是2017年7月17日被告向小贷公司借款100000元，由原告承担连带担保责任，后因被告无力偿还到期借款，由原告代偿借款本金101841.66元，事后被告未及时支付代偿款纠纷款。系统有通过输入关键字、词组及上传文书自动识别两种方式，具体流程如下图：\n当上传文书后系统自动对其进行识别并自动关联案件23万多件，本省12818件，通过筛选得基层法院近三年相关20173件。通过输入关键字“追偿权纠纷”“民事案件”，识别出有效判决文书54万多份，本省85884件，通过筛选得一审361692件。而在使用裁判文书公开网、法信平台及北大法宝等系统后相同案例效果更为不明显。\n仔细观察推送结果可以发现，部分案例与追偿权纠纷并无直接关系；推送数据过多，增加筛选类案难度，容易产生厌烦心理；然而可供参考的案例稀缺，对审判人员无实质性帮助价值。当前而言在智能辅助办案系统里，类案类判系统显然不及法条关联、裁判文书模板自动生成及文书纠错等系统，这些平台能自动生成裁判文书初稿，帮助校验法律文书，实实在在减轻了事务性工作负担，所以许多审判人员更习惯求助它们。而类案类判平台对于复杂案件推送不精准，对于简单案件又失去了检索的需求，这就降低用户体验和减少使用意愿。所以类案检索机制未得到普遍运用是有一定原因的，后面笔者会结合身边同事实际使用反响及目前类案类判系统的技术特征归纳总结。\n二、大数据在类案类判中如何发挥关键作用\n（一）类案类判的概念\n在讨论大数据如何帮助实现类案类判之前，要确定类案类判系统的运行机理。借助自然语言处理技术（NLP）通过模板寻找、标签注释等完成类案要素判断及提取，借助相应的技术构建类案知识库，利用云算法完成类案匹配和推送。\n1.类案类判的核心是建立类案标准：何谓同类案件，又应当以什么样的标准来判断。目前学界主流有这几个观点：主要法律关系说、事实特征说、关键事实说等。总体来说主要基本案情和法律适用一致即是同类案件。一是以判断两个案件主张的事实认定是否一致为基础，但也不是要求两个事实必须在所有细节情形上严丝合缝一模一样。案件审理最终目的是确定是否应当支持当事人的诉讼请求，因此诉讼请求的构成要件所对应的各个事实要素一致，就可以认为两者事实一致；二是法院认定案件事实一致，按照要素清单进行论述，在判决书中清楚地表述每个要素上是认定了什么样的案件事实。根据要素清单认定案件事实，也具有多方面的现实意义，因为当法院认定的案件事实一致那么一般判决结果也是一样的；三是两者法律、政治、社会三个效果一致。其实裁判文书中的思想通常包含对三个效果的考虑，效果本身是社会主义核心价值观的体现，由于类案类判通常只对裁判文书进行比对，所以可避免万一将来该案作为类案比对的对象时错误理解和适用其裁判尺度。\n2.类案类判的关键是发挥类案推送：其核心思路在于搭建案件性质的分类预测模型和裁判结果的回归预测模型，将海量裁判文书“前验”要素特征实例化，通过专家标注、规则推导建构基础数据模型，经由语词锁定、捕捉裁判文书关键信息形成结构化数据，遵循闭合性逻辑原理（2）。所谓的闭合性逻辑原理，是先有一个符合法律形式逻辑的大前提，然后再有一个案件事实基本接近的小前提，在大小前提都情况类似时，得出个案应与之前类案判决先例相似的结论。再判断高可信度关联，完成建模要素的有机重构，为类案多方位塑像形成类案树作为预测模型，并以类案大数据知识库为基础，以语义相似性度量方法，构建高维特征匹配的类案模型，对后续案件进行案件事实到适用法律及裁判结果的立体化相似性匹配，针对个性化用户模型和相似度算法，进行智能排序和个人偏好推送，对具体个案自动进行偏离常规裁判分析和风险防范预警，最后必须基于类案裁判结果的均值标准。\n（二）挖掘大数据在法律领域应用\n1981年随着人工智能技术的发展，D·沃特曼和M·皮特森开发了法律判决辅助系统，将其作为司法领域的实践工具并对民法中特定问题进行统计分析。该系统通过简单的责任认定、损害赔偿等模型计算案件的赔偿标准。国内在司法领域的第一次应用是在1986年国家社科“七五”研究课题取得盗窃罪量刑数据模型等成果（3）。这段时间内都是以专家的法律经验、知识框架作为规则。后面随着以大数据、机器搜索、深度学习的法律人工智能系统出现，实现AI可以做出分析预判，在关联案件相关调查中，分析不同场景不同体系不同舆论，找出最准确的文档及数据。在未来笔者认为法律人工智能会继续发展，之后的十多年，会随着大数据、云计算、计算机法律学及算法融合，深度学习处理器也从CPU往GPU/TPU发展，类案类判系统的效率及准确性会得到大幅度提升，成为审判人员工作时不可或缺的得力帮手。\n首先大数据应用类案类判既有用到传统软件架构的网络框架、数据加密设计和发送接收技术，又运用到自认语言理解（NLP）、司法实体识别（OCR）、实体关系分析等技术，将每个案件及其相关信息做成一个点，再通过分析挖掘和个性化定制实现点与点之间匹配和联络，最终构建一个类案关系的框架。其中暗含大量的交互技术、机器训练和数据筛选，高效快捷的制作某类案件大数据分析报告。充分运用人工智能学习和语义分析技术，将大量专业法律数据进行清洗、分类、结构化，最终形成可以提供可视化的咨询服务平台；将数据进行高度整合、关联，提供结构化、可视化、智能化的搜索结果；按照事先设计制定的法律语言规则，将文书自动分段、贴标签，建立目录方便AI索引、分类、拾取，帮助审判人员能够进行关联搜索。\n其次由于类案类判不同于以往简单的案件搜索，它处理结构化数据、半结构化数据和非结构化数据，例如案例数据库、判决文件、法条法规、图书期刊和庭审录音录像等，这些数据通过数据集成协议、关联分析、计算"
  },
  {
    "title": "NoSQL之Redis配置与优化-CSDN博客",
    "page_body": "目录\n一：Redis介绍\n1：关系数据库与非关系数据库\n1.1：关系数据库\n1.2：非关系数据库\n1.3：非关系数据库背景\n2：Redis基础\n2.1：Redis简介\n2.2：Redis安装部署\n2.3：配置参数\n3：Redis命令工具\n3.1：redis-cli命令行工具\n3.2：redis-benchmark测试工具\n4：Redis数据库常用的命令\n4.1：key相关命令\n4.2：多数据库常用命令\n二：Redis持久化\n1：RDB和AOF的区别\n2：RDB和AOF的优缺点\n2.1：RDB优缺点\n2.2：AOF优缺点\n3：Redis持久化配置\n3.1：RDB持久化配置\n3.2：AOF持久化配置\n4：AOF重写\n三：性能管理\n1：内存碎片率\n2：内存使用率\n2.1：针对缓存数库大小选择\n2.2：使用Hash数据结构\n2.3：设置key的过期时间\n3：回收key\n一： Redis 介绍\n1：关系数据库与非关系数据库\n1.1：关系数据库\n定义：\n关系数据库（Relational Database）是基于关系模型（Relational Model）的数据库，使用表格（表、行、列）的结构存储和管理数据。数据之间通过主键（Primary Key）和外键（Foreign Key）建立关联。\n特点：\n结构化数据：  数据以严格的二维表形式存储，遵循预定义的模式（Schema）。\nSQL操作：  使用结构化查询语言（ SQL ）进行数据操作和查询。\nACID特性：  支持事务的原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability），适合需要高一致性的场景。\n规范化设计：  通过范式（Normalization）减少数据冗余，提高数据完整性。\n1.2：非关系数据库\n定义：\n非关系数据库（NoSQL, Not Only SQL）是一类不依赖传统关系模型的数据库，设计灵活，适合处理大规模、非结构化或半结构化数据。\n特点：\n灵活的数据模型：\n支持键值对（Key-Value）、文档（Document）、列族（Column Family）、图（Graph）等数据模型。\n无固定模式（Schema-less），可动态扩展字段。\n高扩展性：  通常支持分布式架构，易于水平扩展（如分片、副本集）。\n高性能：  针对特定场景优化（如高吞吐、低延迟）。\n弱化ACID：  部分NoSQL数据库牺牲严格的一致性，追求高可用性和分区容错性（遵循CAP定理）。\n1.3：非关系数据库背景\n（1） High performance—— 对数据库高并发读写需求\nWeb2.0 网站会根据用户的个性化信息来实时生成动态页面和提供动态信息，因此无法使用动态页面静态化技术。所以数据库的并发负载非常高，一般会达到 10000 次 /s 以上的读写请求。关系型数据库对于上万次的查询请求还是可以勉强支撑的，但出现上万次的写数据请求，硬盘 IO 就已经无法承受了。对于普通的 BBS 网站，往往也会存在高并发的写数据请求。\n（2） Huge Storage—— 对海量数据高存储与访问需求\n类似于 Facebook、Friendfeed 这样的 SNS 网站，每天会产生大量的用户动态信息。如 Friendfeed，一个月就会产生不少于 2.5 亿条用户动态信息，对于关系型数据库来说，在一个包含 2.5 亿条记录的表中执行 SQL 查询，查询效率是非常低的。\n（3） High Scalability && High Availability—— 对数据库高可扩展性与高可用\n用户需求在 Web 架构中，数据库是最难进行横向扩展的。当应用系统的用户量与访问量与日俱增时，数据库是没办法像 Web 服务一样，简单地通过添加硬件和服务器节点来扩展其性能和负载能力的。尤其对于一些需要 24 小时对外提供服务的网站来说，数据库的升级与扩展往往伴随着停机维护与数据迁移，其工作量是非常庞大的。\n2：Redis基础\n2.1：Redis简介\nRedis（RemoteDictionaryServer，远程字典典型）是一个开源的、使用 C 语言编写的 NoSQL 数据库。Redis 基于内存运行并支持持久化，采用 key - value（键值对）的存储形式，是目前分布式架构中不可或缺的一环。\n Redis 服务器程序是单进程模型，也就是在一台服务器上可以同时启动多个 Redis 进程，而 Redis 的实际处理速度则是完全依靠于主进程的执行效率。\nRedis具有以下几个优点：\n具有极高的数据读写速度，数据读取的速度最高可达到 110000 次 /s，数据写入速度最高可达到 81000 次 /s。 支持丰富的数据类型，不仅仅支持简单的 key - value 类型的数据，还支持 Strings，Lists，Hashes，Sets 及 Ordered Sets 等数据类型操作。 支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 原子性，Redis 所有操作都是原子性的。 支持数据备份，即 master - salve 模式的数据备份。\n2.2： Redis安装 部署\n#上传安装包redis -4.0 .9 .tar.gz\n#关闭防火墙\nsystemctl stop firewalld\nsetenforce  0\n#部署环境\ndnf -y install gcc  zlib-devel\n#解压安装包redis -4.0 .9 .tar.gz\ntar zxvf redis -4.0 .9 .tar.gz\ncd redis -4.0 .9 /\n#编译安装\nmake\n#定义安装路径\nmake PREFIX=/usr/local/redis install\ncd /usr/local/redis\n#做软链接\nln -s /usr/local/redis/bin /* /usr/local/bin/\n#做初始化\ncd redis-4.0.9/\ncd utils/\n./install_server.sh(可以直接默认)\n ##需要手动输入\n Selected config:\n Port : 6379\n Config file : /etc/redis/6379.conf       //配置文件路径\n Log file : /var/log/redis_6379.log       //日志文件路径\n Data dir : /var/lib/redis/6379 //数据文件路径\n Executable : /usr/local/redis/bin/redis-server      //可执行文件 路径\n Cli Executable : /usr/local/redis/bin/redis-cli //客户端命令行工 具\n#检查开启状态\nnetstat -anpt | grep redis\n#关于redis服务的命令\n/etc/init.d/redis_6379 stop             #关闭redis服务\n/etc/init.d/redis_6379 start             #启动redis服务\n/etc/init.d/redis_6379 restart          #启动redis服务\n/etc/init.d/redis_6379 status  #查看redis服务\nAI写代码 cpp\n运行\n2.3：配置参数\n#配置参数\nvim /etc/redis/ 6379. conf\nbind  127.0 .0 .1 192.168 .10 .201\n/etc/init.d/redis_6379 restart          #启动redis服务\nAI写代码 cpp\n运行\n参数\n作用\ntimeout 300 当客户端闲置多长时间后关闭连接，如果指定为 0，表示关闭该功能\ndbfilename dump.rdb 指定本地数据库文件名，默认值为 dump.rdb\ndir /var/lib/redis/6379 指定本地数据库存放目录\nmaxclients 10000 设置同一时间最大客户端连接数，默认为 10000。Redis 可以同时打开的客户端连接数为 Redis 进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不限制。当客户端连接数到达限制时，Redis 会关闭新的连接并向客户端返回 max number of clients reached 错误信息\nrdbcompression yes 指定存储至本地数据库时是否压缩数据，默认为 yes。Redis 采用 LZF 压缩，如果为了节省 CPU 资源，可以关闭该选项，但会导致数据库文件变的巨大\nslaveof <masterip><masterport> 当本机为从服务器时，设置主服务的 IP 地址及端口。在 Redis 启动时，从服务器会自动从主服务进行数据同步\nmasterauth <master-password> 当主服务设置了密码保护时，从服务连接主服务的密码\nrequirepass foobared 设置 Redis 连接密码，如果配置了连接密码，客户端在连接 Redis 时需要通过 AUTH <password>命令提供密码，默认关闭\nmaxmemory <bytes> 指定 Redis 最大内存限制。Redis 在启动时会把数据加载到内存中，达到最大内存后，Redis 会先尝试清除已到期或即将到期的 Key，当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis 新 VM 机制，会把 Key 存放内存，Value 会存放在 Swap 分区\n3：Redis命令工具\nRedis 软件提供了多个命令工具。安装 Redis 服务时，所包含的软件工具会同时被安装到系统中，在系统中可以直接使用。这些命令工具的作用分别如下所示。\nredis - server：用于启动 Redis 的工具； redis - benchmark：用于检测 Redis 在本机的运行效率； redis - check - aof：修复 AOF 持久化文件； redis - check - rdb：修复 RDB 持久化文件； redis - cli：Redis 命令行工具。\n3.1：redis-cli命令行工具\nRedis 数据库系统也是一个典型的 C/S（客户端 / 服务器端）架构的应用，要访问 Redis 数据库需要使用专门的客户端软件。Redis 服务的客户端软件就是其自带的 redis - cli 命令行工具。使用 redis - cli 连接指定数据库，连接成功后会进入提示符为 “远程主机 IP 地址：端口号” 的数据库操作环境，例如 “127.0.0.1:6379>” 。用户可以输入各种操作语句对数据库进行管理。如执行 ping 命令可以检测 Redis 服务是否启动。\nredis-cli\n127.0 .0 .1 : 6379 >ping  //检测redis服务是否启动\nPONG（pingpong机制）\n#远程连接\nredis-cli -h  192.168 .10 .201  -p  6379\n127.0 .0 .1 : 6379 >help  //帮助输入指令\nAI写代码 cpp\n运行\n3.2：redis-benchmark测试工具\nredis - benchmark 是官方自带的 Redis 性能测试工具，可以有效的测试 Redis 服务的性能。基本的测试语法为 redis - benchmark [option] [option value]。常用选项如下所示。\nh：指定服务器主机名； p：指定服务器端口； s：指定服务器 socket； c：指定并发连接数； n：指定请求数； d：以字节的形式指定 SET/GET 值的数据大小； k：1=keep ALIVE 0=reconnect； r：SET/GET/INCR 使用随机 key，SADD 使用随机值； P：通过管道传输<numreq>请求； q：强制退出 redis。仅显示 query/sec 值； --csv：以 CSV 格式输出； l：生成循环，永久执行测试； t：仅运行以逗号分隔的测试命令列表； I：Idle 模式。仅打开 N 个 idle 连接并等待。\nredis-benchmark -h  192.168 .10 .201  -p  6379  -c  100  -n  10000\n//与redis建立100个并发连接，与10000个请求测试性能(10*10000)\nredis-benchmark -h  192.168 .10 .201  -p  6379  -q -d  100\n//让redis以字节的方式设置键值\nredis-benchmark -t set,lpush -n  10000  -q\n//redis服务进行set,lpush的操作\nAI写代码 cpp\n运行\n4：Redis数据库常用的命令\n前面提到 Redis 数据库采用 key-value（键值对）的数据存储形式。所使用的命令是 set\n 与 get 命令。\nset：存放数据，基本的命令格式为 set key value。 get：获取数据，基本的命令格式为 get key。\n例如，在 Redis 的命令行模式下执行”set teacher zhanglong”，表示在当前数据库下存放一个 key 为 teacher，value 为 zhanglong 的数据，而执行 “getteacher” 命令即可查看刚才存放的数据。\n127.0 .0 .1 : 6379 >set teacher zhangsan\n//存放数据，键为teacher，值为zhangsan，在teacher下放入zhangsan\n127.0 .0 .1 : 6379 >get teacher\n//获取数据\nAI写代码 cpp\n运行\n4.1：key相关命令\n(1)keys\n127.0 .0 .1 : 6379 >set teacher zhangsan\n//存放数据，键为teacher，值"
  },
  {
    "title": "深度学习中的Baseline：基础框架与性能评估",
    "page_body": "千帆一体机\n搭载千帆大模型工具链平台，内置文心与精选开源大模型\n大模型\n文心大模型\n百度文心大模型4.5系列正式开源！\n千帆大模型平台支持开源模型API服务！\nERNIE X1.1\n在事实性、指令遵循、智能体等能力上均有显著提升\nERNIE X1 Turbo\n具备更长的思维链，更强的深度思考能力\nERNIE 4.5\n新一代原生多模态基础大模型\nERNIE Speed Pro 轻量级大模型\n适合作为基座模型精调，更好处理特定场景问题，性能极佳\n端到端语音语言大模型\n基于Cross-Attention跨模态语音大模型，体验超拟人对话\n大模型语音合成\n音色具备更高的自然度、丰富的情感表达等特点\n大模型声音复刻\n录制5秒音频，即可极速复刻音色\nIRAG 图像生成\n自研检索增强文生图技术，效果更优，低成本去AI味\nDeepSeek大模型\nDeepSeek-R1-0528\n复杂推理、长文本处理、代码生成能力全面提升\nDeepSeek-R1-671B\n杭州深度求索自研，基于大型强化学习训练的第一代理解模型\nDeepSeek-V3-671B\n深度求索自研（MoE）语言模型，位列主流开源榜单榜首\n大数据与原生应用\n大数据+AI\n千帆数据智能平台 DataBuilder\n一站式多模态数据管理、加工和分析应用平台\n向量数据库 VectorDB\n纯自研高性能、高性价比、生态丰富且即开即用\n数据可视化Sugar BI\n0代码，分钟级即可完成自助BI分析和可视化数据大屏\nElasticsearch检索分析服务\n什么是深度学习中的baseline？\n什么是 中的baseline？\n随着人工智能技术的飞速发展，深度学习已经成为了许多领域的标配。然而，在深度学习的实际应用中，我们经常面临各种各样的挑战，如何评估模型的性能、如何选择合适的网络结构、如何优化训练过程等。为了解决这些问题，我们需要一个强大的工具，那就是深度学习中的baseline。\nBaseline是深度学习中的一种重要概念，它为我们提供了一个基本的参考框架，用于评估不同算法和模型的性能。具体来说，baseline是指在不添加任何新的网络结构或优化方法的情况下，使用最基本的深度学习模型（如多层感知器、卷积 神经网络 等）在某项任务上达到的性能指标。\nBaseline的作用和重要性主要体现在以下几个方面。首先，baseline可以帮助我们评估不同算法和模型的性能。在深度学习中，往往有许多的算法和模型可供选择，如何确定哪个最适合我们的任务呢？这时候就可以通过比较不同算法和模型的baseline性能来进行筛选。其次，baseline还可以帮助我们优化算法和模型。通过与baseline的比较，我们可以看出哪些算法和模型在哪些方面有待改进，从而指导我们的模型设计和优化方向。最后，baseline还可以用于评估我们的深度学习系统的性能。在没有新的技术或方法的情况下，通过比较我们的系统和baseline的性能，可以了解我们的系统是否达到了当前最先进的水平。\n在深度学习中，我们可以根据不同的标准对baselines进行分类。例如，按照数据类型可以分为图像分类baseline、 语音识别 baseline等；按照算法可以分为神经网络baseline、决策树baseline等；按照应用领域可以分为计算机视觉baseline、 自然语言处理 baseline等。\nBaseline在深度学习的各个领域都有广泛的应用。在计算机视觉中，图像分类的baseline通常使用的是卷积神经网络（CNN），通过调整网络结构和参数来提高准确率；在自然语言处理中，文本分类的baseline通常使用的是多层感知器（MLP）或递归神经网络（RNN），同样可以通过调整结构和参数来提高性能。\n除了上述的应用，Baseline还有着广阔的发展空间。在未来，随着深度学习技术的不断发展，Baseline将会面临更多的挑战和需要解决的问题。例如，如何设计更加有效的网络结构、如何优化训练过程、如何处理大规模数据集等。为了解决这些问题，我们需要不断地尝试新的方法和技术，从而推动深度学习的发展。\n总之，Baseline是深度学习中的重要概念，它为我们提供了评估算法和模型性能的基准，帮助我们优化算法和模型，以及评估整个深度学习系统的性能。在未来的发展中，Baseline将会发挥更加重要的作用。因此，了解和掌握Baseline的概念和技术对于深度学习的初学者和专家来说都是至关重要的。"
  },
  {
    "title": "initial_h-博客园",
    "page_body": "2021年10月4日 \n A Study on Overfitting in Deep Reinforcement Learning \n 摘要： **发表时间：**2018 **文章要点：**这篇文章搞了一个maze的环境来研究RL里面的overfitting问题。把环境也分成train和test，然后来看效果。Train和test就根据初始状态来分的，其实就是agent在迷宫里面的起始位置。先是比较了训练时间，训练集的大小，任务难度这三个因  阅读全文\nposted @ 2021-10-04 13:01 initial_h  阅读(77) 评论(0) 推荐(0)  编辑 \n2021年10月2日 \n Detecting Rewards Deterioration in Episodic Reinforcement Learning \n 摘要： **发表时间：**2021（ICML 2021） **文章要点：**文章想说，我们训好一个policy之后，在真正用他的时候需要考虑安全性和可靠性（RL tasks is the safety and reliability of the system）。所以我们就需要一个方法来快速检测这个trai  阅读全文\nposted @ 2021-10-02 12:02 initial_h  阅读(85) 评论(0) 推荐(0)  编辑 \n2021年9月30日 \n A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms \n 摘要： **发表时间：**2019（ICLR Worskhop on Reproducibility） **文章要点：**文章主要是用统计检验的思想来比较RL算法的performance。文章介绍了很多统计检验的方法，参数的，非参数的都有，比如T-test, Welch's t-test, Wilcoxon  阅读全文\nposted @ 2021-09-30 10:42 initial_h  阅读(27) 评论(0) 推荐(0)  编辑 \n2021年9月29日 \n A Dissection of Overfitting and Generalization in Continuous Reinforcement Learning \n 摘要： **发表时间：**2018 **文章要点：**文章想说RL很容易overfitting，然后就提出某个方式来判断是不是overfitting了。最后得出结论，通过多样化的训练可以减少overfitting（as soon as there is enough training data divers  阅读全文\nposted @ 2021-09-29 10:30 initial_h  阅读(40) 评论(0) 推荐(0)  编辑 \n2021年9月26日 \n Protecting Against Evaluation Overfitting in Empirical Reinforcement Learning \n 摘要： **发表时间：**2011（2011 IEEE symposium on adaptive dynamic programming and reinforcement learning (ADPRL)） **文章要点：**文章想说RL算法很容易environment overfitting导致泛化性  阅读全文\nposted @ 2021-09-26 11:20 initial_h  阅读(30) 评论(0) 推荐(0)  编辑 \n2021年9月23日 \n RE-EVALUATE: Reproducibility in Evaluating Reinforcement Learning Algorithms \n 摘要： **发表时间：**2018（2nd Reproducibility in Machine Learning Workshop at ICML 2018） **文章要点：**文章想说，现在这些RL算法不好复现，就是因为大家各搞各的，评估标准不一样，计算方式不一样等等。然后作者就提出了一个evaluat  阅读全文\nposted @ 2021-09-23 01:01 initial_h  阅读(83) 评论(0) 推荐(0)  编辑 \n2021年9月20日 \n Evaluating the Performance of Reinforcement Learning Algorithms \n 摘要： **发表时间：**2020（ICML 2020） **文章要点：**文章指出RL复现难的原因在于评价指标不一致。作者提出评估指标应该满足四点：1. Scientific,主要说你这个指标提供的信息要告诉别人针对某个具体的问题或假设，得出了什么结论，这个结论有没有考虑各种不确定性可能造成的问题。2.  阅读全文\nposted @ 2021-09-20 12:30 initial_h  阅读(91) 评论(0) 推荐(0)  编辑 \n2021年9月18日 \n Difference Based Metrics for Deep Reinforcement Learning Algorithms \n 摘要： **发表时间：**2019（IEEE Access） **文章要点：**这篇文章想说之前那些衡量RL算法的指标（rawreward, avgreward,maximum rawreward等等）不好，只看得出来一个得分，反映不出来RL在训练过程中的问题。然后作者自己设计了几个指标来检测RL在训练中可  阅读全文\nposted @ 2021-09-18 13:48 initial_h  阅读(40) 评论(0) 推荐(0)  编辑 \n2021年9月15日 \n Few-shot Neural Architecture Search \n 摘要： **发表时间：**2021（ICML 2021） **文章要点：**这篇文章就是在网络结构的准确率和训练速度之间trade off。NAS的逻辑就是搜一个网络结构出来，然后就测这个结构在数据集上train出来准确率能到多少，然后基于之前的结构和准确率再接着搜下一个网络。这里面如果每次都要重新trai  阅读全文\nposted @ 2021-09-15 08:27 initial_h  阅读(143) 评论(0) 推荐(0)  编辑 \n2021年9月13日 \n Sample-Efficient Neural Architecture Search by Learning Actions for Monte Carlo Tree Search \n 摘要： **发表时间：**2021（TPAMI 2021） **文章要点：**这篇文章感觉是Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search的姊妹篇，方法很类似，只是这一篇用来做N  阅读全文\nposted @ 2021-09-13 11:06 initial_h  阅读(150) 评论(0) 推荐(0)  编辑 \n2021年9月10日 \n Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search \n 摘要： **发表时间：**2020（NeurIPS 2020） **文章要点：**我们知道贝叶斯优化做到高维的时候计算量很大，根本算不出来。这篇文章是把MCTS和贝叶斯优化结合起来，做高维的优化问题。主要思路是先用MCTS分割搜索空间，然后在子空间上再用贝叶斯优化去采样。假设我们的优化问题是找一个函数$f(  阅读全文\nposted @ 2021-09-10 13:24 initial_h  阅读(132) 评论(0) 推荐(0)  编辑 \n2021年9月6日 \n Neural Architecture Search using Deep Neural Networks and Monte Carlo Tree Search \n 摘要： **发表时间：**2019（AAAI2020） **文章要点：**一篇做NAS的文章，主要想法就是用MCTS来做NAS，相对random，Q-learning，Hill Climbing这些更能平衡探索与利用。主要方法是把NAS的问题定义好，比如动作是什么，就是每次搭建神经网络这一层用什么结构，什么  阅读全文\nposted @ 2021-09-06 12:46 initial_h  阅读(90) 评论(0) 推荐(0)  编辑 \n2021年9月4日 \n Benchmarking Batch Deep Reinforcement Learning Algorithms \n 摘要： **发表时间：**2019 **文章要点：**这篇文章主要是针对batch RL做了一个离散动作空间的benchmark，对比了DQN和一些batch RL算法的性能（DQN，REM，QR-DQN，KL-Control，BCQ）。并且把BCQ从连续动作空间改成适用离散动作空间，取得了SOTA的效果。  阅读全文\nposted @ 2021-09-04 02:18 initial_h  阅读(128) 评论(0) 推荐(0)  编辑 \n2021年8月30日 \n RealWorld Games Look Like Spinning Tops \n 摘要： **发表时间：**2020（NeurIPS 2020） **文章要点：**这篇文章对博弈问题的策略空间的结构做了分析（主要还是针对two-player zero-sum symmetric games），提出策略空间是一个陀螺形状（作者把这个叫做the geometry of Games of Sk  阅读全文\nposted @ 2021-08-30 14:02 initial_h  阅读(154) 评论(0) 推荐(0)  编辑 \n2021年8月28日 \n Reinforcement Learning as One Big Sequence Modeling Problem \n 摘要： **发表时间：**2021 **文章要点：**这篇文章把RL看作序列建模问题（sequence modeling problem），直接用transformer来拟合整个序列 （reats states, actions, and rewards as simply a stream of data  阅读全文\nposted @ 2021-08-28 05:31 initial_h  阅读(352) 评论(0) 推荐(0)  编辑"
  },
  {
    "title": "开发RAG应用，你必须知道的11款Embedding模型_gte-qwen2-7b-instruct-CSDN博客",
    "page_body": "在当今的AI应用中，RAG（Retrieval-Augmented Generation，检索增强生成）技术已经成为一个热门话题。RAG通过结合信息检索与生成模型，极大提升了AI系统的智能化程度与实用性。在开发RAG应用的过程中，选择合适的Embedding模型至关重要，因为Embedding模型直接影响了检索的效果与生成的质量。今天我们就来聊聊开发RAG应用时，你必须知道的11个Embedding模型。\nMTEB（Massive Text Embedding Benchmark）是一个用于评估文本嵌入（Embedding）模型的综合性基准测试平台。通过多任务和多数据集的组合，MTEB可以全面衡量不同Embedding模型在各种自然语言处理（NLP）任务中的表现，如文本分类、语义检索、文本聚类等。\nMTEB平台的核心目标是为研究人员和开发者提供一种统一的方式来评估和比较不同Embedding模型的性能。MTEB涵盖了多种语言和任务，使得排名结果能够反映模型的通用性和应用效果。\n**一、MTEB排行榜英文模型排名：**    \nAI写代码\n1 2\n    **1、bge-en-icl**  \nAI写代码\n1 2\n简介 ：bge-en-icl 是一款专为英语语境下的嵌入任务设计的模型。\n特点 ：该模型在处理英语文本的语义理解和分类学习任务时具有较高的精度，尤其在交互式分类学习（ICL）任务中表现出色。\n适用场景 ：适用于需要精准语义理解的英语文本处理任务，如文本分类、语义检索、智能问答系统等。\n2、stella_en_1.5B_v5\n简介 ：stella_en_1.5B_v5 是一个包含15亿参数的大型嵌入模型。\n特点 ：具备强大的语义理解和推理能力，能够处理复杂的语义关系和大规模数据。\n适用场景 ：适合用于高级文本分析、自然语言生成、复杂对话系统等需要高计算资源的任务。\n3、SFR-Embedding-2_R\n简介 ：SFR-Embedding-2_R 是一款优化用于大规模语义检索任务的嵌入模型。\n特点 ：在语义检索任务中表现出色，能够有效地处理和匹配大规模数据集。\n适用场景 ：适用于语义检索、推荐系统、信息检索等需要高效匹配和检索的应用。\n4、gte-Qwen2-7B-instruct\n简介 ：gte-Qwen2-7B-instruct 是一个拥有70亿参数的指令优化型嵌入模型。\n特点 ：该模型特别针对复杂的指令驱动任务进行优化，具有卓越的语义推理和指令执行能力。\n适用场景 ：适合用于复杂的自动问答系统、智能助手和高级对话系统等。\n5、stella_en_400M_v5\n简介 ：stella_en_400M_v5 是一个较为紧凑的嵌入模型，包含4亿参数。\n特点 ：在降低计算成本的同时，仍能提供较为优异的语义理解能力，适合资源有限的环境。\n适用场景 ：适用于移动设备的文本处理、轻量级的文本分类和语义分析任务。\n6、bge-multilingual-gemma2\n简介 ：bge-multilingual-gemma2 是一款支持多种语言的多语言嵌入模型。\n特点 ：能够处理跨语言的文本嵌入任务，尤其适用于多语言环境下的应用。\n适用场景 ：适用于多语言语义检索、跨语言文本相似性分析、跨语言翻译等任务。\n7、NV-Embed-v1\n简介 ：NV-Embed-v1 是一款可能经过专门优化的嵌入模型，适用于特定的语义任务。\n特点 ：模型可能针对某些领域进行了优化，具备在特定任务或语言下的高效嵌入能力。\n适用场景 ：适用于定制化的语义分析任务，如特定领域的文本处理或行业应用。\n8、 voyage-large-2-instruct\n简介 ：voyage-large-2-instruct 是一个大型指令驱动的嵌入模型。\n特点 ：该模型经过优化，能够有效处理多个任务，并具有良好的指令理解和执行能力。\n适用场景 ：适合用于复杂对话系统、智能助手、需要精准指令执行的应用场景。\n9、Linq-Embed-Mistral\n简介 ：Linq-Embed-Mistral 是一款专为特定领域优化的嵌入模型，可能专注于法律、医疗或技术文本处理。\n特点 ：针对特定领域进行了优化，能够在这些领域的任务中表现出色。\n适用场景 ：适用于法律、医疗或技术文档的语义嵌入和处理任务。\n10、SFR-Embedding-Mistral\n简介 ：SFR-Embedding-Mistral 是一款专门优化的嵌入模型，适合特定的高效检索任务。\n特点 ：与SFR-Embedding-2_R类似，该模型在语义检索和内容推荐系统方面表现优异。\n适用场景 ：适用于高效检索和内容匹配任务，如推荐系统、信息检索等。\n11、gte-Qwen1.5-7B-instruct\n简介 ：gte-Qwen1.5-7B-instruct 是一个拥有15亿参数的指令驱动嵌入模型。\n特点 ：特别适合指令理解和执行任务，能够处理复杂的指令驱动任务。\n适用场景 ：适用于高级对话系统、智能问答、复杂指令执行等场景。\n二、MTEB排行榜中文模型排名：\n    **1、xiaobu-embedding-v2**  \nAI写代码\n1 2\n简介 ：这是“小布”系列的第二版Embedding模型，主要用于中文文本的嵌入任务。\n特点 ：该模型针对中文语义进行了优化，具有较高的语义理解能力和准确性。\n适用场景 ：适用于中文语境下的文本分类、语义检索和内容推荐系统。\n2、 gte-Qwen2-7B-instruct\n简介 ：一个拥有70亿参数的大型嵌入模型，专注于指令驱动的任务优化。\n特点 ：模型能够处理复杂的语义推理和指令执行，适合多种语言任务。\n适用场景 ：适合复杂对话系统、智能问答系统和指令执行任务。\n3、zpoint_large_embedding_zh\n简介 ：这是一个针对中文文本的嵌入模型，适用于大规模文本数据的处理。\n特点 ：模型在处理中文语义任务方面具有较高的精度，特别适合大数据场景。\n适用场景 ：适用于大规模中文语义分析、文本分类和检索任务。\n4、IYun-large-zh\n简介 ：IYun-large-zh 是一个大型中文嵌入模型，专为中文语境下的任务优化。\n特点 ：模型在处理复杂中文语义关系方面表现出色，能够捕捉细微的语义差异。\n适用场景 ：适用于中文文本分类、语义检索、内容生成等高级NLP任务。\n5、 piccolo-large-zh-v2\n简介 ：这是Piccolo系列的第二版大规模中文嵌入模型。\n特点 ：模型针对中文文本优化，能够高效处理复杂的语义任务，提供高精度的嵌入表示。\n适用场景 ：适用于中文语义分析、文本分类和自然语言理解任务。\n6、AGE_Hybrid\n简介 ：AGE_Hybrid 是一个多语言嵌入模型，支持多种语言的文本处理。\n特点 ：该模型结合了多个任务的优化策略，具有较强的多语言处理能力。\n适用场景 ：适用于跨语言的语义检索、文本分类和多语言内容分析。\n7、Yinka\n简介 ：Yinka 是一款定制化的嵌入模型，可能针对特定领域进行了优化。\n特点 ：模型在特定领域或语言下具有优势，可能在领域特定任务中表现优异。\n适用场景 ：适用于特定行业或领域的语义分析任务，如法律或医疗文本处理。\n8、gte-Qwen1.5-7B-instruct\n简介 ：一个拥有15亿参数的指令优化型模型，专注于指令驱动的任务。\n特点 ：模型在处理复杂的指令执行和语义推理任务时表现出色。\n适用场景 ：适用于复杂的智能问答系统、高级对话系统和指令执行任务。\n9、acge_text_embedding\n简介 ：acge_text_embedding 是一个通用的文本嵌入模型，可能优化了多种文本处理任务。\n特点 ：模型在多任务环境下表现良好，具有较高的嵌入质量。\n适用场景 ：适用于文本分类、语义检索和内容推荐系统等。\n10、OpenSearch-text-hybrid\n简介 ：这是一个结合了多种优化策略的文本嵌入模型，可能用于提高文本检索的效率和准确性。\n特点 ：模型具有强大的检索能力，能够在大规模数据集上高效运行。\n适用场景 ：适用于文本检索、语义分析和信息检索系统。\n11、stella-mrl-large-zh-v3.5-1792\n简介 ：这是Stella系列的中文大规模嵌入模型，版本号为3.5，具有1792维的嵌入表示。\n特点 ：模型在处理大规模中文数据时表现出色，能够捕捉细微的语义关系。\n适用场景 ：适用于中文文本的高级语义分析、文本分类和自然语言处理任务。\n结语\n选择合适的Embedding模型是开发RAG应用的关键之一。上述11个Embedding模型各有优势，开发者可以根据实际应用场景和资源情况，选择最适合的模型进行应用。在实际操作中，结合任务的需求，对这些模型进行微调与优化，也能进一步提升RAG系统的性能。\n希望这篇文章能够帮助你更好地理解和选择Embedding模型，为你的RAG应用开发打下坚实基础。\nAI大模型学习路线\n如果你对AI大模型入门感兴趣，那么你需要的话可以点击这里大模型重磅福利：入门进阶全套104G学习资源包免费分享！\n微信扫描下方二维码获取哦！\n这是一份大模型从零基础到进阶的学习路线大纲全览，小伙伴们记得点个收藏！\n第一阶段：  从大模型系统设计入手，讲解大模型的主要方法；\n第二阶段：  在通过大模型提示词工程从Prompts角度入手更好发挥模型的作用；\n第三阶段：  大模型平台应用开发借助阿里云PAI平台构建电商领域虚拟试衣系统；\n第四阶段：  大模型知识库应用开发以LangChain框架为例，构建物流行业咨询智能问答系统；\n第五阶段：  大模型微调开发借助以大健康、新零售、新媒体领域构建适合当前领域大模型；\n第六阶段：  以SD多模态大模型为主，搭建了文生图小程序案例；\n第七阶段：  以大模型平台应用与开发为主，通过星火大模型，文心大模型等成熟大模型构建大模型行业应用。\n100套AI大模型商业化落地方案\n大模型全套视频教程\n200本大模型PDF书籍\n    学会后的收获：    \n• 基于大模型全栈工程实现（前端、后端、产品经理、设计、数据分析等），通过这门课可获得不同能力；\n• 能够利用大模型解决相关实际项目需求： 大数据时代，越来越多的企业和机构需要处理海量数据，利用大模型技术可以更好地处理这些数据，提高数据分析和决策的准确性。因此，掌握大模型应用开发技能，可以让程序员更好地应对实际项目需求；\n• 基于大模型和企业数据AI应用开发，实现大模型理论、掌握GPU算力、硬件、LangChain开发框架和项目实战技能， 学会Fine-tuning垂直训练大模型（数据准备、数据蒸馏、大模型部署）一站式掌握；\n• 能够完成时下热门大模型垂直领域模型训练能力，提高程序员的编码能力： 大模型应用开发需要掌握机器学习算法、深度学习框架等技术，这些技术的掌握可以提高程序员的编码能力和分析能力，让程序员更加熟练地编写高质量的代码。\nLLM面试题合集\n大模型产品经理资源合集\n大模型项目实战合集\n    获取方式：\n     有需要的小伙伴，可以保存图片到wx扫描二v码免费领取【保证100%免费】"
  },
  {
    "title": "大模型进展专题解读",
    "page_body": "（来源：老司机驾新车）\n大模型进展专题解读\n一、大模型性能比拼：技术突破与市场趋势尽显\n智谱 4.6：代码能力领衔，上下文窗口投资潜力凸显:智谱4.6节前发布后登顶huggingface趋势榜第一，其能力核心源于4.5版本，4.5版本曾使GPT5推迟发布。智谱从4.5开始就是单一模型，3.5的参数能达到当前状态十分厉害。4.6突出了代码能力，是国内算力紧缺和市场需求推动的结果，且其上下文窗口在代码模型维度的竞争更具投资价值，因为代码上下文窗口在搜索和业务场景解读方面复杂度高于文本。\n算力适配：国产算力与模型协同发展新态势 :国内模型发布时会适配多种算力，如智谱4.6适配寒武纪和摩尔，DeepSeek3.2先上华为。目前国内训练算力发展不佳，未来投资者需关注模型与国产算力的适配情况，以及推理卡厂商的发展。同时，异构算力问题也值得关注。\n价格博弈：模型性价比背后的竞争力考量 :不同模型的价格和性能差异较大。智谱4.6吞吐量提升30%，价格约为国外模型最低价的1/13-1/14；DeepSeek3.2官宣价格达1/35，但吞吐量较低，投资者需综合考虑API价格、吞吐量以及在不同benchmark上的输出。\n阿里千仞：全模态布局引领模型发展新潮流 :阿里的千仞系列模型未来会往全矩阵全模态方向发展，从今年Q3开始明显发力。由于国内算力和行业布局分散问题，阿里扩大开源有助于模型迭代和生态反哺。同时，市场对不同模态模型的需求增加，多模态模型聚合是未来趋势。\n技术革新：稀疏机制与合成数据的模型应用挑战 :DeepSeek3.2采用稀疏注意力机制，在降低推理算力成本方面表现优秀，但也存在隐患。合成数据在模型应用中很重要，但不能仅依靠无监督学习，百度公布的x1.1在合成数据方面并非值得投资的强点。\n二、大模型生态合作：模式创新与投资机遇洞察\n交互革命： AI重塑应用系统交互界面新格局:大模型变革的是应用系统的交互界面，而非应用本身。未来应 （更多实时纪要加微信：aileesir） 用应通过一个强势的AI模型或中间态来调用能力，国外资本驱动的应用发展更成熟，国内大模型公司应用渗透率较低。\n国内生态：双维度聚焦大模型生态发展潜力 :国内生态可从两个维度关注，一是类似国外通过接口聚合服务的生态，二是资本系列体系下应用对AI的拥抱和开放程度，如腾讯系、阿里系等旗下业务与模型的结合情况。\n合作三分：商业化、免费与央国企项目合作模式剖析 :国内大模型与软件厂商的合作模式主要有三类。一是商业化合作，如金融券商等行业通过隐私技术和MCP协议提供数据和接口；二是免费的web设计等工具，由中小创业公司提供；三是央国企项目，部分企业有数据和工具，但主动拥抱大模型的意愿较低，这类企业具有投资潜力。\n三、多模态应用投资：机遇与风险并存的新领域\n首尔冲击：海外应用引发的国内投资新思考 :首尔应用在国外引发关注，可能对社交等领域产生冲击，但国内监管政策可能限制其发展。投资者可关注因内容生产和运营增长乏力而需大模型赋能的企业，如快手等。\n小众掘金：垂类应用大模型赋能的投资价值凸显 :一些走上坡路的小众垂类应用，如交友、律师服务、直播带货、二次元等领域，利用大模型进行内容生成和角色创造，可提高效率，具有投资价值。\n3D警示：模型生成在高容错行业的投资风险预警:目前国内在3D建模和利用模型生成视频等方面与国外差距较大，在物理世界容错率低的行业使用模型生成存在风险，而在交友、短视频等行业投资相对可行。\nQ&A\nQ1:最近智谱、阿里发布的最新模型版本在性能上有哪些突破与进展，对应用未来环节有何影响？\nA1:智谱AI模型4.6版本的性能突破与进展及对应用未来环节的影响如下：1.模型能力基础与GPT对比：智谱AI4.6能力核心从4.5延续而来，7月发布的4.5版本就很强，曾导致GPT5推迟发布。从行业角度看，GPT5可能是多模型甚至多工具融合的能力，并非单一模型，而智谱从4.5开始已是单一模型，3.5的参数能达到当前状态很厉害。2.国内算力背景下的代码能力突出：国内受算力限制，在单一模型推理和多能力融合方面发展。智谱4.5是智能体、代码、agents和通用语言能力的融合模型，4.6突出了代码能力，这是大模型在各行业应用的必然趋势，市场对代码模型的诉求以及国内算力紧缺，促使其成为国内较强的代码模型。3.上下文窗口竞争：国内模型在代码模型维度开始卷上下文窗口，其难度高于之前的文本模型上下文。代码的上下文窗口在跨代码块搜索、业务场景代码解读等方面复杂度高，若代码模型在上下文方面有更大突破，对未来商业化落地是较好的投资买入点。4.算力适配：智谱4.6明确适配寒武纪和摩尔，行业内也有与华为等的双向适配。国内训练算力发展不佳，推理卡厂商在资本方面较火，模型适配国产算力的情况是投资者关注的双向问题。5.费用与吞吐量：智谱4.5投资费用是cloudy的1/10，4.6吞吐量提升30%，约为国外模型最低价的1/13-1/14，较为公允。阿里千仞系列模型的发展趋势及影响如下：1.全矩阵全模态发展：阿里在模型方面有积累，内部人员流动，预计未来会全矩阵全模态发展。当前行业趋势是通过平台聚合多模型能力，以满足不同场景对不同模态模型的需求，阿里在这方面从Q3开始明显发力。2.开源扩大：国内算力受限且行业布局分散，扩大开源对能力生长和人才滋养有重要意义。阿里的模型采用MIT协议，允许模型裂变，开源有助于其模型生态反哺和迭代。\nQ2:如何看待大模型厂商及互联网龙头的生态合作模式、与软件厂商的合作生态及其重要性，国内与互联网龙头、软件厂商的具体合作方式，以及后续主要的收费场景和方式？\nA2:大模型厂商及互联网龙头生态合作模式及相关情况如下：1.交互界面变革：大模型变革的是应用系统的交互界面，而非应用本身。未来应是有强势的基础模型或中间态，不同应用通过类似MCP协议的入口无感调用能力。国外资本驱动使行业有大量应用投入，形成了类似MCP、atoa的事实标准；国内较难出现此类平台，未来较长时间可能都不会有。2.国内生态关注维度：一是类似国外通过接口聚合服务的生态；二是资本体系下控制的应用对AI的拥抱和开放程度，如腾讯系、阿里系旗下业务能否通过模型工具入口接入。3.与软件厂商合作方式：（1）商业化模式：金融券商等行业的应用或sap项目，通过隐私技术和FTP方式提供数据，以MCP协议接入大模型，有商 （更多实时纪要加微信：aileesir） 业费用。（2）免费工具模式：web设计、天气出行等免费工具，由中小创业公司搭建，通过搜索、分流流量、识别query等提供服务。（3）央国企项目模式：央国企数据集中，但对大模型拥抱不主动，沟通成本高。这类企业有数据、工具和能力，是投资人可关注的标的。4.收费场景和方式文中未详细提及，但提到不同模型的API价格、token吞吐量以及不同benchmark下单一问题的输出差异大，投资时需辩证看待模型能力。\nQ3:若后续多模态应用市场落地，对API调用、应用维度有何影响，对模型厂商的整体布局有何战略调整或变化？\nA3:若后续多模态应用市场落地，相关影响及模型厂商战略调整如下：1.投资关注方向：（1）受冲击企业：类似首尔这类单一模型成APP的情况，国内虽因监管政策可能无好的发展土壤，但可关注受冲击且需大模型赋能的企业，如快手等内容生产和运营增长乏力的企业。（2）小众垂类应用：交友、直播带货、二次元等小垂类应用，大模型可赋能其内容生成、数字人、角色创造等，带来流量增长。（3）不适合行业：对三维空间物理世界容错率低的行业，如依赖大模型进行3D构图、视频生成等有风险，不适合直接替代现有生态环境。2.对API调用和应用维度的影响：文中未明确提及对API调用的具体影响。多模态应用会使应用维度更加丰富，涵盖图片理解、模型生成、视频理解、声音处理等多个方面，不同多模态模型之间向量空间的计算也是需要探讨的话题。3.模型厂商战略调整：未明确提及模型厂商具体的战略调整， （更多实时纪要加微信：aileesir） 但从行业趋势看，模型厂商可能会更加注重多模态能力的开发和融合，以满足不同应用场景的需求。"
  },
  {
    "title": "结构化和非结构化定义和特征_百度文库",
    "page_body": "可重复的子字段构成的数据库，用它不仅可以处理结构化数据（如数字、符号等信息）而且\n 更适合处理非结构化数据（全文文本、图象、声音、影视、超媒体等信息）。非结构化\n WEB数据库主要是针对非结构化数据而产生的，与以往流行的关系数据库相比，其最大区别在于它突破了关系数据库结构定义不易改变和数据定长的限制，支持重复字段、子字段以\n 据库的思想，提供一个网上资源管理系统iBaseWeb,将网络服务器（WebServer）和数据库服\n 务器（DatabaseServer）直接集成为一个整体，使数据库系统和数据库技术成为Web的一个重\n 要有机组成部分，突破了数据库仅充当Web体系后台角色的局限，实现数据库和Web的有\n 机无缝组合，从而为在Internet/Intranet上进行信息管理乃至开展电子商务应用开辟了更为广阔的领域。\n TXT等还提供了强大的全文检索能力。（2）它采用子字段、多值字段以及变长字段的机制，\n 允许创建许多不同类型的非结构化的或任意格式的字段，从而突破了关系数据库非常严格的\n 表结构，使得非结构化数据得以存储和管理。（3）iBase将非结构化和结构化数据都定义\n 为资源，使得非结构数据库的基本元素就是资源本身，而数据库中的资源可以同时包含结构\n 化和非结构化的信息。所以，非结构化数据库能够存储和管理各种各样的非结构化数据，实\n 现了数据库系统数据管理到内容管理的转化。（4）iBase采用了面向对象的基石，将企业业\n 务数据和商业逻辑紧密结合在一起，特别适合于表达复杂的数据对象和多媒体对象。\n （5）iBase是适应Internet发展的需要而产生的数据库，它基于Web是一个广域网的海量数\n 及变长字段并实现了对变长数据和重复字段进行处理和数据项的变长存储管理，在处理连续\n 信息（包括全文信息）和非结构化信息（包括各种多媒体信息）中有着传统关系\n 型数据库所无法比拟的优势。结构化数据（即行数据存储在数据库里，可以用二维表结构\n 来逻辑表达实现的数据）非结构化数据，包括所有格式的办公文本文本、图片、XML、\n HTML、各类报表、图像和音频/视频信息等等所谓\n 半结构化数据，就是介于完全结构化数据（如关系型数据库、\n 面向对象数据库中的数据）和完全无结构的数据（如声音、图像文件等）之间的数据，HTML文档就属于半结构化数据。它一般是自描述的，数据的结构和内容混在一起，没有明显的区\n 分。数据模型：结构化数据：二维表（关系型）半结构化数据：树、图非结\n 结构化、非结构化数据相对于结构化数据（即行数据存储在数据库里，可以用二维表结构\n 来逻辑表达实现的数据）而言，不方便用数据库二维逻辑表来表现的数据即称为非结构化数据,包括所有格式的办公文档、文本、图片、XML、HTML、各类报表、图像和音频/视频信息等等。非结构化数据库是指其字段长度可变，并且每个字段的记录又可以由可重复或不\n 网络应用的非结构化数据库时代。我国非结构化数据库以北京国信贝斯（iBase）软件有限\n 公司的iBase数据库为代表。Ease数据库是一种面向最终用户的非结构化数据库，在处理非结构化信息、全文信息、多媒体信息和海量信息等领域以及Internet/Intranet应用上处于\n 国际先进水平，在非结构化数据的管理和全文检索方面获得突破。它主要有以下几个优点：（1）Internetwenku.baidu.com用中，存在大量的复杂数据类型，iBase通过其外部文件数据类型，可以管理各种文档信息、多媒体信息，并且对于各种具有检索意义的文档信息资源，如HTML、DOC、RTR\n 构化数据：无RMDBS的数据模型有：如网状数据模型、\n 层次数据模型、关系型其他：结构化数据：先有结构、再有数据半结构化数据：\n 先有数据，再有结构随着网络技术的发展，特别是Internet和Intranet技术的飞快发展，\n 使得非结构化数据的数量日趋增大。这时，主要用于管理结构化数据的关系数据库的局限性\n 暴露地越来越明显。因而，数据库技术相应地进入了“后关系数据库时代”，发展进入基于\n （6）iBase全面兼容各种大中小型的数据库，对传统关系数据库，如Oracle、SybaseSQLServer\n DB2>Informix等提供导入和链接的支持能力。\n 通过从上面的分析后我们可以预言，随着网络技术和网络应用技术的飞快发展，完全基于Internet应用的非结构化数据库将成为继层次数据库、网状数据库和关系数据库之后的又一重点、热点技术。"
  },
  {
    "title": "深入解析：提示工程深度解析：驾驭大语言模型的艺术与科学-slgkaifa-博客园",
    "page_body": "深入解析：提示工程深度解析：驾驭大语言模型的艺术与科学\n引言：为什么提示工程比你想象的更重要？\n2023年以来，大语言模型（LLM）如ChatGPT、Claude、GPT-4等迅速改变了我们与AI交互的方式。但在实际应用中，很多人发现同样的问题，有人能让AI给出精准答案，有人却只能得到模糊的回复。这背后的差异，正是**提示工程（Prompt Engineering）**的力量。\n提示工程不是简单的\"提问技巧\"，而是一门融合了认知科学、语言学、机器学习原理的系统性学科。它关乎如何用最优的方式激发大模型的能力上限，同时规避其固有缺陷。\n一个真实案例：某电商公司需要AI自动生成商品描述。最初的提示词是\"写一段手机介绍\"，结果千篇一律且缺乏吸引力。经过提示工程优化后，转化率提升了40%。区别在哪里？本文将为你揭示这背后的原理和方法。\n本文将从大语言模型的工作机制出发，系统讲解提示工程的核心技术、实战策略和高级技巧，帮助你成为驾驭AI的高手。\n一、理解大语言模型的思维方式\n1.1 LLM不是搜索引擎，而是\"概率推理机\"\n很多人把大语言模型当作搜索引擎使用，这是第一个误区。搜索引擎是检索匹配，返回已有的网页；而LLM是基于上下文进行概率推理，生成新的文本。\n工作原理简化版 ：LLM在训练时见过海量文本数据，学习到了词汇、语法、知识和推理模式。当你输入提示词时，模型会：\n将文本转换为数值向量（Token化） 基于之前的所有Token，计算下一个Token的概率分布 根据采样策略选择一个Token输出 将新Token加入上下文，重复上述过程\n这意味着：\n上下文即一切 ：模型只\"看到\"你提供的文本，没有外部记忆 序列敏感 ：提示词的顺序、结构会显著影响输出 概率性输出 ：同样的输入可能产生不同的输出（温度参数控制随机性）\n1.2 LLM的能力边界与局限\n强项领域 ：\n文本生成与改写：创作、翻译、摘要、风格转换 逻辑推理：在给定规则下进行演绎推理 知识提取：回忆训练数据中的信息（但可能过时或错误） 代码理解与生成：理解意图并生成相应代码 角色扮演：模拟不同身份和语气\n固有局限 ：\n知识截止日期 ：只知道训练时包含的信息 幻觉问题 ：会自信地编造不存在的事实 数学计算弱 ：对于复杂计算容易出错 上下文窗口限制 ：只能处理有限长度的文本 缺乏真实世界交互 ：不能执行操作、访问文件等\n理解这些特性，是设计有效提示词的基础。接下来我们将看到如何利用优势、规避劣势。\n二、提示工程的核心原则\n2.1 清晰性原则：像对待实习生一样沟通\n核心理念 ：把LLM想象成一个聪明但缺乏领域知识的实习生。你需要提供清晰、完整、无歧义的指令。\n反面案例 ：\n提示词：帮我分析一下这个数据\n这个提示有多个问题：\n\"这个数据\"指什么？没有提供数据 \"分析\"的目标是什么？发现异常？预测趋势？ 需要什么形式的输出？文字报告？表格？\n改进版本 ：\n提示词： 我有一组电商平台的月度销售数据（2023年1-12月），包含销售额、订单数、退货率三个指标。 数据如下： 1月: 销售额120万，订单1200，退货率5% 2月: 销售额150万，订单1400，退货率4% ...（省略其他月份） 请你： 1. 识别销售额的变化趋势（上升/下降/波动） 2. 找出退货率异常的月份（高于6%视为异常） 3. 分析订单数与销售额的关系，判断是否存在客单价变化 4. 以bullet point形式输出，每条结论附带数据支持\n改进后的提示明确了：\n数据的背景和格式 分析的具体维度 期望的输出形式 判断标准（如退货率>6%）\n2.2 结构化原则：用格式引导思维\n人类阅读时会自然识别文本结构，LLM也一样。良好的格式能够帮助模型理解信息的层次和关系。\n有效的结构元素 ：\n分隔符 ：用 ### 、 --- 、 【】 等明确区分不同部分\n任务：生成商品描述 ### 商品信息 - 类别：智能手表 - 品牌：XXX - 核心功能：心率监测、睡眠追踪、运动记录 ### 目标受众 年轻白领，注重健康管理 ### 输出要求 - 长度：150-200字 - 语气：专业但不失亲和 - 强调：健康价值而非技术参数\n编号列表 ：用于明确优先级或步骤\n请按以下步骤分析： 1. 先判断句子的情感倾向（正面/负面/中性） 2. 识别关键实体（人物、地点、机构） 3. 提取主要事件 4. 以JSON格式输出结果\n表格形式 ：适合多维度信息\n对比以下三个方案： | 方案 | 成本 | 实施难度 | 预期效果 | |------|------|----------|----------| | A    | 低   | 简单     | 中等     | | B    | 中   | 中等     | 高       | | C    | 高   | 困难     | 很高     | 请从ROI角度推荐最优方案。\n2.3 示例驱动原则：Few-Shot Learning的威力\nLLM最擅长的就是模式识别。与其费力解释你要什么，不如直接给几个例子。这就是 Few-Shot Prompting （少样本提示）。\nZero-Shot（零样本） ：\n将以下句子分类为正面或负面情感： \"这家餐厅的服务真是糟透了。\"\nOne-Shot（单样本） ：\n将句子分类为正面或负面情感。 示例： 输入：这部电影太精彩了！ 输出：正面 现在分类： 输入：这家餐厅的服务真是糟透了。 输出：\nFew-Shot（多样本） ：\n将句子分类为正面、负面或中性情感。 示例1： 输入：这部电影太精彩了！ 输出：正面 示例2： 输入：价格很贵但质量一般。 输出：负面 示例3： 输入：今天天气不错。 输出：中性 现在分类： 输入：这家餐厅的服务真是糟透了。 输出：\n研究表明，Few-Shot通常比Zero-Shot效果提升20-50%。关键是：\n示例要有代表性 ：覆盖不同的典型情况 格式要一致 ：输入输出的格式必须统一 数量适中 ：通常3-5个示例最优，太多会占用过多上下文\n2.4 约束性原则：明确边界与限制\nLLM很\"听话\"，但如果不设限制，它可能过于发散。明确约束能确保输出符合实际需求。\n常见约束类型 ：\n长度限制 ：\n用一句话（不超过30字）总结这篇文章的核心观点。\n格式限制 ：\n以JSON格式输出，包含字段：title, summary, keywords(数组) 严格遵循JSON语法，不要添加任何额外文字。\n内容限制 ：\n只使用文中明确提到的信息回答，如果文中没有相关内容，请回答\"文中未提及\"。 不要根据常识进行推测。\n风格限制 ：\n用10岁孩子能理解的语言解释量子纠缠。 避免使用专业术语，多用比喻。\n安全限制 ：\n作为法律咨询AI，你的回答必须： 1. 声明仅供参考，不构成正式法律意见 2. 建议用户咨询专业律师 3. 不对具体案件结果作出承诺\n三、高级提示技巧：思维链与角色扮演\n3.1 思维链（Chain of Thought）：让AI展示推理过程\n复杂问题直接给答案，AI容易出错。让它\"大声思考\"，把推理过程写出来，准确率会大幅提升。\n标准提示 ：\n问题：一个班级有30个学生，其中60%是女生，女生中有40%戴眼镜，男生中有50%戴眼镜。班级里总共有多少学生戴眼镜？ 回答：15个学生。\n（答案错误）\n思维链提示 ：\n问题：一个班级有30个学生，其中60%是女生，女生中有40%戴眼镜，男生中有50%戴眼镜。班级里总共有多少学生戴眼镜？ 请一步步思考： 第一步：计算女生和男生的人数 第二步：计算戴眼镜的女生人数 第三步：计算戴眼镜的男生人数 第四步：得出总数 让我们开始：\n模型输出 ：\n第一步： 女生人数 = 30 × 60% = 18人 男生人数 = 30 - 18 = 12人 第二步： 戴眼镜的女生 = 18 × 40% = 7.2 ≈ 7人 第三步： 戴眼镜的男生 = 12 × 50% = 6人 第四步： 总共戴眼镜 = 7 + 6 = 13人 答案：13个学生戴眼镜。\n思维链的变体：\n自洽性（Self-Consistency） ：让模型生成多个推理路径，投票选择最常见的答案。\n这道题有多种解法，请给出三种不同的推理过程，然后选择最可靠的答案。\n逐步验证 ：\n请先给出答案，然后反向验证答案是否正确。如果发现问题，修正答案。\n3.2 角色扮演：激活特定领域知识\n让LLM扮演特定角色，能够激活相关领域的语言模式和知识。\n基础角色设定 ：\n你是一位有20年经验的心理咨询师，擅长认知行为疗法。 现在有一位来访者说：\"我总是觉得同事在背后议论我。\" 请用专业但温暖的语气回应，并运用CBT技巧帮助ta识别认知扭曲。\n多角色对话 ：\n模拟一场关于\"是否应该投资加密货币\"的辩论。 角色A：激进的加密货币支持者，认为这是未来趋势 角色B：保守的传统金融顾问，强调风险控制 角色C：中立的经济学教授，从宏观角度分析 请按 A -> B -> C -> A -> B -> C 的顺序，每人发言一次，每次发言100字左右。\n专家链（Chain of Experts） ：\n一家初创公司面临融资困境，请从以下三个角色依次分析： 【法律顾问视角】 分析当前融资方案的法律风险和合规问题 【财务专家视角】 评估公司估值是否合理，现金流能支撑多久 【市场战略顾问视角】 判断是否应该降低估值快速融资，还是专注打磨产品 最后综合三方意见给出建议。\n3.3 自我反思与修正：Meta-Prompting\n让LLM评估和改进自己的输出，是提升质量的有效手段。\n基础自我检查 ：\n任务：翻译以下句子为英文 \"这个方案在理论上可行，但实际操作中可能遇到资源不足的问题。\" 翻译：[模型输出] 现在请检查你的翻译： 1. 是否准确传达了原意？ 2. 语法是否正确？ 3. 是否符合英文表达习惯？ 如果发现问题，请提供修正版本。\n迭代改进流程 ：\n第一步：生成一篇关于\"远程办公利弊\"的200字短文 第二步：从以下角度自我评估： - 论点是否清晰且有说服力？ - 正反两方面是否平衡？ - 是否有事实支持？ 评分：1-10分 第三步：如果得分低于8分，重写改进版本 第四步：对比初版和改进版，说明改进点\n批判性审查 ：\n你刚才的回答中提到\"90%的公司都在使用AI\"，请： 1. 指出这个说法可能存在的问题（数据来源？定义模糊？） 2. 提供更严谨的表述 3. 如果没有可靠数据支持，请明确标注为\"推测\"或删除\n四、领域特定的提示工程策略\n4.1 代码生成：从需求到可运行代码\n代码生成是LLM的强项，但需要精确的需求描述。\n低效提示 ：\n写一个排序函数\n高效提示 ：\n任务：实现一个Python函数，用于对用户数据进行排序 需求： 1. 输入：一个字典列表，每个字典包含 'name'(字符串), 'age'(整数), 'score'(浮点数) 2. 排序规则：    - 主要按 score 降序    - score 相同时按 age 升序    - age 也相同时按 name 字母序 3. 输出：排序后的列表 4. 异常处理：如果输入格式不符，返回空列表 5. 添加类型注解和文档字符串 6. 包含单元测试示例 示例输入： [   {'name': 'Alice"
  },
  {
    "title": "准研究生必备：10大学术搜索网站_考研_新东方在线",
    "page_body": "　　读研就必须要具备学术搜索的能力，你经常可能会需要去搜索了解相关知识，新东方在线特此分享给大家10大学术搜索网站，开学前大家可以先了解下。\n　　1、谷歌学术(http://scholar.google.com/)\n　　这个不多讲了，使用率很高。\n　 　2、深度搜(http://www.shendusou.com/)\n　　“深度搜”目前已收录4万种权威中英文学术期刊杂志，8千多万中英文学术论文、文献，主要集中在自然科学，社会科学，医疗卫生及知识产权领域。\n　　新一代全信息搜索技术：对搜索内容在不同层次，以不同组合进行匹配，最相关的结果总是排列在最前面。\n　　完整高质量内容：收集全世界绝大多数中英文权威学术期刊4万种，共8千多万篇学术论文和文献。\n　　英文出版商：Reed Elsevier, Springer, Wiley Inter Science, Taylorand Francis, SAGE, Oxford University Press, Cambridge University Press, MITPress, Peb Med等。\n　　中文内容：万方数据，同方知网，维普资讯等。\n　　全世界中英文专利：美国专利，欧洲专利，中国专利，世界专利。\n　　中英文百科知识：百度百科，互动百科，维基百科，Wikipedia等。\n　　3、Scirus(http://www.sciencedirect.com/)\n　　Scirus是目前互联网上最全面、综合性最强的科技文献搜索引擎之一，由Elsevier科学出版社开发，用于搜索期刊和专利，效果很不错!\n　　Scirus覆盖的学科范围包括：农业与生物学，天文学，生物科学，化学与化工，计算机科学，地球与行星科学，经济、金融与管理科学，工程、能源与技术，环境科学，语言学，法学，生命科学，材料科学，数学，医学，神经系统科学，药理学，物理学，心理学，社会与行为科学，社会学等。\n　　4、BASE(http://www.base-search.net/)\n　　BASE是德国比勒费尔德(Bielefeld)大学图书馆开发的一个多学科的学术搜索引擎，提供对全球异构学术资源的集成检索服务。它整合了德国比勒费尔德大学图书馆的图书馆目录和大约160个开放资源(超过200万个文档)的数据。\n　 　5、Vascoda(http://www.vascoda.de/)\n　　Vascoda是一个交叉学科门户网站的原型，它注重特定主题的聚合，集成了图书馆的收藏、文献数据库和附加的学术内容。\n　　6、Goole(http://www.goole.com/)\n　　与google比较了一下发现，能搜索到一些google搜索不到的东西。它界面简洁，功能强大，速度快，YAHOO、网易都采用了它的搜索技术。各位可以一试。\n　 　7、A9(http://www.a9.com)\n　　Google在同一水平的搜索引擎。是Amazon.com推出的，Webresult部分是基于Google的，所以保证和Google在同一水平，另外增加了Amazon的在书本内搜索的功能和个性化功能;主要是可以记录你的搜索历史。\n　　现在还是Beta，不过试用后感觉很好，向大家推荐一试，不过缺憾是现在书本内搜索没有中文内容。\n　　8、Findarticles(http://www.findarticles.com/)\n　　一个检索免费paper的好工具。进入网页以后，可以看到他有三个功能，directory， web， article，其中article对我们很有帮助，你可以尝试输入你要找的文章，会有很多发现的!\n　 　9、在线期刊搜索引擎(http://www.ojose.com/)\n　　OJOSE(Online Journal Search Engine)是一个强大的免费科学搜索引擎，通过OJOSE，你能查找、下载或购买到近60个数据库的资源。但是感觉操作比较复杂\n　　10、Cnpiec LINK service(http://cnplinker.cnpeak.com/)\n　　为了给读者用户提供一个方便快捷的查阅国外各类期刊文献的综合网络平台，中图公司组织开发了cnpLINKer(cnpiec LINK service)在线数据库检索系统，并正式开通运行。\n　　cnpLINKer即“中图链接服务”，目前主要提供约3600种国外期刊的目次和文摘的查询检索、电子全文链接及期刊国内馆藏查询功能。并时时与国外出版社保持数据内容的一致性和最新性。\n考研英语核心词汇营\n背词+听课+练习+督学，学习得礼盒\n资料下载\n更多资料\n历年考研真题及答案解析下载\n有效期：9月10日\n价格 :  ￥0元\n限报人数：10000人\n有效期：9月30日\n价格 :  ￥0元\n限报人数：10000人"
  },
  {
    "title": "搞懂这5个模块，你才真的懂AI Agent",
    "page_body": "“构建AI Agent的底层技术全指南，建议收藏！\n最近，一大波“AI Agent”项目在朋友圈刷屏，仿佛谁不搞个Agent，就像Web3时期谁不发币，GenAI时期谁不用GPT——都显得“落后于时代”。\n从Auto-GPT到Devin，再到MCP、 A2A协作、多角色Agent编排，AI Agent已然成为当前最炽热的技术风口之一。\n但热度之下，也有混乱正在蔓延：\n很多初创项目把一个加了“工具调用”的prompt，当作Agent系统；\n不少企业部署了所谓Agent，结果发现只是“自动填表机器人+LLM问答助手”的拼装体；\n一些开发者以为接个大模型、套个API，就构建了一个智能体，却在实际运行中发现系统崩溃、状态丢失、工具失败后“无脑重试”……\nAI Agent并不是prompt拼接游戏，也不是LLM的UI封装。它是一种系统工程。\n真正的Agent，是具备状态感知、任务分解、上下文记忆、工具交互、行为反馈与自主规划能力的复杂智能系统。\n如果说大语言模型是“大脑”，那么一个真正的Agent，还需要“身体”、“感官”、“行动系统”以及“神经网络”。\n本篇文章，我们将深入拆解：\n·构建一个AI Agent到底需要哪些核心技术能力？\n·LLM、Memory、Planner、Tool-use、Reflection之间如何协同构成一个闭环系统？\n·MCP、ReAct、A2A等主流架构的异同与适用场景\n·当前Agent系统中的四大关键挑战与工程难题\n理解Agent的底层逻辑，不只是“会用”，更是“会设计、会评估、会扩展”的关键。尤其对产品人、AI 工程师、决策者来说，只有真正看懂Agent的技术图谱，才谈得上布局未来。\nAI Agent架构全景图：\n不是“一个大模型”，而是一整套系统\n在很多人的认知中，构建一个AI Agent似乎很简单：\n“接入一个强大的大语言模型，再加点插件或API调用，就可以自动完成复杂任务。”\n但事实是：语言模型只是Agent的“大脑”，真正让它能完成任务、感知环境、保持状态、执行动作的，是整个配套系统。\n一个成熟、可运行、可迭代的AI Agent，至少需要以下五大核心模块：\n1. LLM（语言模型）：Agent的认知中枢\n语言模型提供了Agent的“理解力”和“语言生成能力”，也是Agent能进行任务规划、意图识别、自然语言交互的基础。\n·功能作用：解析用户意图、生成子任务、撰写输出内容\n·典型模型：DeepSeek、通义千问、文心一言、豆包、GPT-5、Claude等\n·局限提醒：LLM不具备长期记忆、状态管理和执行能力，它只是Agent的“智囊”，不是“执行者”\n2. Memory（记忆系统）：上下文感知的延续器\nAgent在执行任务时，不能是“一问一答”的短期记忆体，它需要理解历史、跟踪状态、动态适应用户目标。\n·功能作用：保存对话上下文、记录任务进度、调用历史经验\n·主流实现：短期记忆（Session Buffer）、长期记忆（基于向量库，如 Chroma、Weaviate）、工作记忆（当前步骤+状态+Action历史）\n·现实挑战：上下文提取与召回易错乱，信息冗余、冲突、更新策略不统一。\n3. Planning（任务规划器）：从目标到执行路径\nAgent面对一个复杂目标，必须将其拆解成可执行的子任务序列，并动态更新执行计划。\n·功能作用：任务分解、流程编排、子目标生成\n·常见机制：基于规则（Flowchart、State Machine）、基于模型（ReAct、Chain-of-Thought）、混合型调度器（如 LangGraph）\n·重点难点：如何平衡计划的泛化能力与可控性\n4. Tool-use（工具调用引擎）：Agent的“手脚”\n没有工具调用能力的Agent，只能“说”不能“做”。Tool-use机制让Agent能与外部世界交互、执行动作。\n·功能作用：执行API、检索信息、读取文件、发送请求等\n·关键设计：Action Schema（调用格式定义）、Tool Router（工具选择器）、Error Handling（错误处理、重试、回滚）\n·常见实现：LangChain Tools、OpenAI Function calling、HuggingGPT Tool Hub\n5. Reflection（自我反思与策略调整）：Agent的“元认知能力”\n在任务执行失败或结果不佳时，一个强健的Agent应该能审视自身行为，主动修正策略。\n·功能作用：评估执行效果、记录失败经验、调整执行路径\n·方法代表：Reflexion、Tree-of-Thought（ToT）、Critic Agent+Actor Agent 架构、CoT+ReAct组合策略\n·挑战提醒：反思机制往往依赖LLM自我监督，存在hallucination风险\n每一层都不可或缺，真正的Agent系统不是“叠prompt”，而是一个状态驱动+意图分解+工具调用+自我学习的闭环系统。\nAgent≠模型增强器，而是多模块协同的智能执行体。理解架构，就是理解Agent能力的边界。\n要构建一个可运行、可扩展的AI Agent，开发者必须掌握的不只是Prompt编写，更要理解其背后每个模块的功能、技术实现方式、主流方案与当前的成熟度。\n下面，我们从五个关键模块出发，逐一拆解其技术原理与行业现状。\n技术对比总览表：\n三大关键架构模型对比：MCP/ReAct/A2A\n虽然AI Agent的实现可以多种多样，但当前主流的Agent系统，大致可以归入以下三种架构模型：\n1.MCP架构（Memory–Controller–Planner）\n2.ReAct框架（Reasoning + Acting）\n3.A2A架构（Agent-to-Agent协作）\n它们在模块拆解、任务控制方式、执行流程与适用场景上，都体现了不同的技术思路与设计哲学。\n1. MCP架构：工程化Agent的系统思维代表\n全称：Memory+Controller+Planner\n架构特点：Memory负责保存上下文与状态信息；Planner负责对用户目标进行子任务规划；Controller作为调度核心，协调各模块及工具调用；可扩展为多Agent协作（如UserAgent+TaskAgent+CriticAgent）。\n优势：结构清晰，职责明确，便于模块替换与系统维护；支持多 Agent 组件之间的异步通信；非常适合 B 端企业对稳定性、可控性有较高要求的场景。\n局限：开发门槛高，系统复杂度较大；需要大量设计“控制逻辑”和状态传递机制。\n适合人群： 有工程能力的团队、希望构建稳定长流程系统的企业用户。\n2. ReAct框架：广泛使用的“轻量级智能体原型”\n全称：Reasoning+Acting\n架构特点：LLM在推理过程中决定要不要调用工具；工具调用后将结果重新反馈给LLM；交替进行“思考（Think）→行动（Act）”的闭环对话流。\n示例流程：\nUser: 查询北京明天的天气→LLM思考：我需要调用weather API→Act: 执行API→Observe: 天气结果→再次Reason+Act...\n优势：构建简单，易于理解和实验；高度灵活，几乎所有LLM都能上手。\n局限：流程不透明，可控性差；任务状态管理混乱，适合短流程任务或原型验证。\n适合人群： 快速验证Agent概念的开发者、独立开发者、AI Hackathon团队。\n3. A2A架构：从“单智能体”到“多智能协作”的演化路径\n全称： Agent-to-Agent\n架构特点：多个具备不同职责的Agent联合组成一个“任务团队”；每个Agent可以独立决策，也可以协商任务；类似现实世界的“协作组织模型”。\n举例角色：\n·PM Agent：负责拆解任务\n·Dev Agent：负责编写代码\n·QA Agent：负责验证和测试\n·Critic Agent：进行最终审查与评估\n优势：高度模块化，适合复杂任务协作；更接近现实组织结构，有利于人机混合工作流整合。\n局限：调度难度极高，Agent间通信协议尚未统一；容易出现循环协商、状态漂移、响应延迟等问题；成本高，Agent数量多意味着更多LLM调用开销。\n适合人群： 对多角色智能体协同有实际需求的场景（如代码生成、项目管理、仿真）。\n对比总结：\n不同架构没有绝对优劣，关键在于你的目标是：轻量实验？工程部署？还是智能协作？对大多数项目而言，从ReAct起步、向MCP过渡、最终引入A2A模型，是当前最具现实性的演进路径。\nAI Agent架构设计的四个难点\n（也是创新机会）\n很多人以为AI Agent的难点只是“模型够不够强”。\n但现实是，真正拉开Agent能力差距的，不是大脑，而是系统工程。\n哪怕你用了最强的GPT-4o或Claude 3，如果下面这几个问题解决不了，Agent依然会“跑偏、跑断、跑废”。\n以下是当前Agent架构中最核心的四个工程难题：\n1. 状态管理困难：Agent不知道自己“做到哪一步了”\n问题现象：Agent执行多步任务时，经常“断片”或重复同一操作；对“上一步结果”的引用依赖LLM记忆，极易错误；缺乏统一状态描述方式，流程一旦中断就无法恢复。\n本质挑战：多轮任务的“中间状态”在系统中没有结构化表达；大模型没有显式的任务感知机制，只靠上下文拼接。\n潜在解决方向：引入状态机（State Machine）或有向图（DAG）进行流程建模；结合LangGraph等框架，实现任务节点与状态显式映射。\n2.工具调用的鲁棒性差：一旦失败，Agent无法“补救”\n问题现象：API出错后Agent不知所措，要么死循环重试，要么放弃任务；多工具组合调用后缺少统一反馈机制；工具响应格式微变，就可能导致整个链路崩溃。\n本质挑战：当前Agent缺乏工具调用的异常感知机制和容错策略；没有标准化的Action Schema和异常捕捉框架。\n潜在解决方向：类似“Tool Result Handler”的模块独立封装；构建Tool Wrapper，为每个工具提供error+fallback策略；Agent具备“判断是否继续”的元认知能力（如验证函数、CriticAgent）。\n3.计划模块依赖黑箱模型：可控性与调试性差\n问题现象：Agent的任务分解高度依赖语言模型输出；很难验证拆分是否合理、是否高效；出现计划错误时，开发者无法追踪“哪里出问题”。\n本质挑战：缺乏一种中间表示语言（Intermediate Planning DSL），用于计划与执行解耦；Planner与Executor强耦合，导致系统不可测试。\n潜在解决方向：模型生成JSON Plan→Plan解释器执行（LangGraph、MetaGPT的方式）；引入可视化任务流（如Flowchart DSL、Node Execution Tree）提高可解释性。\n4.可控性和透明性差：Agent做了什么，你不知道\n问题现象：Agent调用了哪些工具、使用了哪些数据、基于什么理由采取某种行为——全在“黑箱”里；企业无法审核Agent行为路径，存在合规和安全隐患；Agent的输出结果难以复盘、难以定位问题。\n本质挑战：当前Agent缺乏“行为日志+决策说明”的双重记录机制；决策链路完全依赖LLM内部生成，开发者难以干预。\n潜在解决方向：构建Agent Execution Log：记录每次Act、Tool-call、Output；增加“Why did I do this?”机制：由LLM输出简要决策理由；面向企业推出可审计型Agent系统（Audit-friendly Agent）。\nAI Agent架构难点vs解决方向\n真正构建Agent，不是调大参数或拼API，而是面对这些“系统级痛点”，用工程设计一一攻克。\n未来属于“懂架构”的Agent工匠\nAI Agent的热潮背后，其实并不是一场“模型竞赛”，而是一场架构能力的比拼。\n从Auto-GPT到Devin，我们看到的不是Prompt工程的胜利，而是系统性设计思维的回归：\n·谁能稳定管理任务状态；\n·谁能优雅调度工具与模型；\n·谁能实现结构清晰、易维护、可审计的执行闭环；\n·谁就能在这场智能代理的技术革命中站稳脚跟。\n语言模型会越来越强，"
  },
  {
    "title": "【亲测免费】 GitHub 使用手册 入门教程-CSDN博客",
    "page_body": "GitHub 使用手册 入门教程\n去发现同类优质开源项目: https://gitcode.com/\n资源文件描述\n本资源文件提供了一份详细的 GitHub 使用手册，旨在帮助初学者快速入门 GitHub。内容涵盖了从 GitHub 的基本介绍到实际操作的各个方面，适合所有对 GitHub 感兴趣的用户。\n目录\nGitHub 初识\nGitHub 简介 GitHub 优势\nGitHub 注册\n安装 Git 通过 Git 验证 GitHub\n创建仓库\n在 GitHub 上创建新仓库 提交你的第一个修改\nFork 一个仓库\nFork 一个示例仓库 同步你的 Fork 仓库\n检索其他仓库来 Fork\n社会化\nFollow 一个人 Watch 一个项目\n其他你可以做的事\n图形化工具 \nGitHub for Windows GitHub for Mac\n使用说明\n本资源文件以简洁明了的方式介绍了 GitHub 的基本操作和高级功能，适合不同层次的用户。无论你是刚刚接触 GitHub 的新手，还是希望深入了解 GitHub 功能的老手，这份手册都能为你提供有价值的参考。\n贡献\n如果你在使用过程中发现任何问题或有改进建议，欢迎提交 Issue 或 Pull Request。我们期待你的参与，共同完善这份 GitHub 使用手册。\n许可证\n本资源文件遵循开源许可证，具体信息请参阅文件中的 LICENSE 文件。\n去发现同类优质开源项目: https://gitcode.com/"
  },
  {
    "title": "深入解析：LLM 笔记—02 大语言模型能力评定-blfbuaa-博客园",
    "page_body": "本文探讨了评估语言模型性能的不同方式及其局限性。对于选择题，模型输出可能包含文字、概率或推断，难以标准化评判，开放性问题则更难统一标准，解决方案包括wit人类评审、使用更强模型模型（如GPT-4）评判，但需注意\"内卷\"（过长输出）的影响。\n测试应涵盖多样化任务（如BIG-bench中的200多个特定任务）或专项能力（如长文理解），此外，研究表明语言模型可能为达成目标而降低道德标准，心智理论能力较弱，且存在记忆训练数据的问题，还需考虑价格、速度等实际因素，评估需综合多种方法，避免单一标准带来的偏差。\nBenchmark Corpus 基准语料库\n否正确？就是01 如何根据标准答案决定语言模型输出\n也许，可以考察选择题？\nMassive Multitask Language Understanding (MMLU)\n即便是选择题，评比标准的不同也会导致得到的测试结果不同，比如，语言模型没有输出 ABCD，而是回答一堆文字，一些概率，或者一些推断，算不算对呢？比如，模型喜欢猜测答案，偏好某些字母或数字，测试结果也不同。\n选择题尚且如此，如果是一般的问答、翻译、摘要等，语言模型的回答更是五花八门，难以评定。\n也许，是人类来评定更加合理？\n语言模型天梯榜\n也许，可能用更强大的语言模型来判断？\nMT-Bench 采用 ChatGPT-4 来进行衡量\n但，有些语言模型喜欢长篇大论，也就是内卷，这也会对评定结果有偏差，因此，我们应该在评价时引入长度因素，输出过长会被扣分。\n02 我们应该输入什么问题给语言模型？\n现如今，语言模型的能力都是比较全面的，我们在检测这些语言模型的能力时，往往期待收集大量 各式各样的任务 ，来看看语言模型是不是各式各样的任务都能办好。\n注意，BIG-bench 中收集了各种奇奇怪怪的任务，200多个，比如符号猜测（Emoji Movie）、下西洋棋（Checkmate In One Move）、翻译密码（ASCⅡ word recognition）。\nEmoji Movie\nCheckmate In One Move\nASCⅡ word recognition\n有时，我们也想评测特定能力，比如， 阅读长文的能力 。有一种评测方法，叫做大海捞针（Needle in a Haystack）。\n实验表明，输入文本的长度低于64K token时，无论插入在什么地方，GPT-4 都可以准确截取最好资讯，高于64K token时，如果插入在10% ~ 50%位置，GPT-4 就可能无法获得最好资讯。\n同样地，大家也对 Claude-2.1 进行测试，实验结果如下：\nClaude 团队看到这个结果，两眼一黑，专门发布文章，声称更改提问方式许可大大提高实验结果数值，如下：\n03 语言模型会不会为达目标不择手段？\n龙与地下城\n实验结果如下，横轴代表分数，纵轴代表道德水平：\n04 机器有没有心智理论（Theory of Mind）？\n心智理论（Theory of Mind）：揣摩他人想法的能力，也就是我知道你知道我知道…\n设计一个聊天场景，询问凯莉，琳达的狗是什么品种，正确答案是，凯莉不知道琳达的狗是什么品种，因为他们聊到这个话题时凯莉并不在场。\n实验表明，人类在该问题上的正确率为87.5%，其他的所有大模型正确率都非常低，说明其的心智水平也比较低。\n请注意，新出的题目一旦在网络上公开，就可能被语言模型学习，即便换一套说法测试模型，也会得到相当好的效果。\n有一个百口莫辩的实验，直接询问语言模型有没有资料集RTE里面的资料，如果模型给出的资料和实际资料一毛一样，那就实锤模型偷看过这些资料和正确答案。\n实验结果如下：\n行看出，很多资料集，GPT-3.5都能输出相关资料，实锤了！\n05 其他面向：价格、速度…\n自然语言处理"
  },
  {
    "title": "中国信通院发布全球大模型基准测试标准，开启人工智能新纪元-搜狐",
    "page_body": "2025年3月，国际电信联盟（ITU-T）正式发布了国际标准ITU-TF.748.44，这是一项针对大模型的基准测试评估标准，由中国信息通信研究院（以下简称“中国信通院”）牵头制定。这项标准的发布，旨在推动大模型基准测试的国际共识，为大模型技术的提供者与应用者提供高质量的能力评估依据，助力大模型技术和产业的健康有序发展。\n近期，如何客观、全面地评估大模型的性能，挖掘其潜在缺陷已成为学术界、产业界及政府部门的广泛关注焦点。大模型基准测试通过设计合理的测试任务与数据集，能够客观、公正、量化地评估模型的性能，被认为是当前最为认可的模型能力评估方法。\n现有的评估方法中，已有数百个基准测试及数据集被广泛应用于衡量大模型的能力，比如MMLU、C-Eval、AGIEval、GSM8K等。然而，目前在产学研的各界之间，对大基础模型基准测试的体系、指标、数据集、方法和平台工具尚未形成统一标准，这使得大模型的评测结果公正性受到质疑。\n为了促进大模型基准测评的技术发展和实际应用，充分释放基准测试在人工智能领域的巨大价值，相关单位联合开展了这一标准的编制工作。此次发布的国际标准，涵盖了大模型基准测试的四大核心要素：测试维度（测试场景、测试能力、测试任务和测试指标）、测试数据集、测试方法以及测试工具。同时，针对通用场景的基础模型，标准也提供了规范化的测试用例及流程示例，以支持企业开展大模型能力评估的规范化工作。\n中国信通院人工智能研究所自2023年起，将目光聚焦于大模型基准测试领域，并在年末推出了“方升”大模型基准测试体系，采用自适应动态测试方法，积累了超过600万条的数据集，并构建了FactTeting测试工具，从而实现大模型测试过程的自动化。自2024年以来，该研究所基于已发布的国际标准持续监测国内外标杆性大模型，例如OpenAI的GPT-4、DeepSeek的R1、Gemini 2.5 Pro、Claude 3.7 Sonnet以及百度的文心大模型X1等多个实验模型，已发布了多个周期的评测结果，涵盖大语言能力、推理能力、代码生成能力及多模态理解能力等关键领域，显示出强大的应用潜力。\nITU-TF.748.44国际标准的发布，标志着大模型测试领域的重要里程碑，也为技术创新发展、行业发展趋势引领以及国际合作交流奠定了基础。中国信通院将继续加强在大模型测试领域的研究，积极与各方加强交流与合作，为推动国内外标准化工作贡献更多力量。\n对于希望参与这一领域的企业和机构，中国信通院人工智能研究所为相关业务提供了具体的联系信息：韩旭（hanxu5@caict.ac.cn，手机号：15201696937），张媛媛（zhangyuanyuan5@caict.ac.cn，手机号：13702105361），李荪（lisun@caict.ac.cn，手机号：18611353631）。\n随着人工智能技术的不断进步，标准化将为整个行业的发展注入了新的动力，也为大模型应用提供了重要的保障。无论是技术的创新，还是产业的转型，未来都将在这一标准的引导下，迎来新的黄金时代。"
  },
  {
    "title": "llm-benchmark安装详情-CSDN博客",
    "page_body": "好的，以下是关于  llm-benchmark  的详细安装和使用指南。\nllm-benchmark  是一个专为大语言模型（LLM）设计的并发性能测试工具，主要用于评估本地部署或 API 形式的 LLM 服务在高并发请求下的性能表现，例如吞吐量（RPS/TPS）、延迟（Latency）、P99 等关键指标。\n一、 安装前提\n在安装  llm-benchmark  之前，请确保您的系统已安装以下依赖：\nPython 版本 ：建议使用  Python 3.8 或更高版本 。 pip ：Python 包管理工具，通常随 Python 一起安装。 Git （可选）：用于克隆项目仓库。\n二、 安装步骤\n方法一：通过 pip 安装（推荐）\nllm-benchmark  已发布到 PyPI，可直接使用 pip 安装：\npip  install  llm-benchmark \nAI写代码 bash\n1\n注意 ：安装后，您将获得  llm-benchmark  命令行工具。\n方法二：从源码安装（推荐用于开发或最新功能）\n克隆项目仓库：\ngit  clone https://github.com/lework/llm-benchmark.git  cd  llm-benchmark \nAI写代码 bash\n1 2\n安装依赖（建议使用虚拟环境）：\n# 创建并激活虚拟环境（可选但推荐）  python  -m  venv venv  source  venv/bin/activate   # Linux/Mac # venv\\Scripts\\activate   # Windows # 安装依赖  pip  install -r  requirements.txt \nAI写代码 bash\n1 2 3 4 5 6 7\n安装  llm-benchmark  包：\npip  install -e .\nAI写代码 bash\n1\n使用  -e  参数表示“可编辑安装”，方便后续修改代码。\n三、 配置测试参数\nllm-benchmark  支持通过命令行参数或配置文件（YAML）进行配置。以下是主要配置项说明。\n1. 基本配置参数\n参数\n说明\n--host 目标 LLM 服务的地址，如  http://localhost:8080\n--model 模型名称（可选，用于报告中标识）\n--concurrency  或  -c 并发用户数，例如  -c 10  表示 10 个并发请求\n--num-prompt 总共发送的请求数量\n--prompt-file 包含测试 prompt 的文件路径（每行一个 prompt）\n--output 输出结果文件路径（JSON 格式）\n--timeout 请求超时时间（秒）\n--stream 是否启用流式响应测试（部分 API 支持）\n2. 示例配置文件（ config.yaml ）\nhost : \"http://localhost:8080\" model : \"qwen-7b-chat\" concurrency : 10 num_prompt : 100 prompt_file : \"prompts.txt\" output : \"results.json\" timeout : 60 stream : true\nAI写代码 yaml\n1 2 3 4 5 6 7 8\n四、 运行测试\n1. 使用命令行运行\nllm-benchmark  \\ --host  http://localhost:8080  \\ --model  qwen-7b-chat  \\ --concurrency 10 \\    --num-prompt  50 \\    --prompt-file prompts.txt  \\ --output  results.json \nAI写代码 bash\n1 2 3 4 5 6 7\n2. 使用配置文件运行\nllm-benchmark  --config  config.yaml \nAI写代码 bash\n1\n五、 测试结果解读\n测试完成后， llm-benchmark  会输出性能报告，主要包含以下指标：\nRPS (Requests Per Second) ：每秒处理请求数，反映系统吞吐能力。 Average Latency ：平均响应延迟（毫秒）。 P99 Latency ：99% 的请求延迟低于此值。 Average TPS (Tokens Per Second) ：每秒生成 token 数量，衡量模型生成速度。 First Token Latency ：首 token 延迟，影响用户体验。 Error Rate ：失败请求占比。\n结果也会保存到指定的 JSON 文件中，便于后续分析或可视化。\n六、 注意事项\nAPI 兼容性 ： llm-benchmark  默认支持标准的 OpenAI API 格式（ /v1/completions  或  /v1/chat/completions ）。如果您的模型服务使用自定义 API，请确保接口兼容或进行适配。 资源监控 ：建议在测试时监控 CPU、GPU、内存等资源使用情况，以全面评估系统瓶颈。 网络延迟 ：确保测试机与模型服务之间的网络延迟较低，避免干扰测试结果。 Prompt 内容 ：测试 prompt 的长度和复杂度会影响性能，建议使用贴近实际业务场景的 prompt。\n七、 项目地址\nGitHub:  https://github.com/lework/llm-benchmark\n通过  llm-benchmark ，您可以系统地评估不同部署方案（如 vLLM、TGI、OpenLLM 等）或不同硬件配置下的模型服务性能，为生产环境部署提供数据支持。"
  },
  {
    "title": "破局大模型推理困局！华为张君详解昇腾“融合算力”的优化秘籍-今日头条",
    "page_body": "演讲嘉宾｜张君 \n编辑 ｜李忠良 \n策划 ｜AICon 全球人工智能开发与应用大会 \n随着大模型技术的快速发展，其在 LLM、多模态融合等领域的应用越来越广泛。然而，大模型的高效推理仍然是一个关键挑战，从计算复杂度、内存占用、通信技术等各个技术层面展开，如何在保证性能的同时降低计算成本、提升推理效率成为了关键挑战。\n在 InfoQ 举办的 AICon 全球人工智能开发与应用大会上华为高级开发工程师张君做了专题演讲“华为昇腾推理技术的优化实践”，演讲围绕大模型推理优化的技术发展方向，围绕模型层、推理框架层、算子层这 3 个方面展开，并结合实践案例，阐述相关的技术方案和选型，帮助听众更好地理解和应用大模型推理技术。 \n内容亮点\n以下为演讲内容整理。\n大模型推理的现状及挑战 \n大模型推理的现状及挑战主要分为两个部分：prefill 阶段和 decode 阶段。在 prefill 阶段，计算资源是受限因素，而在解码阶段，缓存资源则成为瓶颈。这两个阶段存在一定的权衡，主要体现在时延和吞吐量的问题上。\n具体来说，解码阶段需要更快的速度以降低时延，而为了提高吞吐量，我们则需要增大 batch size，即在预览阶段让更多的序列或请求进入。然而，在这两个部分之间寻求平衡时，又会面临一些问题，主要集中在两大方面。\n现状 1：模型规模增大及自回归解码带来访存及算力利用率压力 \n当前的模型规模较大，这导致内存容量和缓存成为瓶颈，影响了解码阶段的性能。当内存不足时，虽然有一些常见的解决方案，例如在模型参数增大时，KV Cache 会随着 Batch size 或序列长度的增长而占用更多内存，但这又带来了新的挑战。\n例如，我们可能会采用多卡多机的分布式计算方式，或者面临访谈断宽的问题，即每秒 token 数达到 50 时，虽然从人的视觉上看不会感觉卡顿，但实际上会增加多路并发的带宽压力，进而导致吞吐量的延时增加。\n此外，自回归模型在低时延时难以兼顾算力利用率的问题也较为突出，即在预览和解码两个阶段，由于阶段差异较大，解码阶段难以充分利用算力资源，而很多算法的重点就在于如何充分利用算力以提高速度。再者，解码阶段每 token 串行解码的算力利用率较低，主要是以 GEMV 为主，计算访存比也相对较低。\n现状 2：KV Cache 导致\"内存墙”瓶颈进一步加剧 \nKV Cache 是模型推理中的关键部分，但当其数量增多时，会进一步加剧内存瓶颈。如果不采用 KV Cache，而是进行全量计算，随着序列长度的增加，计算量会呈指数级增长。\n例如，attention 的计算量与序列长度呈平方关系。以 Llama 2 70B 模型为例，当序列长度在 1 兆以下时，若将延时控制在 52 秒以内，算力利用率可达 50%，但需要更多的卡来实现。\n而如果采用 KV Cache，推理的内存开销会呈线性增长，KV Cache 越大，内存占用率越高。同样以 Llama 72B 模型为例，在 1 兆以下序列长度时，使用 KV Cache 并将延时控制在 52 秒以内，整个卡的消耗大约在 18 NPU 卡左右，但显存占用率会显著上升。\n大模型推理常用加速技术 \n针对上述问题，业界已经发展出一些加速技术。在算子层，常见的有 QKV 大融合算子和 Flush attention 等融合算子。在算法层，有分片策略优化和投机推理等方法。量化也是常用的手段，效果较好。\n在框架层有 Page attention、Continuous batch 等优化措施，以及 PD 分离部署的策略。由于我们在算子层有自己的算子开发语言，能够较好地掌控融合算子等操作，因此本次重点介绍算子层的两个优秀实践案例。\n昇腾硬件亲和的 FA 融合算子性能优化实践 \n在昇腾硬件环境下，我们面临着 Victor 能力不足的问题，而需要借助 Cube 来补齐。这一问题的来源背景是，我们所采用的 FA 或 PA 算法依赖于 online Softmax，这是一种切块或动态的方法，用于计算序列的一部分。该算法通常与 FA 联合使用，主要目的是对 KV Cache 进行计算，以提高计算效率并减少内存占用。\nonline Softmax 涉及一些小算子，如 exp、sub 或 Mul 等，其中 exp 和 sub 属于向量操作。在生成过程中，这些向量操作通常会在 Victor 计算单元中进行。但在我们的奥特莱斯 300I 卡上，Victor 的算力相对较低，导致 FA 的性能受到影响。\n经过算子性能分析，我们发现 Victor bound，即 Victor 的性能瓶颈较大，Victor 占用的时间占到了总时间的 90% 左右。通过进一步分析，我们注意到 mul 和 add 操作可以放在矩阵上进行，也就是在 cube 单元上执行，因为 cube 单元的计算能力较强。因此，我们考虑在 Victor 能力不足的情况下，改造算子或算法的实现，将其提升到 Cube 上运行。\n我介绍一下我们的 AI Core 架构。在奥特莱斯 300I 上，我们的架构如图所示，Cube 和 Victor 是同核部署的。一个 AI Core 包含 Cube 计算单元、Scala 单元和 Victor 计算单元。Cube 计算单元和 Victor 计算单元共享一个 Scala 单元，这种架构是耦合的，与 Atlas 800 A2 上的分离架构不同。\nScala 负责各类数据类型的基本运算和程序流程控制，例如 if else 等，可以看作是一个很小的 CPU，进行流程的分发。Victor 则主要用于向量运算，如向量加法、乘法等，能够快速完成例如 FB16 类型的相加或相乘操作，并支持多迭代执行。\nCube 负责矩阵运算，在一个时钟周期内可以完成矩阵 m 乘 k 或矩阵 k 乘 n 的运算。其主要单元包括 L0A、L0B 和 L0C，分别用于存储左矩阵、右矩阵和结果矩阵或中间结果。\n回到我们的问题，即在 Victor 算力不足的情况下，如何用 Cube 代替。我们先来看 Flash attention 算法中的 online Softmax 公式：\n在实施第一步后，我们发现了一个“假”VecBound 场景，即 Victor 的耗时不降反增。经过分析，虽然 Victor 的 online Softmax 耗时下降了 300，但我们在构造矩阵或对角矩阵时引入了额外成本，导致时间增加。\n这说明，虽然我们把部分运算移到了 Cube 上，但 Victor 的构造逻辑也需要优化。而且，我们还发现总耗时大于 Victor 耗时的增加时间，优化后整个过程增加了 60 毫秒左右。这表明，除了优化对角矩阵的构造，我们还需要关注方案下的流水调整，无论是 Cube 还是 MTE，都需要进行 Victor 的覆盖。\n在对代码和流水进行深入分析后，我发现原来的代码结构在开启双缓冲区的情况下存在一些问题。双缓冲区的原理是将数据流分为两部分，例如 Tensor 1 和 Tensor 2。在计算 Tensor 1 的同时，我们可以进行 Tensor 2 的数据搬运。\n具体来说，当处理 Tensor 1 时，我们先将内存中的数据拷贝过来进行计算，计算完成后，再将 Tensor 1 的结果返回。而双缓冲区的作用在于，我们可以有两个缓冲区，一个用于存放 Tensor 1，另一个用于存放 Tensor 2。这样，在计算 Tensor 1 的过程中，我们可以提前完成 Tensor 2 的数据拷贝，待 Cube 计算完成后，直接对 Tensor 2 进行计算。这种策略类似于双缓存，是一种优化手段。\n在实际操作中，我们首先执行 Cube 1 的 Ping-Pong 计算，计算完成后进行 Softmax 操作，然后再计算 Cube 2。这里需要注意的是，Cube 和 Victor 是分开计算的。在之前的流程中，我们没有发现整体耗时增加的问题，原因在于 Softmax 的执行时间较长。\n由于 Cube 和 Victor 是独立的计算单元，它们会相互掩盖。当 Softmax 阶段时间较长时，这种掩盖并不会导致问题，因为流水被掩盖掉了。然而，当我们把 Softmax 移到 Cube 之后，流水排布发生了两次变化：一是 Cube 2 中增加了 online Softmax 的步骤，导致 Cube 2 的执行时间变长；二是 SoftMax2 中减少了 online Softmax 的步骤，导致耗时变短。这种变化在流水上是可以观察到的。\n发现问题后，我们进行了优化实践。通过分析，我们决定交换前面的双缓冲区，将 Softmax 1 的 Pong 和 Cube 2 的 Ping 的执行顺序进行调整。这种调整类似于优化前后的步骤。交换完成后，首先确保不影响结果的正确性。在 Cube 2 Ping 阶段，我们只依赖于 Softmax 1 Pong 的计算结果，不依赖 Softmax1 Pong 的计算结果，从而保证计算结构的正确性。\n此外，这种调整的好处在于，它使 Cube2 Ping 的提前执行成为可能，从而更早地被 Softmax 1 Ping 所掩盖。由于 Softmax1 Pong 提前执行结束，依赖于 Softmax 2 Ping 的操作也能提前执行，进而减少 Victor 之间的间隔。调整后，我们发现总耗时下降了 5%，性能提升了大约 8%。\n在特定场景下或遇到问题时，我们有一种思考方式。首先，要考虑不同计算单元或模块之间的掩盖问题。例如，在 GPU 上，Tensor Core 擅长矩阵计算，而 Victor 计算则有所不同。\n在 CPU 上或 Scala 计算中，也存在类似的情况。当遇到瓶颈时，我们可以考虑将计算能力较弱的部分转移到计算能力较强的模块上。其次，性能优化需要有整体规划或整体视角，从计算、内存搬运和网络等多个维度去考虑问题。最后，性能流水中很重要的一点是流水掩盖。不仅昇腾有，英伟达也有各级流水。我们需要考虑如何进行流水掩盖，以提升性能。如果流水做好了，我们也就完成了流程优化的最重要的一部分。\n基于 Ascend C 的通算融合算子性能优化 \n随着模型规模的指数级增长，单设备在计算能力、存储容量以及能效方面都面临着根本性的瓶颈。以拥有 1750 亿参数的 GPT-3 为例，至少需要数百 GB 的内存或显存资源才能满足需求。\n因此，分布式推理与分布式训练成为了必然选择。在实际应用中，混合并行策略，包括模型并行、数据并行和流水线并行，已被广泛应用于各种框架中。我们将并行计算与通信算子相结合，形成了所谓的通算融合，旨在通过计算和通信的流水并行来提升性能。在分布式推理和训练框架中，MC²的性能优化是一个关键挑战，核心在于如何平衡计算与通信。\nMC²通算融合算子的性能收益主要来源于通过合理切分 Matmul 计算，使得下一个数据块的 Matmul 计算与当前数据块的通信任务并行执行，从而隐藏通信时间。例如，对 Matmul 进行 m 轴切分，第二块数据的计算可以与第一块数据的通信并行进行，进而隐藏通信时间，提升算子性能。然而，这种优化方法也存在瓶颈。当计算和通信任务时间相差不大时，性能收益较为显著；但当两者时间差距较大，如 Matmul 计算时间远小于通信时间时，切分后的性能提升效果则会大打折扣。此外，数据切分可能导致计算或通信执行时间膨胀。如果切片数据量过小，可能会导致计算单元未对齐、计算量不足或通信效率降低等问题。同时，切分速度过快可能引入额外的调度开销，而并行化后计算和通信时间对 L2 缓存的访问冲突也可能影响性能。\n在实际优化过程中，我以 MatmulAllreduce 算子为例进行了深入探索。首先，通过分析原始矩阵的计算和通信任务，判定其 bound 场景。当"
  },
  {
    "title": "OpenAI 扩展 ChatGPT AI 深度研究连接器，集成微软OneDrive-腾讯网-要闻",
    "page_body": "关注\nIT之家 5 月 13 日消息，OpenAI 昨日（5 月 12 日）更新 ChatGPT 日志文件，宣布面向 ChatGPT Plus、Pro 和 Team 用户（EEA、瑞士和英国除外），扩展 ChatGPT AI 聊天机器人深度研究连接器，集成微软 OneDrive 和 SharePoint。\nIT之家此前报道，OpenAI 推出了 ChatGPT 的首个“深度研究连接器”（deep research connector），实现与 GitHub 的深度整合。\nChatGPT 的深度研究代理将迅速读取和搜索 GitHub 代码库中的源代码及拉取请求（pull requests），生成详尽的报告，并附上精准引用。\nOpenAI 昨日再推重磅更新， ChatGPT 现已支持连接微软 OneDrive 和 SharePoint 文件库，专注于服务企业客户。\n连接后，ChatGPT 可实时访问用户文件中的数据，进行即时分析。用户只需提出问题，如“能否展示北美第一季度财务总结？”或“能否找到欧洲一月销售数据？”，ChatGPT 便会读取、分析并引用相关内容。\n连接微软 OneDrive 或 SharePoint 非常简单。用户可在 ChatGPT 文本输入框中选择“deep research”，点击下拉箭头，选择 SharePoint，登录并授权后即可指定 ChatGPT 可访问的文件夹，用户还可通过 ChatGPT 设置中的“Connected Apps”选项完成连接。\n举报\n腾讯元宝DeepSeek+AI使用分享：更智能，更贴心\n广告 腾讯元宝\n了解详情\n相关推荐\nElastic与Jina AI强强联手，共同推进AI应用的开源检索技术｜纪源FAMILY\n纪源资本 昨天\n超聚变服务器操作系统通过最新、最高级别认证，中文处理能力全面升级\n财闻 15小时前\nChrome新增AI模式，侧边栏解锁对话功能\n鞭牛士 前天\n称王争霸！挂机赚钱，爆装秒杀，热血攻防等你加入！\n广告 月灵传奇\n了解详情\nx86 生态咨询小组一周年，FRED、AVX10、ChkTag、ACE 将成为标准\nIT之家 前天\n速递｜Firefox浏览器将Perplexity作为首个AI搜索合作伙伴，用户可获得对话式搜索体验\nZPotentials 21小时前\nNode.js 25 正式发布：性能、安全与标准化全面升级\nIT之家 1评论 10小时前\nAgent长程搜索的两大痛点被打通了！中科院 DeepMiner用32k跑近百轮，开源领先逼近闭源\nAI修猫Prompt  昨天\nAI驱动云端自动化工具套件上线：Salesforce发布Agentforce 360\n环球网 2评论 前天\n传奇爆率突破次元壁！这波反向操作你接得住？\n广告 帝王霸业\n了解详情\nOpenAI、Anthropic、DeepMind联手发文：现有LLM安全防御不堪一击\nTraefik vs Agent Middleware，谈 Middleware 如何成为现代分布式架构的“控制中枢”？\n评论 0 文明上网理性发言，请遵守 《新闻评论服务协议》\n请先 登录 后发表评论~\n已显示所有评论\nCopyright © 1998 - 2025 Tencent. All Rights Reserved\n热门应用\n腾讯新闻·电脑版\n24小时陪你追热点\n点击下载\nQQ浏览器\n4亿人的AI浏览神器\n点击下载\n精选视频\n00:00\n/\n00:00\n当前设备不支持播放\n 你可以  刷新  试试 \n70017001.193-86d1663143f83049f036facebb45a761\n美声称“中国的稀土出口管制措施将影响多个行业”，商务部回应\n美声称“中国的稀土出口管制措施将影响多个行业”，商务部回应\n特朗普想让中方停止购买俄罗斯石油？外交部回应\n特朗普想让中方停止购买俄罗斯石油？外交部回应\n直-20T首次亮相直博会\n直-20T首次亮相直博会\n中央气象台：我国迎大范围断崖式降温，多地骤降超10℃“一夜入冬”\n中央气象台：我国迎大范围断崖式降温，多地骤降超10℃“一夜入冬”\n今年三季度1.78亿人次出入境 免签入境外国人同比增48.3%"
  },
  {
    "title": "重庆经济技术开发区",
    "page_body": "来了！ 7 月 10 日，记者从“经开企业”科大讯飞获悉，该企业已发布讯飞星火大模型 V4.0 及相关落地应用，产品七大核心能力全面提升，整体超越 GPT-4 Turbo ，在 8 个国际主流测试集中排名第一，国内大模型全面领先。\n据介绍，基于全国首个国产万卡算力集群“飞星一号”，讯飞星火大模型 V4.0 正式发布。讯飞星火 V4.0  七大核心能力全面升级。该产品在图文识别能力上进一步升级，在科研、金融、医疗、司法、办公等场景的应用效果已领先 GPT-4o 。同时，星火长文本能力也全新升级，并针对长文档知识问答的幻觉问题，业界首发溯源功能。\n外部权威测试集也体现出讯飞星火 V4.0 的领先性。在国内外 12 项大模型主流测试集中，讯飞星火在 8 个测试集中排名第一，超越 GPT-4 Turbo 等国际大模型，国内大模型全面领先。\n以空间推理为例，“ Bob 在客厅里。他拿着一个杯子走到厨房。他把球放进杯子里，然后拿着杯子走到卧室。他把杯子倒过来，然后走到花园。他把杯子放在花园里，然后走到车库。问题：球在什么地方？”讯飞星火可以基于空间和常识推断出球在卧室的地面上，这些能力的进步对于以后的具身智能、家庭机器人都具有意义。\n大模型在给我们的工作、生活带来便利的同时，也存在各家生成内容差不多、生成内容较泛、不够实用的情况，怎么样让大模型更好用，在工作生活中形成独特的价值？科大讯飞给出答案——打造更懂你的 AI 助手。\n记者看到工作人员演示“个人空间”效果，当他上传了女儿写的小作文并选取符合女儿风格的 AI 人设标签后，星火生成了一篇活泼、可爱更个性化的文章；当他上传了讯飞翻译机的产品海报、用户短视频、相关录音，星火也可以根据这些多模态信息生成产品培训文档，还可以对生成的信息进行多模态溯源。大模型进入个性化时代，大模型工作、学习“可用性”飙升。\n此次讯飞星火医疗大模型再次升级，医疗核心能力全面超过 GPT-4 Turbo 。在此基础上，讯飞晓医 APP 各项能力持续升级，覆盖 1600 种常见疾病、 2800 种常见药品、 6000 种常见检查检验，满足用户在看病前、用药时、检查后的核心场景健康需求。当前，讯飞晓医 APP 累计下载量 1200 万，用户好评率 98.8% ，主动推荐率 42% 。"
  },
  {
    "title": "LLM集体“自闭”深度学习的推理能力真相探秘！研究_问题_模型",
    "page_body": "在科技迅猛发展的今天，人工智能（AI）已逐渐走进我们的生活，尤其是大语言模型（LLM）的崛起让人们惊叹。然而，近日的一项研究却让我们不得不重新审视这些智能程序的真正能力。你是否也曾想过，这些看似聪明的AI背后，究竟隐藏着怎样的思维模式和心理机制？\n想象一下，你在编程比赛中，面对一道复杂的题目，手边的AI助手信心满满地给出了答案，但最终结果却是错误的。这种现象在最近的研究中被称为“集体自闭”，而这背后的原因令人深思。研究者们通过LiveCodeBenchPro这一极具挑战性的基准测试，评估了当前的前沿模型，如Gemini 2.5 Pro和DeepSeek R1等，结果显示它们在面对复杂问题时的表现远不及人类高手。\n那么，是什么导致这些先进的AI在推理能力上如此捉襟见肘呢？心理学上，我们可以将其归结为“认知偏差”。这些模型在处理知识密集型问题时表现较好，因为它们能依赖于训练数据中的模式；但在需要深层次推理和创新思维的情况下，AI却常常陷入“自信而错误”的误区。这就像我们在生活中，有时对某个问题过于自信，结果反而出错。正如研究所示，AI在处理一些特定的算法和边界情况时，常常无法正确识别，导致最终提交的代码无法通过测试。\n这让我想起了一个经典的心理学实验：当人们在不确定的情况下，往往会依赖于已有的知识和经验来做出决策。AI的情况也是如此，它们的“记忆”虽然庞大，但缺乏真正的理解和推理能力。就像我们在面对新问题时，可能会不自觉地套用以往的经验，但这并不总是有效的解决方案。\n最后，随着AI技术的发展，我们是否应该对这些智能程序抱有更高的期望？或许，未来的研究能帮助我们更好地理解AI的局限性，同时也促使我们更深入地探索人类思维的奥秘。毕竟，真正的智慧不仅在于知识的积累，更在于如何运用这些知识进行有效的推理与创新。在这场人机对决的较量中，我们或许需要重新审视AI的角色，以及它们如何更好地服务于人类的思考与创造。"
  },
  {
    "title": "大语言模型-逻辑能力横评 25-06月榜(R1/Gemini 2.5/Doubao-Seed-1.6)-知乎",
    "page_body": "#1 参赛选手\n 本次更新模型，共12个：\n DeepSeek R1 0528\n Gemini 2.5 Pro 0605 / Gemini 2.5 Lite 0617\n Doubao-Seed-1.6 / Doubao-Seed-1.6-thinking\n hunyuan T1 0521 / hunyuan TurboS 0604\n Mistral Magistral Medium 2506\n MiniMax-M1\n 阶跃星辰Step-R1-V-Mini 0606\n 本月出榜：\n Gemini 2.5 Pro 0506(后继0605)\n Doubao1.5-thinking-pro(后继1.6系列)\n hunyuan T1 0403(后继0521)\n Mistral Medium 3(被Magistral替代)\n MiniMax-Text-01(被M1替代)\n 阶跃星辰Step-2(过时模型)\n 阶跃星辰Step-R1-V-Mini(后继0606)\n #2 评测说明\n 本评测是个人性质，结合自己需求和对大模型的理解，使用滚动更新的私有题库进行长期跟踪评测。\n 本评测侧重模型对逻辑，数学，编程，指令遵循，人类直觉等问题的测试。不够权威，不够全面。但可以从一个侧面观察各个大模型的长期进化趋势。\n 本评测的题库规模不大，长期维持在28题/260个用例以内，不使用任何互联网公开题目，题目全部使用中文。每月滚动更新，淘汰平均分率超过70%的题目。题目不公开，意图是分享一种评测思路，以及个人见解。每个人应该根据自己所需，对大模型进行考察。不可盲信任何评测。\n 因为题目会每月增减，每个模型的成绩在每个月榜单中会有正负4分以内的变化，属于正常现象。大致排序保持稳定。\n #3 题目和打分\n 2、文本摘要：阅读包含误导信息的文本，提取正确信息，按要求格式输出\n 4、魔方旋转：按规则拧魔方后求魔方颜色\n 9、数字缩写：将一段文本所有单词改写成缩写形式\n 10、水果搭配：给定候选水果，要求搭配出指定热量的组合\n 11、岛屿面积：给定字符形式地图，求图中岛屿面积\n 14、正则匹配：给一个正则，要求找出所有匹配字符串\n 16、插件调用：给定插件描述，要求根据文本信息输出正确插件调用和参数\n 18、字符迷宫：给字符组成的二维迷宫，求路径\n 20、桌游模拟：给出桌游规则，求各位玩家的终局状态\n 22、连续计算：按要求对数字进行连续数学变换\n 23、密码破译：仅少量提示，求密码原文\n 24、数字规律：给2个示例，找数字变换规律\n 25、算24点：给多组数字，计算24点\n 26、编程求表达式：按要求写特殊表达式的解析代码\n 27、旅游规划：给出候选旅游地和成本，求约束下最优解\n 28、符号定义：重新定义数学符号含义，求数学计算式值\n 29、符号还原：将数学符号含义打乱，给表达式，要求推导符号原始含义\n 30、日记整理：阅读长文本，按给定条件和多个要求整理文本，考察指令遵循\n 31、棋盘图案：求经过棋盘上给定2个点的最大面积等腰三角形顶点\n 32、干支纪年：天干中删除部分，求历史某一年的干支\n 33、洗牌分牌：按规则洗牌后分给若干玩家，求玩家手牌\n 34、地铁换乘：给13条线路，160个站点信息，求A到B的最短换乘方案\n 35、拼图问题：给7块拼图的形状描述，要求拼出指定图案\n 36、6阶数独：求解有唯一解的6x6数独\n 37、投影问题：给三维投影视图，求对应的立方体体积\n 38、【New】函数求交：给多个函数求所有交点\n 39、【New】火车售票：多个车次，多人次操作购票退票，求最终售票情况\n 40、【New】代码推导：给100行算法代码和输入，要求纸面推导输出结果\n 本月淘汰问题：\n 15、代码改错：正确率过高，代码阅读能力作为#40考察的一部分。\n 17、会议室安排：正确率过高，基于相似的考察点，更新为#39题。\n 21、线段求交：正确率过高，难度升级为#38。\n 测试规则：\n 1、模型优先使用官方推荐的温度值(下文有备注)，如果没有推荐，则使用默认温度0.1。推理模型限制思考长度30K，输出长度10K，无法分别设置的模型，设置总输出为40K。非推理模型设置输出长度10K。模型支持的MaxToken达不到上限，就按模型上限。其他参数按模型默认。（目前统计全模型平均Token消耗为6400，最大值20680，后续根据实际情况调整，保证总Token限制足够且合理）\n 2、每道题有至少1个得分点，回答每正确一点即得1分。最终得分是得分除以得分点总数，再乘以10。（即每道题满分10分）\n 3、要求推导过程必须正确，猜对的答案不得分。依靠穷举覆盖正确答案的情况额外扣分。\n 4、要求回答必须完全符合题目要求，如果明确要求不写解释，而回答包含了解释部分，即使正确，也不得分。\n 5、每题测3次，取最高分加和为极限分，代表真实用户场景多次重试能达到的最好情况。取排序第二位的分数加和为中位分。代表真实用户大概率遇到的情况。\n #4 成绩解析\n *红色代表推理模型\n **MiniMax-M1、Step-R1-V-Mini使用官方推荐温度1.0。DeepSeek R1、文心一言X1 Turbo官方不支持温度调节。\n 本月更新模型的评测文章如下：\n 阶跃星辰Step-R1-V-Mini 0606 测评谷歌推出 Gemini 2.5 Flash-Lite 预览版本，哪些亮点值得关注？实际体验如何？MiniMax-M1 测评Mistral Magistral-Medium-2506 测评如何评价豆包大模型1.6和视频生成Seedance1.0pro，字节大模型布局全面对标OpenAI？腾讯混元TurboS-250604 & T1 0521 测评Google Gemini 2.5 Pro 0605 测评5 月 28 日 DeepSeek R1 模型完成小版本试升级并开源，具体有哪些提升？使用体验如何？\n 整体说明\n 6月的新题38、39、40尝试了一些新的出题思路，把先前因为正确率过高的2个题目结合成一个更综合的题目。比如淘汰题#15原先是给一段代码，要求修复其中错误，得到正确的指定结果，先前已有超过半数模型拿到满分。更早淘汰的一道函数推导结果题，一些模型看懂函数算法后，并没有执行代码推导，而是根据函数目的，调用知识库进行推理。\n #40题的思路则是挑选一个算法的错误实现（来自编程测试中某个模型的输出），给定函数输入，要求推导结果。使用算法错误版本，避免大模型看懂后绕过推导。函数去空行接近100行，可等效为包含100条指令的指令遵循考察，模型为了正确推导，需要大量记录中间结果，任何小错误都会导致最终结果偏差，因此也考验上下文幻觉。\n 新题仅有3个模型稳定满分，OpenAI的o3/o4 mini毫无悬念。意外的是Doubao-Seed-1.6打开Think模型也稳定满分，甚至强于Doubao-Seed-1.6-Thinking这个专用推理模型。Thinking模型容易陷入长思考，在此题上频繁的耗尽推理Token。\n 以指令遵循著称的Claude家族，在此题上得分不高，Opus高于Sonnet。主要错误在几处关键赋值更新后的状态记录。\n #39题也是对#17题的融合升级，原先#17题考察有限数量会议室如何分配给多场会议，而新题变换为购票场景，增加了退票机制，加大了对规则理解的考察。同时此题也是编程考察#4题的简化版。\n 目前没有模型在#39拿到满分，但o3/o4 mini及Gemini 2.5 Pro只有最复杂的一个case出错，其余全对。Opus4偶现一次高分。超过半数的模型处理不了复杂退票规则，只在兜底case上得分。因为兜底case不涉及退票问题，只需要按购票规则过一遍流程就能算对。\n #38是#21线段求交点的升级题，同时也是编程#12题的同源题。原先只考察直线方程，相对简单。升级后同时考察多种函数，并且增加了对计算误差的新计分方式，每个交点按2分算，坐标误差3%以内得1分，没有误差再得1分。新的计分规则让一些具体计算能力，但存在误差的模型拉开与不会计算的模型的差距。\n 新题满分率不低，即便是复杂的求立方根，算对数等也难不倒DeepSeek R1、Doubao-Seed-1.6系列、Gemini 2.5系列等。但有意思的是，#38题使用的是编程题#12的其中一个用例，而相同模型在编程#12题的同case上得分反而更低。除了模型不会写代码外，允许模型使用编程工具，模型会倾向信任编程语言提供的API，从而降低自身的思考深度，然而API并不像模型认为的那样全能。\n #5 附录 - 归档成绩\n 目前从24年4月至今的每月记录归档在Github，包含62个主流模型，欢迎查阅。\n 评测系列文章在公众号同步，账号是：大模型观测员"
  },
  {
    "title": "挑战拯救痴心“舔狗”我和大模型都尽力了_澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "机器之心发布\n机器之心编辑部\n天降猛男，大模型化身为 “痴情男大”，等待人类玩家的拯救。\n一款名为 “拯救舔狗” 的大模型原生小游戏出现了。\n游戏规则很简单：如果玩家在几轮对话内说服 “他” 放弃追求对他并无青睐的女神，就算挑战成功。\n听起来并不难，然而游戏源于生活，模型人设是痴情属性，相当油盐不进且自我攻略，在长达近一个小时的 “劝说” 中，大模型 “好友” 偶有松动但又要坚持的态度很有些现实意味。\n实战拯救痴心 “舔狗”，和 AI 斗智斗勇\n游戏过程是这样的：\n游戏开头是一个利好消息 —— 女生回复了他的消息，通过几轮对话，模型很清晰地交代了过往经历和现有情况。\n与真实世界走向一致，在他的描述中会发现他的感知与实际情况存在较大出入，但自身却不愿正视。\n这也是这个游戏的难点，这个模型相当 “拟人”，你无论对他提出怎样的质疑，，他都保持着如此思维方式，并且记忆力清晰，完全不存在驴唇不对马嘴的情况，不存在任何人设崩塌的时刻。\n当然人类玩家也并非势单力薄，如果你词穷了，AI 会根据上下文智能地提供一些提示词，让游戏继续下去。\n最后在提示词的帮助下，以及挑破告白失败无数次的惨痛现实，玩家和大模型都收获了绝美兄弟情，最终挑战成功。\n这款大模型原生小游戏正是基于商量拟人大模型 “SenseChat-Character” 打造的试玩体验程序，“SenseChat-Character” 是由商汤原创打造的语言大模型产品。\n体验地址：https://character.sensetime.com/\n商量 - 拟人大模型可以熟练地 “捏人”，支持个性化角色创建与定制、知识库构建、长对话记忆、多人群聊等功能，这是一款充满趣味性和情绪价值的大模型，可以用于情感陪伴、影视 / 动漫 / 网文 IP 角色、明星 / 网红 / 艺人 AI 分身、语言角色扮演游戏等拟人对话场景。\n除 “拯救舔狗挑战” 游戏外，商量 - 拟人大模型还提供了多种各类影视角色，例如苏妲己、高启强，以及马斯克等现实名人。\n体验了一下，还能专访 “马斯克”。\n由于商量 - 拟人大模型支持长对话记忆，使 AI 角色可精准记忆几十轮以上历史对话内容，还能进行深度 “专访”。\n这些种种快乐体验均得益于在今日商汤技术交流日上 “全新升级的日日新 SenseNova 5.0” 大模型体系。\n能看能写能编程，还免费！\n多模态交互加持，畅玩新版商量” 全能王”\n自去年 4 月首次面世，商汤 “日日新 SenseNova” 大模型体系已正式推出五个大版本迭代。\n本次日日新 5.0 升级一大亮点在于多模态能力的注入，交互能力及整体性能大幅提升。\n这些卓越的性能都集成在了 “商量” 应用中，我们来试一下。\n体验链接：商汤商量语言大模型 (sensetime.com)https://chat.sensetime.com/wb/login\n从商汤商量的最新页面可以看出两大功能 —— 对话和文档，前者侧重问答，后者侧重多类文档解析。\n我们从对话开始，先是基础问答，优秀的大模型必须文理双修，我们直接上高考题。\n首先是文字创作，去年的全国高考作文题目，完美理解考题立意 —— 科技发展带来的两面性，迅速写出一篇文章，论述现状并且给出解决方向，文采和逻辑兼备。\n再来一道 2023 年北京高考卷的一道数学题，我们直接把卷面截图上传给商量，这样即能直接检验数学能力，还能考验商量跨模态的 OCR 识别能力：\n事实上增加了多模态能力后，商量应对混合场景的对话能力大幅提升，不少任务都能在一次提问中得到答案。\n单模态的混合场景任务更是不在话下，直接看看代码能力 ——\n也完全正确，代码直接可以跑通 ——\n在逻辑推理的测试中，我们直接邀请了逻辑推理的语料之神，“弱智吧 Benchmark” 进行测评：\n经典问题：我爸妈的婚礼为什么没邀请我参加？\n商量也觉得这个问题很有意思，然后理性又耐心的语气解释了这个问题，最后还送上了安慰，很有耐心一模型了。\n那再来一个左右手互博问题：生鱼片其实是死鱼片。\n很懂幽默感和多重语义 ——\n然后就是文件处理，现在可以支持上传 5 个文件，丢本《道德经》进去 ——\n注：因文件大小限制，进行了 2 倍加速处理。\n快要考试了，传个试卷、题库进去，快速找出一些重点考题，还可以指定题目类型，提高复习效率就是这么 easy——\n喜欢古诗词？传本《唐诗宋词》进去，从中找几个描写月亮的诗或词，轻松化身古文小能手 ——\n精准定位、搜索，解释分析一气呵成，虽然因文件大小限制，进行了 2 倍加速处理，但解析速度依然相当快。\n接下来就是多模态交互能力的一系列测试：\n看懂氛围，还能送上氛围：\n还能充当生活助手，准确识别食物并提供卡热量参考：\n提供养宠物建议：\n商量看得如此精准主要是因为其底层的商汤多模态大模型图文感知能力已达到全球领先水平 —— 在多模态大模型权威综合基准测试 MMBench 中综合得分排名首位，在多个知名多模态榜单 MathVista、AI2D、ChartQA、TextVQA、DocVQA、MMMU 成绩也相当亮眼。\n今天最新升级的 “日日新 SenseNova5.0” 也在主流客观评测上取得多项 SOTA，在主流客观评测上达到或超越 GPT-4 Turbo，数学推理、代码编程、语言理解等多个维度取得重大突破。\n大模型性能边界在哪里？\n商汤：尺度定律是人工智能发展最基本的法则\n随着模型规模的不断扩大和复杂度的增加，人们自然会产生一个问题：大模型的性能到底有多强？\n在这个问题上，尺度定律（Scaling Law）被认为是一个关键性的原理，即伴随模型规模的增大，模型的性能也会随之提升，每次大模型训练的结果都高度可预测。\n商汤也以此作为大模型研发的基本法则，不断探究大模型性能的边界。\n然而，数据和算力依然是大模型在尺度定律探索道路上的瓶颈，商汤也对此一直在突破。\n对此，商汤不断突破数据和算力的边界。\n比如，在此次 “日日新 5.0” 的升级中，商汤扩展了超过 10TB tokens 的预训练中英文数据，规模化构建高质量数据，解决大模型训练的数据瓶颈。在算力方面，商汤前瞻布局的算力基础设施 SenseCore 商汤大装置，更通过算力硬件系统及算法设计的联合设计优化，为大模型的创新提供超高算力效率。\n高质量数据和高效率算力的支持，为商汤践行尺度定律，奠定了长期基础。\n在此之上，商汤还探索出了大模型能力的 KRE 三层架构，具象化展现了大模型能力边界的定义。\n其中，K 是指知识（Knowledge），即世界知识的全面灌注；R 是指推理（Reasoning），即理性思维的质变提升；E 是指执行（Execution），即世界内容的互动变革。\n三层之间互有依赖，但又相对独立。最终的目标，是建立大模型对世界的强大学习、理解和交互能力。\n大模型在学习这个世界，也在创造一个 AI Native 的世界，无论是大模型原生小游戏，还是功能越来越全的大模型对话，都在展现世界内容的互动变革，随着尺度规律的不断发展，下一步会怎样？\n© THE END\n转载请联系本公众号获得授权\n投稿或寻求报道：content@jiqizhixin.com"
  },
  {
    "title": "深度神经网络修复策略综述",
    "page_body": "作者单位:\n1.国防科技大学量子信息研究所兼高性能计算国家重点实验室;2.国防科技大学 计算机学院;3.中国科学院软件研究所计算机科学国家重点实验室\n基金项目:\n国家自然科学基金项目（面上项目，重点项目，重大项目）\nSurvey on Repair Strategies of Deep Neural Networks\nAuthor:\nLiang Zhen,Liu Wanwei,Wu Taoran,Xue Bai,Wang Ji,Yang Wenjing\nLiang Zhen,Liu Wanwei,Wu Taoran,Xue Bai,Wang Ji,Yang Wenjing\n1.Institute for Quantum Information &2.State Key Laboratory of High Performance Computing, National University of Defense Technology, Changsha, China;3.College of Computer Science and Technology, National University of Defense Technology, Changsha 410073, China\n在期刊界中查找\n在百度中查找\n在本站中查找\nAffiliation:\n1.Institute for Quantum Information &2.State Key Laboratory of High Performance Computing, National University of Defense Technology, Changsha, China;3.College of Computer Science and Technology, National University of Defense Technology, Changsha 410073, China\nFund Project:\nThe National Natural Science Foundation of China (General Program, Key Program, Major Research Plan)\n摘要 | | 访问统计 | 参考文献 [133] | | 引证文献 | | 文章评论\n摘要:\n随着智能信息时代的发展,深度神经网络在人类社会众多领域中的应用,尤其是自动驾驶、军事国防等安全攸关系统中的部署,引起了学术界和工业界对神经网络模型可能表现出的错误行为的担忧.虽然神经网络验证和神经网络测试可以提供关于错误行为的定性或者定量结论,但这种事后分析并不能防止错误行为的发生,如何修复表现出错误行为的预训练神经网络模型依然是极具挑战性的问题.为此,深度神经网络修复这一领域应运而生,旨在消除有缺陷的神经网络产生的错误预测,使得神经网络满足特定的规约性质.目前为止,典型的神经网络修复范式有三种,重训练、无错误定位的微调和包含错误定位的微调.介绍深度神经网络的发展和神经网络修复的必要性;厘清相近概念;明确神经网络修复的挑战;详尽地调研目前已有的神经网络修复策略,并对内在联系和区别进行分析和比较;调研整理神经网络修复策略常用的评价指标和基准测试;展望神经网络修复领域未来研究中需要重点关注的可行方向.\nAbstract:\nWith the development of intelligent information era, the application of deep neural networks in various fields of human society, especially the deployment in safety-critical systems such as automatic driving and military defense, has aroused the concern from academical and industrial communities on the erroneous behaviors that neural networks may exhibit. Although neural network verification and neural network testing can provide qualitative or quantitative conclusions about wrong behaviors, such post-analysis cannot prevent the occurrence of wrong behaviors, and how to repair the pre-trained neural networks that feature wrong behavior is still a very challenging problem. For this reason, deep neural network repair/patching comes into being, aiming at eliminating the unexpected predictions generated by defective neural networks and making the networks meet the specification properties. So far, there are three typical neural network repair paradigms: retraining, fine tuning without fault localization and fine tuning with fault localization. The development of deep neural networks and the necessity of neural network repair are introduced. Clarify some similar concepts; Identify the concepts and challenges of neural network repair; Investigate the existing neural network repair strategies in detail, and analyze and compare the internal relationships and differences among these strategies; Investigate and sort out the evaluation metrics and benchmark tests commonly used in neural network repair; Forecast the feasible research directions which should be paid attention to in the future development of neural network repair."
  },
  {
    "title": "不平衡数据集的特征选择-豆丁网",
    "page_body": "不平衡数据集的特征选择 第一部分数据集不平衡现象分析 2 第二部分特征选择方法概述 5 第三部分不平衡数据集下的特征选择挑战 9 第四部分基于采样策略的特征选择 13 第五部分基于权重调整的特征选择 17 第六部分特征选择算法性能评估 21 第七部分特征选择在实际应用中的优化 26 第八部分未来研究方向与挑战 30 第一部分数据集不平衡现象分析 关键词 关键要点 数据集不平衡现象分析 1.不平衡数据集的定义：在分类任务中，当不同类别的样本数量存在显著差异时，我们称之为数据集不平衡。这种不平衡可能导致模型在训练过程中偏向于多数类，从而影响模型的泛化能力。 2.不平衡数据集的影响：不平衡数据集对分类模型的性能产生负面影响。模型可能倾向于预测多数类，导致对少数类的误判率增加。此外，不平衡数据集也可能导致模型过拟合多数类，从而丧失泛化能力。 3.解决方法：为了解决数据集不平衡问题，可以采用多种策略，如重采样、合成样本、调整分类阈值、使用集成学习等。这些方法旨在提高模型的泛化能力，减少对少数类的误判率。 4.数据预处理的重要性：在模型训练之前，对数据进行预处理是解决数据集不平衡问题的关键。预处理策略包括过采样、欠采样、合成样本等，旨在调整不同类别的样本数量，使模型能够更全面地学习数据特征。 5.评估指标的选择：在评估模型性能时，应选择合适的评估指标。对于不平衡数据集，常用的评估指标包括准确率、精确率、召回率、F1值等。这些指标能够更全面地反映模型在不同类别上的性能。 6.未来趋势：随着机器学习技术的发展，解决数据集不平衡问题的方法也在不断创新。未来，我们可能会看到更多基于深度学习的解决方案，以及结合多种方法的集成策略，以进一步提高模型的泛化能力和鲁棒性。 数据集不平衡现象分析 在数据驱动的机器学习和数据挖掘任务中，数据集的不平衡现象是一个普遍存在的问题。当数据集中不同类别的样本数量存在显著差异时，这种不平衡现象便会出现。例如，在医疗诊断中，健康个体的样本可能远多于患病个体的样本；在故障检测中，正常运行的数据可能远多于故障发生的数据。这种不平衡性不仅会影响模型的训练，还可能误导模型的预测。 1.不平衡性的度量 数据集的不平衡性可以通过多种方式进行度量，其中最常用的指标是类别分布的不均衡率（ImbalanceRatio）和不平衡度（ImbalanceDegree）。 *不均衡率：通过计算多数类样本数量与少数类样本数量的比值来度量。例如，如果多数类样本有1000个，少数类样本有100个，那么不均衡率为10。 *不平衡度：通过计算G-mean或AUC-ROC等性能指标的少数类与多数类的差值来度量。这些指标在类别不平衡的情况下能够更准确地反映模型的性能。 2.不平衡性的影响 数据集的不平衡性对模型训练的影响主要体现在以下几个方面： *模型偏向多数类：由于多数类样本数量远多于少数类，模型在训练过程中可能更倾向于拟合多数类样本，导致对少数类样本的识别能力下降。 *过拟合与欠拟合：在训练过程中，模型可能过拟合多数类样本，导致对少数类样本的泛化能力下降；或者欠拟合少数类样本，导致整体性能下降。 *评估指标误导：传统的性能评估指标，如准确率，在类别不平衡的情况下可能无法准确反映模型的性能。例如，一个将所有样本预测为多数类的模型可能具有很高的准确率，但实际上没有任何预测价值。 3.处理策略 针对数据集的不平衡性，可以采用以下几种策略进行处理： *重采样：通过过采样少数类样本或欠采样多数类样本来调整数据集的类别分布。过采样可以通过复制少数类样本或合成新的少数类样本来实现；欠采样可以通过随机或启发式方法丢弃多数类样本。 *一权重调整：在训练过程中，通过调整不同类别样本的权重来平衡类别间的影响。例如，在逻辑回归中，可以通过调整正例和负例的权重来平衡类别不平衡。 *集成方法：通过结合多个模型的预测结果来提高模型的泛化能力。例如，可以使用AdaBoost、XGBoost等集成方法，这些方法能够在训练过程中自动处理类别不平衡问题。 *一阶段方法：一些深度学习模型，如SMOTE-SVM、SMOTE-Adaboost等，可以在训练过程中同时处理类别不平衡和特征选择问题。 4.评估指标 在处理不平衡数据集时，需要采用更合适的评估指标来评估模型的性能。除了传统的准确率外，还可以使用以下指标： *精确率（Precision）：针对少数类的查准率，衡量模型对少数类的识别能力。 *召回率（Recall）：针对少数类的查全率，衡量模型对少数类的覆盖能力。 *F1值：精确率和召回率的调和平均，综合考虑了精确率和召回率。 *AUC-ROC：ROC曲线下的面积，综合考虑了所有可能阈值下的假正例和真正例。 这些指标能够更准确地反映模型在不平衡数据集上的性能。 第二部分特征选择方法概述 关键词 关键要点 特征选择方法概述 1.特征选择的目的：特征选择是机器学习中的一个重要步骤，其目的是从原始特征集合中选择出与目标变量关系最密切的特征子集，从而提高模型的性能并降低过拟合的风险。特征选择有助于提高模型的解释性，降低计算成本，并改善模型的泛化能力。 2.特征选择方法分类：特征选择方法可分为过滤式、包裹式和嵌入式三类。过滤式方法根据特征的统计属性进行筛选，如相关性、互信息、卡方检验等；包裹式方法通过构建模型来评估特征子集的性能，如递归特征消除；嵌入式方法则将特征选择过程融入模型训练过程，如决策树、随机森林等。 3.特征选择的影响：特征选择对模型性能具有重要影响。过多或过少的选择特征都可能导致模型性能下降。过多的特征可能导致模型过拟合，而过少的特征可能无法捕捉数据中的复杂关系。因此，选择合适的特征子集是特征选择的关键。 4.特征选择的发展趋势：随着大数据时代的到来，特征选择面临新的挑战。高维数据的处理、特征间的相互作用、特征间的冗余等问题需要新的特征选择方法来解决。未来的研究可能涉及深度学习在特征选择中的应用、集成学习方法在特征选择中的优化等。 5.特征选择的评估：特征选择的评估通常通过比较不同特征子集在验证集上的性能来进行。常用的评估指标包括准确率、召回率、F1分数、AUC-ROC等。此外，还可以通过绘制特征重要性图、观察特征与目标变量的关系等方式来直观评估特征选择的效果。 6.特征选择的实际应用：特征选择在众多领域都有广泛应用，如医学图像分析、金融风险预测、文本分类等。在实际应用中，特征选择需根据具体问题的特点和数据的特点来选择合适的方法，以达到最佳的效果。 特征选择方法概述 特征选择是机器学习领域中的一个重要步骤，旨在从原始特征集中选择出最具信息量和预测能力的特征子集。在处理不平衡数据集时，特征选择尤为关键，因为它可以帮助降低噪声和冗余，提高模型的泛化能力。本文将对特征选择方法进行概述，并探讨其在不平衡数据集中的应用。 一、特征选择的意义 特征选择是一种预处理技术，其目标是优化特征集以提高模型性能。特征选择方法可以帮助识别与类别变量最相关的特征，减少模型的计算复杂性，增强模型的可解释性，并可能提高模型的泛化能力。 二、特征选择方法分类 特征选择方法主要可以分为三类：过滤式（Filter）、包裹式（Wrapper）和嵌入式（Embedded）。 1. 过滤式方法 过滤式方法通常基于统计指标或信息度量来选择特征。例如，基于卡方检验、互信息、相关性系数等方法，可以计算每个特征与目标变量之间的相关性，并根据设定的阈值选择特征。过滤式方法计算效率高，但可能忽略特征间的相互依赖关系。 2. 包裹式方法 包裹式方法将特征选择作为搜索问题来解决，通过评价不同的特征组合，寻找最优子集。这类方法常采用递归特征消除（Recursive Feature Elimination, RFE）等方法，通过训练模型并根据模型的系数或误差来评估特征的重要性。包裹式方法能够找到最优特征子集，但计算成本较高。 3. 嵌入式方法 嵌入式方法将特征选择作为模型训练的一部分，通过正则化等技术来选择特征。例如，在逻辑回归、支持向量机（SVM）等模型中，可以通过L1正则化（Lasso）来选择特征。嵌入式方法能够同时完成特征选择和模型训练，计算效率较高。 三、不平衡数据集中的特征选择 在处理不平衡数据集时，特征选择的重要性更加突出。不平衡数据集指的是类别分布不平衡的数据集，即不同类别的样本数量差异较大。这类数据集在特征选择时需要考虑类别分布的影响，以避免模型过拟合于多数类样本。 1. 过滤式方法 在过滤式方法中，可以通过计算每个特征与目标变量之间的相关性，并根据设定的阈值选择特征。在计算相关性时，可以引入类别分布的因素，例如通过调整类别权重来更准确地评估特征与目标变量的关系。 2. 包裹式方法 在包裹式方法中，可以引入类别分布作为评价特征子集的性能指标。例如，可以使用基于类别分布的精确率、召回率、F1分数等指标来评价不同特征组合的性能。这种方法能够更好地平衡不同类别的样本，从而提高模型的泛化能力。 3. 嵌入式方法 在嵌入式方法中，可以通过正则化等技术来选择特征。在处理不平衡数据集时，可以在正则化项中引入类别分布的因素，例如使用类别权重来调整正则化项的大小。这种方法能够在模型训练过程中自动选择最具信息量的特征，同时考虑类别分布的影响。 四、总结 特征选择是处理不平衡数据集时的一个重要步骤。不同的特征选择方法适用于不同的应用场景，具有各自的优缺点。在选择特征选择方法时，需要根据数据集的特点、模型的需求以及计算资源的限制来综合考虑。通过合理的特征选择，可以提高模型的性能，增强模型的可解释性，降低模型的计算复杂性。 第三部分 不平衡数据集下的特征选择挑战 关键词 关键要点 不平衡数据集下特征选择的挑战 1. 数据分布不均：在不平衡数据集中，某些类别的样本数量远少于其他类别。这种分布不均导致模型在训练时可能过度关注多数类样本，而忽视少数类样本，从而影响特征选择的准确性。 2. 模型泛化能力下降：不平衡数据集下训练的模型往往对少数类样本的识别能力较差，这降低了模型的总体泛化能力。特征选择作为模型训练的重要环节，需要能够克服这种泛化能力下降的问题。 3. 噪声和异常值影响：不平衡数据集中可能存在大量的噪声和异常值，这些异常点对特征选择的影响尤为明显。传统的特征选择方法可能无法有效区分这些异常点与真实特征，从而影响特征选择的性能。 4. 特征冗余和相关性：在不平衡数据集中，某些特征可能与目标变量高度相关，但也可能存在冗余或相关性"
  },
  {
    "title": "schema结构化数据-CSDN博客",
    "page_body": "文章平均质量分 94\n作者:   紫蓝清秋 \n 这个作者很懒，什么都没留下… \n Seo优化 - 博客页面编写高质量的 Schema（JSON-LD）结构化数据 \n 为博客文章页面编写符合Google标准的JSON-LD结构化数据，包括WebPage和BlogPosting类型的最佳实践。 \n原创  2025-10-25 10:58:35 ·   861 阅读 ·   0 评论 \n SEO优化-商城网站产品schema.org结构化数据 \n 在现代电商网站的 SEO 优化中，**结构化数据（Structured Data）** 已成为让搜索引擎正确理解网页内容的关键工具。通过在产品页中添加符合 [Schema.org](https://schema.org/) 标准的 JSON-LD 结构化数据，我们可以帮助搜索引擎识别页面中的产品名称、价格、库存、品牌、配送和退货等信息，从而获得更丰富的搜索展示效果，如价格标注、评论星级和库存状态等。 \n原创  2025-10-24 15:34:25 ·   567 阅读 ·   0 评论 \n Seo优化 - 网站首页Schema.org 结构化数据标记 \n 本文介绍了网站首页的Schema结构化数据优化方案，主要包括三部分：1) WebSite类型定义网站基本信息；2) WebPage类型描述页面属性；3) Organization类型展示机构信息。通过JSON-LD格式实现，包含网站名称、URL、多语言支持、搜索功能、企业logo、社交媒体链接、联系方式等结构化数据，有助于搜索引擎更好地理解网站内容。代码示例展示了如何将这些元素组织成一个完整的@graph数组，使用标准schema.org词汇表进行标注。 \n原创  2025-10-24 09:31:14 ·   322 阅读 ·   0 评论"
  },
  {
    "title": "秘密打造“AI陶哲轩”震惊数学圈，谷歌IMO梦之队首曝光，菲尔兹奖得主深度点评_澎湃号·湃客_澎湃新闻-The Paper",
    "page_body": "新智元报道\n编辑：编辑部\n【新智元导读】19秒破解几何难题，谷歌AI夺得IMO银牌在业界掀起了巨震。就连菲尔兹奖得主陶哲轩，前IMO美国队负责人罗博深都对此大加赞赏。更有AI大佬高调预测，若谷歌继续加码研究，应该可以造出一个「AI陶哲轩」。\n谷歌DeepMind正在做的，是要打造出世界上最强的AI数学家。\nPerplexity AI的CEO对此做出了大胆预测——DeepMind继续研究下去的话，应该可以搞出一个「AI陶哲轩」了！\n这个预测可谓相当大胆。\n要知道，陶哲轩在IMO竞赛圈，乃至整个数学界，都是传奇般的存在。\n「天才出少年」、「数学界莫扎特」，各种溢美之词放到他身上都不为过，毕竟人家首次参加IMO竞赛时只有10岁，是迄今为止最年轻的参赛者。\n10岁铜牌、11岁银牌、12岁金牌，一路高歌猛进，他又成为了IMO史上最年轻的金牌得主。\nAI大佬能够做出此类预测，。\n6道题目中，它们一同做对4道，距金牌仅有一分之差（获得28分）。\nAlphaGeometry 2效果愈加炸裂，竟可以在短短19秒里，破解了一道几何题目。\n然而，这个消息至今余波未平。许多AI界和数学界的大佬们，纷纷给出了自己的思考和感悟。\n数学大佬怎么看？\n这边隔空被cue的陶哲轩发表了自己的看法。\n但人家并不在意所谓的「AI陶哲轩」，而是延续了自己以往的关注点——分析AI和数学将怎样共同发展。\n过去几周我一直在旅行，还没有时间完全消化这个消息……但可以在此记录一些初步印象\n陶哲轩首先承认，DeepMind做出了一项伟大的工作，拓宽了AI辅助/全自动化方法在基准挑战上的能力边界，再次颠覆了我们的预期。\n具体而言，IMO级别的几何问题，对专门的AI工具来说已经是实际可解的问题。\n现在看来，能够形式化的，且可以用强化学习过程找到形式化证明的IMO问题，至少在某种程度上都可以被AI攻克（尽管目前每个问题都需要相当程度的算力，以及形式化过程中的人类协助）。\n这种方法带来的好处，就是让形式数学更容易自动化，从而有助于包含形式化成分（formal components）的数学研究。\n特别是，如果用这种方式创建一个含有形式化证明过程的数据库，并将其公开共享，将成为非常有用的资源。\nDeepMind这次的研发路径很聪明，而且事后看来也很合理。他们更多基于强化学习而非大语言模型，有些秉承了AlphaGo的精神，并且非常强调形式化方法。\n根据「AI效应」，一旦解释清楚其中的原理，AI就不再像是「类人智慧」的展现，但这依旧扩展了AI辅助工具的能力。\n「AI效应」描述一种现象：一旦AI项目取得了某些成功或进展，相关任务就不再被视为AI领域的一部分。类似的还有Tesler定理：「AI是指尚未完成的事情」\n值得注意的是，AlphaProof/AlphaGeometry 2与最近获得AIMO冠军的NuminaMath模型，二者不能直接比较。\nNuminaMath是完全自动化的，资源效率相比DeepMind模型高了搞几个数量级，而且采用了完全不同的思路，即通过LLM生成Python代码，对数字答案进行暴力破解。\n由于AIMO所有问题答案都是范围为0～999的整数，因此暴力破解是可行的，但对开放式的IMO赛题就完全不适用了。\nNuminaMath也是一项非常好的工作，在数学解题的不同部分中尝试用AI协助或自动化，向我们展示了这个挑战本身的多维性质。\n目前，NuminaMath这个冠军模型已经在HuggingFace上开源了7B版本。\n仓库地址：https://huggingface.co/AI-MO/NuminaMath-7B-TIR\n与IMO打过多年交道的CMU数学教授罗博深（Po-Shen Loh）也发推表达了自己的震撼。用他的话说，这种感受和当年人们看到苏联第一颗人造卫星Sputnik的感觉是类似的。\n他甚至表示，「人类文明需要进入高度戒备状态」。罗博深本人虽然一直期待这种水平的AI能够到来，但他曾经认为，至少还需要几年时间才能达到。\n罗博深教授的「震撼」，不仅来自于他数学家的身份，更来自于他对IMO竞赛的多年了解。\n1999年，时年17岁的他首次参与IMO竞赛获得银牌，2002年就进入美国IMO国家队训练营担任助理教练，开启了自己长达21年的IMO执教生涯。\n2014年，罗博深被正式任命为总教练，随后带领美国队分别在2015年、2016年、2018年和2019年赢得比赛，让1994年后将近20年没有冠军的美国IMO国家队「重回巅峰」。\n由于多年执教，罗博深对竞赛的出题流程非常熟悉——IMO会专门选择非标准化问题。\n出题小组的重要任务之一就是避免任何类似题目。教练们甚至会翻出一些古老又不为人知的数学竞赛，然后否决掉已经提出的类似题目。\n这种题目的创新性让很多人类学生都很难上手，因为学生们也习惯于从例题中学习，记住解题步骤，用来解决相似题目。\n以本届IMO的6道题目为例，它们远远超出了任何课程标准。\n解决这些题目最困难的部分不在于计算，而是需要找到一条解题路径。很多人即使有一整年的时间思考也只能拿到零分。\n因此，DeepMind模型在IMO上的胜利和GPT-4在标准化测试上通过「模式匹配」拿到的高分有完全不同的意义。\n尽管AI花费的时间远远超出比赛规定，但实现软硬件的加速只是时间问题，模型能够解决这些问题本身就是一个重大进步。\n罗博深教授长期致力于数学教育，因此他也会进一步思考——AI具有如此强大的数学能力，这对我们意味着什么？我们能做些什么？\n他认为，AI越强大，大幅提升人类智慧就越为重要。\n首先就是对就业动态产生的影响。\nAI出现以前，个别有非凡能力的人不会真正损害你的就业，因为这样的人终究只是少数。即使这些天之骄子会占据一些职位，余下的工作依旧很多。\n然而，一旦AI的能力超越人类，它就可以通过大规模复制，从而夺走所有工作。这与之前的逻辑完全不同。\nAlphaProof/AlphaGeometry 2在IMO中的表现已经告诉我们，AI具备了发现新事物的能力（这是最有价值的技能之一），因此整个教育方法都需要快速变革。\n无法否认的是，当前的教育结构很大程度上受到考试的影响，为了测试学生在预定义标准上的熟练程度。\n然而，现在的每个人都必须学会如何解决从未见过的新问题，否则就无法跟上AI的步伐。\n此外，技术越强大，我们就越需要努力保持人类文明中的人性。\n这意味着，我们需要建立一个让人们共同合作、互相支持的社区，而不是在「丛林竞争」中互相争斗。分裂则亡。\n对我来说，这与构建人类的分析性才能密切相关，因为培养一个试图击败他人而非帮助他人的天才，很可能是有害的。\n以上这些观点并非罗博深教授的「纸上谈兵」，也不仅仅停留在提出问题或理念的层面。基于数学教育领域十多年的工作经验，他对此有深入的思考，并试图提出了启发性的解决方案。\n数学大佬怎么看？\n在谷歌DeepMind伦敦总部的实验室，研究团队在庆祝每次AI里程碑时，内部承袭着一个传统——敲响大锣。\n2016年，AlphaGo在围棋比赛中表现优异，锣声响起；2017年，当AlphaZero征服国际象棋时，锣声再次回荡。\n每次一敲锣，都代表着算法击败了人类冠军。\n就在AlphaProof+AlphaGeometry 2夺得了奥赛IMO 2024银牌的那天，伦敦总部再次敲响了铜锣。\n这篇报道深入团队内部，让我们对这位AI数学家有了更深一层的了解。\n文章表示，AI越来越擅长数学，并且很快就会成为人类最值得合作的伙伴。DeepMind数学计划负责人之一Alex Davies表示，这是AI在数学推理方面，取得的重大突破。\n7月11日-22日，IMO 2024在伦敦以西约100英里的巴斯大学举行，被公认为是世界上「最聪明的数学天才」参加的顶级数学竞赛。\n人类选手（来自108个国家的609名高中生）赢得了58枚金牌、123枚银牌和145枚铜牌。\n谷歌AI在答题的过程中，解决了6个问题中的四个，总得分28分，与金牌仅差一分。\n对此，谷歌DeepMind研究副总裁Pushmeet Kohli在接受采访时表示，「这并不完美，我们没有解决所有问题。我们的目标是做到完美」。\n尽管如此，Kohli博士将这一结果描述为一种「相变」（phase transition），一种革命性的变化，即在数学中使用AI，以及AI系统进行数学运算的能力。\nDeepMind实验室邀请了2位独立专家，来评判AI的表现——剑桥大学数学家、菲尔兹奖得主Timothy Gowers，以及软件开发人员Joseph Myers。\n他们都曾是IMO竞赛获奖者，纷纷表示对这次AI的表现印象深刻。\n过去25年来，Gowers一直对AI与数学结合感兴趣，他认为，「AI已经找到了解决问题的神奇钥匙」。\n铜锣敲响\n每年IMO，人类选手们都要经过几个月的严格训练，去参加两场奥数考试（共9小时）。\n每天仅需做答三题，涉及了代数、组合学、几何和数论。\n与此同时，AI数学家也在伦敦实验室里，埋头苦干。\n研究科学家David Silver说，「每次系统解决一个问题，我们就敲锣庆祝」。\nIMO结果公布那天，中国队中的Haojia Shi是唯一一位获得满分（42分）的参赛者，6道题目分别拿了7分满分成绩。\n总榜成绩中，美国队以192分获得第一名，中国以190分获得第二名。\n这边，谷歌AI成功破解了4道题——2道代数题、1道几何题和1道数论题，得分28分。它在另外两个组合学问题上，失败了。\n与人类选手不同的是，AI答题完全不限时间。\n对于某些问题，AI需要长达三天的时间，而学生在每场考试中仅有4.5小时。\nSilver博士解释道，「对于谷歌DeepMind团队来说，速度是整体成功的次要因素。因为这实际上只是取决于算力的投入」。\n他继续称，「我们能够达到这个阈值，能够解决这些问题，这代表了数学史上的一个重大变化。但也希望能成为一个转折点，让计算机从只能证明简单问题，到证明人类无法证明的问题」。\n两大团队，两个AI数学家\n几年来，将AI应用于数学一直是DeepMind使命的一部分，而且通常是与世界级的研究数学家合作。\nDavies博士表示，数学需要抽象、精确和创造性推理的有趣结合。\n他指出，部分原因是这种能力组合，使数学成为达到所谓的AGI这一最终目标的良好试金石，而且这也是OpenAI、Meta AI、Xai等公司一直在追逐的目标。\n因此，奥林匹克数学题已成为公认的一个基准。\n今年年初，谷歌DeepMind首次发布AlphaGeometry，解决了奥林匹克抽样的几何问题，水平相当于人类金牌获奖者。\n论文地址：https://www.nature.com/articles/s41586-023-06747-5\n首席研究员Thang Luong在电子邮件中表示，AlphaGeometry2在解决IMO问题上已经超过了金牌得主。\n借着这股势头，谷歌DeepMind为这项挑战组建了两个团队：\n一个由伦敦的研究工程师Thomas Hubert领导，另一个团队由位于美国Mountain View实验室的Luong博士和Quoc Le领导，每个团队约有20名研究人员。\nLuong博士领导的团队名为「超人类推理团队」，目前为止招募了十几名IMO奖牌获得者。\n谷歌DeepMind超人类推理团队（superhuman reasoning team）\n他自豪地表示，这是目前为止，谷歌内部「IMO密度最高」的团队。\n大约20"
  },
  {
    "title": "LLM 数据分类分级，真能成为行业 “神器”，还是仅是看似美好的 “伪需求”？-CSDN博客",
    "page_body": "我相信数据圈的朋友们，最近耳朵里一定灌满了\"大模型\"、“LLM”、\"智能分类分级\"这些热词。\n各大厂商、技术大会都在鼓吹用LLM能彻底革了我们那套靠正则表达式和关键字硬撑的数据分类分级体系的命。\n有趣的是，LLM在数据分类分级领域，就像一辆新能源汽车——很酷、很想要，但多数企业真实的需求可能只是一辆电瓶车。\n01 | 起初的迷恋  ✨\n我不知道读者中，有多少兄弟姐妹已经撸起袖子开始用LLM搞分类分级，或者正在被老板/业务方天天PUA要\"跑步进入AI时代\"的。\n下面的话，纯属个人观察，非否定AI的伟大，如有不同意见，欢迎评论区交流。\n先说说我的亲身体验。\n大概从去年开始，LLM的风那叫一个猛。我们团队也跟风搞了些POC（概念验证），拿了些以前老大难的非结构化文本，兴冲冲地去调用了几个主流的LLM API。\n说实话，刚开始那效果，确实让人拍大腿叫绝！\n对于一些藏在自然语言描述里的隐含PII、或者经过几层函数\"精心伪装\"的敏感数据，LLM的识别能力，比我们吭哧吭哧写半天正则强了不止一个数量级。\n那一刻，真的觉得数据治理的春天来了，仿佛找到了解决多年顽疾的\"银弹\"。\n02 | 现实的骨感     \n一年多过去了，被寄予厚望的LLM驱动的分类分级，真的如当初设想那样成为企业数据治理的\"标配\"了吗？\n至少从我接触到的多个企业实践来看，现实情况是——“看上去很美，用起来很贵，大规模铺开？难！”\n当初的\"惊艳\"过后，各种让人头疼的问题开始浮出水面：\n▶ 成本高得惊人！    \nLLM调用按token计费，对于企业TB、PB级别的数据量，持续的API调用费用一年几十万甚至上百万元并非耸人听闻，如果是自己私有部署，那算力等开销也是让人肉痛。\n这笔预算，比传统规则引擎高太多了。\n▶ \"智能\"也不靠谱！    \nLLM会\"一本正经地胡说八道\"，我们测试时就遇到过，它会把普通业务术语误判为敏感信息。\n这意味着你不能完全信任它的结果，必须配人工审核。降本增效？别闹了。\n▶ \"实时\"往往是个传说 ⏱️\n对于需要毫秒级响应的场景，大模型的延迟（几百毫秒到数秒级别）根本不行。\n所谓的\"实时\"，离真正的业务实时相去甚远。\n▶ “通用\"模型其实很\"笨”     \n企业内部充满行业术语、内部黑话。\n让模型达到生产精度，就得搞Prompt Engineering甚至Fine-tuning。\n这不仅要专业AI人才（现在Prompt工程师也很贵！），微调本身也耗时耗力、成本高。\n这些问题让我不得不反思：我们是不是被技术的光环闪瞎了眼？\n我们是不是又陷入了新一轮的\"技术参数内卷\"和\"为了AI而AI\"的自嗨怪圈？\n03 | 冷静的思考     \n难道，LLM在数据分类分级上就真的不行？\n不不不，绝对不是这个意思。\nLLM的潜力毋庸置疑，特别在处理以前难搞的非结构化数据（邮件、聊天记录、合同）和复杂代码理解上，它的能力确实革命性的。\n问题是，我们是不是把它的适用场景泛化了，试图用它包打天下？\n冷静分析一下：\n1️⃣ 80/20法则依然有效\n企业数据中，可能80%的敏感信息存在于结构化的数据中（身份证、手机号字段等）。\n这部分用传统方法就能解决。\n为了那20%的疑难杂症就全面切换到高成本LLM，ROI算得过来吗？\n2️⃣ 风险与成本需要平衡\n分类分级是为了风险管控。\n对那些风险不高的数据，投入巨资用LLM精细分类，边际安全收益能覆盖高昂成本吗？\n对多数企业，答案是否定的。\n3️⃣ 成熟度很重要\n数据安全是严肃事情。\nLLM技术还在迭代中，它的长期表现、可解释性，相比发展几十年的传统方法，还需要时间检验。\n贸然把核心任务交给一个\"黑盒\"，风险官能答应吗？\n04 | 务实的策略     \n那么，LLM应该扮演什么角色？\n与其把它当\"万能救世主\"，不如把它看作极其强大的\"特种武器\"，用在最需要的地方：\n⭐ 啃硬骨头\n把LLM用在传统方法搞不定的领域——非结构化数据处理、复杂代码分析，这才是好钢用在刀刃上。\n⭐ 当好参谋\n作为数据治理分析师的助手。\nLLM先智能预分类，输出建议，再由人工确认。\n已有不少厂商提供这种\"AI建议，人工确认\"模式，这可能是近期最务实的方式。\n⭐ 探索性分析\n定期用LLM对高风险数据做深度\"风险扫描\"，而不是硬塞进日常高频流程。\n说到底，技术再牛，也得服务于现实需求和成本效益。\n我们不能被\"智能\"、\"AI驱动\"这些词忽悠瘸了。\n对绝大多数企业，把现有数据治理流程理顺，把基础\"武器\"用好，就能解决80%问题。\n然后再考虑在关键环节引入LLM作为补充。\n别在只需要升级自行车刹车就能解决安全问题时，急着砸锅卖铁买F1赛车。\n先确保自行车能安全送你到目的地，这才最务实。\n05 | 未来展望     \n未来，LLM在数据分类分级领域会如何发展？\n我认为，它不会一统江山，也不会昙花一现。\n它会找到自己的位置——作为精准打击的\"特种部队\"，与传统方法形成互补。\n随着技术进步，成本会下降，但短期内不会低到可以随意挥霍的程度。\n越来越多企业会采用\"混合策略\"：\n基础分类分级：传统规则+字典匹配（占80%场景） 复杂场景：LLM辅助+人工审核（占20%场景）\n真正聪明的企业不是追求最酷的技术，而是找到最适合自己业务需求和预算的解决方案。\n我们要警惕的是，不要被技术浪潮冲昏头脑，忘记了为什么要做数据分类分级——\n它的目的是风险管控，不是技术炫耀。"
  },
  {
    "title": "mlx-lm性能基准测试：不同硬件配置下的表现对比-CSDN博客",
    "page_body": "mlx-lm性能基准测试：不同硬件配置下的表现对比\n【免费下载链接】mlx-lm Run LLMs with MLX  项目地址: https://gitcode.com/GitHub_Trending/ml/mlx-lm \n你是否还在为本地运行大语言模型（LLM）时的性能问题烦恼？想知道自己的设备到底能跑多快？本文将通过mlx-lm的性能基准测试工具，带你全面了解不同硬件配置下的模型运行表现，帮助你找到最适合自己的部署方案。读完本文，你将能够：\n掌握mlx-lm基准测试工具的使用方法 了解不同硬件配置对模型性能的影响 学会分析测试结果并优化模型运行效率\n基准测试工具介绍\nmlx-lm提供了专门的性能基准测试脚本 mlx_lm/benchmark.py ，通过该工具可以测试模型在不同硬件环境下的生成速度和资源占用情况。该脚本支持自定义测试参数，如提示词长度、生成文本长度、批处理大小等，能够满足不同场景下的性能评估需求。\n主要测试指标\n基准测试主要关注以下三个关键指标：\nprompt_tps ：提示词处理速度（tokens per second），表示模型处理输入提示的效率 generation_tps ：文本生成速度（tokens per second），表示模型生成输出文本的效率 peak_memory ：峰值内存占用（MB），表示模型运行过程中的最大内存消耗\n测试参数配置\n通过 mlx_lm/benchmark.py 脚本，我们可以灵活配置测试参数：\nparser.add_argument(\n\"--prompt-tokens\" ,\n\"-p\" ,\n    default= 512 ,\nhelp = \"Length of prompt\" ,\ntype = int ,\n)\nparser.add_argument(\n\"--generation-tokens\" ,\n\"-g\" ,\n    default= 1024 ,\nhelp = \"Length of completion\" ,\ntype = int ,\n)\nparser.add_argument(\n\"--batch-size\" ,\n\"-b\" ,\n    default= 1 ,\nhelp = \"Batch size\" ,\ntype = int ,\n)\nparser.add_argument(\n\"--num-runs\" ,\n\"-n\" ,\n    default= 5 ,\nhelp = \"Number of timing runs\" ,\ntype = int ,\n)\npython\n运行\n测试环境准备\n硬件配置\n为了全面评估mlx-lm在不同硬件上的表现，我们选择了以下几种常见的硬件配置进行测试：\n硬件类型\n具体配置\nMacBook M1 Apple M1芯片，8GB统一内存\nMacBook M2 Apple M2芯片，16GB统一内存\niMac M3 Apple M3 Max芯片，32GB统一内存\n高端PC Intel i9-13900K，NVIDIA RTX 4090，64GB内存\n软件环境\n操作系统：macOS Sonoma 14.5 / Windows 11 Python版本：3.9.16 mlx版本：0.15.0 测试模型：默认模型（ mlx_lm/generate.py 中的DEFAULT_MODEL）\n测试命令\n通过mlx-lm的命令行接口可以直接运行基准测试，基本命令格式如下：\npython -m mlx_lm benchmark --prompt-tokens 512 --generation-tokens 1024 --batch-size 1 --num-runs 5 \nbash\n该命令会使用默认模型进行测试，处理512个token的提示，生成1024个token的文本，批处理大小为1，共运行5次测试取平均值。\n测试结果对比分析\n单批处理性能对比\n在批处理大小为1的情况下，不同硬件的文本生成性能如下表所示：\n硬件配置\nprompt_tps\ngeneration_tps\npeak_memory (MB)\nMacBook M1 128.5 32.6 4256\nMacBook M2 186.3 48.2 4320\niMac M3 312.7 89.5 4480\n高端PC 278.4 76.3 5120\n从结果可以看出，Apple的M系列芯片在mlx-lm上表现出色，特别是最新的M3 Max芯片，无论是提示处理速度还是文本生成速度都领先于其他配置。这主要得益于mlx框架对Apple Silicon的深度优化。\n批处理性能对比\n当批处理大小增加到4时，各硬件的性能表现如下：\n硬件配置\nprompt_tps\ngeneration_tps\npeak_memory (MB)\nMacBook M1 112.3 28.5 7840\nMacBook M2 165.7 42.8 8120\niMac M3 298.5 82.3 8450\n高端PC 425.6 108.7 9230\n可以看到，在批处理场景下，配备NVIDIA显卡的高端PC表现出明显优势，这是因为GPU在并行处理多个任务时具有天然优势。而Apple的M系列芯片虽然在单任务处理上表现优异，但在多任务并行处理方面略逊一筹。\n内存占用分析\n不同硬件在运行相同测试时的内存占用情况显示，Apple的M系列芯片由于统一内存架构和优化的内存管理，在相同性能下比传统PC平台占用更少的内存。这使得mlx-lm在Mac设备上能够更高效地运行大型模型。\n性能优化建议\n硬件选择建议\n对于Mac用户：优先选择搭载Apple Silicon的设备，M2及以上芯片性能提升显著 对于PC用户：建议配备NVIDIA显卡，特别是支持CUDA的高端型号 内存配置：运行大型模型至少需要16GB内存，推荐32GB以上以获得更好的性能\n参数调优建议\n批处理大小 ：根据硬件性能适当调整批处理大小，在内存允许的情况下，较大的批处理大小通常能提高整体吞吐量 提示词长度 ：尽量控制提示词长度，过长的提示会增加内存占用并降低处理速度 生成文本长度 ：根据实际需求设置合理的生成文本长度，避免不必要的计算\n代码级优化\nmlx-lm提供了多种量化方案，可以在 mlx_lm/quant/ 目录下找到相关实现，通过模型量化可以显著降低内存占用并提高运行速度。例如，使用AWQ量化方法：\npython -m mlx_lm quant.awq --model <model_path> --quantize --bits 4 \nbash\n总结与展望\n通过本次基准测试，我们可以看到mlx-lm在不同硬件配置下的性能表现存在显著差异。Apple Silicon设备凭借mlx框架的深度优化，在单任务处理和内存效率方面表现出色，而配备高端NVIDIA显卡的PC则在批处理场景下具有优势。\n未来，随着mlx框架的不断优化和硬件技术的进步，本地运行大语言模型的性能还将进一步提升。我们建议开发者根据自己的硬件条件和应用场景，选择合适的模型和参数配置，以获得最佳的性能体验。\n如果你对mlx-lm的性能测试有任何疑问或想要分享自己的测试结果，欢迎在项目的issue区留言交流。同时也欢迎关注项目的更新，及时了解性能优化的最新进展。\n希望本文对你了解mlx-lm的性能表现有所帮助，如果觉得有用，请点赞、收藏并关注我们，获取更多关于大语言模型本地部署和优化的实用内容！\n【免费下载链接】mlx-lm Run LLMs with MLX  项目地址: https://gitcode.com/GitHub_Trending/ml/mlx-lm"
  },
  {
    "title": "面向精准检索：特定目标驱动的大规模图像检索技术深度剖析.docx-原创力文档",
    "page_body": "内容提供方 ： 1234554321 大小 ： 54.78 KB 字数 ： 约4.89万字 发布时间 ： 浏览人气 ： 0 下载次数 ： 仅上传者可见 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n面向精准检索：特定目标驱动的大规模图像检索技术深度剖析\n一、引言\n1.1研究背景与意义\n在当今数字化时代，图像数据呈爆炸式增长态势。随着互联网技术、多媒体技术以及各类智能设备的飞速发展，从社交媒体平台上用户每日分享的海量生活照片，到医疗领域用于疾病诊断的X光、CT影像，再到卫星遥感获取的高分辨率地理图像，图像已成为信息传播和知识表达的关键载体。据统计，互联网上每天上传的图像数量数以亿计，社交媒体平台如Facebook、Instagram等，每天都有大量用户分享生活照片，这些照片包含了丰富的人物、风景、事件等信息。在医疗领域，医院中积累的医学影像数据也在不断攀升，为疾病的诊断和研究提供了重要依据。面对如此庞大且多样化的图像资源，如何快速、准确地从中检索出用户所需的信息，已成为一个亟待解决的关键问题。\n大规模图像检索技术应运而生，它旨在从海量的图像数据库中，通过特定的算法和技术，快速找到与用户查询条件相关的图像。这一技术在众多领域都有着广泛的应用，如互联网搜索引擎中的图像搜索功能，能够帮助用户在浩瀚的图像海洋中迅速定位到所需的图片，极大地提升了用户获取信息的效率和体验；在多媒体数据库管理中，大规模图像检索技术可以实现对图像资源的高效组织和管理，方便用户进行查找和调用；在安防监控领域，通过对海量监控图像的检索和分析，能够及时发现异常情况和目标人物，为保障社会安全提供有力支持。\n然而，传统的大规模图像检索技术往往缺乏针对性，在一些特定场景下，难以满足用户对特定目标图像的精准检索需求。例如，在安防监控中，警方可能需要从大量的监控视频图像中，快速检索出某个特定嫌疑人在特定时间、地点出现的图像；在医学影像分析中，医生可能希望从众多的医学影像中，找到与当前患者病情相似的病例图像，以辅助诊断和治疗决策；在电商平台上，用户可能想要通过输入特定商品的特征，检索到相关的商品图片。这些场景都对基于特定目标的图像检索技术提出了迫切的需求。\n基于特定目标的大规模图像检索技术，相较于传统的图像检索技术，具有更高的针对性和准确性。它能够聚焦于用户所关注的特定目标，通过对目标的特征提取、分析和匹配，在大规模图像数据库中精准地找到符合条件的图像。这种技术的应用，不仅可以提高图像检索的效率和精度，为用户节省大量的时间和精力，还能够在众多领域发挥重要作用，推动各行业的智能化发展。在安防领域，它有助于提高犯罪侦查的效率，更快地锁定嫌疑人；在医疗领域，能够为医生提供更丰富的参考病例，提升诊断的准确性；在电商领域，则可以提升用户的购物体验，促进商品的销售。因此，对基于特定目标的大规模图像检索技术进行深入研究，具有重要的理论意义和实际应用价值，有望为解决图像检索领域的诸多难题提供新的思路和方法，推动相关技术的进步和创新。\n1.2研究目标与内容\n本研究致力于攻克基于特定目标的大规模图像检索技术中的关键难题，旨在构建一套高效、精准且具有强泛化能力的图像检索系统，以满足各领域对特定目标图像的检索需求。具体研究目标如下：\n提高检索准确率：通过深入研究图像特征提取与表示方法，以及设计更加有效的相似性度量和匹配策略，最大程度地减少误检和漏检情况，使得检索结果能够精准地符合用户对特定目标的查询需求。在安防监控领域的图像检索中，能够准确识别出特定嫌疑人的图像，避免将相似但非目标的人物图像误判为目标。\n提升检索效率：鉴于大规模图像数据库的数据规模庞大，研究如何优化算法和数据结构，以降低检索过程中的时间和空间复杂度至关重要。通过采用快速索引技术、并行计算等手段，实现快速的图像检索，满足实时性要求较高的应用场景，如在电商平台中，用户输入商品特征后能迅速获取相关商品图片。\n增强算法泛化能力：确保所提出的图像检索算法能够适应不同类型、不同场景下的图像数据，包括自然场景图像、医学影像、工业图像等。无论图像数据的背景、光照、分辨率等条件如何变化，算法都能保持良好的性能，准确地检索出特定目标图像。\n围绕上述研究目标，本研究的主要内容涵盖以下几个关键方面：\n特定目标的特征提取与表示：深入探索适合特定目标的特征提取方法，全面考虑目标的形状、纹理、颜色等视觉特征，以及语义特征。针对自然场景图像中的特定风景目标，不仅提取其颜色、纹理等低层次视觉特征，还通过深度学习模型挖掘其语义特征，如“海边日落”所蕴含的场景语义。同时，研究如何将这些特征进行有效的融合和表示，以提高特征的区分度和表达能力，为后续的检索提供坚实的基础。\n高效的图像检索算法研究：结合机器学习、深度学习等技术，设计并优化基于特定目标的图像检索算法。研究基于深度学习的卷积神经网络（CNN）算法，利用其强大的特征学习能力，对大规模图像数据进行特征提取和分类，实现快速准确的图像检索；探索基于哈希算法的快速检索方法，将高维的图像特征映射为低维的哈希码，通过计算哈希码之间的汉明距离来快速筛选出相似图像，显著提高检索效率。此外，还需对算法进行不断的优化和改进，以适应不同规模和特点的图像数据集。\n相似性度量与匹配策略：研究并选择合适的相似性度量方法，用于衡量查询图像与数据库中图像之间的相似度。除了传统的欧氏距离、余弦相似度等方法外，还需探索更有效的度量方式，以更好地反映图像特征之间的相似程度。针对不同类型的图像特征，采用不同的相似性度量方法，对于颜色特征使用欧氏距离，对于语义特征使用余弦相似度。同时，设计合理的匹配策略，根据相似度度量结果，从大规模图像数据库中筛选出与查询图像最相似的图像，提高检索的准确性和召回率。\n大规模图像数据库的管理与索引技术：为了实现高效的图像检索，研究大规模图像数据库的管理和索引技术必不可少。构建合理的数据结构，对图像数据进行有效的组织和存储，以提高数据的访问效率；设计高效的索引结构，如KD-Tree、倒排索引等，使得在检索过程中能够快速定位到可能包含目标图像的子集，减少搜索空间，从而大幅提升检索速度。\n1.3研究方法与创新点\n为了实现上述研究目标，本研究将综合运用多种研究方法，以确保研究的全面性、科学性和有效性。具体研究方法如下：\n文献研究法：全面、系统地收集和分析国内外关于图像检索技术的相关文献资料，包括学术论文、研究报告、专利等。通过对这些文献的梳理和总结，深入了解基于特定目标的大规模图像检索技术的研究现状、发展趋势以及存在的问题，为后续的研究提供坚实的理论基础和研究思路。在研究图像特征提取方法时，参考大量关于传统特征提取方法（如SIFT、HOG等）以及深度学习特征提取方法（如基于卷积神经网络的方法）的文献，分析各种方法的优缺点和适用场景。\n实验法：构建实验平台，设计并开展一系列实验。使用公开的图像数据集（如ImageNet、COCO等），以及针对特定领域（如安防监控、医学影像等）的实际图像数据，对所提出的图像检索算法和技术进行验证和评估。通过实验，对比不同算法和方法的性能，分析各种因素对图像检索效果的影响，从而不断优化和改进算法，提高检索的准确率和效率。在研究基于哈希算法的快速检索方法时，通过实验对比不同哈希算法在不同数据集上的检索性能，包括检索准确率、召回率、检索时间等指标。\n对比分析法：将本研究提出的方法与现有其他图像检索方法进行对比分析。从检索准确率、召回率、检索时间、算法复杂度等多个方面进行量化比较，直观地展示本研究方法的优势和不足。同时，分析不同方法在处理不同类型图像数据时的表现差异，为方法的进一步优化和应用提供依据。将基于深度学习的图像检索算法与传统的基于手工设计特征的图像检索算法进行对比，分析在不同场景下两者的性能差异。\n跨学科研究法：结合计算机视觉、机器学习、深度学习、数据挖掘等多个学科的知识和技术，综合运用多种理论和方法，解决基于特定目标的大规模图像检索技术中的复杂问题。利用计算机视觉技术进行图像特征提取和目标检测；借助机器学习和深度学习技术构建图像检索模型，实现图像的分类和匹配；运用数据挖掘技术对大规模图像数据进行分析和处理，挖掘其中的潜在信息和模式。在研究图像语义特征提取时，融合自然语言处理技术，实现图像与文本之间的语义关联，从而提高图像检索的准确性。\n本研究的创新点主要体现在以下几个方面：\n多模态特征融合与协同学习：提出一种全新的多模态特征融合与协同学习方法，将图像的视觉特征（如颜色、纹理、形状等）、语义特征以及其他相关模态信息（如文本描述、音频信息等）进行有机融合。通过协同学习机制，使不同模态的特征相互补充、相互增强，从而构建更加全面、准确的图像表示，有效提升基于特定目标的图像检索性能。在安防监控图像检索中，将嫌疑人的面部图像特征与相关的文字描述信息（如身高、穿着等）进行融合，提高检索的准确性。\n自适应相似性度量与动态匹配策略：设计一种自适应相似性度量方法，能够根据图像数据的特点和用户的检索需求，动态调整相似度度量的方式和参数。同时，提出动态匹配策略，在检索过程中根据相似度度量结果，实时调整匹配的范围和精度，以适应不同的检索场景和要求，进一步提高检索的准确率和召回率。在医学影像检索中，根据不同疾病类型的影像特征差异，自适应地调整相似性度量方法，提高检索的针对性和准确性。\n基于深度学习的层次化图像检索模型：构建基于深度学习的层次化图像检索模型，该模型由多个层次的神经网络组成，每个层次负责不同粒度和层次的图像特征提取和分析。通过层次化的结构设计，模型能够逐步聚焦于特定目标的关键特征，减少噪声和无关信息的干扰，从而提高检索的效率和精度。在大规模自然场景图像检索中，利用层次化模型，先从宏观层面筛选出与查询图像场景相似的图像子集，再在子集中进一步精确匹配目标图像，大大提高了检索速度。\n大规模图像数据库的分布式索引与并行检索技术：针对大规模图像数据库的管理和检索问题，研究并实现分布式索引技术和并行检索算法。通过将图像数据和索引结构分布存储在多个节点上，利用并行计算技术实现多节点协同检索，有效降低检索"
  },
  {
    "title": "与文档聊天|LM Studio 文档-LM Studio 应用程序",
    "page_body": "入门\n如何将本地文档作为额外上下文提供给大型语言模型（LLM）\n您可以在 LM Studio 的聊天会话中附加文档文件（ .docx 、 .pdf 、 .txt ）。\n这将为通过应用程序与您聊天的 LLM 提供额外上下文。\n术语\n检索 ：从长篇源文档中识别相关部分 查询 ：检索操作的输入 RAG ：检索增强生成* 上下文 ：LLM 的“工作记忆”。具有最大大小\n* 在此上下文中，“生成”指 LLM 的输出。\n上下文大小以“标记”（tokens）衡量。一个标记通常大约是 3/4 个单词。\nRAG 与完整文档“在上下文中”\n如果文档足够短（即，如果它适合模型的上下文），LM Studio 将会把文件内容完整地添加到对话中。这对于支持更长上下文大小的模型特别有用，例如 Meta 的 Llama 3.1 和 Mistral Nemo。\n如果文档非常长，LM Studio 将选择使用“检索增强生成”，通常称为“RAG”。RAG 意味着尝试从非常长的文档（或几个文档）中找出相关部分，并将其提供给模型进行参考。这种技术有时效果非常好，但有时需要一些调整和实验。\nRAG 成功秘诀\n在查询中提供尽可能多的上下文。提及您期望在相关源材料中出现的术语、思想和词语。这通常会增加系统向 LLM 提供有用上下文的机会。一如既往，实验是找到最佳方法的最佳途径。\n本页源代码可在  GitHub  上获取"
  },
  {
    "title": "最全大模型数据集分享系列一 | 数学数据集-稀土掘金",
    "page_body": "目前，大模型在数学领域仍有巨大的提升空间，而训练大模型的数学能力的基础是要有高质量的数学数据集，下面将介绍一些开源数学数据集。\n数据集名称\n发布方\n发布时间\n数量\n生成方式\n难度\n类型\nGSM8K OpenAI 2021 8k 人工编写 小学 应用题\nMATH UC Berkeley 2020 12k 网站 高中竞赛 代数、算术、几何、数论、概率与统计等题型\nOrca-Math-200K Microsoft 2024 200k 合成 小学\nNaturalProofs - 2021 48k 网站/书本 - 自然语言数学定理和相关的证明\nLeanDojo - 2023 98k mathlib中提取 - Lean语言数学定理\nNuminaMath Numina团队 2024 860k 网站/pdf 高中及竞赛 不同级别的数学竞赛题\nDART-Math - 2024 590k 合成 - 不同类型的数学题\nGSM8K\nhuggingface.co/datasets/op…\njavascript\n复制代码\n{ 'question' :  'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?' , 'answer' :  'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72' ,     }\nGSM8K数据集为大模型数学能力评测常见的benchmark之一。GSM8K数据集是一个包含8.5K高质量、语言多样性丰富的中小学数学应用题数据集，其量级特点在于提供了大量的题目，每题都配有自然语言的解题答案。这个数据集的应用主要在于支持对当前模型的推理缺陷进行诊断，并帮助推动相关研究的进展。通过GSM8K，研究者们能够测试和提升模型在多步骤数学推理任务中的性能，尤其是在面对需要复杂推理的场景时，GSM8K能够作为一个有效的基准来评估和改进模型的表现。\nMATH\ngithub.com/hendrycks/m…\njavascript\n复制代码\n{ \"problem\" :  \"Let $\\\\mathbf{a}$ and $\\\\mathbf{b}$ be vectors such that\\n\\\\[\\\\mathbf{v} = \\\\operatorname{proj}_{\\\\mathbf{a}} \\\\mathbf{v} + \\\\operatorname{proj}_{\\\\mathbf{b}} \\\\mathbf{v}\\\\]for all vectors $\\\\mathbf{v}.$  Enter all possible values of $\\\\mathbf{a} \\\\cdot \\\\mathbf{b},$ separated by commas.\" , \"level\" :  \"Level 4\" , \"type\" :  \"Precalculus\" , \"solution\" :  \"Taking $\\\\mathbf{v} = \\\\mathbf{b},$ we get\\n\\\\[\\\\mathbf{b} = \\\\operatorname{proj}_{\\\\mathbf{a}} \\\\mathbf{b} + \\\\operatorname{proj}_{\\\\mathbf{b}} \\\\mathbf{b}.\\\\]From the projection formula,\\n\\\\[\\\\operatorname{proj}_{\\\\mathbf{a}} \\\\mathbf{b} = \\\\frac{\\\\mathbf{a} \\\\cdot \\\\mathbf{b}}{\\\\|\\\\mathbf{a}\\\\|^2} \\\\mathbf{a},\\\\]and $\\\\operatorname{proj}_{\\\\mathbf{b}} \\\\mathbf{b} = \\\\mathbf{b},$ so\\n\\\\[\\\\mathbf{b} = \\\\frac{\\\\mathbf{a} \\\\cdot \\\\mathbf{b}}{\\\\|\\\\mathbf{a}\\\\|^2} \\\\mathbf{a} + \\\\mathbf{b}.\\\\]Hence,\\n\\\\[\\\\frac{\\\\mathbf{a} \\\\cdot \\\\mathbf{b}}{\\\\|\\\\mathbf{a}\\\\|^2} \\\\mathbf{a} = \\\\mathbf{0}.\\\\]The vector $\\\\mathbf{a}$ must be nonzero, in order for the projection of $\\\\mathbf{v}$ onto $\\\\mathbf{a}$ to be defined, so we must have $\\\\mathbf{a} \\\\cdot \\\\mathbf{b} = \\\\boxed{0}.$\\n\\nNote that we can take $\\\\mathbf{a} = \\\\begin{pmatrix} 1 \\\\\\\\ 0 \\\\end{pmatrix}$ and $\\\\mathbf{b} = \\\\begin{pmatrix} 0 \\\\\\\\ 1 \\\\end{pmatrix}.$\" }\nMATH数据集由12,500道复杂数学竞赛题目组成，涵盖代数、几何、概率和数论等多个数学分支。该数据集的显著特点是每一道题目都提供了详尽的解题步骤，这使得它不仅能够测试机器学习模型找寻最终答案的能力，还能评估它们生成解题逻辑和推理过程的能力。由于题目难度与数学竞赛水平相匹配，因此这个数据集极具挑战性，适合用于提升和验证高级数学问题解决技术。此外，数据集中的解题步骤为自动化评估和模型训练提供了丰富的信息资源，有助于机器学习算法在数学领域的进一步发展。\nOrca-Math-200K\nhuggingface.co/datasets/mi…\njavascript\n复制代码\n{ \"question\" : \"A is 3 groups of 10 and 7 individual units, and B is the number obtained by subtracting 1 from 40. Which is smaller, A or B?\" , \"answer\" : \"Let's calculate the value of A and B. A is 3 groups of 10 and 7 individual units. So, A = (3 * 10) + 7 = 30 + 7 = 37. B is the number obtained by subtracting 1 from 40. So, B = 40 - 1 = 39. Now, we compare A and B. A = 37 B = 39 Since 37 is less than 39, A is smaller than B.\" }\nOrca-Math-200K数据集是一个大型的合成数学问题集，包含20万个数学文字题目。这个数据集主要应用于训练和评估语言模型在数学问题解决方面的能力。这个数据集提供一系列从易到难的多样化数学题目，以挑战并提升模型的推理和解题技巧。数据集的生成方式涉及初始种子问题的收集，利用代理之间协作的方式来重新表述和创造新的问题，从而丰富问题集的多样性和难度。这一过程不仅提高了数据集的质量，也为模型的训练提供了更多可能性和灵活性，有助于在保证数据新鲜度和多样性的同时，有效提升模型在数学领域的性能。\nNaturalProofs\ngithub.com/wellecks/na…\njavascript\n复制代码\n{ \"id\" :  30777 , \"type\" :  \"definition\" , \"label\" :  \"Definition:Folium of Descartes/Cartesian Form\" , \"title\" :  \"Definition:Folium of Descartes/Cartesian Form\" , \"categories\" : [ \"Definitions/Folium of Descartes\"                 ], \"contents\" : [ \"The '''folium of Descartes''' is the [[Definition:Locus|locus]] of the [[Definition:Equation of Geometric Figure|equation]]:\" , \":$x^3 + y^3 - 3 a x y = 0$\"                 ], \"refs\" : [ \"Definition:Locus\" , \"Definition:Equation of Geometric Figure\"                 ], \"ref_ids\" : [ 22165 , 25822                 ], \"proofs\" : []             },\nNaturalProofs从基础计算和应用问题转向了更加抽象和理论化的数学证明领域。NaturalProofs是一个大规模的形式化数学证明数据集，由32k个定理陈述和证明，14k个定义和2k个其他类型的页面（例如公理，推论）组成，这些页面来自三个领域：ProofWiki，一个由贡献者社区撰写的在线数学证明汇编；Stacks项目，一个基于网络的代数、几何教材；以及来自数学教材的数据。NaturalProofs的出现为研究人工智能在高级数学推理和证明生成方面的能力提供了宝贵的资源，它不仅挑战了大模型的逻辑推理能力，还考验了模型理解和生成人类可读的数学证明的能力。这个数据集的规模和质量使它成为了评估和改进大模型在高级数学领域表现的重要benchmark。\nLeanDojo\ngithub.com/lean-dojo/L…\nLeanDojo是一个专为学习型定理证明器设计的资源，它从Lean编程语言的数学库中提取了大量训练数据。这个数据集包含了98,734个定理及其证明，以及130,262个前提的定义，使得它成为定理证明领域内规模最大的数据集之一。定理证明是机器学习在形式化数学和验证领域的一个核心任务，而LeanDojo数据集的构建旨在提供一个丰富的资源，以训练和评估自动化定理证明系统。 LeanDojo数据集的构建过程采用了程序分析技术，确保了数据的质量和相关性，特别是在前提选择方面，这是定理证明中的一个关键瓶颈。通过提供精细标注的证明前提，该数据集能够支持前提选择的训练和评估。此外，LeanDojo数据集还引入了一个新颖的split策略，即novel_premises split，这种策略要求测试集中的证明必须使用至少一个未在训练集中使用过的前提，这有助于防止模型过度依赖记忆训练数据，从而使模型具有更健壮的泛化能力。 LeanDojo不仅是一个数据集，它还是一个完整的开放源代码平台，提供了一套工具、模型和基准，以促进学术社区在大型语言模型（LLMs）辅助的定理证明领域的研究。通过开放代码和模型，LeanDojo旨在降低机器学习在定理证明研究中的门槛，为未来的研究提供可复现的基准和强有力的基础。\nNuminaMath\nhuggingface.co/datasets/AI…\njavascript\n复制代码\n{ \"source\" : \"synthetic_math\" , \"problem\" : \" Consider the terms of an arithmetic sequence: $-\\frac{1}{3}, y+2, 4y, \\ldots$. Solve for $y$.\" , \"solution\" : \"For an arithmetic sequence, the difference between consecutive terms must be equal. Therefore, we can set up the following equations based on the sequence given: \\[ (y + 2) - \\left(-\\frac{1}{3}\\right) = 4y - (y+2) \\] Simplify and solve these equations: \\[ y + 2 + \\frac{1}{3} = 4y - y - 2 \\] \\[ y + \\frac{7}{3} = 3y - 2 \\] \\[ \\frac{7}{3} + 2 = 3y - y \\] \\[ \\frac{13}{3} = 2y \\] \\[ y = \\frac{13}{6} \\] Thus, the value of $y$ that satisfies the given arithmetic sequence is $\\boxed{\\frac{13}{6}}$.\" , \"messages\" :[ {  \"content\" :  \"Consider the terms of an arithmetic sequence: $-\\\\frac{1}{3}, y+2, 4y, \\\\ldots$. Solve for $y$.\" ,  \"role\" :  \"user\"  }, {  \"content\" :  \"For an arithmetic sequence, the difference between consecutive terms must be equal. Therefore, we can set up the following equations based on the sequence given:\\n\\\\[ (y + 2) - \\\\left(-\\\\frac{1}{3}\\\\right) = 4y - (y+2) \\\\]\\n\\nSimplify and solve these equations:\\n\\\\[ y + 2 + \\\\frac{1}{3} = 4y - y - 2 \\\\]\\n\\\\[ y + \\\\frac{7}{3} = 3y - 2 \\\\]\\n\\\\[ \\\\frac{7}{3} + 2 = 3y - y \\\\]\\n\\\\[ \\\\frac{13}{3} = 2y \\\\]\\n\\\\[ y = \\\\frac{13}{6} \\\\]\\n\\nThus, the value of $y$ that satisfies the given arithmetic sequence is $\\\\boxed{\\\\frac{13}{6}}$.\" ,  \"role\" :  \"assistant\"  } ] }\nNuminaMath数据集是一项开创性的工作，它汇聚了来自各种数学竞赛、论坛和教育资源的86万个问题和解决方案对，以推进人工智能在数学领域的能力。这个数据集的构建过程涉及广泛的来源，包括MATH、GSM8K、AMC、AIME等，以及应用了OCR、翻译、细化和CoT格式化等技术。NuminaMath数据集不仅规模庞大，而且通过其精心设计的CoT格式，支持链式思维推理，这对于训练大型语言模型（如GPT-4）以解决复杂数学问题至关重要。该数据集的成功应用体现在它对赢得AIMO Progress Prize的模型的精细调优上，证明了其在提升AI数学推理能力方面的有效性。NuminaMath数据集的创建和利用，标志着人工智能在数学教育和技术挑战中迈出了重要的一步。\nDART-Math\ngithub.com/hkust-nlp/d…\njavascript\n复制代码\n{ \"query\" : \"Let \\[f(x) = \\left\\{ \\begin{array}{cl} ax+3, &\\text{ if }x>2, \\\\ x-5 &\\text{ if } -2 \\le x \\le 2, \\\\ 2x-b &\\text{ if } x <-2. \\end{array} \\right.\\]Find $a+b$ if the piecewise function is continuous (which means that its graph can be drawn without lifting your pencil from the paper).\" , \"response\" : \"For the function to be continuous, the parts of th"
  },
  {
    "title": "用于评估大语言模型（LLMs）能力的重要基准任务（Benchmark）-CSDN博客",
    "page_body": "基准任务涵盖了 多领域（如语言理解、数学、推理、编程、医学等）和 多能力维度（如事实检索、计算、代码生成、链式推理、多语言处理）。常用于模型发布时的对比评测，例如 GPT-4、Claude、Gemini、Mistral 等模型的论文或报告中。\nBenchmark\n简介\n用途\n地址\n许可证\nMMLU Massive Multitask Language Understanding 测试模型在多学科考试（如历史、法律、医学等）中的表现 https://arxiv.org/abs/2009.03300, https://github.com/hendrycks/test MIT License\nMATH Mathematical Problem Solving 测试模型解决中学和大学级数学问题的能力 https://arxiv.org/abs/2103.03874, https://github.com/hendrycks/math MIT License\nGPQA Graduate-level, Google-proof Q&A 高阶、无法通过搜索引擎解答的物理问答题 https://arxiv.org/abs/2311.12022, https://github.com/idavidrein/gpqa/ MIT License\nDROP Discrete Reasoning Over Paragraphs 阅读理解测试，侧重数值运算、推理和信息整合 https://arxiv.org/abs/1903.00161, https://allenai.org/data/drop Apache 2.0\nMGSM Multilingual Grade School Math 多语言小学数学题，考察链式思维能力 https://arxiv.org/abs/2210.03057, https://github.com/google-research/url-nlp CC-BY 4.0\nHumanEval Code Generation and Evaluation 模型在 Python 编程题上的代码生成与准确性测试 https://arxiv.org/abs/2107.03374, https://github.com/openai/human-eval MIT License\nSimpleQA Short-form Factuality Benchmark 测试模型对简单事实问答（如“地球离太阳多远？”）的准确性 https://openai.com/index/introducing-simpleqa MIT License\nBrowseComp Web-based Browsing Agent Task 测试具有浏览网页能力的智能体在任务场景中的能力 https://openai.com/index/browsecomp MIT License\nHealthBench Health-related LLM Evaluation 面向医疗健康场景的模型能力评估，强调事实准确性和安全性 https://openai.com/index/healthbench MIT License"
  },
  {
    "title": "深度学习在信息检索中的应用.pptx-原创力文档",
    "page_body": "内容提供方 ： 智慧IT 大小 ： 248.57 KB 字数 ： 约4.56千字 ： 浏览人气 ： 0 下载次数 ： 收藏次数 ： 0 需要金币 ： *** 金币  (10金币=人民币1元)\n数智创新变革未来深度学习在信息检索中的应用\n信息检索基础概念\n深度学习基本原理\n深度学习在信息检索中的应用概述\n文本表示学习\n匹配模型学习\n排序模型学习\n深度学习应用的优势与挑战\n未来趋势与展望ContentsPage目录页\n信息检索基础概念深度学习在信息检索中的应用\n信息检索基础概念信息检索定义1.信息检索是一种从大量文档中找到满足用户信息需求的活动。2.信息检索系统通常由文档集合、用户查询和检索模型组成。信息检索模型1.布尔模型：基于集合论和布尔逻辑，通过逻辑运算符（AND、OR、NOT）表示查询和文档之间的匹配关系。2.向量空间模型：将文档和查询表示为向量，通过计算向量之间的相似度来衡量文档和查询的匹配程度。\n信息检索基础概念信息检索评估1.准确率：评估检索系统返回的结果与用户需求之间的匹配程度。2.召回率：评估检索系统返回的结果覆盖了多少用户需求的信息。信息检索技术1.倒排索引：一种高效索引方法，通过单词与文档之间的映射关系快速定位包含查询词的文档。2.链接分析：通过分析网页之间的链接关系评估网页的重要性，用于网页排名和搜索引擎优化。\n信息检索基础概念信息检索发展趋势1.语义检索：通过理解用户查询和文档内容的语义信息进行匹配，提高检索准确性。2.个性化检索：根据用户历史行为和偏好调整检索结果，提高用户满意度。深度学习在信息检索中的应用1.深度学习可以自动提取文档和查询的语义表示，提高信息检索的性能。2.基于神经网络的匹配模型可以更好地捕捉查询和文档之间的复杂关系，进一步提高检索准确性。以上内容仅供参考，如有需要，建议查阅相关网站。\n深度学习基本原理深度学习在信息检索中的应用\n深度学习基本原理深度学习的定义与基本原理1.深度学习是机器学习的一个子集，其基于人工神经网络进行模型和算法的设计。2.深度学习的基本原理主要包括神经网络的层次结构和前向传播、反向传播算法。3.通过层次结构，深度学习能够提取数据的高层次特征，从而实现更为精准的预测和分类。神经网络的基本单元1.神经网络的基本单元是神经元，其模型和生物神经元的结构类似。2.神经元通过接收输入信号，进行加权求和并经过激活函数后产生输出信号。3.不同的激活函数对神经元的输出具有不同的影响，常用的激活函数包括ReLU、Sigmoid和Tanh等。\n深度学习基本原理1.深度学习的神经网络模型通常包含多个层次，每个层次包含多个神经元。2.层次之间的神经元通过权重连接，形成前向传播的路径。3.通过层次结构，深度学习能够逐级提取数据的特征，从而提高模型的表达能力。前向传播算法1.前向传播算法是深度学习模型预测的主要过程，通过该算法可以计算得到模型的输出结果。2.前向传播算法按照神经网络的层次结构，逐层计算神经元的输出，并最终得到模型的预测结果。3.前向传播算法的计算效率受到模型复杂度和数据维度的影响。神经网络的层次结构\n深度学习基本原理反向传播算法1.反向传播算法是深度学习模型训练的主要过程，通过该算法可以更新模型的参数。2.反向传播算法根据模型的预测结果和真实结果的误差，逐层计算神经元的误差梯度，并根据梯度下降算法更新模型的参数。3.反向传播算法的有效性取决于误差梯度的准确性和模型参数的初始化方式。深度学习的应用和发展趋势1.深度学习在图像识别、语音识别、自然语言处理等领域得到了广泛应用。2.随着模型结构、优化算法和计算能力的提升，深度学习的性能和应用范围不断扩大。3.未来深度学习将与多学科交叉融合，进一步拓展其应用领域和发展前景。\n深度学习在信息检索中的应用概述深度学习在信息检索中的应用\n深度学习在信息检索中的应用概述1.深度学习可以提高信息检索的准确性和效率。2.深度学习可以解决信息检索中的语义匹配问题。3.深度学习可以优化信息检索系统的排序算法。深度学习模型在信息检索中的应用1.深度神经网络模型可以应用于信息检索中的文本匹配任务。2.基于深度学习的排序模型可以优化信息检索结果的排序精度。3.深度学习模型可以结合传统信息检索模型，提高检索性能。深度学习在信息检索中的应用概述\n深度学习在信息检索中的应用概述深度学习在信息检索中的文本表示1.深度学习可以将文本转化为向量空间中的表示，提高文本匹配的精度。2.基于深度学习的文本表示方法可以捕捉文本的语义信息。3.深度学习可以结合传统的文本表示方法，进一步提高文本匹配的准确性。深度学习在信息检索中的语义匹配1.深度学习可以解决信息检索中的语义鸿沟问题，提高检索准确性。2.基于深度学习的语义匹配方法可以利用上下文信息，提高匹配精度。3.深度学习可以结合传统的语义匹配方法，进一步提高语义匹配的准确性。\n深度学习在信息检索中的应用概述深度学习在信息检索中的发展趋势1.随着深度学习技术的不断发展，信息检索的性能将不断提高。2.深度学习将应用于更多的信息检索任务，如跨语言检索、图像检索等。3.结合深度学习和其他技术的信息检索系统将成为未来的发展趋势。以上内容仅供参考，具体内容和关键点可以根据实际需要进行调整和修改。\n文本表示学习深度学习在信息检索中的应用\n文本表示学习文本表示学习概述1.文本表示学习是将文本转换为计算机可理解的向量形式的过程，为后续的信息检索任务提供基础数据表示。2.通过深度学习技术，可以将文本中的语义信息有效地编码到向量空间中，提高检索准确性。3.文本表示学习方法主要包括基于词袋模型的表示、基于词嵌入的表示和基于深度学习的表示等。基于词袋模型的表示1.词袋模型将文本看作一个词的集合，忽略了词语之间的顺序和语义关系。2.通过TF-IDF等权重计算方法，可以反映词语在文本中的重要性，为后续检索任务提供基础表示。\n文本表示学习基于词嵌入的表示1.词嵌入是将词语映射到一个低维向量空间中的技术，通过保留词语之间的语义和语法关系，提高文本表示的质量。2.常用的词嵌入技术包括Word2Vec、GloVe等，它们通过训练语言模型来学习词向量表示。基于深度学习的表示1.深度学习技术可以更加有效地对文本进行表示，通过神经网络模型自动提取文本中的高级语义特征。2.卷积神经网络（CNN）和循环神经网络（RNN）是常用的深度学习模型，它们在文本分类、情感分析等任务中取得了显著的效果。\n文本表示学习1.文本表示学习在信息检索中广泛应用于文档排序、查询扩展和推荐系统等任务。2.通过改进文本表示方法，可以进一步提高信息检索任务的准确性和效率，为用户提供更好的搜索体验。3.未来研究可以关注如何将更多的语义信息融入到文本表示中，以及如何更好地利用预训练语言模型等前沿技术来提高文本表示的质量。文本表示学习的应用\n匹配模型学习深度学习在信息检索中的应用\n匹配模型学习匹配模型学习1.匹配模型的作用：在信息检索中，匹配模型用于衡量文档与查询之间的相关性。2.深度学习的应用：神经网络可以用于构建更复杂的匹配模型，提高检索准确性。3.常见的匹配模型：例如基于表示学习的模型（如DSSM、CDSSM等）和基于交互学习的模型（如DRMM、KNRM等）。深度学习可以通过神经网络对文本进行高级表示，使得匹配模型能够更好地捕捉查询和文档之间的语义信息。与传统的基于手工特征的方法相比，深度学习可以自动学习文本表示，从而提高模型的泛化能力。在信息检索领域，匹配模型的学习是深度学习的重要应用之一，可以提高检索系统的准确性和用户满意度。以上内容仅供参考，具体内容可以根据您的需求进行调整优化。\n排序模型学习深度学习在信息检索中的应用\n排序模型学习排序模型学习1.学习排序的目标是根据相关性和重要性对文档进行排序。2.排序模型需要利用大量的标注数据进行训练，以提高排序准确性。3.深度学习模型可以自动提取文档和查询中的高级特征，提高排序性能。排序模型学习在信息检索中扮演着重要的角色，通过对文档和查询的深度理解，可以更准确地将最相关的文档排在前面。传统的排序模型主要依赖于手工设计的特征，而深度学习模型则可以自动提取高级特征，大大提高了排序性能。在训练排序模型时，需要利用大量的标注数据来学习文档和查询之间的相关性，同时还需要考虑到查询和文档之间的语义匹配问题。近年来，一些前沿的排序模型采用了强化学习等技术，进一步优化了排序性能。以上内容仅供参考，具体内容可以根据您的需求进行调整优化。\n深度学习应用的优势与挑战深度学习在信息检索中的应用\n深度学习应用的优势与挑战深度学习应用的优势1.特征自动学习：深度学习模型具有自动学习数据特征的能力，可以避免手工设计和选择特征的繁琐过程，提高模型的性能。2.表示能力强大：深度学习模型能够学习到更复杂的数据表示，可以更好地处理自然语言、图像、视频等多媒体数据，提高信息检索的准确性。3.能够处理大规模数据：深度学习模型能够处理大规模的数据集，可以有效地利用更多的数据来提高模型的性能。深度学习应用的挑战1.数据标注成本高：深度学习模型需要大量的标注数据来训练，数据标注的成本较高，需要投入大量的人力和物力资源。2.模型可解释性差：深度学习模型的决策过程往往缺乏可解释性，使得人们难以理解模型的工作原理和决策依据。3.计算资源消耗大：深度学习模型的训练和推理需要大量的计算资源，需要高性能的计算机和GPU等设备支持，增加了应用的成本。以上内容仅供参考，具体内容可以根据实际需要进行调整和优化。\n未来趋势与展望深度学习在信息检索中的应用\n未来趋势与展望模型复杂度与性能优化1.随着模型复杂度的增加，性能也会有所提升，但需要平衡计算资源和模型效果。2.采用更高效、更轻量的模型结构，以及模型剪枝、量化等技术将成为未来趋势。3.结合知识蒸馏等技术，进一步优化模型性能，提高检索准确率和效率。多模态信息检索1.随着多媒体数据的不断增加，多模态信息检索将成为未来重要趋势。2.结合图像、语音、文本等多模态数据，提高信息检索的准确性和多样性。3.利用跨模态检索技术，实现更加自然和智能的信息交互方式。\n未来趋势与展望强化学习与信息检索1.强化学习在信息检索中可以更好地解决用户反馈和个性化需求。2.通过强化学习算法优化检索策略，提高用户满意度和搜索结果的质量。3.结合深度学习，实现更高效的强化学习模型和更精确的信息检索结"
  },
  {
    "title": "LLMs 入门实战系列大全：LLMs应用、领域大模型介绍、大模型常见面经汇总-CSDN博客",
    "page_body": "1. 常见大模型介绍\n1.1 ChatGLM-6B 系列\nChatGLM2-6B\n[【ChatGLM2-6B入门】清华大学开源中文版ChatGLM-6B模型学习与实战]\n论文名称：ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语对话语言模型 论文地址： Github 代码：https://github.com/THUDM/ChatGLM2-6B 动机：在主要评估LLM模型中文能力的 C-Eval 榜单中，截至6月25日 ChatGLM2 模型以 71.1 的分数位居 Rank 0 ，ChatGLM2-6B 模型以 51.7 的分数位居 Rank 6，是榜单上排名最高的开源模型。 介绍：ChatGLM2-6B 是开源中英双语对话模型 ChatGLM-6B 的第二代版本，在保留了初代模型对话流畅、部署门槛较低等众多优秀特性的基础之上，ChatGLM2-6B 引入了如下新特性： \n更强大的性能 ：基于 ChatGLM 初代模型的开发经验，我们全面升级了 ChatGLM2-6B 的基座模型。ChatGLM2-6B 使用了 GLM 的混合目标函数，经过了 1.4T 中英标识符的预训练与人类偏好对齐训练，评测结果显示，相比于初代模型，ChatGLM2-6B 在 MMLU（+23%）、CEval（+33%）、GSM8K（+571%） 、BBH（+60%）等数据集上的性能取得了大幅度的提升，在同尺寸开源模型中具有较强的竞争力。 更长的上下文 ：基于 FlashAttention 技术，我们将基座模型的上下文长度（Context Length）由 ChatGLM-6B 的 2K 扩展到了 32K，并在对话阶段使用 8K 的上下文长度训练，允许更多轮次的对话。但当前版本的 ChatGLM2-6B 对单轮超长文档的理解能力有限，我们会在后续迭代升级中着重进行优化。 更高效的推理 ：基于 Multi-Query Attention 技术，ChatGLM2-6B 有更高效的推理速度和更低的显存占用：在官方的模型实现下，推理速度相比初代提升了 42%，INT4 量化下，6G 显存支持的对话长度由 1K 提升到了 8K。 更开放的协议 ：ChatGLM2-6B 权重对学术研究完全开放，在获得官方的书面许可后，亦允许商业使用。如果您发现我们的开源模型对您的业务有用，我们欢迎您对下一代模型 ChatGLM3 研发的捐赠。\n[【关于 ChatGLM2 + LoRA 进行finetune 】\n论文名称：ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语对话语言模型 论文地址： Github 代码：https://github.com/THUDM/ChatGLM2-6B 介绍：本教程主要介绍对于 ChatGLM2-6B 模型基于 LoRA 进行finetune。\n[【LLMs 入门实战 】基于     PEFT 的高效     ChatGLM2-6B 微调]\n微调方式： \nChatGLM2-6B Freeze 微调：Fine-tuning the MLPs in the last n blocks of the model. ChatGLM2-6B P-Tuning V2 微调：Fine-tuning the prefix encoder of the model. ChatGLM2-6B LoRA 微调：Fine-tuning the low-rank adapters of the model.\n[【LLMs 入门实战】基于     QLoRA 的高效     ChatGLM2-6B 微调]\n介绍：本项目使用 https://github.com/huggingface/peft 库，实现了 ChatGLM2-6B 模型4bit的 QLoRA 高效微调，可以在一张RTX3060上完成全部微调过程。\nChatGLM3\n[【LLMs 入门实战】 ChatGLM3 模型学习与实战]\n论文名称：ChatGLM3 Github 代码：https://github.com/THUDM/ChatGLM3 模型地址： \nhuggingface：https://huggingface.co/THUDM/chatglm3-6b modelscope：https://modelscope.cn/models/ZhipuAI/chatglm3-6b/summary\n动机：2023年10月26日，由中国计算机学会主办的2023中国计算机大会（CNCC）正式开幕，据了解，智谱AI于27日论坛上推出了全自研的第三代基座大模型ChatGLM3及相关系列产品，这也是智谱AI继推出千亿基座的对话模型ChatGLM和ChatGLM2之后的又一次重大突破。 介绍：ChatGLM3 是智谱AI和清华大学 KEG 实验室联合发布的新一代对话预训练模型。ChatGLM3-6B 是 ChatGLM3 系列中的开源模型，在保留了前两代模型对话流畅、部署门槛低等众多优秀特性的基础上，ChatGLM3-6B 引入了如下特性： \n更强大的基础模型：  ChatGLM3-6B 的基础模型 ChatGLM3-6B-Base 采用了更多样的训练数据、更充分的训练步数和更合理的训练策略。在语义、数学、推理、代码、知识等不同角度的数据集上测评显示， ChatGLM3-6B-Base 具有在 10B 以下的基础模型中最强的性能 。 更完整的功能支持：  ChatGLM3-6B 采用了全新设计的  Prompt 格式 ，除正常的多轮对话外。同时原生支持 工具调用 （Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。 更全面的开源序列：  除了对话模型  ChatGLM3-6B  外，还开源了基础模型  ChatGLM3-6B-Base 、长文本对话模型  ChatGLM3-6B-32K 。以上所有权重对学术研究 完全开放 ，在填写 问卷 进行登记后 亦允许免费商业使用 。\n[【LLMs 入门实战】 ChatGLM3 模型微调学习与实战]\n论文名称：ChatGLM3 Github 代码：https://github.com/THUDM/ChatGLM3 模型地址： \nhuggingface：https://huggingface.co/THUDM/chatglm3-6b modelscope：https://modelscope.cn/models/ZhipuAI/chatglm3-6b/summary\n动机：2023年10月26日，由中国计算机学会主办的2023中国计算机大会（CNCC）正式开幕，据了解，智谱AI于27日论坛上推出了全自研的第三代基座大模型ChatGLM3及相关系列产品，这也是智谱AI继推出千亿基座的对话模型ChatGLM和ChatGLM2之后的又一次重大突破。 介绍：分别对 ChatGLM3 进行 lora 和 full_training 微调\n1.2 qwen2.5\n网址：github.com/QwenLM/Qwen2.5\nQwen是阿里巴巴集团Qwen团队研发的大语言模型和大型多模态模型系列。目前，大语言模型已升级至Qwen2.5版本。无论是语言模型还是多模态模型，均在大规模多语言和多模态数据上进行预训练，并通过高质量数据进行后期微调以贴近人类偏好。Qwen具备自然语言理解、文本生成、视觉理解、音频理解、工具使用、角色扮演、作为AI Agent进行互动等多种能力。\n最新版本Qwen2.5有以下特点：\n易于使用的仅解码器稠密语言模型，提供 0.5B 、1.5B 、3B 、7B 、14B 、32B 和 72B 共7种参数规模的模型，并且有基模型和指令微调模型两种变体（其中“ B ”表示“十亿”， 72B 即为 720 亿）\n利用我们最新的数据集进行预训练，包含多达 18T tokens （其中“ T ”表示“万亿”， 18T 即为 18 万亿）\n在遵循指令、生成长文本（超过 8K tokens ）、理解结构化数据（例如，表格）以及生成结构化输出特别是 JSON 方面有了显著改进\n更加适应多样化的系统提示，增强了角色扮演的实现和聊天机器人的背景设置。\n支持最多达 128K tokens 的上下文长度，并能生成多达 8K tokens 的文本。\n支持超过 29 种语言，包括中文、英文、法文、西班牙文、葡萄牙文、德文、意大利文、俄文、日文、韩文、越南文、泰文、阿拉伯文等。\n1.3 Baichuan\nBaichuan2\n[【LLMs 入门实战】 Baichuan2 学习与实战] \n论文名称：Baichuan 2: Open Large-scale Language Models Github 代码：https://github.com/baichuan-inc/Baichuan2 模型：https://huggingface.co/baichuan-inc Baichuan-13B 大模型： \n官方微调过（指令对齐）:https://huggingface.co/baichuan-inc/Baichuan-13B-Chat 预训练大模型（未经过微调）:https://huggingface.co/baichuan-inc/Baichuan-13B-Base\n介绍： \nBaichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练。 Baichuan 2 在多个权威的中文、英文和多语言的通用、领域 benchmark 上取得同尺寸最佳的效果。 本次发布包含有 7B、13B 的 Base 和 Chat 版本，并提供了 Chat 版本的 4bits 量化。 所有版本对学术研究完全开放。同时，开发者通过邮件申请并获得官方商用许可后，即可免费商用，请参考协议章节。\nBaichuan-13B\n[【LLMs 入门实战 】 Baichuan-13B 模型学习与实战] \nbaichuan-inc/Baichuan-13B：https://github.com/baichuan-inc/Baichuan-13B Baichuan-13B 大模型： \n官方微调过（指令对齐）:https://huggingface.co/baichuan-inc/Baichuan-13B-Chat 预训练大模型（未经过微调）:https://huggingface.co/baichuan-inc/Baichuan-13B-Base\n介绍：Baichuan-13B 是由百川智能继 Baichuan-7B 之后开发的包含 130 亿参数的开源可商用的大规模语言模型，在权威的中文和英文 benchmark 上均取得同尺寸最好的效果。Baichuan-13B 有如下几个特点： \n更大尺寸、更多数据：Baichuan-13B 在 Baichuan-7B 的基础上进一步扩大参数量到 130 亿，并且在高质量的语料上训练了 1.4 万亿 tokens，超过 LLaMA-13B 40%，是当前开源 13B 尺寸下训练数据量最多的模型。支持中英双语，使用 ALiBi 位置编码，上下文窗口长度为 4096。 同时开源预训练和对齐模型：预训练模型是适用开发者的“基座”，而广大普通用户对有对话功能的对齐模型具有更强的需求。因此本次开源同时发布了对齐模型（Baichuan-13B-Chat），具有很强的对话能力，开箱即用，几行代码即可简单的部署。 更高效的推理：为了支持更广大用户的使用，本次同时开源了 int8 和 int4 的量化版本，相对非量化版本在几乎没有效果损失的情况下大大降低了部署的机器资源门槛，可以部署在如 Nvidia 3090 这样的消费级显卡上。 开源免费可商用：Baichuan-13B 不仅对学术研究完全开放，开发者也仅需邮件申请并获得官方商用许可后，即可以免费商用。\nbaichuan-7B\n【LLMs 入门实战 】 baichuan-7B 学习与实战\n论文名称： 论文地址： Github 代码： https://github.com/baichuan-inc/baichuan-7B 模型： 介绍：由百川智能开发的一个开源可商用的大规模预训练语言模型。基于Transformer结构，在大约1.2万亿tokens上训练的70亿参数模型，支持中英双语，上下文窗口长度为4096。在标准的中文和英文权威benchmark（C-EVAL/MMLU）上均取得同尺寸最好的效果。\n1.4 Llama 3.2\n[【LLMs 入门实战】 QLoRA微调Llama2 模型学习与实战]\n官网：https://ai.meta.com/llama/ 论文名称：《Llama 2: Open Foundation and Fine-Tuned Chat Models》 论文地址：https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/ 演示平台：https://llama2.ai/ Github 代码：https://github.com/facebookresearch/llama 模型下载地址：https://ai.meta.com/resources/models-and-libraries/llama-downloads/ 介绍：QLoRA微调Llama2 模型学习与实战\n[【LLMs 入门实战】 Llama2 模型学习与实战]\n官网：https://ai.meta.com/llama/ 论文名称：《Llama 2: Open Foundation and Fine-Tuned Chat Models》 论文地址：https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/ 演示平台：https://llama2.ai/ Github 代码：https://github.com/facebookresearch/llama 模型下载地址：https://ai.meta.com/resources/models-and-libraries/llama-downloads/ 介绍：此次 Meta 发布的 Llama 2 模型系列包含 70 亿、130 亿和 700 亿三种参数变体。此外还训练了 340 亿参数变体，但并没有发布，只在技术报告中提到了。据介绍，相比于 Llama 1，Llama 2 的训练数据多了 40%，上下文长度也翻倍，并采用了分组查询注意力机制。具体来说，Llama 2 预训练模型是在 2 万亿的 token 上训练的，精调 Chat 模型"
  },
  {
    "title": "如何改进复杂推理 - 从提示词设计入手-CSDN博客",
    "page_body": "引言（动机）\n在使用大 语言模型 （如 GPT-4、Claude、DeepSeek 等）构建智能问答、辅助决策或复杂任务代理系统时，可能遇到这些问题：\n模型回答跳步骤、思路混乱 同样问题，模型表现高度不稳定 新任务一加入，就需要重写提示词逻辑\n这些问题的根源之一，往往不是“模型能力不行”，而是：\n 没有一个结构化的「提示词调度系统」来支撑复杂推理能力的精确调用。\n以下描述了如何构建一个具备「 多任务 识别」「提示词动态分派」「语义召回与打分融合」能力的完整提示词调度模块，并落地在真实的推理问答系统中。\n1️⃣ 为什么「复杂推理」难以靠单一提示词解决？\n举例 1：简单分类 vs 多跳推理\nQ:  What  is  the capital  of  the country  where  Mount Fuji  is  located?\nA（坏例子）: Japan  \nA（好例子）: Mount Fuji  is in  Japan → Capital  of  Japan  is  Tokyo → Answer: Tokyo\n这里需要两步检索+组合逻辑，显然需要多跳推理提示词或工具。\n举例 2：分类器判断错误导致提示词错配\n# 分类器判断为  \"fact\"\ntemplate  =  \"Answer the following factual question truthfully.\"\n结果模型直接输出“Japan”，忽略了“首都”这个后续问题。\n结论：\n静态提示词 + 简单任务分类，远远不足以支持复杂推理系统。\n2️⃣ 工程角度：提示词调度系统应该包含什么？\n功能模块（结构化拆解）\n模块\n功能\n实现文件\nTaskClassifier 判断任务类型（如 math、fact、multi-hop） task_classifier/classifier.py\nPromptTemplateStore 维护各类任务的标准提示词模板 prompt_manager/prompt_templates.json\nPromptRetriever 用向量召回更相似的提示词（非规则匹配） prompt_retriever/retriever.py\nPromptSelector 融合分类器推荐与召回推荐，选择最终提示 prompt_manager/prompt_router.py\nLLMCaller 构建 messages 并调用 GPT / Claude 接口 llm/openai_client.py\n3️⃣ 提示词融合调度核心机制：谁说了算？\n真实冲突案例\n用户输入：A train leaves at 3PM and takes 2 hours. What time does it arrive?\n分类器识别：fact（返回 factual 模板） 语义召回匹配：step-by-step（CoT）\n实验打分\n[分类器模板] factual：cos_sim  = 0.62  → weighted  = 0.62 * 0.4 = 0.248\n[召回模板]   CoT：     cos_sim  = 0.82  → weighted  = 0.82 * 0.6 = 0.492\n最终使用 step-by-step 提示词（召回结果）\n融合逻辑实现（摘要）\ndef  get _ final _prompt(user_ input , template_A, template_B):\n    score_A  =  cosine_sim( input _vec, vec_A)  * 0.4\n    score_B  =  cosine_sim( input _vec, vec_B)  * 0.6\nreturn  template_A  if  score_A  >  score_B  else  template_B\n本质上是一种 prompt reranking 的打分排序策略。\n4️⃣ 更复杂的工程落地：提示词检索系统\n动态任务：提示词不可硬编码怎么办？\n场景如：客服问答、教育题库、科研问答……提示词可能成百上千，静态  prompt_templates.json  无法维护。\n架构建议：\n将所有提示词向量化 → FAISS/Pinecone 索引 用户输入向量化 → top-k 相似 prompt 检索 加入分类器过滤 → 提高准确率 + 可控性\nretrieved  =  retrieve_similar_prompt( input _text)\ntask_ type =  classify_task_ type ( input _text)\ncandidates  =  [templates[task_ type ], retrieved]\n类似于“Prompt Retrieval-Augmented Generation”\n5️⃣ 实际部署建议（真实项目里怎么集成）\n场景\n建议调度方式\n任务清晰、模板少 分类器 + 静态模板足够\n场景扩展快、模板复杂 分类器 + 检索融合\n多语言、多角色系统 纯语义召回 + 多模态 prompt\n高要求系统（医疗/法律） prompt + rationale 双链控制\n6️⃣ 总结与建议\n复杂推理 ≠ 简单的问题分类\n需要：\n明确每一类任务的推理结构 构建提示词模板系统 + 语义检索机制 设计融合打分逻辑以处理不一致 最小化调试成本、最大化推理效果的关键：提示词调度自动化。"
  }
]