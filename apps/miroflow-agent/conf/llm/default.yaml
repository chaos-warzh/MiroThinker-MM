# conf/llm/default.yaml - Default LLM configuration
provider: "openai" # openai, anthropic, qwen
model_name: "gpt-4.1"
async_client: false
temperature: 0.3
top_p: 1.0
min_p: 0.0
top_k: -1
max_tokens: 4096
max_context_length: 200000
api_key: ""
base_url: 
keep_tool_result: -1
